- op: abs
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: abs_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: accuracy
  inputs: (Tensor x, Tensor indices, Tensor label)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(accuracy), Tensor(correct), Tensor(total)

- op: acos
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: acos_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: acosh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: acosh_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: adadelta_
  inputs: (Tensor param, Tensor grad, Tensor avg_squared_grad, Tensor avg_squared_update,
    Tensor learning_rate, Tensor master_param)
  attrs: (float rho, float epsilon, bool multi_precision, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment_out), Tensor(inf_norm_out), Tensor(master_param_out)
  optionals: master_param,master_param_out

- op: adagrad_
  inputs: (Tensor param, Tensor grad, Tensor moment, Tensor learning_rate, Tensor
    master_param)
  attrs: (float epsilon, bool multi_precision, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment_out), Tensor(master_param_out)
  optionals: master_param,master_param_out

- op: adam_
  inputs: (Tensor param, Tensor grad, Tensor learning_rate, Tensor moment1, Tensor
    moment2, Tensor beta1_pow, Tensor beta2_pow, Tensor master_param, Tensor skip_update,
    Tensor Beta1Tensor, Tensor Beta2Tensor, Tensor EpsilonTensor)
  attrs: (float beta1, float beta2, float epsilon, bool lazy_mode, int64_t min_row_size_to_use_multithread,
    bool multi_precision, bool use_global_beta_pow, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment1_out), Tensor(moment2_out), Tensor(beta1_pow_out),
    Tensor(beta2_pow_out), Tensor(master_param_out)
  optionals: master_param,skip_update,Beta1Tensor,Beta2Tensor,EpsilonTensor,master_param_out

- op: adamax_
  inputs: (Tensor param, Tensor grad, Tensor learning_rate, Tensor moment, Tensor
    inf_norm, Tensor beta1_pow, Tensor master_param)
  attrs: (float beta1, float beta2, float epsilon, bool multi_precision, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment_out), Tensor(inf_norm_out), Tensor(master_param_out)
  optionals: master_param,master_param_out

- op: adamw_
  inputs: (Tensor param, Tensor grad, Tensor learning_rate, Tensor moment1, Tensor
    moment2, Tensor beta1_pow, Tensor beta2_pow, Tensor master_param, Tensor skip_update,
    Tensor Beta1Tensor, Tensor Beta2Tensor, Tensor EpsilonTensor)
  attrs: (float beta1, float beta2, float epsilon, float lr_ratio, float coeff, bool
    with_decay, bool lazy_mode, int64_t min_row_size_to_use_multithread, bool multi_precision,
    bool use_global_beta_pow, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment1_out), Tensor(moment2_out), Tensor(beta1_pow_out),
    Tensor(beta2_pow_out), Tensor(master_param_out)
  optionals: master_param,skip_update,Beta1Tensor,Beta2Tensor,EpsilonTensor,master_param_out

- op: add_position_encoding
  inputs: (Tensor X)
  attrs: (float alpha, float beta, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: addmm
  inputs: (Tensor input, Tensor x, Tensor y)
  attrs: (float beta, float alpha, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: addmm_
  inputs: (Tensor input, Tensor x, Tensor y)
  attrs: (float beta, float alpha, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: input->out

- op: affine_channel
  inputs: (Tensor X, Tensor Scale, Tensor Bias)
  attrs: (str data_layout, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: affine_channel_
  inputs: (Tensor X, Tensor Scale, Tensor Bias)
  attrs: (str data_layout, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  inpalces: X->Out

- op: affine_grid
  inputs: (Tensor input, Tensor OutputShape)
  attrs: (int[] output_shape, bool align_corners, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: OutputShape

- op: all_gather
  inputs: (Tensor x)
  attrs: (int ring_id, int nranks, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: all_reduce
  inputs: (Tensor x)
  attrs: (int ring_id, int reduce_type, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: all_to_all
  inputs: (Tensor x)
  attrs: (int ring_id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: allclose
  inputs: (Tensor x, Tensor y, Tensor Rtol, Tensor Atol)
  attrs: (str rtol, str atol, bool equal_nan, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Rtol,Atol

- op: alloc_float_status
  inputs: ()
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(FloatStatus)

- op: alltoall
  inputs: (Tensor X)
  attrs: (int ring_id, bool use_calc_stream, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: anchor_generator
  inputs: (Tensor Input)
  attrs: (float[] anchor_sizes, float[] aspect_ratios, float[] variances, float[]
    stride, float offset, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Anchors), Tensor(Variances)

- op: angle
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: argmax
  inputs: (Tensor x)
  attrs: (int64_t axis, bool keepdims, bool flatten, int dtype, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: argmin
  inputs: (Tensor x)
  attrs: (int64_t axis, bool keepdims, bool flatten, int dtype, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: argsort
  inputs: (Tensor x)
  attrs: (int axis, bool descending, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(indices)

- op: as_complex
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: as_real
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: as_strided
  inputs: (Tensor input)
  attrs: (int64_t[] dims, int64_t[] stride, int64_t offset, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: asin
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: asin_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: asinh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: asinh_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: assert
  inputs: (Tensor cond, Tensor[] data)
  attrs: (int64_t summarize, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: assign
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: x

- op: assign_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: x
  inpalces: x->out

- op: assign_pos
  inputs: (Tensor X, Tensor cum_count, Tensor eff_num_len)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: assign_value
  inputs: (Tensor ValuesTensor)
  attrs: (int[] shape, int dtype, Scalar[] values, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ValuesTensor

- op: atan
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: atan2
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: atan_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: atanh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: atanh_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: attention_lstm
  inputs: (Tensor X, Tensor C0, Tensor H0, Tensor AttentionWeight, Tensor AttentionBias,
    Tensor AttentionScalar, Tensor AttentionScalarBias, Tensor LSTMWeight, Tensor
    LSTMBias)
  attrs: (str gate_activation, str cell_activation, str candidate_activation, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Hidden), Tensor(Cell), Tensor(AttentionedX), Tensor(AttentionFCOut),
    Tensor(LSTMX), Tensor(LSTMOUT)
  optionals: H0,AttentionBias,AttentionScalar,AttentionScalarBias

- op: auc
  inputs: (Tensor x, Tensor label, Tensor stat_pos, Tensor stat_neg, Tensor ins_tag_weight)
  attrs: (str curve, int num_thresholds, int slide_steps, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(auc), Tensor(stat_pos_out), Tensor(stat_neg_out)
  optionals: ins_tag_weight

- op: average_accumulates
  inputs: (Tensor param, Tensor in_sum_1, Tensor in_sum_2, Tensor in_sum_3, Tensor
    in_num_accumulates, Tensor in_old_num_accumulates, Tensor in_num_updates)
  attrs: (float average_window, int64_t max_average_window, int64_t min_average_window,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out_sum_1), Tensor(out_sum_2), Tensor(out_sum_3), Tensor(out_num_accumulates),
    Tensor(out_old_num_accumulates), Tensor(out_num_updates)

- op: barrier
  inputs: (Tensor X)
  attrs: (int ring_id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: batch_fc
  inputs: (Tensor Input, Tensor W, Tensor Bias)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: batch_norm
  inputs: (Tensor x, Tensor scale, Tensor bias, Tensor mean, Tensor variance, Tensor
    MomentumTensor)
  attrs: (bool is_test, float momentum, float epsilon, str data_format, bool use_global_stats,
    bool trainable_statistics, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean_out), Tensor(variance_out), Tensor(saved_mean),
    Tensor(saved_variance), Tensor(reserve_space)
  optionals: scale,bias,MomentumTensor,reserve_space

- op: bce_loss
  inputs: (Tensor input, Tensor label)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: bce_loss_
  inputs: (Tensor input, Tensor label)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: input->out

- op: beam_search
  inputs: (Tensor pre_ids, Tensor pre_scores, Tensor ids, Tensor scores)
  attrs: (int level, int beam_size, int end_id, bool is_accumulated, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(selected_ids), Tensor(selected_scores), Tensor(parent_idx)
  optionals: ids,parent_idx

- op: beam_search_decode
  inputs: (Tensor|TensorArray? Ids, Tensor|TensorArray? Scores)
  attrs: (int beam_size, int end_id, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(SentenceIds), Tensor(SentenceScores)

- op: bernoulli
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: bicubic_interp
  inputs: (Tensor X, Tensor OutSize, Tensor[] SizeTensor, Tensor Scale)
  attrs: (str data_layout, int out_d, int out_h, int out_w, float scale, str interp_method,
    bool align_corners, int align_mode, bool use_mkldnn, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: OutSize,SizeTensor,Scale

- op: bicubic_interp
  inputs: (Tensor x, Tensor out_size, Tensor[] size_tensor, Tensor scale_tensor)
  attrs: (str data_format, int out_d, int out_h, int out_w, float[] scale, str interp_method,
    bool align_corners, int align_mode, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: out_size,size_tensor,scale_tensor

- op: bilateral_slice
  inputs: (Tensor X, Tensor Grid, Tensor Guide)
  attrs: (bool has_offset, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: bilinear_interp
  inputs: (Tensor X, Tensor OutSize, Tensor[] SizeTensor, Tensor Scale)
  attrs: (str data_layout, int out_d, int out_h, int out_w, float scale, str interp_method,
    bool align_corners, int align_mode, bool use_mkldnn, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: OutSize,SizeTensor,Scale

- op: bilinear_interp
  inputs: (Tensor x, Tensor out_size, Tensor[] size_tensor, Tensor scale_tensor)
  attrs: (str data_format, int out_d, int out_h, int out_w, float[] scale, str interp_method,
    bool align_corners, int align_mode, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: out_size,size_tensor,scale_tensor

- op: bilinear
  inputs: (Tensor x, Tensor y, Tensor weight, Tensor bias)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias

- op: bincount
  inputs: (Tensor x, Tensor weights)
  attrs: (int minlength, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: weights

- op: bipartite_match
  inputs: (Tensor DistMat)
  attrs: (str match_type, float dist_threshold, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(ColToRowMatchIndices), Tensor(ColToRowMatchDist)

- op: bitwise_and
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: bitwise_and_
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: bitwise_not
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: bitwise_not_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: bitwise_or
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: bitwise_or_
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: bitwise_xor
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: bitwise_xor_
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: bmm
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: box_clip
  inputs: (Tensor Input, Tensor ImInfo)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Output)

- op: box_coder
  inputs: (Tensor prior_box, Tensor prior_box_var, Tensor target_box)
  attrs: (str code_type, bool box_normalized, int axis, float[] variance, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output_box)
  optionals: prior_box_var

- op: box_decoder_and_assign
  inputs: (Tensor PriorBox, Tensor PriorBoxVar, Tensor TargetBox, Tensor BoxScore)
  attrs: (float box_clip, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(DecodeBox), Tensor(OutputAssignBox)
  optionals: PriorBoxVar

- op: bpr_loss
  inputs: (Tensor X, Tensor Label)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: hardtanh
  inputs: (Tensor x)
  attrs: (float t_min, float t_max, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: brelu_
  inputs: (Tensor x)
  attrs: (float t_min, float t_max, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: broadcast
  inputs: (Tensor x)
  attrs: (int ring_id, int root, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: broadcast_tensors
  inputs: (Tensor[] input)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](out)

- op: c_allgather
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, int nranks, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_allreduce_max
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_allreduce_max_
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: c_allreduce_min
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_allreduce_min_
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: c_allreduce_prod
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_allreduce_prod_
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: c_allreduce_sum
  inputs: (Tensor x, Tensor Cond)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Cond

- op: c_allreduce_sum_
  inputs: (Tensor x, Tensor Cond)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Cond
  inpalces: x->out

- op: c_broadcast
  inputs: (Tensor x)
  attrs: (int ring_id, int root, bool use_calc_stream, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_concat
  inputs: (Tensor x)
  attrs: (int rank, int nranks, int ring_id, bool use_calc_stream, bool use_model_parallel,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: c_embedding
  inputs: (Tensor weight, Tensor x)
  attrs: (int64_t start_index, int64_t vocab_size, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_identity
  inputs: (Tensor x)
  attrs: (int ring_id, bool use_calc_stream, bool use_model_parallel, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_reduce_max
  inputs: (Tensor X)
  attrs: (int ring_id, int root_id, bool use_calc_stream, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: c_reduce_min
  inputs: (Tensor x)
  attrs: (int ring_id, int root_id, bool use_calc_stream, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_reduce_prod
  inputs: (Tensor X)
  attrs: (int ring_id, int root_id, bool use_calc_stream, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: c_reduce_sum
  inputs: (Tensor x)
  attrs: (int ring_id, int root_id, bool use_calc_stream, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_reducescatter
  inputs: (Tensor x)
  attrs: (int ring_id, int nranks, bool use_calc_stream, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_scatter
  inputs: (Tensor X)
  attrs: (int ring_id, int root, int nranks, bool use_calc_stream, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: c_softmax_with_cross_entropy
  inputs: (Tensor logits, Tensor label)
  attrs: (int64_t ignore_index, int ring_id, int rank, int nranks, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(softmax), Tensor(loss)

- op: c_softmax_with_cross_entropy_
  inputs: (Tensor logits, Tensor label)
  attrs: (int64_t ignore_index, int ring_id, int rank, int nranks, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(softmax), Tensor(loss)
  inpalces: logits->softmax

- op: c_split
  inputs: (Tensor X)
  attrs: (int rank, int nranks, int ring_id, bool use_calc_stream, bool use_model_parallel,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out)

- op: c_sync_calc_stream
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_sync_comm_stream
  inputs: (Tensor[] x)
  attrs: (int ring_id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor[](out)

- op: cast
  inputs: (Tensor x)
  attrs: (int out_dtype, int in_dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: ceil
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: ceil_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: celu
  inputs: (Tensor x)
  attrs: (float alpha, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: channel_shuffle
  inputs: (Tensor x)
  attrs: (int groups, str data_format, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: check_finite_and_unscale_
  inputs: (Tensor[] x, Tensor scale)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](out), Tensor(found_infinite)

- op: check_finite_and_unscale_
  inputs: (Tensor[] x, Tensor scale)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](out), Tensor(found_infinite)
  inpalces: x->out

- op: check_memory_continue
  inputs: (Tensor[] X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](Out), Tensor(XOut)

- op: check_numerics
  inputs: (Tensor tensor)
  attrs: (str op_type, str var_name, int check_nan_inf_level, int stack_height_limit,
    str output_dir, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(stats), Tensor(values)

- op: cholesky
  inputs: (Tensor x)
  attrs: (bool upper, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cholesky_solve
  inputs: (Tensor x, Tensor y)
  attrs: (bool upper, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: chunk_eval
  inputs: (Tensor Inference, Tensor Label, Tensor SeqLength)
  attrs: (int num_chunk_types, str chunk_scheme, int[] excluded_chunk_types, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Precision), Tensor(Recall), Tensor(F1-Score), Tensor(NumInferChunks),
    Tensor(NumLabelChunks), Tensor(NumCorrectChunks)
  optionals: SeqLength

- op: class_center_sample
  inputs: (Tensor label)
  attrs: (int num_classes, int num_samples, int ring_id, int rank, int nranks, bool
    fix_seed, int seed, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(remapped_label), Tensor(sampled_local_class_center)

- op: clear_float_status
  inputs: (Tensor FloatStatus)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(FloatStatusOut)

- op: clip
  inputs: (Tensor x, Tensor Min, Tensor Max)
  attrs: (float min, float max, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Min,Max

- op: clip_
  inputs: (Tensor x, Tensor Min, Tensor Max)
  attrs: (float min, float max, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Min,Max
  inpalces: x->out

- op: clip_by_norm
  inputs: (Tensor x)
  attrs: (float max_norm, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: coalesce_tensor
  inputs: (Tensor[] input)
  attrs: (int dtype, bool copy_data, bool set_constant, bool persist_output, float
    constant, bool use_align, int align_size, int size_of_dtype, int64_t[] concated_shapes,
    int64_t[] concated_ranks, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](output), Tensor(fused_output)

- op: collect_fpn_proposals
  inputs: (Tensor[] MultiLevelRois, Tensor[] MultiLevelScores, Tensor[] MultiLevelRoIsNum)
  attrs: (int post_nms_topN, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(FpnRois), Tensor(RoisNum)
  optionals: MultiLevelRoIsNum,RoisNum

- op: complex
  inputs: (Tensor real, Tensor imag)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: concat
  inputs: (Tensor[] x, Tensor AxisTensor)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: AxisTensor

- op: conj
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: conv2d
  inputs: (Tensor input, Tensor filter)
  attrs: (int[] strides, int[] paddings, str padding_algorithm, int[] dilations, int
    groups, str data_format, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: conv2d_inception_fusion
  inputs: (Tensor Input, Tensor[] Filter, Tensor[] Bias)
  attrs: (str pooling_type, bool exclusive, str activation, int workspace_size_MB,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Output), Tensor[](TempOutput)

- op: conv2d_transpose
  inputs: (Tensor x, Tensor filter, Tensor bias)
  attrs: (int[] strides, int[] paddings, int[] output_padding, int[] output_size,
    str padding_algorithm, int groups, int[] dilations, str data_format, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias

- op: conv3d
  inputs: (Tensor input, Tensor filter)
  attrs: (int[] strides, int[] paddings, str padding_algorithm, int groups, int[]
    dilations, str data_format, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: conv3d_transpose
  inputs: (Tensor x, Tensor filter)
  attrs: (int[] strides, int[] paddings, int[] output_padding, int[] output_size,
    str padding_algorithm, int groups, int[] dilations, str data_format, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: correlation
  inputs: (Tensor Input1, Tensor Input2)
  attrs: (int pad_size, int kernel_size, int max_displacement, int stride1, int stride2,
    int corr_type_multiply, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Output)

- op: cos
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cos_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: cosh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cosh_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: crf_decoding
  inputs: (Tensor Emission, Tensor Transition, Tensor Label, Tensor Length)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(ViterbiPath)
  optionals: Label,Length

- op: crop
  inputs: (Tensor X, Tensor Y, Tensor Offsets)
  attrs: (int[] offsets, int[] shape, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: Y,Offsets

- op: crop
  inputs: (Tensor x, Tensor Shape, Tensor[] ShapeTensor, Tensor Offsets, Tensor[]
    OffsetsTensor)
  attrs: (int[] shape, int[] offsets, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Shape,ShapeTensor,Offsets,OffsetsTensor

- op: cross
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cross_entropy
  inputs: (Tensor X, Tensor Label)
  attrs: (bool soft_label, int ignore_index, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: cross_entropy2
  inputs: (Tensor X, Tensor Label)
  attrs: (int ignore_index, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y), Tensor(XShape), Tensor(MatchX)

- op: ctc_align
  inputs: (Tensor Input, Tensor InputLength)
  attrs: (int blank, bool merge_repeated, int padding_value, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Output), Tensor(OutputLength)
  optionals: InputLength,OutputLength

- op: cudnn_lstm
  inputs: (Tensor Input, Tensor InitH, Tensor InitC, Tensor W, Tensor[] WeightList,
    Tensor SequenceLength)
  attrs: (float dropout_prob, bool is_bidirec, int input_size, int hidden_size, int
    num_layers, bool is_test, int seed, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Reserve), Tensor(StateOut), Tensor(Out), Tensor(LastH), Tensor(LastC)
  optionals: W,WeightList,SequenceLength

- op: cummax
  inputs: (Tensor x)
  attrs: (int axis, int dtype, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(indices)

- op: cummin
  inputs: (Tensor x)
  attrs: (int axis, int dtype, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(indices)

- op: cumprod
  inputs: (Tensor x)
  attrs: (int dim, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cumprod_
  inputs: (Tensor x)
  attrs: (int dim, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: cumsum
  inputs: (Tensor x)
  attrs: (int axis, bool flatten, bool exclusive, bool reverse, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cumsum_
  inputs: (Tensor x)
  attrs: (int axis, bool flatten, bool exclusive, bool reverse, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: cvm
  inputs: (Tensor X, Tensor CVM)
  attrs: (bool use_cvm, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: data
  inputs: (Tensor ShapeTensor, Tensor[] ShapeTensorList)
  attrs: (str name, int64_t[] shape, int dtype, int place, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ShapeTensor,ShapeTensorList

- op: data_norm
  inputs: (Tensor scale_w, Tensor bias, Tensor X, Tensor BatchSize, Tensor BatchSum,
    Tensor BatchSquareSum)
  attrs: (float epsilon, int slot_dim, float summary_decay_rate, bool enable_scale_and_shift,
    str data_layout, bool sync_stats, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y), Tensor(Means), Tensor(Scales)
  optionals: scale_w,bias

- op: decayed_adagrad
  inputs: (Tensor param, Tensor grad, Tensor moment, Tensor learning_rate)
  attrs: (float decay, float epsilon, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment_out)

- op: decode_jpeg
  inputs: (Tensor x)
  attrs: (str mode, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: deformable_conv
  inputs: (Tensor x, Tensor offset, Tensor filter, Tensor mask)
  attrs: (int[] strides, int[] paddings, int[] dilations, int deformable_groups, int
    groups, int im2col_step, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: deformable_conv
  inputs: (Tensor x, Tensor offset, Tensor filter)
  attrs: (int[] strides, int[] paddings, int[] dilations, int groups, int deformable_groups,
    int im2col_step, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: deformable_psroi_pooling
  inputs: (Tensor Input, Tensor ROIs, Tensor Trans)
  attrs: (bool no_trans, float spatial_scale, int output_dim, int[] group_size, int
    pooled_height, int pooled_width, int[] part_size, int sample_per_part, float trans_std,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(TopCount), Tensor(Output)

- op: density_prior_box
  inputs: (Tensor Input, Tensor Image)
  attrs: (float[] variances, bool clip, bool flatten_to_2d, float step_w, float step_h,
    float offset, float[] fixed_sizes, float[] fixed_ratios, int[] densities, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Boxes), Tensor(Variances)

- op: depthwise_conv2d
  inputs: (Tensor input, Tensor filter)
  attrs: (int[] strides, int[] paddings, str padding_algorithm, int groups, int[]
    dilations, str data_format, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: depthwise_conv2d_transpose
  inputs: (Tensor x, Tensor filter, Tensor bias)
  attrs: (int[] strides, int[] paddings, int[] output_padding, int[] output_size,
    str padding_algorithm, int groups, int[] dilations, str data_format, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias

- op: dequantize
  inputs: (Tensor input)
  attrs: (float scale, float shift, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)

- op: dequantize_abs_max
  inputs: (Tensor X, Tensor Scale)
  attrs: (float max_range, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: dequantize_linear
  inputs: (Tensor X, Tensor Scale, Tensor ZeroPoint, Tensor InAccum, Tensor InState)
  attrs: (int quant_axis, int bit_length, int round_type, bool is_test, bool only_observer,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Y), Tensor(OutState), Tensor(OutAccum), Tensor(OutScale)
  optionals: InAccum,InState,OutState,OutAccum,OutScale

- op: dequantize_log
  inputs: (Tensor X, Tensor Dict)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: detection_map
  inputs: (Tensor DetectRes, Tensor Label, Tensor HasState, Tensor PosCount, Tensor
    TruePos, Tensor FalsePos)
  attrs: (int class_num, int background_label, float overlap_threshold, bool evaluate_difficult,
    str ap_type, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(AccumPosCount), Tensor(AccumTruePos), Tensor(AccumFalsePos), Tensor(MAP)
  optionals: HasState,PosCount,TruePos,FalsePos

- op: det
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: dgc
  inputs: (Tensor U, Tensor V, Tensor Grad, Tensor Param, Tensor current_step, Tensor
    nranks)
  attrs: (float m, bool use_nesterov, float[] sparsity, float rampup_begin_step, float
    rampup_step, float regular_coeff, int regular_type, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(U_out), Tensor(V_out), Tensor(EncodeGrad), Tensor(Grad_out), Tensor(k),
    Tensor(GatherBuff)

- op: dgc_clip_by_norm
  inputs: (Tensor current_step, Tensor X)
  attrs: (float rampup_begin_step, float max_norm, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: dgc_momentum
  inputs: (Tensor Param, Tensor Grad, Tensor Velocity, Tensor LearningRate, Tensor
    MasterParam, Tensor current_step, Tensor nranks)
  attrs: (float mu, bool use_nesterov, str regularization_method, float regularization_coeff,
    bool multi_precision, float rescale_grad, float rampup_begin_step, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(ParamOut), Tensor(VelocityOut), Tensor(MasterParamOut), Tensor(Grad_out)
  optionals: MasterParam,MasterParamOut

- op: diag_embed
  inputs: (Tensor input)
  attrs: (int offset, int dim1, int dim2, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: diag
  inputs: (Tensor x)
  attrs: (int offset, float padding_value, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: diagonal
  inputs: (Tensor x)
  attrs: (int offset, int axis1, int axis2, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: digamma
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: digamma_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: dirichlet
  inputs: (Tensor alpha)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: dist
  inputs: (Tensor x, Tensor y)
  attrs: (float p, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: distribute_fpn_proposals
  inputs: (Tensor fpn_rois, Tensor rois_num)
  attrs: (int min_level, int max_level, int refer_level, int refer_scale, bool pixel_offset,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor[](multi_fpn_rois), Tensor(restore_index), Tensor[](multi_level_rois_num)
  optionals: rois_num,multi_level_rois_num

- op: distributed_fused_lamb
  inputs: (Tensor[] Param, Tensor[] Grad, Tensor FP32FusedParam, Tensor FP32FusedGrad,
    Tensor FP16FusedParam, Tensor FP16FusedGrad, Tensor Moment1, Tensor Moment2, Tensor
    Beta1Pow, Tensor Beta2Pow, Tensor FusedParamOffsets, Tensor FP32ShardFusedParamOffsets,
    Tensor FP16ShardFusedParamOffsets, Tensor ParamInfo, Tensor ParamOrder, Tensor
    LearningRate, Tensor GlobalScale)
  attrs: (int acc_steps, float beta1, float beta2, float epsilon, float max_global_grad_norm,
    float weight_decay, bool clip_after_allreduce, bool use_master_param_norm, bool
    use_master_acc_grad, bool is_grad_scaled_by_nranks, int64_t nranks, int[] ring_ids,
    bool use_hierarchical_allreduce, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(FP32FusedParamOut), Tensor(FP16FusedParamOut), Tensor(FP32AccFusedGrad),
    Tensor(FP16AccFusedGrad), Tensor(Moment1Out), Tensor(Moment2Out), Tensor(Beta1PowOut),
    Tensor(Beta2PowOut), Tensor[](ParamOut), Tensor(FoundInf), Tensor(AccStep), Tensor(StopUpdate),
    Tensor(Step)
  optionals: FP32FusedParam,FP32FusedGrad,FP16FusedParam,FP16FusedGrad,FP32FusedParamOut,FP16FusedParamOut,FP32AccFusedGrad,FP16AccFusedGrad,AccStep,StopUpdate

- op: distributed_fused_lamb_init
  inputs: (Tensor[] Param, Tensor[] Grad)
  attrs: (float beta1, float beta2, int[] apply_weight_decay, int alignment, int rank,
    int nranks, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(FP32FusedParam), Tensor(FP32FusedGrad), Tensor(FP16FusedParam),
    Tensor(FP16FusedGrad), Tensor(Moment1), Tensor(Moment2), Tensor(Beta1Pow), Tensor(Beta2Pow),
    Tensor(FusedParamOffsets), Tensor(FP32ShardFusedParamOffsets), Tensor(FP16ShardFusedParamOffsets),
    Tensor(ParamInfo), Tensor(ParamOrder), Tensor[](ParamOut), Tensor[](MasterParamOut),
    Tensor[](GradOut), Tensor(GlobalScale), Tensor(Step)
  optionals: FP32FusedParam,FP32FusedGrad,FP16FusedParam,FP16FusedGrad

- op: distributed_lookup_table
  inputs: (Tensor[] ids, Tensor w)
  attrs: (int table_id, bool is_distributed, str lookup_table_version, int64_t padding_idx,
    int dtype, bool is_test, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](outputs)

- op: distributed_push_sparse
  inputs: (Tensor[] Ids, Tensor[] Shows, Tensor[] Clicks)
  attrs: (int table_id, int size, bool is_distributed, str push_sparse_version, int64_t
    padding_idx, int dtype, bool is_test, bool use_cvm_op, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Outputs)

- op: dot
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: dpsgd
  inputs: (Tensor param, Tensor grad, Tensor learning_rate)
  attrs: (float clip, float batch_size, float sigma, int seed, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out)

- op: dropout
  inputs: (Tensor x, Tensor seed_tensor)
  attrs: (float p, bool is_test, str mode, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mask)
  optionals: seed_tensor

- op: dropout_nd
  inputs: (Tensor X, Tensor Seed)
  attrs: (float dropout_prob, bool is_test, str dropout_implementation, int[] axis,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out), Tensor(Mask)
  optionals: Seed

- op: edit_distance
  inputs: (Tensor hyps, Tensor refs, Tensor hypslength, Tensor refslength)
  attrs: (bool normalized, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(sequencenum), Tensor(out)
  optionals: hypslength,refslength

- op: eig
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out_w), Tensor(out_v)

- op: eigh
  inputs: (Tensor x)
  attrs: (str UPLO, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out_w), Tensor(out_v)

- op: eigvals
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: eigvalsh
  inputs: (Tensor x)
  attrs: (str uplo, bool is_test, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(eigenvalues), Tensor(eigenvectors)

- op: einsum
  inputs: (Tensor[] x)
  attrs: (str equation, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor[](inner_cache), Tensor[](xshape)

- op: add
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: elementwise_add_
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: divide
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: floor_divide
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fmax
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fmin
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: heaviside
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: maximum
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: minimum
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: remainder
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: elementwise_mod_
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: multiply
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: elementwise_pow
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: subtract
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: elementwise_sub_
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: elu
  inputs: (Tensor x)
  attrs: (float alpha, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: elu_
  inputs: (Tensor x)
  attrs: (float alpha, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: empty
  inputs: (Tensor ShapeTensor, Tensor[] ShapeTensorList)
  attrs: (int64_t[] shape, int dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ShapeTensor,ShapeTensorList

- op: equal
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, bool force_cpu, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: equal_all
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: erf
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: erf_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: erfinv
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: erfinv_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: exp
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: exp_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: expand
  inputs: (Tensor X, Tensor ExpandTimes, Tensor[] expand_times_tensor)
  attrs: (int[] expand_times, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: ExpandTimes,expand_times_tensor

- op: expand_as
  inputs: (Tensor x, Tensor y)
  attrs: (int[] target_shape, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: y

- op: expand
  inputs: (Tensor x, Tensor Shape, Tensor[] expand_shapes_tensor)
  attrs: (int[] shape, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Shape,expand_shapes_tensor

- op: expm1
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: expm1_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: exponential_
  inputs: (Tensor x)
  attrs: (float lam, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: exponential_
  inputs: (Tensor x)
  attrs: (float lam, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: eye
  inputs: ()
  attrs: (int64_t num_rows, int64_t num_columns, int dtype, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fake_channel_wise_dequantize_max_abs
  inputs: (Tensor X, Tensor[] Scales)
  attrs: (int[] quant_bits, int quant_axis, int x_num_col_dims, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fake_channel_wise_quantize_abs_max
  inputs: (Tensor X)
  attrs: (int quant_axis, int bit_length, bool is_test, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale)

- op: fake_channel_wise_quantize_dequantize_abs_max
  inputs: (Tensor X)
  attrs: (int quant_axis, int bit_length, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale)

- op: fake_dequantize_max_abs
  inputs: (Tensor X, Tensor Scale)
  attrs: (float max_range, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fake_quantize_abs_max
  inputs: (Tensor X)
  attrs: (int bit_length, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale)

- op: fake_quantize_dequantize_abs_max
  inputs: (Tensor X)
  attrs: (int bit_length, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale)

- op: fake_quantize_dequantize_moving_average_abs_max
  inputs: (Tensor X, Tensor InScale, Tensor InAccum, Tensor InState)
  attrs: (float moving_rate, int bit_length, bool is_test, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale), Tensor(OutState), Tensor(OutAccum)
  optionals: InAccum,InState,OutState,OutAccum

- op: fake_quantize_moving_average_abs_max
  inputs: (Tensor X, Tensor InScale, Tensor InAccum, Tensor InState)
  attrs: (float moving_rate, int bit_length, bool is_test, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale), Tensor(OutState), Tensor(OutAccum)
  optionals: InAccum,InState,OutState,OutAccum

- op: fake_quantize_range_abs_max
  inputs: (Tensor X, Tensor InScale, Tensor Iter)
  attrs: (int window_size, int bit_length, bool is_test, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale), Tensor(OutScales)
  optionals: Iter,OutScales

- op: faster_tokenizer
  inputs: (Tensor Vocab, Tensor Text, Tensor TextPair)
  attrs: (bool do_lower_case, bool is_split_into_words, int max_seq_len, bool pad_to_max_seq_len,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(InputIds), Tensor(SegmentIds)
  optionals: TextPair

- op: fc
  inputs: (Tensor input, Tensor w, Tensor bias)
  attrs: (int in_num_col_dims, str activation_type, bool padding_weights, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias

- op: feed
  inputs: (Tensor X)
  attrs: (int col, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fetch
  inputs: (Tensor x)
  attrs: (int col, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fetch
  inputs: (Tensor x)
  attrs: (int col, bool deepcopy, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fft_c2c
  inputs: (Tensor x)
  attrs: (int64_t[] axes, str normalization, bool forward, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fft_c2r
  inputs: (Tensor x)
  attrs: (int64_t[] axes, str normalization, bool forward, int64_t last_dim_size,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: fft_r2c
  inputs: (Tensor x)
  attrs: (int64_t[] axes, str normalization, bool forward, bool onesided, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fill
  inputs: ()
  attrs: (float[] value, int[] shape, int dtype, bool force_cpu, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fill
  inputs: (Tensor x)
  attrs: (float value, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fill_any_
  inputs: (Tensor x)
  attrs: (float value, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: full_like
  inputs: (Tensor x)
  attrs: (float value, int dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: full
  inputs: (Tensor ValueTensor, Tensor ShapeTensor, Tensor[] ShapeTensorList)
  attrs: (int dtype, int64_t[] shape, float value, str str_value, bool force_cpu,
    int place_type, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ValueTensor,ShapeTensor,ShapeTensorList

- op: full_batch_size_like
  inputs: (Tensor input)
  attrs: (int[] shape, int input_dim_idx, int output_dim_idx, int dtype, float value,
    str str_value, bool force_cpu, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fill_diagonal
  inputs: (Tensor x)
  attrs: (float value, int offset, bool wrap, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fill_diagonal_
  inputs: (Tensor x)
  attrs: (float value, int offset, bool wrap, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: fill_diagonal_tensor
  inputs: (Tensor x, Tensor y)
  attrs: (int64_t offset, int dim1, int dim2, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fill_diagonal_tensor_
  inputs: (Tensor x, Tensor y)
  attrs: (int64_t offset, int dim1, int dim2, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: fill_zeros_like
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fill_zeros_like2
  inputs: (Tensor X)
  attrs: (int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: flatten2
  inputs: (Tensor X)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(XShape)

- op: flatten2_
  inputs: (Tensor X)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(XShape)
  inpalces: X->Out

- op: flatten
  inputs: (Tensor x)
  attrs: (int start_axis, int stop_axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)

- op: flatten_contiguous_range_
  inputs: (Tensor x)
  attrs: (int start_axis, int stop_axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)
  inpalces: x->out

- op: flip
  inputs: (Tensor x)
  attrs: (int[] axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: floor
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: floor_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: fold
  inputs: (Tensor x)
  attrs: (int[] output_sizes, int[] kernel_sizes, int[] strides, int[] paddings, int[]
    dilations, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: frame
  inputs: (Tensor x)
  attrs: (int frame_length, int hop_length, int axis, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: frobenius_norm
  inputs: (Tensor x)
  attrs: (int[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: fsp
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: ftrl
  inputs: (Tensor param, Tensor squared_accumulator, Tensor linear_accumulator, Tensor
    grad, Tensor learning_rate)
  attrs: (float l1, float l2, float lr_power, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(squared_accum_out), Tensor(linear_accum_out)

- op: full_int_array
  inputs: ()
  attrs: (int64_t[] value, int dtype, int place, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fused_adam
  inputs: (Tensor[] Params, Tensor[] Grads, Tensor LearningRate, Tensor[] Moments1,
    Tensor[] Moments2, Tensor[] Beta1Pows, Tensor[] Beta2Pows, Tensor[] MasterParams,
    Tensor SkipUpdate)
  attrs: (float beta1, float beta2, float epsilon, int chunk_size, float weight_decay,
    bool use_adamw, bool multi_precision, bool use_global_beta_pow, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](ParamsOut), Tensor[](Moments1Out), Tensor[](Moments2Out), Tensor[](Beta1PowsOut),
    Tensor[](Beta2PowsOut), Tensor[](MasterParamsOut)
  optionals: MasterParams,SkipUpdate,MasterParamsOut

- op: fused_attention
  inputs: (Tensor x, Tensor ln_scale, Tensor ln_bias, Tensor qkv_weight, Tensor qkv_bias,
    Tensor cache_kv, Tensor src_mask, Tensor out_linear_weight, Tensor out_linear_bias,
    Tensor ln_scale_2, Tensor ln_bias_2)
  attrs: (int num_heads, bool transpose_qkv_wb, bool pre_layer_norm, float epsilon,
    float attn_dropout_rate, bool is_test, bool attn_dropout_fix_seed, int attn_dropout_seed,
    str attn_dropout_implementation, float dropout_rate, bool dropout_fix_seed, int
    dropout_seed, str dropout_implementation, float ln_epsilon, bool add_residual,
    int ring_id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(ln_mean), Tensor(ln_var), Tensor(ln_out), Tensor(qkv_out), Tensor(qkv_bias_out),
    Tensor(transpose_out_2), Tensor(qk_out), Tensor(qktv_out), Tensor(softmax_out),
    Tensor(attn_dropout_mask_out), Tensor(attn_dropout_out), Tensor(src_mask_out),
    Tensor(fmha_out), Tensor(out_linear_out), Tensor(dropout_mask_out), Tensor(ln_mean_2),
    Tensor(ln_var_2), Tensor(bias_dropout_residual_out), Tensor(cache_kv_out), Tensor(out)
  optionals: ln_scale,ln_bias,qkv_bias,cache_kv,src_mask,out_linear_bias,ln_scale_2,ln_bias_2,cache_kv_out

- op: fused_batch_norm_act
  inputs: (Tensor x, Tensor scale, Tensor bias, Tensor mean, Tensor variance)
  attrs: (float momentum, float epsilon, str act_type, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean_out), Tensor(variance_out), Tensor(saved_mean),
    Tensor(saved_variance), Tensor(reserve_space)

- op: fused_bias_dropout_residual_layer_norm
  inputs: (Tensor x, Tensor residual, Tensor bias, Tensor ln_scale, Tensor ln_bias)
  attrs: (float dropout_rate, bool is_test, bool dropout_fix_seed, int dropout_seed,
    str dropout_implementation, float ln_epsilon, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(y), Tensor(bias_dropout_residual_out), Tensor(dropout_mask_out),
    Tensor(ln_mean), Tensor(ln_variance)
  optionals: bias,ln_scale,ln_bias

- op: fused_bn_add_activation_
  inputs: (Tensor x, Tensor z, Tensor scale, Tensor bias, Tensor mean, Tensor variance)
  attrs: (float momentum, float epsilon, str act_type, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean_out), Tensor(variance_out), Tensor(saved_mean),
    Tensor(saved_variance), Tensor(reserve_space)

- op: fused_conv2d
  inputs: (Tensor input, Tensor filter, Tensor bias, Tensor residual_param)
  attrs: (int[] strides, int[] paddings, str padding_algorithm, int[] dilations, int
    groups, str data_format, str fuse_activation, bool fuse_residual_connection, bool
    force_fp32_output, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: bias,residual_param

- op: fused_conv3d
  inputs: (Tensor input, Tensor filter, Tensor bias, Tensor residual_param)
  attrs: (int[] strides, int[] paddings, str padding_algorithm, int[] dilations, int
    groups, str data_format, str fuse_activation, bool fuse_residual_connection, bool
    force_fp32_output, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: bias,residual_param

- op: fused_elementwise_add
  inputs: (Tensor X, Tensor Y)
  attrs: (int axis, str fuse_activation, float fuse_alpha, float fuse_beta, float
    fused_output_scale, int[] fused_unsqueeze2_axes, float scale_x, float scale_y,
    float scale_out, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_elementwise_div
  inputs: (Tensor X, Tensor Y)
  attrs: (int axis, str fuse_activation, float fuse_alpha, float fuse_beta, float
    fused_output_scale, int[] fused_unsqueeze2_axes, float scale_x, float scale_y,
    float scale_out, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_elementwise_mul
  inputs: (Tensor X, Tensor Y)
  attrs: (int axis, str fuse_activation, float fuse_alpha, float fuse_beta, float
    fused_output_scale, int[] fused_unsqueeze2_axes, float scale_x, float scale_y,
    float scale_out, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_elementwise_sub
  inputs: (Tensor X, Tensor Y)
  attrs: (int axis, str fuse_activation, float fuse_alpha, float fuse_beta, float
    fused_output_scale, int[] fused_unsqueeze2_axes, float scale_x, float scale_y,
    float scale_out, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_elemwise_activation
  inputs: (Tensor X, Tensor Y)
  attrs: (int axis, float scale, bool save_intermediate_out, str[] functor_list, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out), Tensor(IntermediateOut)

- op: fused_elemwise_add_activation
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, float scale, bool save_intermediate_out, str[] functor_list, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(intermediate_out)

- op: fused_embedding_eltwise_layernorm
  inputs: (Tensor[] ids, Tensor[] embs, Tensor bias, Tensor scale)
  attrs: (float epsilon, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fused_embedding_fc_lstm
  inputs: (Tensor Ids, Tensor Embeddings, Tensor WeightH, Tensor Bias, Tensor H0,
    Tensor C0)
  attrs: (bool use_peepholes, bool is_reverse, bool use_seq, str gate_activation,
    str cell_activation, str candidate_activation, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Hidden), Tensor(Cell), Tensor(XX), Tensor(BatchedInput), Tensor(BatchedHidden),
    Tensor(BatchedCell), Tensor(ReorderedH0), Tensor(ReorderedC0)
  optionals: H0,C0

- op: fused_embedding_seq_pool
  inputs: (Tensor W, Tensor Ids)
  attrs: (str combiner, int64_t padding_idx, bool grad_inplace, bool is_sparse, bool
    ALL_KERNELS_MUST_COMPUTE_RUNTIME_SHAPE, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_fc_elementwise_layernorm
  inputs: (Tensor x, Tensor w, Tensor y, Tensor bias0, Tensor scale, Tensor bias1)
  attrs: (int x_num_col_dims, str activation_type, float epsilon, int begin_norm_axis,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean), Tensor(variance)
  optionals: bias0,scale,bias1,mean,variance

- op: fused_feedforward
  inputs: (Tensor x, Tensor dropout1_seed_val, Tensor dropout2_seed_val, Tensor linear1_weight,
    Tensor linear1_bias, Tensor linear2_weight, Tensor linear2_bias, Tensor ln1_scale,
    Tensor ln1_bias, Tensor ln2_scale, Tensor ln2_bias)
  attrs: (bool pre_layer_norm, float ln1_epsilon, float ln2_epsilon, str act_method,
    float dropout1_prob, float dropout2_prob, str dropout1_implementation, str dropout2_implementation,
    bool is_test, bool dropout1_fix_seed, bool dropout2_fix_seed, int dropout1_seed_val,
    int dropout2_seed_val, bool add_residual, int ring_id, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(dropout1_mask), Tensor(dropout2_mask), Tensor(ln1_mean),
    Tensor(ln1_variance), Tensor(ln2_mean), Tensor(ln2_variance), Tensor(linear1_out),
    Tensor(ln1_out), Tensor(dropout1_out), Tensor(dropout2_out)
  optionals: dropout1_seed_val,dropout2_seed_val,linear1_bias,linear2_bias,ln1_scale,ln1_bias,ln2_scale,ln2_bias

- op: fused_gate_attention
  inputs: (Tensor Query, Tensor Key, Tensor QueryWeight, Tensor KeyWeight, Tensor
    ValueWeight, Tensor QKVWeight, Tensor NonbatchedBias, Tensor SrcMask, Tensor GateWeight,
    Tensor GateBias, Tensor OutLinearWeight, Tensor OutLinearBias)
  attrs: (bool has_gating, bool merge_qkv, bool use_flash_attn, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(QueryTransposeOut), Tensor(KeyTransposeOut), Tensor(ValueTransposeOut),
    Tensor(QKVTransposeOut), Tensor(SoftmaxOut), Tensor(SoftmaxLse), Tensor(FMHAOut),
    Tensor(GateOut), Tensor(Out)
  optionals: Key,QueryWeight,KeyWeight,ValueWeight,QKVWeight,NonbatchedBias,GateWeight,GateBias,QueryTransposeOut,KeyTransposeOut,ValueTransposeOut,QKVTransposeOut,SoftmaxLse,GateOut

- op: fused_matmul
  inputs: (Tensor X, Tensor Y, Tensor ResidualData)
  attrs: (bool trans_x, bool trans_y, float matmul_alpha, str fuse_activation, float
    fuse_alpha, float fuse_beta, float fused_output_scale, int[] fused_reshape_X,
    int[] fused_transpose_X, int[] fused_reshape_Y, int[] fused_transpose_Y, int[]
    fused_reshape_Out, int[] fused_transpose_Out, str mkldnn_data_type, float Scale_x,
    float Scale_y, float Scale_in_eltwise, float Scale_out, bool force_fp32_output,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: ResidualData

- op: fused_multi_transformer
  inputs: (Tensor X, Tensor[] LnScale, Tensor[] LnBias, Tensor[] QKVW, Tensor[] QKVBias,
    Tensor[] CacheKV, Tensor[] PreCaches, Tensor RotaryPosEmb, Tensor TimeStep, Tensor
    SeqLengths, Tensor SrcMask, Tensor[] OutLinearW, Tensor[] OutLinearBias, Tensor[]
    FFNLnScale, Tensor[] FFNLnBias, Tensor[] FFN1Weight, Tensor[] FFN1Bias, Tensor[]
    FFN2Weight, Tensor[] FFN2Bias)
  attrs: (bool pre_layer_norm, int rotary_emb_dims, float epsilon, float dropout_rate,
    bool is_test, str dropout_implementation, str act_method, bool trans_qkvw, int
    ring_id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor[](CacheKVOut), Tensor(Out)
  optionals: QKVBias,CacheKV,PreCaches,RotaryPosEmb,TimeStep,SeqLengths,SrcMask,OutLinearBias,FFN1Bias,FFN2Bias,CacheKVOut

- op: fused_multi_transformer_int8
  inputs: (Tensor X, Tensor[] LnScale, Tensor[] LnBias, Tensor[] QKVW, Tensor[] QKVBias,
    Tensor[] CacheKV, Tensor TimeStep, Tensor SrcMask, Tensor[] OutLinearW, Tensor[]
    OutLinearBias, Tensor[] FFNLnScale, Tensor[] FFNLnBias, Tensor[] FFN1Weight, Tensor[]
    FFN1Bias, Tensor[] FFN2Weight, Tensor[] FFN2Bias, Tensor[] QKVOutScale, Tensor[]
    OutLinearOutScale, Tensor[] FFN1OutScale, Tensor[] FFN2OutScale)
  attrs: (bool pre_layer_norm, float epsilon, float dropout_rate, bool is_test, str
    dropout_implementation, str act_method, bool trans_qkvw, int ring_id, int num_head,
    int dim_head, int dim_ffn, float[] qkv_in_scale, float[] out_linear_in_scale,
    float[] ffn1_in_scale, float[] ffn2_in_scale, int quant_round_type, float quant_max_bound,
    float quant_min_bound, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](CacheKVOut), Tensor(Out)
  optionals: QKVBias,CacheKV,TimeStep,SrcMask,OutLinearBias,FFN1Bias,FFN2Bias,QKVOutScale,OutLinearOutScale,FFN1OutScale,FFN2OutScale,CacheKVOut

- op: fused_seqpool_cvm
  inputs: (Tensor[] X, Tensor CVM)
  attrs: (str pooltype, float pad_value, bool use_cvm, int cvm_offset, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: fused_softmax_mask
  inputs: (Tensor X, Tensor Mask)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_softmax_mask_upper_triangle
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_softplus
  inputs: (Tensor X)
  attrs: (float beta, float threshold, str fuse_activation, float fuse_alpha, float
    fuse_beta, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_token_prune
  inputs: (Tensor Attn, Tensor X, Tensor Mask, Tensor NewMask)
  attrs: (bool keep_first_token, bool keep_order, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(SlimmedX), Tensor(CLSInds)

- op: fused_transpose
  inputs: (Tensor X)
  attrs: (int[] axis, int[] fused_squeeze2_axes, int[] fused_unsqueeze2_axes, int[]
    fused_reshape2_shape, float scale, float shift, str output_data_type, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(XShape)

- op: fusion_group
  inputs: (Tensor[] Inputs)
  attrs: (int[] outs_dtype, int[] inputs_dtype, int type, str func_name, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Outs)

- op: fusion_gru
  inputs: (Tensor x, Tensor h0, Tensor weight_x, Tensor weight_h, Tensor bias)
  attrs: (str activation, str gate_activation, bool is_reverse, bool use_seq, bool
    origin_mode, bool use_mkldnn, str mkldnn_data_type, float scale_data, float shift_data,
    float[] scale_weights, bool force_fp32_output, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(reordered_h0), Tensor(xx), Tensor(batched_input), Tensor(batched_out),
    Tensor(hidden)
  optionals: h0,bias

- op: fusion_lstm
  inputs: (Tensor X, Tensor WeightX, Tensor WeightH, Tensor Bias, Tensor H0, Tensor
    C0)
  attrs: (bool use_peepholes, bool is_reverse, bool use_seq, str gate_activation,
    str cell_activation, str candidate_activation, float Scale_data, float Shift_data,
    float[] Scale_weights, bool force_fp32_output, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Hidden), Tensor(Cell), Tensor(XX), Tensor(BatchedInput), Tensor(BatchedHidden),
    Tensor(BatchedCell), Tensor(ReorderedH0), Tensor(ReorderedC0), Tensor(CheckedCell)
  optionals: H0,C0

- op: fusion_repeated_fc_relu
  inputs: (Tensor x, Tensor[] w, Tensor[] bias)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](relu_out), Tensor(out)

- op: fusion_seqconv_eltadd_relu
  inputs: (Tensor x, Tensor filter, Tensor bias)
  attrs: (int context_length, int context_start, int context_stride, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(col_mat)

- op: fusion_seqexpand_concat_fc
  inputs: (Tensor[] x, Tensor fc_weight, Tensor fc_bias)
  attrs: (str fc_activation, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(fc_out)
  optionals: fc_bias

- op: fusion_seqpool_concat
  inputs: (Tensor[] X)
  attrs: (str pooltype, int axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fusion_seqpool_cvm_concat
  inputs: (Tensor[] X, Tensor CVM)
  attrs: (str pooltype, bool use_cvm, int axis, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fusion_squared_mat_sub
  inputs: (Tensor x, Tensor y)
  attrs: (float scalar, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(squared_x), Tensor(squared_y), Tensor(squared_xy), Tensor(out)

- op: fusion_transpose_flatten_concat
  inputs: (Tensor[] x)
  attrs: (int[] trans_axis, int flatten_axis, int concat_axis, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: gather
  inputs: (Tensor x, Tensor index, Tensor Axis)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Axis

- op: gather_nd
  inputs: (Tensor x, Tensor index)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: gather_tree
  inputs: (Tensor ids, Tensor parents)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: gaussian
  inputs: (Tensor ShapeTensor, Tensor[] ShapeTensorList)
  attrs: (int64_t[] shape, float mean, float std, int seed, int dtype, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ShapeTensor,ShapeTensorList

- op: gelu
  inputs: (Tensor x)
  attrs: (bool approximate, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: generate_mask_labels
  inputs: (Tensor ImInfo, Tensor GtClasses, Tensor IsCrowd, Tensor GtSegms, Tensor
    Rois, Tensor LabelsInt32)
  attrs: (int num_classes, int resolution, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(MaskRois), Tensor(RoiHasMaskInt32), Tensor(MaskInt32)

- op: generate_proposal_labels
  inputs: (Tensor RpnRois, Tensor GtClasses, Tensor IsCrowd, Tensor GtBoxes, Tensor
    ImInfo, Tensor MaxOverlap)
  attrs: (int batch_size_per_im, float fg_fraction, float fg_thresh, float bg_thresh_hi,
    float bg_thresh_lo, float[] bbox_reg_weights, int class_nums, bool use_random,
    bool is_cascade_rcnn, bool is_cls_agnostic, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Rois), Tensor(LabelsInt32), Tensor(BboxTargets), Tensor(BboxInsideWeights),
    Tensor(BboxOutsideWeights), Tensor(MaxOverlapWithGT)
  optionals: MaxOverlap

- op: generate_proposals
  inputs: (Tensor Scores, Tensor BboxDeltas, Tensor ImInfo, Tensor Anchors, Tensor
    Variances)
  attrs: (int pre_nms_topN, int post_nms_topN, float nms_thresh, float min_size, float
    eta, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(RpnRois), Tensor(RpnRoiProbs), Tensor(RpnRoisNum)
  optionals: RpnRoisNum

- op: generate_proposals
  inputs: (Tensor scores, Tensor bbox_deltas, Tensor im_shape, Tensor anchors, Tensor
    variances)
  attrs: (int pre_nms_top_n, int post_nms_top_n, float nms_thresh, float min_size,
    float eta, bool pixel_offset, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(rpn_rois), Tensor(rpn_roi_probs), Tensor(rpn_rois_num)
  optionals: rpn_rois_num

- op: get_float_status
  inputs: (Tensor FloatStatus)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(FloatStatusOut)

- op: get_tensor_from_selected_rows
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: global_gather
  inputs: (Tensor X, Tensor local_count, Tensor global_count)
  attrs: (int ring_id, bool use_calc_stream, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: global_scatter
  inputs: (Tensor X, Tensor local_count, Tensor global_count)
  attrs: (int ring_id, bool use_calc_stream, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: grad_add
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: graph_khop_sampler
  inputs: (Tensor row, Tensor eids, Tensor colptr, Tensor x)
  attrs: (int[] sample_sizes, bool return_eids, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out_src), Tensor(out_dst), Tensor(sample_index), Tensor(reindex_x),
    Tensor(out_eids)
  optionals: eids

- op: reindex_graph
  inputs: (Tensor x, Tensor neighbors, Tensor count, Tensor hashtable_value, Tensor
    hashtable_index)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(reindex_src), Tensor(reindex_dst), Tensor(out_nodes)
  optionals: hashtable_value,hashtable_index

- op: graph_sample_neighbors
  inputs: (Tensor row, Tensor colptr, Tensor x, Tensor eids, Tensor perm_buffer)
  attrs: (int sample_size, bool return_eids, bool flag_perm_buffer, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_count), Tensor(out_eids)
  optionals: eids,perm_buffer

- op: send_u_recv
  inputs: (Tensor x, Tensor src_index, Tensor dst_index, Tensor Out_size)
  attrs: (str reduce_op, int64_t[] out_size, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(dst_count)
  optionals: Out_size

- op: send_ue_recv
  inputs: (Tensor x, Tensor y, Tensor src_index, Tensor dst_index, Tensor Out_size)
  attrs: (str message_op, str reduce_op, int64_t[] out_size, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(dst_count)
  optionals: Out_size

- op: send_uv
  inputs: (Tensor x, Tensor y, Tensor src_index, Tensor dst_index)
  attrs: (str message_op, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: greater_equal
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, bool force_cpu, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: greater_than
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, bool force_cpu, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: grid_sample
  inputs: (Tensor x, Tensor grid)
  attrs: (str mode, str padding_mode, bool align_corners, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: group_norm
  inputs: (Tensor x, Tensor scale, Tensor bias)
  attrs: (float epsilon, int groups, str data_format, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(y), Tensor(mean), Tensor(variance)
  optionals: scale,bias

- op: gru
  inputs: (Tensor Input, Tensor H0, Tensor Weight, Tensor Bias)
  attrs: (str activation, str gate_activation, bool is_reverse, bool origin_mode,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(BatchGate), Tensor(BatchResetHiddenPrev), Tensor(BatchHidden), Tensor(Hidden)
  optionals: H0,Bias

- op: gru_unit
  inputs: (Tensor Input, Tensor HiddenPrev, Tensor Weight, Tensor Bias)
  attrs: (int activation, int gate_activation, bool origin_mode, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Gate), Tensor(ResetHiddenPrev), Tensor(Hidden)
  optionals: Bias

- op: gumbel_softmax
  inputs: (Tensor x)
  attrs: (float temperature, bool hard, int axis, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: hardshrink
  inputs: (Tensor x)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: hardsigmoid
  inputs: (Tensor x)
  attrs: (float slope, float offset, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: hardswish
  inputs: (Tensor x)
  attrs: (float threshold, float scale, float offset, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: hash
  inputs: (Tensor X)
  attrs: (int num_hash, int64_t mod_by, bool ALL_KERNELS_MUST_COMPUTE_RUNTIME_SHAPE,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out)

- op: hsigmoid_loss
  inputs: (Tensor x, Tensor w, Tensor label, Tensor path, Tensor code, Tensor bias)
  attrs: (int num_classes, int trainer_id, int64_t[] height_sections, str[] epmap,
    str[] table_names, bool is_sparse, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(pre_out), Tensor(w_out)
  optionals: path,code,bias

- op: hinge_loss
  inputs: (Tensor Logits, Tensor Labels)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Loss)

- op: histogram
  inputs: (Tensor input)
  attrs: (int64_t bins, int min, int max, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: huber_loss
  inputs: (Tensor input, Tensor label)
  attrs: (float delta, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(residual)

- op: i0
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: i0_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: i0e
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: i1
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: i1e
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: identity_loss
  inputs: (Tensor x)
  attrs: (int reduction, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: identity_loss_
  inputs: (Tensor x)
  attrs: (int reduction, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: im2sequence
  inputs: (Tensor X, Tensor Y)
  attrs: (int[] kernels, int[] strides, int[] paddings, int[] out_stride, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: Y

- op: imag
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: increment
  inputs: (Tensor x)
  attrs: (float step, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: index_add
  inputs: (Tensor x, Tensor index, Tensor add_value)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: index_add_
  inputs: (Tensor x, Tensor index, Tensor add_value)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: index_put
  inputs: (Tensor x, Tensor[] indices, Tensor value)
  attrs: (bool accumulate, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: index_put_
  inputs: (Tensor x, Tensor[] indices, Tensor value)
  attrs: (bool accumulate, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: index_sample
  inputs: (Tensor x, Tensor index)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: index_select
  inputs: (Tensor x, Tensor index)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: index_select_strided
  inputs: (Tensor x)
  attrs: (int64_t index, int axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: instance_norm
  inputs: (Tensor x, Tensor scale, Tensor bias)
  attrs: (float epsilon, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(y), Tensor(saved_mean), Tensor(saved_variance)
  optionals: scale,bias

- op: inverse
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: iou_similarity
  inputs: (Tensor X, Tensor Y)
  attrs: (bool box_normalized, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: is_empty
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: isclose
  inputs: (Tensor x, Tensor y, Tensor Rtol, Tensor Atol)
  attrs: (str rtol, str atol, bool equal_nan, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Rtol,Atol

- op: isfinite
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: isinf
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: isinf
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: isnan
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: isnan
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: kldiv_loss
  inputs: (Tensor x, Tensor label)
  attrs: (str reduction, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: kron
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: kthvalue
  inputs: (Tensor x)
  attrs: (int k, int axis, bool keepdim, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(indices)

- op: l1_norm
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: label_smooth
  inputs: (Tensor label, Tensor prior_dist)
  attrs: (float epsilon, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: prior_dist

- op: lamb_
  inputs: (Tensor param, Tensor grad, Tensor learning_rate, Tensor moment1, Tensor
    moment2, Tensor beta1_pow, Tensor beta2_pow, Tensor master_param, Tensor skip_update)
  attrs: (float weight_decay, float beta1, float beta2, float epsilon, bool always_adapt,
    bool multi_precision, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment1_out), Tensor(moment2_out), Tensor(beta1_pow_out),
    Tensor(beta2_pow_out), Tensor(master_param_outs)
  optionals: master_param,skip_update,beta1_pow_out,beta2_pow_out,master_param_outs

- op: lars_momentum
  inputs: (Tensor[] param, Tensor[] grad, Tensor[] velocity, Tensor[] learning_rate,
    Tensor[] master_param)
  attrs: (float mu, float lars_coeff, float[] lars_weight_decay, float epsilon, bool
    multi_precision, float rescale_grad, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](param_out), Tensor[](velocity_out), Tensor[](master_param_out)
  optionals: master_param,master_param_out

- op: layer_norm
  inputs: (Tensor x, Tensor scale, Tensor bias)
  attrs: (float epsilon, int begin_norm_axis, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean), Tensor(variance)
  optionals: scale,bias

- op: leaky_relu
  inputs: (Tensor x)
  attrs: (float negative_slope, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: leaky_relu_
  inputs: (Tensor x)
  attrs: (float negative_slope, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: lerp
  inputs: (Tensor x, Tensor y, Tensor weight)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lerp_
  inputs: (Tensor x, Tensor y, Tensor weight)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: less_equal
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, bool force_cpu, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: less_than
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, bool force_cpu, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lgamma
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lgamma_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: limit_by_capacity
  inputs: (Tensor expert_count, Tensor capacity)
  attrs: (int n_worker, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: linear_chain_crf
  inputs: (Tensor Emission, Tensor Transition, Tensor Label, Tensor Length)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Alpha), Tensor(EmissionExps), Tensor(TransitionExps), Tensor(LogLikelihood)
  optionals: Length

- op: linear_interp
  inputs: (Tensor X, Tensor OutSize, Tensor[] SizeTensor, Tensor Scale)
  attrs: (str data_layout, int out_d, int out_h, int out_w, float scale, str interp_method,
    bool align_corners, int align_mode, bool use_mkldnn, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: OutSize,SizeTensor,Scale

- op: linear_interp
  inputs: (Tensor x, Tensor out_size, Tensor[] size_tensor, Tensor scale_tensor)
  attrs: (str data_format, int out_d, int out_h, int out_w, float[] scale, str interp_method,
    bool align_corners, int align_mode, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: out_size,size_tensor,scale_tensor

- op: linspace
  inputs: (Tensor start, Tensor stop, Tensor number)
  attrs: (int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: load
  inputs: ()
  attrs: (bool load_as_fp16, str file_path, int64_t seek, int64_t[] shape, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: load_combine
  inputs: ()
  attrs: (bool load_as_fp16, str file_path, bool model_from_memory, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: locality_aware_nms
  inputs: (Tensor BBoxes, Tensor Scores)
  attrs: (int background_label, float score_threshold, int nms_top_k, float nms_threshold,
    float nms_eta, int keep_top_k, bool normalized, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: lod_reset
  inputs: (Tensor X, Tensor Y)
  attrs: (int[] target_lod, bool append, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: Y

- op: lod_reset_
  inputs: (Tensor X, Tensor Y)
  attrs: (int[] target_lod, bool append, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: Y
  inpalces: X->Out

- op: log
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: log10
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: log10_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: log1p
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: log1p_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: log2
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: log2_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: log_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: log_loss
  inputs: (Tensor input, Tensor label)
  attrs: (float epsilon, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: log_softmax
  inputs: (Tensor x)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logcumsumexp
  inputs: (Tensor x)
  attrs: (int axis, bool flatten, bool exclusive, bool reverse, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logical_and
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logical_and_
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: logical_not
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logical_not_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: logical_or
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logical_or_
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: logical_xor
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logical_xor_
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: logit
  inputs: (Tensor x)
  attrs: (float eps, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logit_
  inputs: (Tensor x)
  attrs: (float eps, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: logsigmoid
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logspace
  inputs: (Tensor start, Tensor stop, Tensor num, Tensor base)
  attrs: (int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: logsumexp
  inputs: (Tensor x)
  attrs: (int[] axis, bool keepdim, bool reduce_all, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lookup_table
  inputs: (Tensor W, Tensor Ids)
  attrs: (bool is_sparse, bool is_distributed, int64_t padding_idx, bool remote_prefetch,
    str entry_config, bool is_test, str entry, str table_class, str[] table_names,
    int trainer_id, int slot, bool grad_inplace, str[] epmap, int64_t[] height_sections,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out)

- op: lookup_table_dequant
  inputs: (Tensor W, Tensor Ids)
  attrs: (int64_t padding_idx, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: embedding
  inputs: (Tensor x, Tensor weight)
  attrs: (int64_t padding_idx, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lrn
  inputs: (Tensor x)
  attrs: (int n, float k, float alpha, float beta, str data_format, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mid_out)

- op: lstm
  inputs: (Tensor Input, Tensor H0, Tensor C0, Tensor Weight, Tensor Bias)
  attrs: (bool use_peepholes, bool is_reverse, bool is_test, str gate_activation,
    str cell_activation, str candidate_activation, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Hidden), Tensor(Cell), Tensor(BatchGate), Tensor(BatchCellPreAct)
  optionals: H0,C0

- op: lstsq
  inputs: (Tensor x, Tensor y)
  attrs: (float rcond, str driver, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(solution), Tensor(residuals), Tensor(rank), Tensor(singular_values)
  optionals: residuals

- op: lu
  inputs: (Tensor x)
  attrs: (bool pivot, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(pivots), Tensor(infos)

- op: lu_
  inputs: (Tensor x)
  attrs: (bool pivot, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(pivots), Tensor(infos)
  inpalces: x->out

- op: lu_unpack
  inputs: (Tensor x, Tensor y)
  attrs: (bool unpack_ludata, bool unpack_pivots, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(pmat), Tensor(l), Tensor(u)

- op: margin_cross_entropy
  inputs: (Tensor logits, Tensor label)
  attrs: (bool return_softmax, int ring_id, int rank, int nranks, float margin1, float
    margin2, float margin3, float scale, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(softmax), Tensor(loss)

- op: masked_select
  inputs: (Tensor x, Tensor mask)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: match_matrix_tensor
  inputs: (Tensor x, Tensor y, Tensor w)
  attrs: (int dim_t, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(tmp)

- op: matmul
  inputs: (Tensor x, Tensor y)
  attrs: (bool transpose_X, bool transpose_Y, float alpha, bool use_mkldnn, bool use_quantizer,
    str mkldnn_data_type, float Scale_x, float Scale_y, float Scale_out, bool force_fp32_output,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: matmul
  inputs: (Tensor x, Tensor y)
  attrs: (bool transpose_x, bool transpose_y, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: matrix_nms
  inputs: (Tensor bboxes, Tensor scores)
  attrs: (float score_threshold, int nms_top_k, int keep_top_k, float post_threshold,
    bool use_gaussian, float gaussian_sigma, int background_label, bool normalized,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(index), Tensor(roisnum)
  optionals: roisnum

- op: matrix_power
  inputs: (Tensor x)
  attrs: (int n, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: matrix_rank
  inputs: (Tensor x, Tensor atol_tensor)
  attrs: (float tol, bool hermitian, bool use_default_tol, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: atol_tensor

- op: max_pool2d_with_index
  inputs: (Tensor x)
  attrs: (int[] kernel_size, int[] strides, int[] paddings, bool global_pooling, bool
    adaptive, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mask)

- op: max_pool3d_with_index
  inputs: (Tensor x)
  attrs: (int[] kernel_size, int[] strides, int[] paddings, bool global_pooling, bool
    adaptive, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mask)

- op: maxout
  inputs: (Tensor x)
  attrs: (int groups, int axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: mean_all
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: memcpy
  inputs: (Tensor x)
  attrs: (int dst_place_type, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: memcpy_d2h
  inputs: (Tensor x)
  attrs: (int dst_place_type, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: memcpy_h2d
  inputs: (Tensor X)
  attrs: (int dst_place_type, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: merge_selected_rows
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: merged_adam
  inputs: (Tensor[] Param, Tensor[] Grad, Tensor[] LearningRate, Tensor[] Moment1,
    Tensor[] Moment2, Tensor[] Beta1Pow, Tensor[] Beta2Pow, Tensor[] MasterParam)
  attrs: (float beta1, float beta2, float epsilon, bool multi_precision, bool use_global_beta_pow,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor[](ParamOut), Tensor[](Moment1Out), Tensor[](Moment2Out), Tensor[](Beta1PowOut),
    Tensor[](Beta2PowOut), Tensor[](MasterParamOut)
  optionals: MasterParam,MasterParamOut

- op: merged_momentum_
  inputs: (Tensor[] param, Tensor[] grad, Tensor[] velocity, Tensor[] learning_rate,
    Tensor[] master_param)
  attrs: (float mu, bool use_nesterov, str[] regularization_method, float[] regularization_coeff,
    bool multi_precision, float rescale_grad, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](param_out), Tensor[](velocity_out), Tensor[](master_param_out)
  optionals: master_param,master_param_out

- op: meshgrid
  inputs: (Tensor[] inputs)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](out)

- op: mine_hard_examples
  inputs: (Tensor ClsLoss, Tensor LocLoss, Tensor MatchIndices, Tensor MatchDist)
  attrs: (float neg_pos_ratio, float neg_dist_threshold, int sample_size, str mining_type,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(NegIndices), Tensor(UpdatedMatchIndices)
  optionals: LocLoss

- op: minus
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: mish
  inputs: (Tensor x)
  attrs: (float lambda, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: mode
  inputs: (Tensor x)
  attrs: (int axis, bool keepdim, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(indices)

- op: modified_huber_loss
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(IntermediateVal), Tensor(Out)

- op: momentum_
  inputs: (Tensor param, Tensor grad, Tensor velocity, Tensor learning_rate, Tensor
    master_param)
  attrs: (float mu, bool use_nesterov, str regularization_method, float regularization_coeff,
    bool multi_precision, float rescale_grad, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(velocity_out), Tensor(master_param_out)
  optionals: master_param,master_param_out

- op: moving_average_abs_max_scale
  inputs: (Tensor X, Tensor InAccum, Tensor InState)
  attrs: (float moving_rate, bool is_test, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(OutScale), Tensor(OutState), Tensor(OutAccum)
  optionals: InAccum,InState,Out,OutState,OutAccum

- op: mp_allreduce_sum
  inputs: (Tensor X)
  attrs: (int ring_id, bool use_calc_stream, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: mp_allreduce_sum_
  inputs: (Tensor X)
  attrs: (int ring_id, bool use_calc_stream, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  inpalces: X->Out

- op: matmul_with_flatten
  inputs: (Tensor x, Tensor y)
  attrs: (int x_num_col_dims, int y_num_col_dims, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: multi_dot
  inputs: (Tensor[] x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: multi_gru
  inputs: (Tensor x, Tensor[] weight_x, Tensor[] weight_h, Tensor[] bias, Tensor[]
    scale_weights)
  attrs: (str activation, str gate_activation, int layers, bool origin_mode, str mkldnn_data_type,
    float scale_data, float shift_data, bool force_fp32_output, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(hidden)
  optionals: bias,scale_weights

- op: multiclass_nms
  inputs: (Tensor BBoxes, Tensor Scores)
  attrs: (int background_label, float score_threshold, int nms_top_k, float nms_threshold,
    float nms_eta, int keep_top_k, bool normalized, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: multiclass_nms2
  inputs: (Tensor BBoxes, Tensor Scores)
  attrs: (int background_label, float score_threshold, int nms_top_k, float nms_threshold,
    float nms_eta, int keep_top_k, bool normalized, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(Index)

- op: multiclass_nms3
  inputs: (Tensor bboxes, Tensor scores, Tensor rois_num)
  attrs: (float score_threshold, int nms_top_k, int keep_top_k, float nms_threshold,
    bool normalized, float nms_eta, int background_label, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(index), Tensor(nms_rois_num)
  optionals: rois_num,nms_rois_num

- op: multihead_matmul
  inputs: (Tensor input, Tensor w, Tensor bias, Tensor bias_qk)
  attrs: (bool transpose_q, bool transpose_k, bool transpose_v, float alpha, int head_number,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias_qk

- op: multinomial
  inputs: (Tensor x)
  attrs: (int num_samples, bool replacement, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: multiplex
  inputs: (Tensor[] inputs, Tensor index)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: mv
  inputs: (Tensor x, Tensor vec)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: nanmedian
  inputs: (Tensor x)
  attrs: (int[] axis, bool keepdim, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(medians)

- op: nce
  inputs: (Tensor input, Tensor label, Tensor weight, Tensor bias, Tensor sample_weight,
    Tensor custom_dist_probs, Tensor custom_dist_alias, Tensor custom_dist_alias_probs)
  attrs: (int num_total_classes, int num_neg_samples, int sampler, int seed, bool
    is_sparse, bool remote_prefetch, bool is_test, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(cost), Tensor(sample_logits), Tensor(sample_labels)
  optionals: bias,sample_weight,custom_dist_probs,custom_dist_alias,custom_dist_alias_probs

- op: nearest_interp
  inputs: (Tensor X, Tensor OutSize, Tensor[] SizeTensor, Tensor Scale)
  attrs: (str data_layout, int out_d, int out_h, int out_w, float scale, str interp_method,
    bool align_corners, int align_mode, bool use_mkldnn, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: OutSize,SizeTensor,Scale

- op: nearest_interp
  inputs: (Tensor x, Tensor out_size, Tensor[] size_tensor, Tensor scale_tensor)
  attrs: (str data_format, int out_d, int out_h, int out_w, float[] scale, str interp_method,
    bool align_corners, int align_mode, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: out_size,size_tensor,scale_tensor

- op: nextafter
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: nll_loss
  inputs: (Tensor input, Tensor label, Tensor weight)
  attrs: (int64_t ignore_index, str reduction, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(total_weight)
  optionals: weight

- op: nms
  inputs: (Tensor x)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: nop
  inputs: (Tensor[] X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: norm
  inputs: (Tensor x)
  attrs: (int axis, float epsilon, bool is_test, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(norm)

- op: not_equal
  inputs: (Tensor x, Tensor y)
  attrs: (int axis, bool force_cpu, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: npu_identity
  inputs: (Tensor x)
  attrs: (int format, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: number_count
  inputs: (Tensor numbers)
  attrs: (int upper_range, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: one_hot
  inputs: (Tensor x, Tensor depth_tensor)
  attrs: (int depth, int dtype, bool allow_out_of_range, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: depth_tensor

- op: overlap_add
  inputs: (Tensor x)
  attrs: (int hop_length, int axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: p_norm
  inputs: (Tensor x)
  attrs: (float porder, int axis, float epsilon, bool keepdim, bool asvector, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: p_recv
  inputs: ()
  attrs: (int ring_id, int peer, int dtype, bool dynamic_shape, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: p_recv_array
  inputs: ()
  attrs: (int ring_id, int peer, int dtype, int[] out_shape, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: p_send
  inputs: (Tensor x)
  attrs: (int ring_id, int peer, bool dynamic_shape, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: p_send_array
  inputs: (Tensor[] x)
  attrs: (int ring_id, int peer, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: pad
  inputs: (Tensor x)
  attrs: (int[] paddings, float pad_value, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: pad2d
  inputs: (Tensor X, Tensor Paddings)
  attrs: (int[] paddings, float pad_value, str mode, str data_format, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: Paddings

- op: pad3d
  inputs: (Tensor x, Tensor Paddings)
  attrs: (int[] paddings, str mode, float pad_value, str data_format, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: Paddings

- op: partial_allgather
  inputs: (Tensor X)
  attrs: (int ring_id, bool use_calc_stream, int nranks, int rank, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: partial_allgather_
  inputs: (Tensor X)
  attrs: (int ring_id, bool use_calc_stream, int nranks, int rank, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  inpalces: X->Out

- op: partial_concat
  inputs: (Tensor[] X)
  attrs: (int start_index, int length, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: partial_recv
  inputs: ()
  attrs: (int ring_id, int peer, int dtype, int[] out_shape, bool use_calc_stream,
    int num, int id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: partial_send
  inputs: (Tensor x)
  attrs: (int ring_id, int peer, bool use_calc_stream, int num, int id, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: partial_sum
  inputs: (Tensor[] X)
  attrs: (int start_index, int length, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: pixel_shuffle
  inputs: (Tensor x)
  attrs: (int upscale_factor, str data_format, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: pixel_unshuffle
  inputs: (Tensor x)
  attrs: (int downscale_factor, str data_format, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: poisson
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: polygamma
  inputs: (Tensor x)
  attrs: (int n, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: polygamma_
  inputs: (Tensor x)
  attrs: (int n, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: polygon_box_transform
  inputs: (Tensor Input)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Output)

- op: pool2d
  inputs: (Tensor x)
  attrs: (int[] kernel_size, int[] strides, int[] paddings, bool ceil_mode, bool exclusive,
    str data_format, str pooling_type, bool global_pooling, bool adaptive, str padding_algorithm,
    bool use_cudnn, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: pool3d
  inputs: (Tensor x)
  attrs: (int[] kernel_size, int[] strides, int[] paddings, bool ceil_mode, bool exclusive,
    str data_format, str pooling_type, bool global_pooling, bool adaptive, str padding_algorithm,
    bool use_cudnn, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: positive_negative_pair
  inputs: (Tensor Score, Tensor Label, Tensor QueryID, Tensor AccumulatePositivePair,
    Tensor AccumulateNegativePair, Tensor AccumulateNeutralPair, Tensor Weight)
  attrs: (int column, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(PositivePair), Tensor(NegativePair), Tensor(NeutralPair)
  optionals: AccumulatePositivePair,AccumulateNegativePair,AccumulateNeutralPair,Weight,NeutralPair

- op: pow
  inputs: (Tensor x, Tensor FactorTensor)
  attrs: (float y, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: FactorTensor

- op: pow2_decay_with_linear_warmup
  inputs: (Tensor LearningRate, Tensor Step)
  attrs: (int64_t warmup_steps, int64_t total_steps, float base_lr, float end_lr,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(LearningRateOut), Tensor(StepOut)

- op: pow_
  inputs: (Tensor x, Tensor FactorTensor)
  attrs: (float y, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: FactorTensor
  inpalces: x->out

- op: precision_recall
  inputs: (Tensor MaxProbs, Tensor Indices, Tensor Labels, Tensor Weights, Tensor
    StatesInfo)
  attrs: (int class_number, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(BatchMetrics), Tensor(AccumMetrics), Tensor(AccumStatesInfo)
  optionals: Weights,StatesInfo

- op: prelu
  inputs: (Tensor x, Tensor alpha)
  attrs: (str data_format, str mode, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: prior_box
  inputs: (Tensor input, Tensor image)
  attrs: (float[] min_sizes, float[] max_sizes, float[] aspect_ratios, float[] variances,
    bool flip, bool clip, float step_w, float step_h, float offset, bool min_max_aspect_ratios_order,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(var)

- op: proximal_gd
  inputs: (Tensor Param, Tensor Grad, Tensor LearningRate)
  attrs: (float l1, float l2, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(ParamOut)

- op: prune_gate_by_capacity
  inputs: (Tensor GateIdx, Tensor ExpertCount)
  attrs: (int64_t n_expert, int64_t n_worker, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(NewGateIdx)

- op: psroi_pool
  inputs: (Tensor x, Tensor boxes, Tensor boxes_num)
  attrs: (int pooled_height, int pooled_width, int output_channels, float spatial_scale,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: boxes_num

- op: pull_box_extended_sparse
  inputs: (Tensor[] Ids)
  attrs: (int emb_size, int emb_extended_size, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out), Tensor[](OutExtend)

- op: pull_box_sparse
  inputs: (Tensor W, Tensor[] Ids)
  attrs: (bool is_sparse, bool is_distributed, int size, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)
  optionals: W

- op: pull_gpups_sparse
  inputs: (Tensor W, Tensor[] Ids)
  attrs: (int[] size, bool is_sparse, bool is_distributed, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)
  optionals: W

- op: pull_sparse
  inputs: (Tensor[] Ids, Tensor[] W)
  attrs: (int EmbeddingDim, int TableId, str AccessorClass, str CtrLabelName, int
    PaddingId, bool ScaleSparseGrad, str[] InputNames, bool is_distributed, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: pull_sparse_v2
  inputs: (Tensor[] Ids, Tensor[] W)
  attrs: (int EmbeddingDim, int TableId, str AccessorClass, str CtrLabelName, int
    PaddingId, bool ScaleSparseGrad, str[] InputNames, bool is_distributed, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: push_dense
  inputs: (Tensor[] Ids)
  attrs: (int TableId, float ScaleDataNorm, str[] InputNames, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: put_along_axis
  inputs: (Tensor arr, Tensor indices, Tensor values)
  attrs: (int axis, str reduce, bool include_self, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: put_along_axis_
  inputs: (Tensor arr, Tensor indices, Tensor values)
  attrs: (int axis, str reduce, bool include_self, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: arr->out

- op: pyramid_hash
  inputs: (Tensor X, Tensor W, Tensor WhiteList, Tensor BlackList)
  attrs: (int num_emb, int space_len, int pyramid_layer, int rand_len, float drop_out_percent,
    int is_training, bool use_filter, int white_list_len, int black_list_len, int
    seed, float lr, str distribute_update_vars, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(DropPos), Tensor(X_Temp_Out)

- op: qr
  inputs: (Tensor x)
  attrs: (str mode, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(q), Tensor(r)

- op: quantize
  inputs: (Tensor input)
  attrs: (bool is_negative_input, float scale, float shift, str output_format, bool
    bfloat16, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(output)

- op: quantize_linear
  inputs: (Tensor X, Tensor Scale, Tensor ZeroPoint, Tensor InAccum, Tensor InState)
  attrs: (int quant_axis, int bit_length, int round_type, bool is_test, bool only_observer,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Y), Tensor(OutState), Tensor(OutAccum), Tensor(OutScale)
  optionals: InAccum,InState,OutState,OutAccum,OutScale

- op: randint
  inputs: (Tensor ShapeTensor, Tensor[] ShapeTensorList)
  attrs: (int low, int high, int64_t[] shape, int dtype, int seed, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ShapeTensor,ShapeTensorList

- op: random_routing
  inputs: (Tensor Prob, Tensor TopK_Value, Tensor TopK_Idx)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: random_routing_
  inputs: (Tensor Prob, Tensor TopK_Value, Tensor TopK_Idx)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  inpalces: TopK_Idx->Out

- op: randperm
  inputs: ()
  attrs: (int n, int dtype, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: arange
  inputs: (Tensor start, Tensor end, Tensor step)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: rank_attention
  inputs: (Tensor X, Tensor RankOffset, Tensor RankParam)
  attrs: (int MaxRank, int MaxSize, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(InputHelp), Tensor(Out), Tensor(InsRank)
  optionals: InputHelp,InsRank

- op: rank_loss
  inputs: (Tensor Label, Tensor Left, Tensor Right)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: read_file
  inputs: ()
  attrs: (str filename, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: real
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: reciprocal
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: reciprocal_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: recv_v2
  inputs: ()
  attrs: (int ring_id, int peer, int dtype, int[] out_shape, bool use_calc_stream,
    bool dynamic_shape, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: reduce
  inputs: (Tensor x)
  attrs: (int ring_id, int root_id, int reduce_type, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: all
  inputs: (Tensor x, Tensor AxisTensor, Tensor[] AxisTensorList)
  attrs: (int64_t[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: AxisTensor,AxisTensorList

- op: amax
  inputs: (Tensor x, Tensor AxisTensor, Tensor[] AxisTensorList)
  attrs: (int64_t[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: AxisTensor,AxisTensorList

- op: amin
  inputs: (Tensor x, Tensor AxisTensor, Tensor[] AxisTensorList)
  attrs: (int64_t[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: AxisTensor,AxisTensorList

- op: any
  inputs: (Tensor x, Tensor AxisTensor, Tensor[] AxisTensorList)
  attrs: (int64_t[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: AxisTensor,AxisTensorList

- op: max
  inputs: (Tensor x)
  attrs: (int[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: mean
  inputs: (Tensor x)
  attrs: (int[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: min
  inputs: (Tensor x)
  attrs: (int[] axis, bool keepdim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: prod
  inputs: (Tensor x)
  attrs: (int[] dims, bool keep_dim, bool reduce_all, int in_dtype, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: reduce_scatter
  inputs: (Tensor x)
  attrs: (int ring_id, int nranks, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sum
  inputs: (Tensor x)
  attrs: (int[] axis, bool keepdim, bool reduce_all, int in_dtype, int dtype, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: relu
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: relu6
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: relu_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: renorm
  inputs: (Tensor x)
  attrs: (float p, int axis, float max_norm, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: renorm_
  inputs: (Tensor x)
  attrs: (float p, int axis, float max_norm, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: repeat_interleave
  inputs: (Tensor x, Tensor RepeatsTensor)
  attrs: (int repeats, int axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: RepeatsTensor

- op: requantize
  inputs: (Tensor input)
  attrs: (float scale_in, float scale_out, float shift_in, float shift_out, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)

- op: reshape
  inputs: (Tensor X, Tensor Shape, Tensor[] ShapeTensor)
  attrs: (int[] shape, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: Shape,ShapeTensor

- op: reshape
  inputs: (Tensor x, Tensor Shape, Tensor[] ShapeTensor)
  attrs: (int[] shape, bool use_quantizer, str mkldnn_data_type, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)
  optionals: Shape,ShapeTensor

- op: reshape2_
  inputs: (Tensor x, Tensor Shape, Tensor[] ShapeTensor)
  attrs: (int[] shape, bool use_quantizer, str mkldnn_data_type, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)
  optionals: Shape,ShapeTensor
  inpalces: x->out

- op: reshape_
  inputs: (Tensor X, Tensor Shape, Tensor[] ShapeTensor)
  attrs: (int[] shape, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: Shape,ShapeTensor
  inpalces: X->Out

- op: resnet_unit
  inputs: (Tensor X, Tensor FilterX, Tensor ScaleX, Tensor BiasX, Tensor MeanX, Tensor
    VarX, Tensor Z, Tensor FilterZ, Tensor ScaleZ, Tensor BiasZ, Tensor MeanZ, Tensor
    VarZ)
  attrs: (int stride, int stride_z, int padding, int dilation, int group, float momentum,
    float epsilon, str data_format, bool fuse_add, bool has_shortcut, bool use_global_stats,
    bool is_test, bool use_addto, str act_type, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y), Tensor(BitMask), Tensor(ConvX), Tensor(SavedMeanX), Tensor(SavedInvstdX),
    Tensor(RunningMeanX), Tensor(RunningVarX), Tensor(ConvZ), Tensor(SavedMeanZ),
    Tensor(SavedInvstdZ), Tensor(RunningMeanZ), Tensor(RunningVarZ)
  optionals: Z,FilterZ,ScaleZ,BiasZ,MeanZ,VarZ,ConvZ,SavedMeanZ,SavedInvstdZ,RunningMeanZ,RunningVarZ

- op: retinanet_detection_output
  inputs: (Tensor[] BBoxes, Tensor[] Scores, Tensor[] Anchors, Tensor ImInfo)
  attrs: (float score_threshold, int nms_top_k, float nms_threshold, float nms_eta,
    int keep_top_k, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: retinanet_target_assign
  inputs: (Tensor Anchor, Tensor GtBoxes, Tensor GtLabels, Tensor IsCrowd, Tensor
    ImInfo)
  attrs: (float positive_overlap, float negative_overlap, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(LocationIndex), Tensor(ScoreIndex), Tensor(TargetBBox), Tensor(TargetLabel),
    Tensor(BBoxInsideWeight), Tensor(ForegroundNumber)

- op: reverse
  inputs: (Tensor x)
  attrs: (int[] axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: rmsprop_
  inputs: (Tensor param, Tensor mean_square, Tensor grad, Tensor moment, Tensor learning_rate,
    Tensor mean_grad, Tensor master_param)
  attrs: (float epsilon, float decay, float momentum, bool centered, bool multi_precision,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(moment_out), Tensor(mean_square_out), Tensor(mean_grad_out),
    Tensor(master_param_outs)
  optionals: mean_grad,master_param,master_param_outs

- op: rnn
  inputs: (Tensor x, Tensor[] pre_state, Tensor[] weight_list, Tensor sequence_length)
  attrs: (float dropout_prob, bool is_bidirec, int input_size, int hidden_size, int
    num_layers, str mode, int seed, bool is_test, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(dropout_state_out), Tensor[](state), Tensor(reserve)
  optionals: sequence_length,dropout_state_out

- op: roi_align
  inputs: (Tensor x, Tensor boxes, Tensor boxes_num)
  attrs: (int pooled_height, int pooled_width, float spatial_scale, int sampling_ratio,
    bool aligned, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: boxes_num

- op: roi_pool
  inputs: (Tensor x, Tensor boxes, Tensor boxes_num)
  attrs: (int pooled_height, int pooled_width, float spatial_scale, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(arg_max)
  optionals: boxes_num

- op: roll
  inputs: (Tensor x, Tensor ShiftsTensor)
  attrs: (int64_t[] shifts, int64_t[] axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ShiftsTensor

- op: round
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: round_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: row_conv
  inputs: (Tensor x, Tensor filter)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: rpn_target_assign
  inputs: (Tensor Anchor, Tensor GtBoxes, Tensor IsCrowd, Tensor ImInfo)
  attrs: (int rpn_batch_size_per_im, float rpn_straddle_thresh, float rpn_positive_overlap,
    float rpn_negative_overlap, float rpn_fg_fraction, bool use_random, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(LocationIndex), Tensor(ScoreIndex), Tensor(TargetBBox), Tensor(TargetLabel),
    Tensor(BBoxInsideWeight)

- op: rrelu
  inputs: (Tensor x)
  attrs: (bool is_test, float lower, float upper, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(noise)

- op: rsqrt
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: rsqrt_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: run_program
  inputs: (Tensor[] X, Tensor[] Params)
  attrs: (BLOCK global_block, int64_t start_op_index, int64_t end_op_index, bool is_test,
    bool in_pir_pt_mode, int64_t program_id, str cuda_graph_capture_mode, int64_t
    cuda_graph_pool_id, bool use_interpretorcore, BLOCK forward_global_block, BLOCK
    backward_global_block, str[] param_grad_names, str[] out_grad_names, str[] x_names,
    str[] x_grad_names, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor[](Out), Tensor(OutScope), Tensor[](DOut), Tensor(CUDAGraph)
  optionals: Params,DOut,CUDAGraph

- op: sampling_id
  inputs: (Tensor X)
  attrs: (float min, float max, int seed, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: save
  inputs: (Tensor X)
  attrs: (bool overwrite, bool save_as_fp16, str file_path, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(kLookupTablePath)
  optionals: kLookupTablePath

- op: save_combine
  inputs: (Tensor[] x)
  attrs: (bool overwrite, bool save_as_fp16, str file_path, bool save_to_memory, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Y)
  optionals: Y

- op: scale
  inputs: (Tensor x, Tensor ScaleTensor)
  attrs: (float scale, float bias, bool bias_after_scale, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ScaleTensor

- op: scale_
  inputs: (Tensor x, Tensor ScaleTensor)
  attrs: (float scale, float bias, bool bias_after_scale, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ScaleTensor
  inpalces: x->out

- op: scatter
  inputs: (Tensor x, Tensor index, Tensor updates)
  attrs: (bool overwrite, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: scatter_
  inputs: (Tensor x, Tensor index, Tensor updates)
  attrs: (bool overwrite, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: scatter_nd_add
  inputs: (Tensor x, Tensor index, Tensor updates)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: searchsorted
  inputs: (Tensor sorted_sequence, Tensor values)
  attrs: (bool out_int32, bool right, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: seed
  inputs: ()
  attrs: (int seed, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: segment_pool
  inputs: (Tensor x, Tensor segment_ids)
  attrs: (str pooltype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(summed_ids)

- op: self_dp_attention
  inputs: (Tensor x)
  attrs: (float alpha, int head_number, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: selu
  inputs: (Tensor x)
  attrs: (float scale, float alpha, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: send_and_recv
  inputs: (Tensor[] X)
  attrs: (str message_name, str mode, str[] send_var_name, str[] recv_var_name, int
    trainer_id, str[] endpoints, str[] next_endpoints, str[] previous_endpoints, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor[](Out)

- op: send_v2
  inputs: (Tensor x)
  attrs: (int ring_id, int peer, bool use_calc_stream, bool dynamic_shape, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: sequence_concat
  inputs: (Tensor[] X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_conv
  inputs: (Tensor X, Tensor PaddingData, Tensor Filter)
  attrs: (bool paddingTrainable, int contextLength, int contextStart, int contextStride,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: PaddingData

- op: sequence_enumerate
  inputs: (Tensor X)
  attrs: (int win_size, int pad_value, bool ALL_KERNELS_MUST_COMPUTE_RUNTIME_SHAPE,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_erase
  inputs: (Tensor X)
  attrs: (int[] tokens, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_expand
  inputs: (Tensor X, Tensor Y)
  attrs: (int ref_level, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_expand_as
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_mask
  inputs: (Tensor x, Tensor MaxLenTensor)
  attrs: (int max_len, int out_dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(y)
  optionals: MaxLenTensor

- op: sequence_pad
  inputs: (Tensor X, Tensor PadValue)
  attrs: (int padded_length, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(Length)

- op: sequence_pool
  inputs: (Tensor X)
  attrs: (bool is_test, str pooltype, float pad_value, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(MaxIndex)

- op: sequence_reshape
  inputs: (Tensor X)
  attrs: (int new_dim, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_reverse
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: sequence_scatter
  inputs: (Tensor X, Tensor Ids, Tensor Updates)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_slice
  inputs: (Tensor X, Tensor Offset, Tensor Length)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_softmax
  inputs: (Tensor X)
  attrs: (bool use_cudnn, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sequence_unpad
  inputs: (Tensor X, Tensor Length)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: set_value
  inputs: (Tensor x, Tensor ValueTensor, Tensor[] StartsTensorList, Tensor[] EndsTensorList,
    Tensor[] StepsTensorList)
  attrs: (int dtype, int64_t[] axes, int64_t[] starts, int64_t[] ends, int64_t[] steps,
    int64_t[] decrease_axes, int64_t[] none_axes, Scalar[] values, int64_t[] shape,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ValueTensor,StartsTensorList,EndsTensorList,StepsTensorList

- op: set_value_
  inputs: (Tensor x, Tensor ValueTensor, Tensor[] StartsTensorList, Tensor[] EndsTensorList,
    Tensor[] StepsTensorList)
  attrs: (int dtype, int64_t[] axes, int64_t[] starts, int64_t[] ends, int64_t[] steps,
    int64_t[] decrease_axes, int64_t[] none_axes, Scalar[] values, int64_t[] shape,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ValueTensor,StartsTensorList,EndsTensorList,StepsTensorList
  inpalces: x->out

- op: sgd_
  inputs: (Tensor param, Tensor learning_rate, Tensor grad, Tensor master_param)
  attrs: (bool multi_precision, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(master_param_out)
  optionals: master_param,master_param_out

- op: shadow_output
  inputs: (Tensor x)
  attrs: (str name, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: shape
  inputs: (Tensor input)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: shard_index
  inputs: (Tensor input)
  attrs: (int index_num, int nshards, int shard_id, int ignore_value, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: share_buffer
  inputs: (Tensor[] x)
  attrs: (BOOLEANS share_dims_and_dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](out), Tensor[](xout)

- op: share_data
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: shuffle_batch
  inputs: (Tensor x, Tensor seed)
  attrs: (int startup_seed, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(shuffle_idx), Tensor(seed_out)

- op: shuffle_channel
  inputs: (Tensor X)
  attrs: (int group, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sigmoid
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sigmoid_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: sigmoid_cross_entropy_with_logits
  inputs: (Tensor x, Tensor label, Tensor pos_weight)
  attrs: (bool normalize, int ignore_index, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: pos_weight

- op: sigmoid_cross_entropy_with_logits_
  inputs: (Tensor x, Tensor label, Tensor pos_weight)
  attrs: (bool normalize, int ignore_index, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: pos_weight
  inpalces: x->out

- op: sign
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: silu
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: similarity_focus
  inputs: (Tensor X)
  attrs: (int axis, int[] indexes, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sin
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sin_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: sinh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sinh_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: numel
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(size)

- op: skip_layernorm
  inputs: (Tensor x, Tensor y, Tensor scale, Tensor bias)
  attrs: (float epsilon, int begin_norm_axis, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: slice
  inputs: (Tensor input, Tensor StartsTensor, Tensor EndsTensor, Tensor[] StartsTensorList,
    Tensor[] EndsTensorList)
  attrs: (int[] axes, int[] starts, int[] ends, int[] infer_flags, int[] decrease_axis,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: StartsTensor,EndsTensor,StartsTensorList,EndsTensorList

- op: slogdet
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: soft_relu
  inputs: (Tensor x)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: soft_relu_
  inputs: (Tensor x)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: softmax
  inputs: (Tensor x)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: softmax_
  inputs: (Tensor x)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: cross_entropy_with_softmax
  inputs: (Tensor input, Tensor label)
  attrs: (bool soft_label, bool use_softmax, bool numeric_stable_mode, int ignore_index,
    int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(softmax), Tensor(loss)

- op: softmax_with_cross_entropy_
  inputs: (Tensor input, Tensor label)
  attrs: (bool soft_label, bool use_softmax, bool numeric_stable_mode, int ignore_index,
    int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(softmax), Tensor(loss)
  inpalces: input->softmax

- op: softplus
  inputs: (Tensor x)
  attrs: (float beta, float threshold, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: softshrink
  inputs: (Tensor x)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: softsign
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: solve
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_conv3d
  inputs: (Tensor x, Tensor kernel)
  attrs: (int[] paddings, int[] dilations, int[] strides, int groups, bool subm, str
    key, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(rulebook), Tensor(counter)

- op: sparse_maxpool
  inputs: (Tensor x)
  attrs: (int[] kernel_sizes, int[] paddings, int[] dilations, int[] strides, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(rulebook), Tensor(counter)

- op: sparse_momentum
  inputs: (Tensor param, Tensor grad, Tensor velocity, Tensor index, Tensor axis,
    Tensor learning_rate, Tensor master_param)
  attrs: (float mu, bool use_nesterov, str regularization_method, float regularization_coeff,
    bool multi_precision, float rescale_grad, int axis, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(velocity_out), Tensor(master_param_out)
  optionals: axis,master_param,master_param_out

- op: spectral_norm
  inputs: (Tensor weight, Tensor u, Tensor v)
  attrs: (int dim, int power_iters, float eps, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: split
  inputs: (Tensor x, Tensor AxisTensor, Tensor[] SectionsTensorList)
  attrs: (int[] sections, int num, int axis, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](out)
  optionals: AxisTensor,SectionsTensorList

- op: spp
  inputs: (Tensor X)
  attrs: (int pyramid_height, str pooling_type, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sqrt
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sqrt_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: square
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: squared_l2_norm
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: squeeze
  inputs: (Tensor x)
  attrs: (int[] axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)

- op: squeeze2_
  inputs: (Tensor x)
  attrs: (int[] axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)
  inpalces: x->out

- op: stack
  inputs: (Tensor[] x)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: stanh
  inputs: (Tensor x)
  attrs: (float scale_a, float scale_b, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: stft
  inputs: (Tensor X, Tensor Window)
  attrs: (int n_fft, int hop_length, bool normalized, bool onesided, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: strided_slice
  inputs: (Tensor x, Tensor StartsTensor, Tensor[] StartsTensorList, Tensor EndsTensor,
    Tensor[] EndsTensorList, Tensor StridesTensor, Tensor[] StridesTensorList)
  attrs: (int[] axes, int[] starts, int[] ends, int[] strides, int[] infer_flags,
    int[] decrease_axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: StartsTensor,StartsTensorList,EndsTensor,EndsTensorList,StridesTensor,StridesTensorList

- op: add_n
  inputs: (Tensor[] inputs)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sum_
  inputs: (Tensor[] inputs)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: inputs->out

- op: svd
  inputs: (Tensor x)
  attrs: (bool full_matrices, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(u), Tensor(s), Tensor(vh)

- op: swish
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sync_batch_norm
  inputs: (Tensor x, Tensor scale, Tensor bias, Tensor mean, Tensor variance, Tensor
    MomentumTensor)
  attrs: (bool is_test, float momentum, float epsilon, str data_format, bool use_global_stats,
    bool trainable_statistics, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean_out), Tensor(variance_out), Tensor(saved_mean),
    Tensor(saved_variance), Tensor(reserve_space)
  optionals: scale,bias,MomentumTensor,reserve_space

- op: take_along_axis
  inputs: (Tensor arr, Tensor indices)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: tan
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: tan_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: tanh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: tanh_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: tanh_shrink
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: tdm_child
  inputs: (Tensor X, Tensor TreeInfo)
  attrs: (int child_nums, int dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Child), Tensor(LeafMask)

- op: tdm_sampler
  inputs: (Tensor x, Tensor travel, Tensor layer)
  attrs: (bool output_positive, int[] neg_samples_num_list, int[] layer_offset_lod,
    int seed, int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(labels), Tensor(mask)
  optionals: labels

- op: teacher_student_sigmoid_loss
  inputs: (Tensor X, Tensor Label)
  attrs: (float soft_max_up_bound, float soft_max_lower_bound, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: temporal_shift
  inputs: (Tensor x)
  attrs: (int seg_num, float shift_ratio, str data_format, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: tensor_unfold
  inputs: (Tensor input)
  attrs: (int64_t axis, int64_t size, int64_t step, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: thresholded_relu
  inputs: (Tensor x)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: thresholded_relu_
  inputs: (Tensor x)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: tile
  inputs: (Tensor x, Tensor RepeatTimes, Tensor[] repeat_times_tensor)
  attrs: (int[] repeat_times, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: RepeatTimes,repeat_times_tensor

- op: top_k
  inputs: (Tensor X, Tensor K)
  attrs: (int k, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(Indices)
  optionals: K

- op: topk
  inputs: (Tensor x, Tensor K)
  attrs: (int k, int axis, bool largest, bool sorted, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(indices)
  optionals: K

- op: trace
  inputs: (Tensor x)
  attrs: (int offset, int axis1, int axis2, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: transfer_dtype
  inputs: (Tensor X)
  attrs: (int out_dtype, int in_dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: transfer_layout
  inputs: (Tensor X)
  attrs: (int src_layout, int dst_layout, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: transpose
  inputs: (Tensor X)
  attrs: (int[] axis, bool use_mkldnn, str data_format, str mkldnn_data_type, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Out)

- op: transpose
  inputs: (Tensor x)
  attrs: (int[] perm, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(XShape)

- op: triangular_solve
  inputs: (Tensor x, Tensor y)
  attrs: (bool upper, bool transpose, bool unitriangular, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: tril_indices
  inputs: ()
  attrs: (int rows, int cols, int offset, int dtype, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: tril_triu
  inputs: (Tensor x)
  attrs: (int diagonal, bool lower, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: trilinear_interp
  inputs: (Tensor X, Tensor OutSize, Tensor[] SizeTensor, Tensor Scale)
  attrs: (str data_layout, int out_d, int out_h, int out_w, float scale, str interp_method,
    bool align_corners, int align_mode, bool use_mkldnn, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)
  optionals: OutSize,SizeTensor,Scale

- op: trilinear_interp
  inputs: (Tensor x, Tensor out_size, Tensor[] size_tensor, Tensor scale_tensor)
  attrs: (str data_format, int out_d, int out_h, int out_w, float[] scale, str interp_method,
    bool align_corners, int align_mode, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output)
  optionals: out_size,size_tensor,scale_tensor

- op: triu_indices
  inputs: ()
  attrs: (int row, int col, int offset, int dtype, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: trunc
  inputs: (Tensor input)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: trunc_
  inputs: (Tensor input)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: input->out

- op: truncated_gaussian_random
  inputs: ()
  attrs: (int[] shape, float mean, float std, int seed, int dtype, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: unbind
  inputs: (Tensor input)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor[](out)

- op: unfold
  inputs: (Tensor x)
  attrs: (int[] kernel_sizes, int[] strides, int[] paddings, int[] dilations, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: uniform
  inputs: (Tensor ShapeTensor, Tensor[] ShapeTensorList)
  attrs: (int64_t[] shape, int dtype, float min, float max, int seed, int diag_num,
    int diag_step, float diag_val, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ShapeTensor,ShapeTensorList

- op: uniform_random_batch_size_like
  inputs: (Tensor input)
  attrs: (int[] shape, int input_dim_idx, int output_dim_idx, float min, float max,
    int seed, int diag_num, int diag_step, float diag_val, int dtype, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: uniform_inplace
  inputs: (Tensor x)
  attrs: (float min, float max, int seed, int diag_num, int diag_step, float diag_val,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: uniform_random_inplace_
  inputs: (Tensor x)
  attrs: (float min, float max, int seed, int diag_num, int diag_step, float diag_val,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: unique
  inputs: (Tensor x)
  attrs: (bool return_index, bool return_inverse, bool return_counts, int[] axis,
    int dtype, bool is_sorted, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(indices), Tensor(inverse), Tensor(counts)
  optionals: indices,counts

- op: unique_consecutive
  inputs: (Tensor x)
  attrs: (bool return_inverse, bool return_counts, int[] axis, int dtype, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(index), Tensor(counts)
  optionals: index,counts

- op: unique_with_counts
  inputs: (Tensor X)
  attrs: (int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(Index), Tensor(Count)

- op: unpool
  inputs: (Tensor x, Tensor indices)
  attrs: (int[] ksize, str unpooling_type, int[] strides, int[] padding, int[] output_size,
    str data_format, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: unpool3d
  inputs: (Tensor x, Tensor indices)
  attrs: (int[] ksize, int[] strides, int[] paddings, int[] output_size, str data_format,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)

- op: unsqueeze
  inputs: (Tensor x, Tensor AxesTensor, Tensor[] AxesTensorList)
  attrs: (int[] axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)
  optionals: AxesTensor,AxesTensorList

- op: unsqueeze2_
  inputs: (Tensor x, Tensor AxesTensor, Tensor[] AxesTensorList)
  attrs: (int[] axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(xshape)
  optionals: AxesTensor,AxesTensorList
  inpalces: x->out

- op: unstack
  inputs: (Tensor x)
  attrs: (int axis, int num, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](out)

- op: unzip
  inputs: (Tensor X, Tensor lod)
  attrs: (int len, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: update_loss_scaling_
  inputs: (Tensor[] x, Tensor found_infinite, Tensor prev_loss_scaling, Tensor in_good_steps,
    Tensor in_bad_steps, Tensor StopUpdate)
  attrs: (int incr_every_n_steps, int decr_every_n_nan_or_inf, float incr_ratio, float
    decr_ratio, bool stop_update, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](out), Tensor(loss_scaling), Tensor(out_good_steps), Tensor(out_bad_steps)
  optionals: StopUpdate

- op: var_conv_2d
  inputs: (Tensor X, Tensor ROW, Tensor COLUMN, Tensor W)
  attrs: (int InputChannel, int OutputChannel, int StrideH, int StrideW, int KernelH,
    int KernelW, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(Col)

- op: view_dtype
  inputs: (Tensor input)
  attrs: (int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: view_shape
  inputs: (Tensor input)
  attrs: (int64_t[] dims, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: viterbi_decode
  inputs: (Tensor potentials, Tensor transition_params, Tensor lengths)
  attrs: (bool include_bos_eos_tag, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(scores), Tensor(path)

- op: warpctc
  inputs: (Tensor logits, Tensor label, Tensor logits_length, Tensor labels_length)
  attrs: (int blank, bool norm_by_times, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(loss), Tensor(warpctcgrad)
  optionals: logits_length,labels_length

- op: warprnnt
  inputs: (Tensor input, Tensor label, Tensor input_lengths, Tensor label_lengths)
  attrs: (int blank, float fastemit_lambda, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(loss), Tensor(warprnntgrad)

- op: weight_quantize
  inputs: (Tensor x)
  attrs: (str algo, int arch, int group_size, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(scale)

- op: weighted_sample_neighbors
  inputs: (Tensor row, Tensor colptr, Tensor edge_weight, Tensor input_nodes, Tensor
    eids)
  attrs: (int sample_size, bool return_eids, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out_neighbors), Tensor(out_count), Tensor(out_eids)
  optionals: eids

- op: where
  inputs: (Tensor condition, Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: where_
  inputs: (Tensor condition, Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: nonzero
  inputs: (Tensor condition)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: yolo_box
  inputs: (Tensor x, Tensor img_size)
  attrs: (int[] anchors, int class_num, float conf_thresh, int downsample_ratio, bool
    clip_bbox, float scale_x_y, bool iou_aware, float iou_aware_factor, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(boxes), Tensor(scores)

- op: yolo_box_head
  inputs: (Tensor X)
  attrs: (int[] anchors, int class_num, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: yolo_box_post
  inputs: (Tensor Boxes0, Tensor Boxes1, Tensor Boxes2, Tensor ImageShape, Tensor
    ImageScale)
  attrs: (int[] anchors0, int[] anchors1, int[] anchors2, int class_num, float conf_thresh,
    int downsample_ratio0, int downsample_ratio1, int downsample_ratio2, bool clip_bbox,
    float scale_x_y, float nms_threshold, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(NmsRoisNum)

- op: yolo_loss
  inputs: (Tensor x, Tensor gt_box, Tensor gt_label, Tensor gt_score)
  attrs: (int[] anchors, int[] anchor_mask, int class_num, float ignore_thresh, int
    downsample_ratio, bool use_label_smooth, float scale_x_y, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(loss), Tensor(objectness_mask), Tensor(gt_match_mask)
  optionals: gt_score

- op: reorder_lod_tensor_by_rank
  inputs: (Tensor X, Tensor RankTable)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_bias_residual_layernorm
  inputs: (Tensor x, Tensor bias, Tensor residual, Tensor norm_weight, Tensor norm_bias)
  attrs: (float epsilon, float residual_alpha, int begin_norm_axis, float quant_scale,
    int quant_round_type, float quant_max_bound, float quant_min_bound, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(residual_out), Tensor(mean), Tensor(variance)
  optionals: bias,residual,norm_weight,norm_bias,residual_out

- op: split_lod_tensor
  inputs: (Tensor X, Tensor Mask)
  attrs: (int level, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(OutTrue), Tensor(OutFalse)

- op: embedding_with_eltwise_add_xpu
  inputs: (Tensor[] ids, Tensor[] tables, Tensor mask)
  attrs: (int64_t padding_idx, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(seq_lod), Tensor(max_seq_len)
  optionals: mask,seq_lod,max_seq_len

- op: sparse_leaky_relu
  inputs: (Tensor x)
  attrs: (float alpha, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: block_multihead_attention
  inputs: (Tensor qkv, Tensor key_cache, Tensor value_cache, Tensor seq_lens_encoder,
    Tensor seq_lens_decoder, Tensor seq_lens_this_time, Tensor padding_offsets, Tensor
    cum_offsets, Tensor cu_seqlens_q, Tensor cu_seqlens_k, Tensor block_tables, Tensor
    pre_key_cache, Tensor pre_value_cache, Tensor rope_emb, Tensor mask, Tensor tgt_mask,
    Tensor cache_k_quant_scales, Tensor cache_v_quant_scales, Tensor cache_k_dequant_scales,
    Tensor cache_v_dequant_scales, Tensor qkv_out_scale, Tensor qkv_bias, Tensor out_shift,
    Tensor out_smooth)
  attrs: (int max_seq_len, int block_size, bool use_neox_style, bool dynamic_cachekv_quant,
    int quant_round_type, float quant_max_bound, float quant_min_bound, float out_scale,
    str compute_dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(fmha_out), Tensor(qkv_out), Tensor(key_cache_out), Tensor(value_cache_out)
  optionals: pre_key_cache,pre_value_cache,rope_emb,mask,tgt_mask,cache_k_quant_scales,cache_v_quant_scales,cache_k_dequant_scales,cache_v_dequant_scales,qkv_out_scale,qkv_bias,out_shift,out_smooth

- op: masked_multihead_attention
  inputs: (Tensor x, Tensor cache_kv, Tensor bias, Tensor src_mask, Tensor cum_offsets,
    Tensor sequence_lengths, Tensor rotary_tensor, Tensor beam_cache_offset, Tensor
    qkv_out_scale, Tensor out_shift, Tensor out_smooth)
  attrs: (int seq_len, int rotary_emb_dims, bool use_neox_rotary_style, str compute_dtype,
    float out_scale, int quant_round_type, float quant_max_bound, float quant_min_bound,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(cache_kv_out), Tensor(beam_cache_offset_out)
  optionals: bias,src_mask,cum_offsets,sequence_lengths,rotary_tensor,beam_cache_offset,qkv_out_scale,out_shift,out_smooth

- op: sparse_indices
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: conditional_block_infer
  inputs: (Tensor[] Cond, Tensor[] Input)
  attrs: (BLOCK sub_block, bool is_scalar_condition, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out), Tensor(Scope)

- op: flash_attn
  inputs: (Tensor q, Tensor k, Tensor v, Tensor fixed_seed_offset, Tensor attn_mask)
  attrs: (float dropout, bool causal, bool return_softmax, bool is_test, str rng_name,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(softmax), Tensor(softmax_lse), Tensor(seed_offset)
  optionals: fixed_seed_offset,attn_mask

- op: gt_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: fused_dconv_drelu_dbn
  inputs: (Tensor grad_output, Tensor weight, Tensor grad_output_add, Tensor residual_input,
    Tensor bn1_eqscale, Tensor bn1_eqbias, Tensor conv_input, Tensor bn1_mean, Tensor
    bn1_inv_std, Tensor bn1_gamma, Tensor bn1_beta, Tensor bn1_input, Tensor bn2_mean,
    Tensor bn2_inv_std, Tensor bn2_gamma, Tensor bn2_beta, Tensor bn2_input)
  attrs: (int[] paddings, int[] dilations, int[] strides, str padding_algorithm, int
    groups, str data_format, bool fuse_shortcut, bool fuse_dual, bool fuse_add, bool
    exhaustive_search, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(grad_weight), Tensor(grad_bn1_input), Tensor(grad_bn1_gamma), Tensor(grad_bn1_beta),
    Tensor(grad_bn2_input), Tensor(grad_bn2_gamma), Tensor(grad_bn2_beta)
  optionals: grad_output_add,residual_input,bn1_eqscale,bn1_eqbias,conv_input,bn2_mean,bn2_inv_std,bn2_gamma,bn2_beta,bn2_input,grad_bn2_input,grad_bn2_gamma,grad_bn2_beta

- op: recurrent
  inputs: (Tensor[] inputs, Tensor[] initial_states, Tensor[] parameters)
  attrs: (bool has_states, str[] ex_states, str[] states, BLOCK sub_block, bool reverse,
    bool is_train, str[] skip_eager_deletion_vars, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](outputs), Tensor(step_scopes)

- op: gen_nccl_id
  inputs: ()
  attrs: (str[] trainers, int trainer_id, int nccl_comm_num, bool use_hierarchical_allreduce,
    int hierarchical_allreduce_inter_nranks, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(NCCLID)

- op: sparse_relu6
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fused_scale_bias_add_relu
  inputs: (Tensor x1, Tensor scale1, Tensor bias1, Tensor x2, Tensor scale2, Tensor
    bias2)
  attrs: (bool fuse_dual, bool exhaustive_search, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: scale2,bias2

- op: sparse_atan
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_sinh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fused_dropout_add
  inputs: (Tensor x, Tensor y, Tensor seed_tensor, Tensor PTensor)
  attrs: (float p, bool is_test, str mode, int seed, bool fix_seed, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(seed_offset)
  optionals: seed_tensor,PTensor

- op: sparse_sync_batch_norm
  inputs: (Tensor x, Tensor mean, Tensor variance, Tensor scale, Tensor bias)
  attrs: (bool is_test, float momentum, float epsilon, str data_layout, bool use_global_stats,
    bool trainable_statistics, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean_out), Tensor(variance_out), Tensor(saved_mean),
    Tensor(saved_variance), Tensor(reserve_space)

- op: max_pool2d_v2
  inputs: (Tensor x)
  attrs: (int[] kernel_size, int[] strides, int[] paddings, str data_format, bool
    global_pooling, bool adaptive, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(saved_idx)

- op: sparse_square
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: merge_lod_tensor
  inputs: (Tensor X, Tensor Mask, Tensor InTrue, Tensor InFalse)
  attrs: (int level, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: add_act_xpu
  inputs: (Tensor x, Tensor x_max, Tensor y, Tensor y_max)
  attrs: (int act_type, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_max)
  optionals: x_max,y_max

- op: sparse_scale
  inputs: (Tensor x)
  attrs: (float scale, float bias, bool bias_after_scale, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: quant_linear
  inputs: (Tensor x, Tensor w, Tensor bias)
  attrs: (int in_num_col_dims, str activation_type, bool padding_weights, float scale_in,
    float[] scale_weights, int quant_round_type, float quant_max_bound, float quant_min_bound,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias

- op: scatter_add_p
  inputs: (Tensor X, Tensor Y, Tensor IndexTensor)
  attrs: (int64_t axis, int64_t[] index, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Z)
  optionals: IndexTensor

- op: reshape_p
  inputs: (Tensor X)
  attrs: (int64_t[] shape, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: delete_var
  inputs: (Tensor[] X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: ''

- op: standard_gamma
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: listen_and_serv
  inputs: (Tensor[] X)
  attrs: (str endpoint, int pserver_id, str[] grad_to_block_id, int distributed_mode,
    bool dc_asgd, BLOCKS optimize_blocks, str[] prefetch_var_name_to_block_id, str[]
    sparse_grad_to_param, int Fanin, int checkpint_block_id, int lr_decay_block_id,
    int rpc_get_thread_num, int rpc_send_thread_num, int rpc_prefetch_thread_num,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: ''

- op: add_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: dist_concat
  inputs: (Tensor x)
  attrs: (int ring_id, int nranks, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: shrink_rnn_memory
  inputs: (Tensor X, Tensor RankTable, Tensor I)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_bias_act
  inputs: (Tensor x, Tensor bias, Tensor dequant_scales, Tensor shift, Tensor smooth)
  attrs: (str act_method, str compute_dtype, float quant_scale, int quant_round_type,
    float quant_max_bound, float quant_min_bound, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias,dequant_scales,shift,smooth

- op: rprop
  inputs: (Tensor param, Tensor grad, Tensor prev, Tensor learning_rate, Tensor master_param,
    Tensor learning_rate_range, Tensor etas)
  attrs: (bool multi_precision, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(param_out), Tensor(prev_out), Tensor(learning_rate_out), Tensor(master_param_out)
  optionals: master_param,master_param_out

- op: sparse_to_dense
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: dequantize_xpu
  inputs: (Tensor x)
  attrs: (int out_dtype, float scale, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(y)

- op: send_barrier
  inputs: (Tensor[] X)
  attrs: (int trainer_id, str[] endpoints, bool half_async, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: div_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: sparse_fused_attention
  inputs: (Tensor query, Tensor key, Tensor value, Tensor sparse_mask, Tensor key_padding_mask,
    Tensor attn_mask)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(softmax)
  optionals: key_padding_mask,attn_mask

- op: array_to_lod_tensor
  inputs: (Tensor X, Tensor RankTable)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: conv2d_xpu
  inputs: (Tensor x, Tensor x_max, Tensor filter, Tensor filter_max, Tensor bias,
    Tensor branch, Tensor branch_max, Tensor scale_max, Tensor out_max_in)
  attrs: (int[] paddings, int[] dilations, int[] strides, str padding_algorithm, int
    groups, int act_type, float act_param, int out_dtype, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_max)
  optionals: x_max,bias,branch,branch_max,scale_max,out_max_in

- op: transpose_p
  inputs: (Tensor X)
  attrs: (int64_t[] axis, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: conv2d_transpose_xpu
  inputs: (Tensor x, Tensor x_max, Tensor filter, Tensor filter_max, Tensor bias,
    Tensor OutputSizeTensor, Tensor[] OutputSizeTensorList)
  attrs: (int[] strides, int[] paddings, int[] output_padding, int64_t[] output_size,
    str padding_algorithm, int groups, int[] dilations, str data_format, bool has_bias,
    bool with_act, str act_type, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_max)
  optionals: x_max,bias,OutputSizeTensor,OutputSizeTensorList

- op: squeeze_excitation_block
  inputs: (Tensor x, Tensor filter, Tensor filter_max, Tensor bias, Tensor branch)
  attrs: (int[] act_type, float[] act_param, int[] filter_dims, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias,branch

- op: fused_multi_transformer_xpu
  inputs: (Tensor x, Tensor[] ln_scale, Tensor[] ln_bias, Tensor[] qkvw, Tensor[]
    qkvw_max, Tensor[] qkv_bias, Tensor[] out_linear_w, Tensor[] out_linear_wmax,
    Tensor[] out_linear_bias, Tensor[] ffn_ln_scale, Tensor[] ffn_ln_bias, Tensor[]
    ffn1_weight, Tensor[] ffn1_weight_max, Tensor[] ffn1_bias, Tensor[] ffn2_weight,
    Tensor[] ffn2_weight_max, Tensor[] ffn2_bias, Tensor[] cache_kv, Tensor[] pre_caches,
    Tensor rotary_pos_emb, Tensor time_step, Tensor seq_lengths, Tensor src_mask,
    Tensor gather_index, Tensor max_buffer)
  attrs: (bool pre_layer_norm, int rotary_emb_dims, float epsilon, float dropout_rate,
    bool is_test, str dropout_implementation, str act_method, bool trans_qkvw, int
    ring_id, int gather_axis, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor[](cache_kv_out)
  optionals: cache_kv,pre_caches,rotary_pos_emb,time_step,seq_lengths,src_mask,gather_index

- op: sparse_cast
  inputs: (Tensor x)
  attrs: (int index_dtype, int value_dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: c_comm_init_multitrainer
  inputs: (Tensor X)
  attrs: (int ntrainers, int trainer_id, int[] devices, int ring_id, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: memory_efficient_attention
  inputs: (Tensor query, Tensor key, Tensor value, Tensor bias, Tensor cu_seqlens_q,
    Tensor cu_seqlens_k, Tensor causal_diagonal, Tensor seqlen_k, Tensor MaxSeqlenQTensor,
    Tensor MaxSeqlenKTensor)
  attrs: (float max_seqlen_q, float max_seqlen_k, bool causal, double dropout_p, float
    scale, bool is_test, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(output), Tensor(logsumexp), Tensor(seed_and_offset)
  optionals: bias,cu_seqlens_q,cu_seqlens_k,causal_diagonal,seqlen_k,MaxSeqlenQTensor,MaxSeqlenKTensor

- op: fused_conv2d_add_act
  inputs: (Tensor input, Tensor filter, Tensor bias, Tensor residual_data)
  attrs: (int[] strides, int[] paddings, str padding_algorithm, int[] dilations, int
    groups, str data_format, str activation, int[] split_channels, bool exhaustive_search,
    int workspace_size_MB, float fuse_alpha, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(output), Tensor[](outputs)
  optionals: bias,residual_data,outputs

- op: dequeue
  inputs: ()
  attrs: (str queue_name, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: sqrt_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: sparse_reshape
  inputs: (Tensor x, Tensor ShapeTensor, Tensor[] ShapeTensorList)
  attrs: (int64_t[] shape, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ShapeTensor,ShapeTensorList

- op: sub_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: fused_rotary_position_embedding
  inputs: (Tensor q, Tensor k, Tensor v, Tensor sin, Tensor cos, Tensor position_ids)
  attrs: (bool use_neox_rotary_style, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out_q), Tensor(out_k), Tensor(out_v)
  optionals: k,v,sin,cos,position_ids,out_k,out_v

- op: conditional_block
  inputs: (Tensor[] Cond, Tensor[] Input)
  attrs: (BLOCK sub_block, bool is_scalar_condition, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out), Tensor(Scope)

- op: select_input
  inputs: (Tensor[] X, Tensor Mask)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: exp_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: enqueue
  inputs: (Tensor X)
  attrs: (str queue_name, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: sparse_divide_scalar
  inputs: (Tensor x)
  attrs: (float scalar, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cast_p
  inputs: (Tensor X)
  attrs: (int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: uniform_random_p
  inputs: ()
  attrs: (int64_t[] shape, float min, float max, int seed, int dtype, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: variable_length_memory_efficient_attention
  inputs: (Tensor query, Tensor key, Tensor value, Tensor seq_lens, Tensor kv_seq_lens,
    Tensor mask)
  attrs: (float scale, bool causal, int pre_cache_length, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: mask

- op: c_comm_init
  inputs: (Tensor X)
  attrs: (int nranks, int rank, int device_id, int ring_id, str endpoints, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: sparse_abs
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: cos_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: fast_where_xpu
  inputs: (Tensor condition, Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: slice_assign_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int64_t[] axis, int64_t[] starts, int64_t[] ends, int64_t[] strides, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Z)

- op: split_p
  inputs: (Tensor X)
  attrs: (int64_t axis, int64_t[] num_or_sections, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](YS)

- op: multi_encoder_xpu
  inputs: (Tensor x, Tensor[] fc_weight, Tensor[] fc_weight_max, Tensor[] fc_bias,
    Tensor[] ln_scale, Tensor[] ln_bias, Tensor mask, Tensor seq_lod, Tensor max_seq_len)
  attrs: (int layer_num, bool norm_before, int hidden_dim, int head_num, int size_per_head,
    int ffn_hidden_dim_scale, int act_type, int relative_type, int slice_idx, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(out), Tensor(x_fp16), Tensor(out_fp16)
  optionals: mask,seq_lod,max_seq_len,x_fp16,out_fp16

- op: generate_sequence_xpu
  inputs: (Tensor x)
  attrs: (int dtype, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: top_p_sampling
  inputs: (Tensor x, Tensor ps, Tensor threshold)
  attrs: (int seed, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(ids)
  optionals: threshold

- op: send
  inputs: (Tensor[] X)
  attrs: (int table_id, int is_sparse, str[] send_varnames, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: sparse_divide
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lod_rank_table
  inputs: (Tensor X)
  attrs: (int level, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sparse_attention
  inputs: (Tensor Q, Tensor K, Tensor V, Tensor Offset, Tensor Columns, Tensor KeyPaddingMask,
    Tensor AttnMask)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out), Tensor(SparseDotSdd), Tensor(Softmax)
  optionals: KeyPaddingMask,AttnMask

- op: tanh_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: sparse_addmm
  inputs: (Tensor input, Tensor x, Tensor y)
  attrs: (float beta, float alpha, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_log1p
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lod_array_length
  inputs: (Tensor|TensorArray? x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: lod_tensor_to_array
  inputs: (Tensor X, Tensor RankTable)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor|TensorArray?(Out)

- op: write_to_array
  inputs: (Tensor x, Tensor i)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor|TensorArray?(out)

- op: fused_dot_product_attention
  inputs: (Tensor q, Tensor k, Tensor v, Tensor mask)
  attrs: (float scaling_factor, float dropout_probability, bool is_training, bool
    is_causal_masking, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(softmax_out), Tensor(rng_state)

- op: binomial
  inputs: (Tensor count, Tensor prob)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: pylayer
  inputs: (Tensor[] Input)
  attrs: (BLOCKS blocks, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor[](Out), Tensor(Scope)

- op: llm_int8_linear
  inputs: (Tensor x, Tensor weight, Tensor bias, Tensor weight_scale)
  attrs: (float threshold, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias

- op: sparse_coalesce
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: reduce_sum_p
  inputs: (Tensor X)
  attrs: (int64_t[] axis, bool keepdim, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: fused_scale_bias_relu_conv_bn
  inputs: (Tensor x, Tensor w, Tensor scale, Tensor bias, Tensor bn_scale, Tensor
    bn_bias, Tensor input_running_mean, Tensor input_running_var)
  attrs: (int[] paddings, int[] dilations, int[] strides, str padding_algorithm, int
    groups, str data_format, float momentum, float epsilon, bool fuse_prologue, bool
    exhaustive_search, int64_t accumulation_count, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_running_mean), Tensor(out_running_var), Tensor(saved_mean),
    Tensor(saved_var), Tensor(eq_scale), Tensor(eq_bias)
  optionals: scale,bias

- op: sparse_asinh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: conv1d_xpu
  inputs: (Tensor x, Tensor x_max, Tensor filter, Tensor filter_max, Tensor bias,
    Tensor branch, Tensor branch_max)
  attrs: (int[] paddings, str padding_algorithm, int dilations, int strides, int groups,
    int act_type, float act_param, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_max)
  optionals: x_max,bias,branch,branch_max

- op: flash_attn_unpadded
  inputs: (Tensor q, Tensor k, Tensor v, Tensor cu_seqlens_q, Tensor cu_seqlens_k,
    Tensor fixed_seed_offset, Tensor attn_mask)
  attrs: (int64_t max_seqlen_q, int64_t max_seqlen_k, float scale, float dropout,
    bool causal, bool return_softmax, bool is_test, str rng_name, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(softmax), Tensor(softmax_lse), Tensor(seed_offset)
  optionals: fixed_seed_offset,attn_mask

- op: mul_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: sparse_tanh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_masked_matmul
  inputs: (Tensor x, Tensor y, Tensor mask)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_acos
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_atanh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_to_sparse_coo
  inputs: (Tensor x)
  attrs: (int64_t sparse_dim, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sin_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: c_gen_xccl_id
  inputs: ()
  attrs: (str endpoint, str[] other_endpoints, int rank, int ring_id, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sparse_matmul
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: merge_lod_tensor_infer
  inputs: (Tensor X, Tensor Mask, Tensor InTrue, Tensor InFalse)
  attrs: (int level, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: fused_multi_transformer_int8_xpu
  inputs: (Tensor x, Tensor[] ln_scale, Tensor[] ln_bias, Tensor[] qkv_in_max, Tensor[]
    qkvw, Tensor[] qkv_bias, Tensor[] qkv_scales, Tensor[] out_linear_in_max, Tensor[]
    out_linear_w, Tensor[] out_linear_bias, Tensor[] out_linear_scales, Tensor[] ffn_ln_scale,
    Tensor[] ffn_ln_bias, Tensor[] ffn1_in_max, Tensor[] ffn1_weight, Tensor[] ffn1_bias,
    Tensor[] ffn1_scales, Tensor[] ffn2_in_max, Tensor[] ffn2_weight, Tensor[] ffn2_bias,
    Tensor[] ffn2_scales, Tensor[] cache_kv, Tensor[] pre_caches, Tensor rotary_pos_emb,
    Tensor time_step, Tensor seq_lengths, Tensor src_mask, Tensor gather_index, Tensor
    max_buffer)
  attrs: (bool pre_layer_norm, int rotary_emb_dims, float epsilon, float dropout_rate,
    bool is_test, str dropout_implementation, str act_method, bool trans_qkvw, int
    ring_id, int gather_axis, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor[](cache_kv_out)
  optionals: cache_kv,pre_caches,rotary_pos_emb,time_step,seq_lengths,src_mask,gather_index

- op: queue_generator
  inputs: ()
  attrs: (str[] names, int capacity, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: bn_act_xpu
  inputs: (Tensor x, Tensor mean, Tensor variance, Tensor scale, Tensor bias)
  attrs: (float momentum, float epsilon, str data_format, int act_type, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: max_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: c_comm_init_all
  inputs: ()
  attrs: (int[] devices, int ring_id, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: slice_select_p
  inputs: (Tensor X)
  attrs: (int64_t[] axis, int64_t[] starts, int64_t[] ends, int64_t[] strides, int
    op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(Y)

- op: gather_p
  inputs: (Tensor X, Tensor IndexTensor)
  attrs: (int64_t axis, int64_t[] index, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)
  optionals: IndexTensor

- op: sparse_sqrt
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: add_layernorm_xpu
  inputs: (Tensor x, Tensor y, Tensor scale, Tensor bias)
  attrs: (int begin_norm_axis, float epsilon, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_acosh
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: while
  inputs: (Tensor[] X, Tensor[] Condition)
  attrs: (BLOCK sub_block, bool is_test, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out), Tensor(StepScopes)

- op: sparse_slice
  inputs: (Tensor x, Tensor AxesTensor, Tensor[] AxesTensorList, Tensor StartsTensor,
    Tensor[] StartsTensorList, Tensor EndsTensor, Tensor[] EndsTensorList)
  attrs: (int64_t[] axes, int64_t[] starts, int64_t[] ends, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: AxesTensor,AxesTensorList,StartsTensor,StartsTensorList,EndsTensor,EndsTensorList

- op: sparse_isnan
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: log_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: weight_only_linear
  inputs: (Tensor x, Tensor weight, Tensor bias, Tensor weight_scale)
  attrs: (str weight_dtype, int arch, int group_size, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: bias

- op: fill_constant_p
  inputs: ()
  attrs: (float value, int64_t[] shape, int dtype, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: sparse_expm1
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_asin
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fetch_barrier
  inputs: (Tensor[] X)
  attrs: (int trainer_id, str[] endpoints, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)
  optionals: X

- op: max_sequence_len
  inputs: (Tensor RankTable)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: sparse_softmax
  inputs: (Tensor x)
  attrs: (int axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_to_sparse_csr
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_add
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: rsqrt_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: sparse_values
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: rms_norm
  inputs: (Tensor x, Tensor bias, Tensor residual, Tensor norm_weight, Tensor norm_bias)
  attrs: (float epsilon, int begin_norm_axis, float quant_scale, int quant_round_type,
    float quant_max_bound, float quant_min_bound, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(residual_out)
  optionals: bias,residual,norm_bias,residual_out

- op: sparse_transpose
  inputs: (Tensor x)
  attrs: (int[] perm, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: abs_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: copy_cross_scope
  inputs: (Tensor X, Tensor Id)
  attrs: (bool to_main_scope, int num_micro_batches, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: fast_layernorm_xpu
  inputs: (Tensor x, Tensor scale, Tensor bias)
  attrs: (int begin_norm_axis, float epsilon, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: layer_norm_act_xpu
  inputs: (Tensor x, Tensor scale, Tensor bias)
  attrs: (int begin_norm_axis, float epsilon, int act_type, float act_param, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: eq_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: sparse_subtract
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: gammaln
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: gammaln_
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: sparse_batch_norm
  inputs: (Tensor x, Tensor mean, Tensor variance, Tensor scale, Tensor bias)
  attrs: (bool is_test, float momentum, float epsilon, str data_layout, bool use_global_stats,
    bool trainable_statistics, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(mean_out), Tensor(variance_out), Tensor(saved_mean),
    Tensor(saved_variance), Tensor(reserve_space)

- op: print
  inputs: (Tensor in)
  attrs: (int first_n, str message, int summarize, bool print_tensor_name, bool print_tensor_type,
    bool print_tensor_shape, bool print_tensor_layout, bool print_tensor_lod, str
    print_phase, bool is_forward, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_sum
  inputs: (Tensor x, Tensor AxisTensor, Tensor[] AxisTensorList)
  attrs: (int64_t[] axis, int dtype, bool keepdim, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: AxisTensor,AxisTensorList

- op: erf_p
  inputs: (Tensor X)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: read
  inputs: (Tensor Reader)
  attrs: (bool throw_eof_exp, bool infer_out, bool drop_last, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: fc_xpu
  inputs: (Tensor x, Tensor x_max, Tensor w, Tensor w_max, Tensor bias, Tensor scale_max,
    Tensor out_max_in)
  attrs: (int in_num_col_dims, bool transpose_x, float alpha, float beta, int act_type,
    float act_alpha, int out_dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_max)
  optionals: x_max,bias,scale_max,out_max_in

- op: sparse_sparse_coo_tensor
  inputs: (Tensor values, Tensor indices)
  attrs: (int64_t[] shape, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: fused_gemm_epilogue
  inputs: (Tensor x, Tensor y, Tensor bias)
  attrs: (bool trans_x, bool trans_y, str activation, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(reserve_space)
  optionals: reserve_space

- op: array_to_tensor
  inputs: (Tensor|TensorArray? x)
  attrs: (int axis, bool use_stack, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor|TensorArray?(out_index)

- op: ge_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: bernoulli_p
  inputs: ()
  attrs: (int64_t[] shape, int dtype, float p, int op_role, str[] op_role_var, str
    op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: sparse_mv
  inputs: (Tensor x, Tensor vec)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_multiply
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: matmul_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: broadcast_p
  inputs: (Tensor X)
  attrs: (int64_t[] shape, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: fake_init
  inputs: ()
  attrs: (int64_t[] shape, int op_role, str[] op_role_var, str op_namescope, str[]
    op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: qkv_attention_xpu
  inputs: (Tensor q, Tensor k, Tensor v, Tensor q_max, Tensor k_max, Tensor v_max)
  attrs: (float alpha, int head_num, int head_dim, bool qkv_fc_fusion, int out_dtype,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor(qkv), Tensor(qkv_max)
  optionals: q_max,k_max,v_max

- op: quantize_xpu
  inputs: (Tensor x)
  attrs: (int out_dtype, float scale, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(y)

- op: moe
  inputs: (Tensor X, Tensor Gate, Tensor Bmm0, Tensor Bias0, Tensor Bmm1, Tensor Bias1)
  attrs: (str act_type, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: c_wait_compute
  inputs: (Tensor[] X)
  attrs: (int ring_id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: weight_dequantize
  inputs: (Tensor x, Tensor scale)
  attrs: (str algo, int out_dtype, int group_size, int op_role, str[] op_role_var,
    str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sine_pos_xpu
  inputs: (Tensor x, Tensor y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: concat_p
  inputs: (Tensor[] XS)
  attrs: (int64_t axis, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(Y)

- op: sparse_tan
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: select_output
  inputs: (Tensor|TensorArray? X, Tensor Mask)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: sparse_sin
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: gaussian_inplace
  inputs: (Tensor x)
  attrs: (float mean, float std, int seed, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: gaussian_inplace_
  inputs: (Tensor x)
  attrs: (float mean, float std, int seed, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  inpalces: x->out

- op: read_from_array
  inputs: (Tensor|TensorArray? array, Tensor i, Tensor X_W)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: X_W

- op: pow_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: c_wait_comm
  inputs: (Tensor[] X)
  attrs: (int ring_id, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor[](Out)

- op: sparse_full_like
  inputs: (Tensor x, Tensor ValueTensor)
  attrs: (float value, int dtype, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(out)
  optionals: ValueTensor

- op: select_p
  inputs: (Tensor Condition, Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: ne_p
  inputs: (Tensor X, Tensor Y)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Z)

- op: py_func
  inputs: (Tensor[] X)
  attrs: (int forward_callable_id, int backward_callable_id, str[] backward_skip_vars,
    int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str op_device,
    bool with_quant_attr)
  outputs: Tensor[](Out)

- op: c_gen_nccl_id
  inputs: ()
  attrs: (str endpoint, str[] other_endpoints, int rank, int ring_id, int op_role,
    str[] op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: heter_listen_and_serv
  inputs: (Tensor[] X)
  attrs: (str endpoint, int pserver_id, str[] message_to_block_id, int distributed_mode,
    BLOCKS optimize_blocks, int fanin, int rpc_exec_thread_num, int op_role, str[]
    op_role_var, str op_namescope, str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: ''

- op: sparse_pow
  inputs: (Tensor x)
  attrs: (float factor, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: get_places
  inputs: ()
  attrs: (int device_count, str device_type, int op_role, str[] op_role_var, str op_namescope,
    str[] op_callstack, str op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: yolo_box_xpu
  inputs: (Tensor x, Tensor x_max, Tensor grid, Tensor stride, Tensor anchor_grid)
  attrs: (float offset, int op_role, str[] op_role_var, str op_namescope, str[] op_callstack,
    str op_device, bool with_quant_attr)
  outputs: Tensor(out), Tensor(out_max)
  optionals: x_max

- op: depend
  inputs: (Tensor X, Tensor[] Dep)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(Out)

- op: addcmul_xpu
  inputs: (Tensor x, Tensor y, Tensor w)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: sparse_relu
  inputs: (Tensor x)
  attrs: (int op_role, str[] op_role_var, str op_namescope, str[] op_callstack, str
    op_device, bool with_quant_attr)
  outputs: Tensor(out)

- op: ncclBcast
  inputs: (Tensor X, Tensor Communicator)
  attrs: (int root)
  outputs: Tensor(Out)

- op: ipu_runtime
  inputs: (Tensor FeedList)
  attrs: ()
  outputs: Tensor(FetchList)

- op: push_box_sparse
  inputs: (Tensor W, Tensor[] Ids)
  attrs: (bool is_sparse, bool is_distributed, int size)
  outputs: Tenor[](Out)
  optionals: W

- op: push_box_extended_sparse
  inputs: (Tensor[] Ids)
  attrs: (int emb_size, int emb_extended_size)
  outputs: Tensor[](Out), Tensor[](OutExtend)

- op: ncclAllReduce
  inputs: (Tensor X,Tensor)
  attrs: (str reduction)
  outputs: Tensor(Out)

- op: ncclReduce
  inputs: (Tensor X, Tensor Communicator)
  attrs: (str reduction, int root)
  outputs: Tensor(Out)

- op: ncclInit
  inputs: (Tensor X, Tensor Communicator)
  attrs: (int root)
  outputs: Tensor(Out)

- op: cinn_launch
  inputs: (Tensor[] kX, Tensor[] kNoNeedBufferX)
  attrs: (int64_t kCompilationKey)
  outputs: Tensor[](kOutputs)
  optionals: kNoNeedBufferX

- op: cinn_instruction_run
  inputs: (Tensor[] kX)
  attrs: (int64_t kCachedIndex, int64_t kInstructionIndex)
  outputs: Tensor[](kOutputs)

- op: fake_sum
  inputs: (Tensor X)
  attrs: (int op_role)
  outputs: Tensor(Out)

- op: create_custom_reader
  inputs: ()
  attrs: (BLOCK sub_block, str[] source_var_names, str[] sink_var_names)
  outputs: ()

- op: resnet_basic_block
  inputs: (Tensor X, Tensor Filter1, Tensor Scale1, Tensor Bias1, Tensor Mean1, Tensor
    Var1, Tensor Filter2, Tensor Scale2, Tensor Bias2, Tensor Mean2, Tensor Var2,
    Tensor Filter3, Tensor Scale3, Tensor Bias3, Tensor Mean3, Tensor Var3)
  attrs: (int stride1, int stride2, int stride3, int padding1, int padding2, int padding3,
    int dilation1, int dilation2, int dilation3, int group, float momentum, float
    epsilon, str data_format, bool has_shortcut, bool use_global_stats,BOOLEAN, bool
    trainable_statistics, str act_type, bool find_conv_input_max)
  outputs: Tensor(Y), Tensor(Conv1), Tensor(SavedMean1), Tensor(SavedInvstd1), Tensor(Mean1Out),
    Tensor(Var1Out), Tensor(Conv2), Tensor(Conv2Input), Tensor(SavedMean2), Tensor(SavedInvstd2),
    Tensor(Mean2Out), Tensor(Var2Out), Tensor(Conv3), Tensor(SavedMean3), Tensor(SavedInvstd3),
    Tensor(Mean3Out), Tensor(Var3Out), Tensor(MaxInput1), Tensor(MaxFilter1), Tensor(MaxInput2),
    Tensor(MaxFilter2), Tensor(MaxInput3), Tensor(MaxFilter3)
  optionals: Filter3,Scale3,Bias3,Mean3,Var3,Conv3,SavedMean3,SavedInvstd3,Mean3Out,Var3Out

- op: dummy
  inputs: (Tensor X)
  attrs: ()
  outputs: Tensor(Out)

- op: c_gen_bkcl_id
  inputs: ()
  attrs: (str endpoint, str[] other_endpoints, int rank, int ring_id)
  outputs: Tensor(out)

- op: tensorrt_engine
  inputs: (Tensor[] Xs)
  attrs: (str subgraph, str calibration_data, str engine_serialized_data, str engine_key,
    int max_batch_size, int64_t workspace_size, BLOCK sub_block, bool enable_int8)
  outputs: Tensor[](Ys)

- op: dlnne_engine
  inputs: (Tensor[] Xs)
  attrs: (str subgraph, str engine_key, int max_batch_size, bool use_static_batch,
    str weight_share_mode, bool use_calib_mode, bool enable_int8, bool calibration_mode,
    str calibration_data_path, str subgraph_root_path, BLOCK sub_block)
  outputs: Tensor[](Ys)

- op: gen_bkcl_id
  inputs: ()
  attrs: (str[] trainers, int trainer_id, int bkcl_comm_num, bool use_hierarchical_allreduce,
    int hierarchical_allreduce_inter_nranks)
  outputs: Tensor(Out)

- op: fake_test_op
  inputs: (Tensor[] X, Tensor[] Y)
  attrs: ()
  outputs: Tensor[](Out)

- op: lite_engine
  inputs: (Tensor[] Xs)
  attrs: (str engine_key)
  outputs: Tensor[](Ys)
