# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# repo: PaddleClas
# model: ppcls^configs^ImageNet^PeleeNet^PeleeNet
# api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.pooling.max_pool2d,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.pooling.avg_pool2d,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.pooling.avg_pool2d,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.pooling.avg_pool2d,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu,api||paddle.tensor.manipulation.concat,api||paddle.nn.functional.conv._conv_nd,api||paddle.nn.functional.norm.batch_norm,api||paddle.nn.functional.activation.relu
import unittest

import numpy as np

import paddle


class SIR80(paddle.nn.Layer):
    def __init__(self):
        super().__init__()
        self.var_532 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_837 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_440 = self.create_parameter(
            shape=[32, 128, 1, 1],
            dtype=paddle.float32,
        )
        self.var_351 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_469 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1132 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1048 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_785 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_303 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_493 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_962 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1133 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_667 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_261 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_659 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_442 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_695 = self.create_parameter(
            shape=[64, 320, 1, 1],
            dtype=paddle.float32,
        )
        self.var_377 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1036 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_292 = self.create_parameter(
            shape=[16, 32, 1, 1],
            dtype=paddle.float32,
        )
        self.var_541 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_707 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_450 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_764 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_452 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1108 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_960 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1122 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1134 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_297 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1155 = self.create_parameter(
            shape=[64, 672, 1, 1],
            dtype=paddle.float32,
        )
        self.var_843 = self.create_parameter(
            shape=[64, 448, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1103 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_341 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1057 = self.create_parameter(
            shape=[64, 608, 1, 1],
            dtype=paddle.float32,
        )
        self.var_360 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_602 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_453 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_557 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_749 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_608 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1102 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1175 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_524 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_605 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_780 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_795 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_912 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_632 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_500 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_747 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_526 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_573 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_788 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_854 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_588 = self.create_parameter(
            shape=[256, 256, 1, 1],
            dtype=paddle.float32,
        )
        self.var_963 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_401 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_287 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_807 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1069 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_871 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_294 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_905 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1125 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_268 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_862 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_970 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_897 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_386 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_525 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_681 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_705 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_889 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1143 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_277 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_278 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_492 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_411 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_555 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_716 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_732 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1117 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_302 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_384 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_853 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_810 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_955 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1028 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1127 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1165 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_624 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_761 = self.create_parameter(
            shape=[64, 384, 1, 1],
            dtype=paddle.float32,
        )
        self.var_927 = self.create_parameter(
            shape=[512],
            dtype=paddle.float32,
        )
        self.var_646 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_736 = self.create_parameter(
            shape=[64, 352, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1021 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_271 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_774 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_910 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_406 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1059 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_329 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_888 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1142 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_679 = self.create_parameter(
            shape=[64, 320, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1118 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_262 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_939 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_724 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1171 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_418 = self.create_parameter(
            shape=[128],
            dtype=paddle.float32,
        )
        self.var_987 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_978 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1185 = self.create_parameter(
            shape=[704],
            dtype=paddle.float32,
        )
        self.var_834 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_379 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_349 = self.create_parameter(
            shape=[16, 64, 1, 1],
            dtype=paddle.float32,
        )
        self.var_485 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_530 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_429 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_649 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_470 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_936 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_374 = self.create_parameter(
            shape=[16, 96, 1, 1],
            dtype=paddle.float32,
        )
        self.var_565 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1167 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_728 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_996 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1116 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_398 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_519 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_658 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_582 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_814 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_409 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_980 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_483 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_673 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_744 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1068 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_460 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_740 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_436 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_870 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1070 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_713 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_336 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1176 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_820 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_477 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_683 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_731 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_818 = self.create_parameter(
            shape=[64, 416, 1, 1],
            dtype=paddle.float32,
        )
        self.var_403 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_497 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_845 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1050 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1168 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_629 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_782 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_320 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_657 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_522 = self.create_parameter(
            shape=[32, 192, 1, 1],
            dtype=paddle.float32,
        )
        self.var_591 = self.create_parameter(
            shape=[256],
            dtype=paddle.float32,
        )
        self.var_305 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1024 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_848 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1166 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_432 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_643 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1150 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_316 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_697 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_757 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_756 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_730 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_310 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1152 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_288 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_475 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_919 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_904 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1012 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1034 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_527 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1130 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_324 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_739 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_607 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_618 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_654 = self.create_parameter(
            shape=[64, 288, 1, 1],
            dtype=paddle.float32,
        )
        self.var_944 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1003 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1183 = self.create_parameter(
            shape=[704],
            dtype=paddle.float32,
        )
        self.var_279 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_395 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_354 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_419 = self.create_parameter(
            shape=[128],
            dtype=paddle.float32,
        )
        self.var_839 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_895 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_892 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_804 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_879 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_613 = self.create_parameter(
            shape=[64, 256, 1, 1],
            dtype=paddle.float32,
        )
        self.var_319 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_741 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_969 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_979 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_887 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_946 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_867 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_918 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_966 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_274 = self.create_parameter(
            shape=[32, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_367 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_886 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_806 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_444 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_458 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_387 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1010 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_692 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_961 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1157 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_689 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_662 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_392 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1007 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_640 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_813 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_456 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_286 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1110 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_930 = self.create_parameter(
            shape=[512],
            dtype=paddle.float32,
        )
        self.var_805 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_345 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_393 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_977 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_385 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_311 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_666 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_877 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_560 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_566 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_925 = self.create_parameter(
            shape=[512, 512, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1093 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_674 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_258 = self.create_parameter(
            shape=[32, 3, 3, 3],
            dtype=paddle.float32,
        )
        self.var_921 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_597 = self.create_parameter(
            shape=[64, 256, 1, 1],
            dtype=paddle.float32,
        )
        self.var_337 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_312 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_872 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_715 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_812 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_830 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1084 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_772 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_994 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1018 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1111 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_945 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_880 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1061 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_518 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_929 = self.create_parameter(
            shape=[512],
            dtype=paddle.float32,
        )
        self.var_723 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1151 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1114 = self.create_parameter(
            shape=[64, 640, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1067 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1124 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1149 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_576 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_514 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_859 = self.create_parameter(
            shape=[64, 448, 1, 1],
            dtype=paddle.float32,
        )
        self.var_547 = self.create_parameter(
            shape=[32, 224, 1, 1],
            dtype=paddle.float32,
        )
        self.var_434 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1174 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1016 = self.create_parameter(
            shape=[64, 576, 1, 1],
            dtype=paddle.float32,
        )
        self.var_465 = self.create_parameter(
            shape=[32, 160, 1, 1],
            dtype=paddle.float32,
        )
        self.var_382 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_625 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_720 = self.create_parameter(
            shape=[64, 352, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1139 = self.create_parameter(
            shape=[64, 672, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1159 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_579 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_540 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_634 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_592 = self.create_parameter(
            shape=[256],
            dtype=paddle.float32,
        )
        self.var_682 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_615 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_400 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1043 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1009 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_829 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_516 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_567 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_568 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_590 = self.create_parameter(
            shape=[256],
            dtype=paddle.float32,
        )
        self.var_333 = self.create_parameter(
            shape=[16, 64, 1, 1],
            dtype=paddle.float32,
        )
        self.var_748 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1019 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_823 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_861 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1035 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_559 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1065 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1119 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1141 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_326 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_934 = self.create_parameter(
            shape=[64, 512, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1100 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_781 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_467 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_797 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_651 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_947 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_672 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_538 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_648 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_390 = self.create_parameter(
            shape=[16, 96, 1, 1],
            dtype=paddle.float32,
        )
        self.var_691 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_359 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_856 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_451 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_584 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1092 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_670 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_511 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_684 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_847 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_798 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_920 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1002 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_846 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_344 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_510 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_664 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_517 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_766 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_550 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_991 = self.create_parameter(
            shape=[64, 544, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1158 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_878 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_765 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_295 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1037 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_435 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_300 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_633 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_953 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_266 = self.create_parameter(
            shape=[16, 32, 1, 1],
            dtype=paddle.float32,
        )
        self.var_1098 = self.create_parameter(
            shape=[64, 640, 1, 1],
            dtype=paddle.float32,
        )
        self.var_558 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_571 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_851 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_437 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_542 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_574 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_828 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_836 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_445 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_999 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1109 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_875 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_884 = self.create_parameter(
            shape=[64, 480, 1, 1],
            dtype=paddle.float32,
        )
        self.var_459 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_952 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_506 = self.create_parameter(
            shape=[32, 192, 1, 1],
            dtype=paddle.float32,
        )
        self.var_461 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_708 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_777 = self.create_parameter(
            shape=[64, 384, 1, 1],
            dtype=paddle.float32,
        )
        self.var_855 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_494 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_725 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1089 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_365 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_581 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_617 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_711 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_993 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_831 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_771 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_665 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_958 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_534 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_902 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_722 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_328 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1044 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_304 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_468 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_535 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_790 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_378 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1032 = self.create_parameter(
            shape=[64, 576, 1, 1],
            dtype=paddle.float32,
        )
        self.var_938 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_402 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1091 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_549 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_593 = self.create_parameter(
            shape=[256],
            dtype=paddle.float32,
        )
        self.var_601 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_338 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_289 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1020 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_426 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_937 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_986 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1027 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1052 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_826 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1182 = self.create_parameter(
            shape=[704],
            dtype=paddle.float32,
        )
        self.var_543 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_499 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1073 = self.create_parameter(
            shape=[64, 608, 1, 1],
            dtype=paddle.float32,
        )
        self.var_361 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_551 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1051 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_308 = self.create_parameter(
            shape=[16, 32, 1, 1],
            dtype=paddle.float32,
        )
        self.var_583 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1077 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_894 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_448 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_394 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_650 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_822 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_491 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_509 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_755 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_478 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_699 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_690 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_631 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_641 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_502 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_321 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_796 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_616 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_908 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_599 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_971 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1160 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_802 = self.create_parameter(
            shape=[64, 416, 1, 1],
            dtype=paddle.float32,
        )
        self.var_968 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_988 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_900 = self.create_parameter(
            shape=[64, 480, 1, 1],
            dtype=paddle.float32,
        )
        self.var_424 = self.create_parameter(
            shape=[32, 128, 1, 1],
            dtype=paddle.float32,
        )
        self.var_443 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_563 = self.create_parameter(
            shape=[32, 224, 1, 1],
            dtype=paddle.float32,
        )
        self.var_763 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_815 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_706 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1163 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_623 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1075 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_427 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1011 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_787 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_368 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_626 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_928 = self.create_parameter(
            shape=[512],
            dtype=paddle.float32,
        )
        self.var_698 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_983 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_864 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1001 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_501 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_738 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_869 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1040 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1126 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_600 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_950 = self.create_parameter(
            shape=[64, 512, 1, 1],
            dtype=paddle.float32,
        )
        self.var_609 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_575 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_752 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_415 = self.create_parameter(
            shape=[128, 128, 1, 1],
            dtype=paddle.float32,
        )
        self.var_769 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_793 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_703 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_353 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_773 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_508 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1083 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_975 = self.create_parameter(
            shape=[64, 544, 1, 1],
            dtype=paddle.float32,
        )
        self.var_263 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1086 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_995 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_733 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_985 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_789 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_489 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_533 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_428 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_638 = self.create_parameter(
            shape=[64, 288, 1, 1],
            dtype=paddle.float32,
        )
        self.var_779 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_270 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_896 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_369 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_335 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_376 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_420 = self.create_parameter(
            shape=[128],
            dtype=paddle.float32,
        )
        self.var_476 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_313 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_484 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_486 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_1053 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1078 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1045 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1081 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_269 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_754 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_362 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1106 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_714 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_276 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_327 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_746 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_417 = self.create_parameter(
            shape=[128],
            dtype=paddle.float32,
        )
        self.var_656 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_821 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1029 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1184 = self.create_parameter(
            shape=[704],
            dtype=paddle.float32,
        )
        self.var_1060 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_642 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1173 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_284 = self.create_parameter(
            shape=[32, 64, 1, 1],
            dtype=paddle.float32,
        )
        self.var_473 = self.create_parameter(
            shape=[16, 32, 3, 3],
            dtype=paddle.float32,
        )
        self.var_610 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_410 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1144 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1085 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_687 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_903 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1026 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1076 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_318 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_675 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1004 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_552 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_863 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_838 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1042 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1147 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1062 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1180 = self.create_parameter(
            shape=[704, 704, 1, 1],
            dtype=paddle.float32,
        )
        self.var_357 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_700 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_408 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_913 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_954 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_296 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_370 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_260 = self.create_parameter(
            shape=[32],
            dtype=paddle.float32,
        )
        self.var_942 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )
        self.var_1094 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_1101 = self.create_parameter(
            shape=[64],
            dtype=paddle.float32,
        )
        self.var_1135 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_352 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_916 = self.create_parameter(
            shape=[16, 16, 3, 3],
            dtype=paddle.float32,
        )
        self.var_911 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_343 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_346 = self.create_parameter(
            shape=[16],
            dtype=paddle.float32,
        )
        self.var_481 = self.create_parameter(
            shape=[32, 160, 1, 1],
            dtype=paddle.float32,
        )
        self.var_621 = self.create_parameter(
            shape=[16, 64, 3, 3],
            dtype=paddle.float32,
        )

    def forward(
        self,
        var_257,  # (shape: [86, 3, 224, 224], dtype: paddle.float32, stop_gradient: True)
    ):
        var_259 = paddle.nn.functional.conv._conv_nd(
            var_257,
            self.var_258,
            bias=None,
            stride=[2, 2],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_264 = paddle.nn.functional.norm.batch_norm(
            var_259,
            self.var_260,
            self.var_261,
            weight=self.var_262,
            bias=self.var_263,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_265 = paddle.nn.functional.activation.relu(var_264)
        var_267 = paddle.nn.functional.conv._conv_nd(
            var_265,
            self.var_266,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_272 = paddle.nn.functional.norm.batch_norm(
            var_267,
            self.var_268,
            self.var_269,
            weight=self.var_270,
            bias=self.var_271,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_273 = paddle.nn.functional.activation.relu(var_272)
        var_275 = paddle.nn.functional.conv._conv_nd(
            var_273,
            self.var_274,
            bias=None,
            stride=[2, 2],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_280 = paddle.nn.functional.norm.batch_norm(
            var_275,
            self.var_276,
            self.var_277,
            weight=self.var_278,
            bias=self.var_279,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_281 = paddle.nn.functional.activation.relu(var_280)
        var_282 = paddle.nn.functional.pooling.max_pool2d(
            var_265,
            kernel_size=2,
            stride=2,
            padding=0,
            return_mask=False,
            ceil_mode=False,
            data_format='NCHW',
            name=None,
        )
        var_283 = paddle.tensor.manipulation.concat([var_282, var_281], 1)
        var_285 = paddle.nn.functional.conv._conv_nd(
            var_283,
            self.var_284,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_290 = paddle.nn.functional.norm.batch_norm(
            var_285,
            self.var_286,
            self.var_287,
            weight=self.var_288,
            bias=self.var_289,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_291 = paddle.nn.functional.activation.relu(var_290)
        var_293 = paddle.nn.functional.conv._conv_nd(
            var_291,
            self.var_292,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_298 = paddle.nn.functional.norm.batch_norm(
            var_293,
            self.var_294,
            self.var_295,
            weight=self.var_296,
            bias=self.var_297,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_299 = paddle.nn.functional.activation.relu(var_298)
        var_301 = paddle.nn.functional.conv._conv_nd(
            var_299,
            self.var_300,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_306 = paddle.nn.functional.norm.batch_norm(
            var_301,
            self.var_302,
            self.var_303,
            weight=self.var_304,
            bias=self.var_305,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_307 = paddle.nn.functional.activation.relu(var_306)
        var_309 = paddle.nn.functional.conv._conv_nd(
            var_291,
            self.var_308,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_314 = paddle.nn.functional.norm.batch_norm(
            var_309,
            self.var_310,
            self.var_311,
            weight=self.var_312,
            bias=self.var_313,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_315 = paddle.nn.functional.activation.relu(var_314)
        var_317 = paddle.nn.functional.conv._conv_nd(
            var_315,
            self.var_316,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_322 = paddle.nn.functional.norm.batch_norm(
            var_317,
            self.var_318,
            self.var_319,
            weight=self.var_320,
            bias=self.var_321,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_323 = paddle.nn.functional.activation.relu(var_322)
        var_325 = paddle.nn.functional.conv._conv_nd(
            var_323,
            self.var_324,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_330 = paddle.nn.functional.norm.batch_norm(
            var_325,
            self.var_326,
            self.var_327,
            weight=self.var_328,
            bias=self.var_329,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_331 = paddle.nn.functional.activation.relu(var_330)
        var_332 = paddle.tensor.manipulation.concat(
            [var_291, var_307, var_331], 1
        )
        var_334 = paddle.nn.functional.conv._conv_nd(
            var_332,
            self.var_333,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_339 = paddle.nn.functional.norm.batch_norm(
            var_334,
            self.var_335,
            self.var_336,
            weight=self.var_337,
            bias=self.var_338,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_340 = paddle.nn.functional.activation.relu(var_339)
        var_342 = paddle.nn.functional.conv._conv_nd(
            var_340,
            self.var_341,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_347 = paddle.nn.functional.norm.batch_norm(
            var_342,
            self.var_343,
            self.var_344,
            weight=self.var_345,
            bias=self.var_346,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_348 = paddle.nn.functional.activation.relu(var_347)
        var_350 = paddle.nn.functional.conv._conv_nd(
            var_332,
            self.var_349,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_355 = paddle.nn.functional.norm.batch_norm(
            var_350,
            self.var_351,
            self.var_352,
            weight=self.var_353,
            bias=self.var_354,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_356 = paddle.nn.functional.activation.relu(var_355)
        var_358 = paddle.nn.functional.conv._conv_nd(
            var_356,
            self.var_357,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_363 = paddle.nn.functional.norm.batch_norm(
            var_358,
            self.var_359,
            self.var_360,
            weight=self.var_361,
            bias=self.var_362,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_364 = paddle.nn.functional.activation.relu(var_363)
        var_366 = paddle.nn.functional.conv._conv_nd(
            var_364,
            self.var_365,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_371 = paddle.nn.functional.norm.batch_norm(
            var_366,
            self.var_367,
            self.var_368,
            weight=self.var_369,
            bias=self.var_370,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_372 = paddle.nn.functional.activation.relu(var_371)
        var_373 = paddle.tensor.manipulation.concat(
            [var_332, var_348, var_372], 1
        )
        var_375 = paddle.nn.functional.conv._conv_nd(
            var_373,
            self.var_374,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_380 = paddle.nn.functional.norm.batch_norm(
            var_375,
            self.var_376,
            self.var_377,
            weight=self.var_378,
            bias=self.var_379,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_381 = paddle.nn.functional.activation.relu(var_380)
        var_383 = paddle.nn.functional.conv._conv_nd(
            var_381,
            self.var_382,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_388 = paddle.nn.functional.norm.batch_norm(
            var_383,
            self.var_384,
            self.var_385,
            weight=self.var_386,
            bias=self.var_387,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_389 = paddle.nn.functional.activation.relu(var_388)
        var_391 = paddle.nn.functional.conv._conv_nd(
            var_373,
            self.var_390,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_396 = paddle.nn.functional.norm.batch_norm(
            var_391,
            self.var_392,
            self.var_393,
            weight=self.var_394,
            bias=self.var_395,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_397 = paddle.nn.functional.activation.relu(var_396)
        var_399 = paddle.nn.functional.conv._conv_nd(
            var_397,
            self.var_398,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_404 = paddle.nn.functional.norm.batch_norm(
            var_399,
            self.var_400,
            self.var_401,
            weight=self.var_402,
            bias=self.var_403,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_405 = paddle.nn.functional.activation.relu(var_404)
        var_407 = paddle.nn.functional.conv._conv_nd(
            var_405,
            self.var_406,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_412 = paddle.nn.functional.norm.batch_norm(
            var_407,
            self.var_408,
            self.var_409,
            weight=self.var_410,
            bias=self.var_411,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_413 = paddle.nn.functional.activation.relu(var_412)
        var_414 = paddle.tensor.manipulation.concat(
            [var_373, var_389, var_413], 1
        )
        var_416 = paddle.nn.functional.conv._conv_nd(
            var_414,
            self.var_415,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_421 = paddle.nn.functional.norm.batch_norm(
            var_416,
            self.var_417,
            self.var_418,
            weight=self.var_419,
            bias=self.var_420,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_422 = paddle.nn.functional.activation.relu(var_421)
        var_423 = paddle.nn.functional.pooling.avg_pool2d(
            var_422,
            kernel_size=2,
            stride=2,
            padding=0,
            ceil_mode=False,
            exclusive=True,
            divisor_override=None,
            data_format='NCHW',
            name=None,
        )
        var_425 = paddle.nn.functional.conv._conv_nd(
            var_423,
            self.var_424,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_430 = paddle.nn.functional.norm.batch_norm(
            var_425,
            self.var_426,
            self.var_427,
            weight=self.var_428,
            bias=self.var_429,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_431 = paddle.nn.functional.activation.relu(var_430)
        var_433 = paddle.nn.functional.conv._conv_nd(
            var_431,
            self.var_432,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_438 = paddle.nn.functional.norm.batch_norm(
            var_433,
            self.var_434,
            self.var_435,
            weight=self.var_436,
            bias=self.var_437,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_439 = paddle.nn.functional.activation.relu(var_438)
        var_441 = paddle.nn.functional.conv._conv_nd(
            var_423,
            self.var_440,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_446 = paddle.nn.functional.norm.batch_norm(
            var_441,
            self.var_442,
            self.var_443,
            weight=self.var_444,
            bias=self.var_445,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_447 = paddle.nn.functional.activation.relu(var_446)
        var_449 = paddle.nn.functional.conv._conv_nd(
            var_447,
            self.var_448,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_454 = paddle.nn.functional.norm.batch_norm(
            var_449,
            self.var_450,
            self.var_451,
            weight=self.var_452,
            bias=self.var_453,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_455 = paddle.nn.functional.activation.relu(var_454)
        var_457 = paddle.nn.functional.conv._conv_nd(
            var_455,
            self.var_456,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_462 = paddle.nn.functional.norm.batch_norm(
            var_457,
            self.var_458,
            self.var_459,
            weight=self.var_460,
            bias=self.var_461,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_463 = paddle.nn.functional.activation.relu(var_462)
        var_464 = paddle.tensor.manipulation.concat(
            [var_423, var_439, var_463], 1
        )
        var_466 = paddle.nn.functional.conv._conv_nd(
            var_464,
            self.var_465,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_471 = paddle.nn.functional.norm.batch_norm(
            var_466,
            self.var_467,
            self.var_468,
            weight=self.var_469,
            bias=self.var_470,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_472 = paddle.nn.functional.activation.relu(var_471)
        var_474 = paddle.nn.functional.conv._conv_nd(
            var_472,
            self.var_473,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_479 = paddle.nn.functional.norm.batch_norm(
            var_474,
            self.var_475,
            self.var_476,
            weight=self.var_477,
            bias=self.var_478,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_480 = paddle.nn.functional.activation.relu(var_479)
        var_482 = paddle.nn.functional.conv._conv_nd(
            var_464,
            self.var_481,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_487 = paddle.nn.functional.norm.batch_norm(
            var_482,
            self.var_483,
            self.var_484,
            weight=self.var_485,
            bias=self.var_486,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_488 = paddle.nn.functional.activation.relu(var_487)
        var_490 = paddle.nn.functional.conv._conv_nd(
            var_488,
            self.var_489,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_495 = paddle.nn.functional.norm.batch_norm(
            var_490,
            self.var_491,
            self.var_492,
            weight=self.var_493,
            bias=self.var_494,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_496 = paddle.nn.functional.activation.relu(var_495)
        var_498 = paddle.nn.functional.conv._conv_nd(
            var_496,
            self.var_497,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_503 = paddle.nn.functional.norm.batch_norm(
            var_498,
            self.var_499,
            self.var_500,
            weight=self.var_501,
            bias=self.var_502,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_504 = paddle.nn.functional.activation.relu(var_503)
        var_505 = paddle.tensor.manipulation.concat(
            [var_464, var_480, var_504], 1
        )
        var_507 = paddle.nn.functional.conv._conv_nd(
            var_505,
            self.var_506,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_512 = paddle.nn.functional.norm.batch_norm(
            var_507,
            self.var_508,
            self.var_509,
            weight=self.var_510,
            bias=self.var_511,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_513 = paddle.nn.functional.activation.relu(var_512)
        var_515 = paddle.nn.functional.conv._conv_nd(
            var_513,
            self.var_514,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_520 = paddle.nn.functional.norm.batch_norm(
            var_515,
            self.var_516,
            self.var_517,
            weight=self.var_518,
            bias=self.var_519,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_521 = paddle.nn.functional.activation.relu(var_520)
        var_523 = paddle.nn.functional.conv._conv_nd(
            var_505,
            self.var_522,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_528 = paddle.nn.functional.norm.batch_norm(
            var_523,
            self.var_524,
            self.var_525,
            weight=self.var_526,
            bias=self.var_527,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_529 = paddle.nn.functional.activation.relu(var_528)
        var_531 = paddle.nn.functional.conv._conv_nd(
            var_529,
            self.var_530,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_536 = paddle.nn.functional.norm.batch_norm(
            var_531,
            self.var_532,
            self.var_533,
            weight=self.var_534,
            bias=self.var_535,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_537 = paddle.nn.functional.activation.relu(var_536)
        var_539 = paddle.nn.functional.conv._conv_nd(
            var_537,
            self.var_538,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_544 = paddle.nn.functional.norm.batch_norm(
            var_539,
            self.var_540,
            self.var_541,
            weight=self.var_542,
            bias=self.var_543,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_545 = paddle.nn.functional.activation.relu(var_544)
        var_546 = paddle.tensor.manipulation.concat(
            [var_505, var_521, var_545], 1
        )
        var_548 = paddle.nn.functional.conv._conv_nd(
            var_546,
            self.var_547,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_553 = paddle.nn.functional.norm.batch_norm(
            var_548,
            self.var_549,
            self.var_550,
            weight=self.var_551,
            bias=self.var_552,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_554 = paddle.nn.functional.activation.relu(var_553)
        var_556 = paddle.nn.functional.conv._conv_nd(
            var_554,
            self.var_555,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_561 = paddle.nn.functional.norm.batch_norm(
            var_556,
            self.var_557,
            self.var_558,
            weight=self.var_559,
            bias=self.var_560,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_562 = paddle.nn.functional.activation.relu(var_561)
        var_564 = paddle.nn.functional.conv._conv_nd(
            var_546,
            self.var_563,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_569 = paddle.nn.functional.norm.batch_norm(
            var_564,
            self.var_565,
            self.var_566,
            weight=self.var_567,
            bias=self.var_568,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_570 = paddle.nn.functional.activation.relu(var_569)
        var_572 = paddle.nn.functional.conv._conv_nd(
            var_570,
            self.var_571,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_577 = paddle.nn.functional.norm.batch_norm(
            var_572,
            self.var_573,
            self.var_574,
            weight=self.var_575,
            bias=self.var_576,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_578 = paddle.nn.functional.activation.relu(var_577)
        var_580 = paddle.nn.functional.conv._conv_nd(
            var_578,
            self.var_579,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_585 = paddle.nn.functional.norm.batch_norm(
            var_580,
            self.var_581,
            self.var_582,
            weight=self.var_583,
            bias=self.var_584,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_586 = paddle.nn.functional.activation.relu(var_585)
        var_587 = paddle.tensor.manipulation.concat(
            [var_546, var_562, var_586], 1
        )
        var_589 = paddle.nn.functional.conv._conv_nd(
            var_587,
            self.var_588,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_594 = paddle.nn.functional.norm.batch_norm(
            var_589,
            self.var_590,
            self.var_591,
            weight=self.var_592,
            bias=self.var_593,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_595 = paddle.nn.functional.activation.relu(var_594)
        var_596 = paddle.nn.functional.pooling.avg_pool2d(
            var_595,
            kernel_size=2,
            stride=2,
            padding=0,
            ceil_mode=False,
            exclusive=True,
            divisor_override=None,
            data_format='NCHW',
            name=None,
        )
        var_598 = paddle.nn.functional.conv._conv_nd(
            var_596,
            self.var_597,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_603 = paddle.nn.functional.norm.batch_norm(
            var_598,
            self.var_599,
            self.var_600,
            weight=self.var_601,
            bias=self.var_602,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_604 = paddle.nn.functional.activation.relu(var_603)
        var_606 = paddle.nn.functional.conv._conv_nd(
            var_604,
            self.var_605,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_611 = paddle.nn.functional.norm.batch_norm(
            var_606,
            self.var_607,
            self.var_608,
            weight=self.var_609,
            bias=self.var_610,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_612 = paddle.nn.functional.activation.relu(var_611)
        var_614 = paddle.nn.functional.conv._conv_nd(
            var_596,
            self.var_613,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_619 = paddle.nn.functional.norm.batch_norm(
            var_614,
            self.var_615,
            self.var_616,
            weight=self.var_617,
            bias=self.var_618,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_620 = paddle.nn.functional.activation.relu(var_619)
        var_622 = paddle.nn.functional.conv._conv_nd(
            var_620,
            self.var_621,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_627 = paddle.nn.functional.norm.batch_norm(
            var_622,
            self.var_623,
            self.var_624,
            weight=self.var_625,
            bias=self.var_626,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_628 = paddle.nn.functional.activation.relu(var_627)
        var_630 = paddle.nn.functional.conv._conv_nd(
            var_628,
            self.var_629,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_635 = paddle.nn.functional.norm.batch_norm(
            var_630,
            self.var_631,
            self.var_632,
            weight=self.var_633,
            bias=self.var_634,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_636 = paddle.nn.functional.activation.relu(var_635)
        var_637 = paddle.tensor.manipulation.concat(
            [var_596, var_612, var_636], 1
        )
        var_639 = paddle.nn.functional.conv._conv_nd(
            var_637,
            self.var_638,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_644 = paddle.nn.functional.norm.batch_norm(
            var_639,
            self.var_640,
            self.var_641,
            weight=self.var_642,
            bias=self.var_643,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_645 = paddle.nn.functional.activation.relu(var_644)
        var_647 = paddle.nn.functional.conv._conv_nd(
            var_645,
            self.var_646,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_652 = paddle.nn.functional.norm.batch_norm(
            var_647,
            self.var_648,
            self.var_649,
            weight=self.var_650,
            bias=self.var_651,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_653 = paddle.nn.functional.activation.relu(var_652)
        var_655 = paddle.nn.functional.conv._conv_nd(
            var_637,
            self.var_654,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_660 = paddle.nn.functional.norm.batch_norm(
            var_655,
            self.var_656,
            self.var_657,
            weight=self.var_658,
            bias=self.var_659,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_661 = paddle.nn.functional.activation.relu(var_660)
        var_663 = paddle.nn.functional.conv._conv_nd(
            var_661,
            self.var_662,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_668 = paddle.nn.functional.norm.batch_norm(
            var_663,
            self.var_664,
            self.var_665,
            weight=self.var_666,
            bias=self.var_667,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_669 = paddle.nn.functional.activation.relu(var_668)
        var_671 = paddle.nn.functional.conv._conv_nd(
            var_669,
            self.var_670,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_676 = paddle.nn.functional.norm.batch_norm(
            var_671,
            self.var_672,
            self.var_673,
            weight=self.var_674,
            bias=self.var_675,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_677 = paddle.nn.functional.activation.relu(var_676)
        var_678 = paddle.tensor.manipulation.concat(
            [var_637, var_653, var_677], 1
        )
        var_680 = paddle.nn.functional.conv._conv_nd(
            var_678,
            self.var_679,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_685 = paddle.nn.functional.norm.batch_norm(
            var_680,
            self.var_681,
            self.var_682,
            weight=self.var_683,
            bias=self.var_684,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_686 = paddle.nn.functional.activation.relu(var_685)
        var_688 = paddle.nn.functional.conv._conv_nd(
            var_686,
            self.var_687,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_693 = paddle.nn.functional.norm.batch_norm(
            var_688,
            self.var_689,
            self.var_690,
            weight=self.var_691,
            bias=self.var_692,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_694 = paddle.nn.functional.activation.relu(var_693)
        var_696 = paddle.nn.functional.conv._conv_nd(
            var_678,
            self.var_695,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_701 = paddle.nn.functional.norm.batch_norm(
            var_696,
            self.var_697,
            self.var_698,
            weight=self.var_699,
            bias=self.var_700,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_702 = paddle.nn.functional.activation.relu(var_701)
        var_704 = paddle.nn.functional.conv._conv_nd(
            var_702,
            self.var_703,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_709 = paddle.nn.functional.norm.batch_norm(
            var_704,
            self.var_705,
            self.var_706,
            weight=self.var_707,
            bias=self.var_708,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_710 = paddle.nn.functional.activation.relu(var_709)
        var_712 = paddle.nn.functional.conv._conv_nd(
            var_710,
            self.var_711,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_717 = paddle.nn.functional.norm.batch_norm(
            var_712,
            self.var_713,
            self.var_714,
            weight=self.var_715,
            bias=self.var_716,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_718 = paddle.nn.functional.activation.relu(var_717)
        var_719 = paddle.tensor.manipulation.concat(
            [var_678, var_694, var_718], 1
        )
        var_721 = paddle.nn.functional.conv._conv_nd(
            var_719,
            self.var_720,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_726 = paddle.nn.functional.norm.batch_norm(
            var_721,
            self.var_722,
            self.var_723,
            weight=self.var_724,
            bias=self.var_725,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_727 = paddle.nn.functional.activation.relu(var_726)
        var_729 = paddle.nn.functional.conv._conv_nd(
            var_727,
            self.var_728,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_734 = paddle.nn.functional.norm.batch_norm(
            var_729,
            self.var_730,
            self.var_731,
            weight=self.var_732,
            bias=self.var_733,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_735 = paddle.nn.functional.activation.relu(var_734)
        var_737 = paddle.nn.functional.conv._conv_nd(
            var_719,
            self.var_736,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_742 = paddle.nn.functional.norm.batch_norm(
            var_737,
            self.var_738,
            self.var_739,
            weight=self.var_740,
            bias=self.var_741,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_743 = paddle.nn.functional.activation.relu(var_742)
        var_745 = paddle.nn.functional.conv._conv_nd(
            var_743,
            self.var_744,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_750 = paddle.nn.functional.norm.batch_norm(
            var_745,
            self.var_746,
            self.var_747,
            weight=self.var_748,
            bias=self.var_749,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_751 = paddle.nn.functional.activation.relu(var_750)
        var_753 = paddle.nn.functional.conv._conv_nd(
            var_751,
            self.var_752,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_758 = paddle.nn.functional.norm.batch_norm(
            var_753,
            self.var_754,
            self.var_755,
            weight=self.var_756,
            bias=self.var_757,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_759 = paddle.nn.functional.activation.relu(var_758)
        var_760 = paddle.tensor.manipulation.concat(
            [var_719, var_735, var_759], 1
        )
        var_762 = paddle.nn.functional.conv._conv_nd(
            var_760,
            self.var_761,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_767 = paddle.nn.functional.norm.batch_norm(
            var_762,
            self.var_763,
            self.var_764,
            weight=self.var_765,
            bias=self.var_766,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_768 = paddle.nn.functional.activation.relu(var_767)
        var_770 = paddle.nn.functional.conv._conv_nd(
            var_768,
            self.var_769,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_775 = paddle.nn.functional.norm.batch_norm(
            var_770,
            self.var_771,
            self.var_772,
            weight=self.var_773,
            bias=self.var_774,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_776 = paddle.nn.functional.activation.relu(var_775)
        var_778 = paddle.nn.functional.conv._conv_nd(
            var_760,
            self.var_777,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_783 = paddle.nn.functional.norm.batch_norm(
            var_778,
            self.var_779,
            self.var_780,
            weight=self.var_781,
            bias=self.var_782,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_784 = paddle.nn.functional.activation.relu(var_783)
        var_786 = paddle.nn.functional.conv._conv_nd(
            var_784,
            self.var_785,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_791 = paddle.nn.functional.norm.batch_norm(
            var_786,
            self.var_787,
            self.var_788,
            weight=self.var_789,
            bias=self.var_790,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_792 = paddle.nn.functional.activation.relu(var_791)
        var_794 = paddle.nn.functional.conv._conv_nd(
            var_792,
            self.var_793,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_799 = paddle.nn.functional.norm.batch_norm(
            var_794,
            self.var_795,
            self.var_796,
            weight=self.var_797,
            bias=self.var_798,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_800 = paddle.nn.functional.activation.relu(var_799)
        var_801 = paddle.tensor.manipulation.concat(
            [var_760, var_776, var_800], 1
        )
        var_803 = paddle.nn.functional.conv._conv_nd(
            var_801,
            self.var_802,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_808 = paddle.nn.functional.norm.batch_norm(
            var_803,
            self.var_804,
            self.var_805,
            weight=self.var_806,
            bias=self.var_807,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_809 = paddle.nn.functional.activation.relu(var_808)
        var_811 = paddle.nn.functional.conv._conv_nd(
            var_809,
            self.var_810,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_816 = paddle.nn.functional.norm.batch_norm(
            var_811,
            self.var_812,
            self.var_813,
            weight=self.var_814,
            bias=self.var_815,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_817 = paddle.nn.functional.activation.relu(var_816)
        var_819 = paddle.nn.functional.conv._conv_nd(
            var_801,
            self.var_818,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_824 = paddle.nn.functional.norm.batch_norm(
            var_819,
            self.var_820,
            self.var_821,
            weight=self.var_822,
            bias=self.var_823,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_825 = paddle.nn.functional.activation.relu(var_824)
        var_827 = paddle.nn.functional.conv._conv_nd(
            var_825,
            self.var_826,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_832 = paddle.nn.functional.norm.batch_norm(
            var_827,
            self.var_828,
            self.var_829,
            weight=self.var_830,
            bias=self.var_831,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_833 = paddle.nn.functional.activation.relu(var_832)
        var_835 = paddle.nn.functional.conv._conv_nd(
            var_833,
            self.var_834,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_840 = paddle.nn.functional.norm.batch_norm(
            var_835,
            self.var_836,
            self.var_837,
            weight=self.var_838,
            bias=self.var_839,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_841 = paddle.nn.functional.activation.relu(var_840)
        var_842 = paddle.tensor.manipulation.concat(
            [var_801, var_817, var_841], 1
        )
        var_844 = paddle.nn.functional.conv._conv_nd(
            var_842,
            self.var_843,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_849 = paddle.nn.functional.norm.batch_norm(
            var_844,
            self.var_845,
            self.var_846,
            weight=self.var_847,
            bias=self.var_848,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_850 = paddle.nn.functional.activation.relu(var_849)
        var_852 = paddle.nn.functional.conv._conv_nd(
            var_850,
            self.var_851,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_857 = paddle.nn.functional.norm.batch_norm(
            var_852,
            self.var_853,
            self.var_854,
            weight=self.var_855,
            bias=self.var_856,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_858 = paddle.nn.functional.activation.relu(var_857)
        var_860 = paddle.nn.functional.conv._conv_nd(
            var_842,
            self.var_859,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_865 = paddle.nn.functional.norm.batch_norm(
            var_860,
            self.var_861,
            self.var_862,
            weight=self.var_863,
            bias=self.var_864,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_866 = paddle.nn.functional.activation.relu(var_865)
        var_868 = paddle.nn.functional.conv._conv_nd(
            var_866,
            self.var_867,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_873 = paddle.nn.functional.norm.batch_norm(
            var_868,
            self.var_869,
            self.var_870,
            weight=self.var_871,
            bias=self.var_872,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_874 = paddle.nn.functional.activation.relu(var_873)
        var_876 = paddle.nn.functional.conv._conv_nd(
            var_874,
            self.var_875,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_881 = paddle.nn.functional.norm.batch_norm(
            var_876,
            self.var_877,
            self.var_878,
            weight=self.var_879,
            bias=self.var_880,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_882 = paddle.nn.functional.activation.relu(var_881)
        var_883 = paddle.tensor.manipulation.concat(
            [var_842, var_858, var_882], 1
        )
        var_885 = paddle.nn.functional.conv._conv_nd(
            var_883,
            self.var_884,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_890 = paddle.nn.functional.norm.batch_norm(
            var_885,
            self.var_886,
            self.var_887,
            weight=self.var_888,
            bias=self.var_889,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_891 = paddle.nn.functional.activation.relu(var_890)
        var_893 = paddle.nn.functional.conv._conv_nd(
            var_891,
            self.var_892,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_898 = paddle.nn.functional.norm.batch_norm(
            var_893,
            self.var_894,
            self.var_895,
            weight=self.var_896,
            bias=self.var_897,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_899 = paddle.nn.functional.activation.relu(var_898)
        var_901 = paddle.nn.functional.conv._conv_nd(
            var_883,
            self.var_900,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_906 = paddle.nn.functional.norm.batch_norm(
            var_901,
            self.var_902,
            self.var_903,
            weight=self.var_904,
            bias=self.var_905,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_907 = paddle.nn.functional.activation.relu(var_906)
        var_909 = paddle.nn.functional.conv._conv_nd(
            var_907,
            self.var_908,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_914 = paddle.nn.functional.norm.batch_norm(
            var_909,
            self.var_910,
            self.var_911,
            weight=self.var_912,
            bias=self.var_913,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_915 = paddle.nn.functional.activation.relu(var_914)
        var_917 = paddle.nn.functional.conv._conv_nd(
            var_915,
            self.var_916,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_922 = paddle.nn.functional.norm.batch_norm(
            var_917,
            self.var_918,
            self.var_919,
            weight=self.var_920,
            bias=self.var_921,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_923 = paddle.nn.functional.activation.relu(var_922)
        var_924 = paddle.tensor.manipulation.concat(
            [var_883, var_899, var_923], 1
        )
        var_926 = paddle.nn.functional.conv._conv_nd(
            var_924,
            self.var_925,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_931 = paddle.nn.functional.norm.batch_norm(
            var_926,
            self.var_927,
            self.var_928,
            weight=self.var_929,
            bias=self.var_930,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_932 = paddle.nn.functional.activation.relu(var_931)
        var_933 = paddle.nn.functional.pooling.avg_pool2d(
            var_932,
            kernel_size=2,
            stride=2,
            padding=0,
            ceil_mode=False,
            exclusive=True,
            divisor_override=None,
            data_format='NCHW',
            name=None,
        )
        var_935 = paddle.nn.functional.conv._conv_nd(
            var_933,
            self.var_934,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_940 = paddle.nn.functional.norm.batch_norm(
            var_935,
            self.var_936,
            self.var_937,
            weight=self.var_938,
            bias=self.var_939,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_941 = paddle.nn.functional.activation.relu(var_940)
        var_943 = paddle.nn.functional.conv._conv_nd(
            var_941,
            self.var_942,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_948 = paddle.nn.functional.norm.batch_norm(
            var_943,
            self.var_944,
            self.var_945,
            weight=self.var_946,
            bias=self.var_947,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_949 = paddle.nn.functional.activation.relu(var_948)
        var_951 = paddle.nn.functional.conv._conv_nd(
            var_933,
            self.var_950,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_956 = paddle.nn.functional.norm.batch_norm(
            var_951,
            self.var_952,
            self.var_953,
            weight=self.var_954,
            bias=self.var_955,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_957 = paddle.nn.functional.activation.relu(var_956)
        var_959 = paddle.nn.functional.conv._conv_nd(
            var_957,
            self.var_958,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_964 = paddle.nn.functional.norm.batch_norm(
            var_959,
            self.var_960,
            self.var_961,
            weight=self.var_962,
            bias=self.var_963,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_965 = paddle.nn.functional.activation.relu(var_964)
        var_967 = paddle.nn.functional.conv._conv_nd(
            var_965,
            self.var_966,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_972 = paddle.nn.functional.norm.batch_norm(
            var_967,
            self.var_968,
            self.var_969,
            weight=self.var_970,
            bias=self.var_971,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_973 = paddle.nn.functional.activation.relu(var_972)
        var_974 = paddle.tensor.manipulation.concat(
            [var_933, var_949, var_973], 1
        )
        var_976 = paddle.nn.functional.conv._conv_nd(
            var_974,
            self.var_975,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_981 = paddle.nn.functional.norm.batch_norm(
            var_976,
            self.var_977,
            self.var_978,
            weight=self.var_979,
            bias=self.var_980,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_982 = paddle.nn.functional.activation.relu(var_981)
        var_984 = paddle.nn.functional.conv._conv_nd(
            var_982,
            self.var_983,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_989 = paddle.nn.functional.norm.batch_norm(
            var_984,
            self.var_985,
            self.var_986,
            weight=self.var_987,
            bias=self.var_988,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_990 = paddle.nn.functional.activation.relu(var_989)
        var_992 = paddle.nn.functional.conv._conv_nd(
            var_974,
            self.var_991,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_997 = paddle.nn.functional.norm.batch_norm(
            var_992,
            self.var_993,
            self.var_994,
            weight=self.var_995,
            bias=self.var_996,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_998 = paddle.nn.functional.activation.relu(var_997)
        var_1000 = paddle.nn.functional.conv._conv_nd(
            var_998,
            self.var_999,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1005 = paddle.nn.functional.norm.batch_norm(
            var_1000,
            self.var_1001,
            self.var_1002,
            weight=self.var_1003,
            bias=self.var_1004,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1006 = paddle.nn.functional.activation.relu(var_1005)
        var_1008 = paddle.nn.functional.conv._conv_nd(
            var_1006,
            self.var_1007,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1013 = paddle.nn.functional.norm.batch_norm(
            var_1008,
            self.var_1009,
            self.var_1010,
            weight=self.var_1011,
            bias=self.var_1012,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1014 = paddle.nn.functional.activation.relu(var_1013)
        var_1015 = paddle.tensor.manipulation.concat(
            [var_974, var_990, var_1014], 1
        )
        var_1017 = paddle.nn.functional.conv._conv_nd(
            var_1015,
            self.var_1016,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1022 = paddle.nn.functional.norm.batch_norm(
            var_1017,
            self.var_1018,
            self.var_1019,
            weight=self.var_1020,
            bias=self.var_1021,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1023 = paddle.nn.functional.activation.relu(var_1022)
        var_1025 = paddle.nn.functional.conv._conv_nd(
            var_1023,
            self.var_1024,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1030 = paddle.nn.functional.norm.batch_norm(
            var_1025,
            self.var_1026,
            self.var_1027,
            weight=self.var_1028,
            bias=self.var_1029,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1031 = paddle.nn.functional.activation.relu(var_1030)
        var_1033 = paddle.nn.functional.conv._conv_nd(
            var_1015,
            self.var_1032,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1038 = paddle.nn.functional.norm.batch_norm(
            var_1033,
            self.var_1034,
            self.var_1035,
            weight=self.var_1036,
            bias=self.var_1037,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1039 = paddle.nn.functional.activation.relu(var_1038)
        var_1041 = paddle.nn.functional.conv._conv_nd(
            var_1039,
            self.var_1040,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1046 = paddle.nn.functional.norm.batch_norm(
            var_1041,
            self.var_1042,
            self.var_1043,
            weight=self.var_1044,
            bias=self.var_1045,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1047 = paddle.nn.functional.activation.relu(var_1046)
        var_1049 = paddle.nn.functional.conv._conv_nd(
            var_1047,
            self.var_1048,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1054 = paddle.nn.functional.norm.batch_norm(
            var_1049,
            self.var_1050,
            self.var_1051,
            weight=self.var_1052,
            bias=self.var_1053,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1055 = paddle.nn.functional.activation.relu(var_1054)
        var_1056 = paddle.tensor.manipulation.concat(
            [var_1015, var_1031, var_1055], 1
        )
        var_1058 = paddle.nn.functional.conv._conv_nd(
            var_1056,
            self.var_1057,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1063 = paddle.nn.functional.norm.batch_norm(
            var_1058,
            self.var_1059,
            self.var_1060,
            weight=self.var_1061,
            bias=self.var_1062,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1064 = paddle.nn.functional.activation.relu(var_1063)
        var_1066 = paddle.nn.functional.conv._conv_nd(
            var_1064,
            self.var_1065,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1071 = paddle.nn.functional.norm.batch_norm(
            var_1066,
            self.var_1067,
            self.var_1068,
            weight=self.var_1069,
            bias=self.var_1070,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1072 = paddle.nn.functional.activation.relu(var_1071)
        var_1074 = paddle.nn.functional.conv._conv_nd(
            var_1056,
            self.var_1073,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1079 = paddle.nn.functional.norm.batch_norm(
            var_1074,
            self.var_1075,
            self.var_1076,
            weight=self.var_1077,
            bias=self.var_1078,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1080 = paddle.nn.functional.activation.relu(var_1079)
        var_1082 = paddle.nn.functional.conv._conv_nd(
            var_1080,
            self.var_1081,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1087 = paddle.nn.functional.norm.batch_norm(
            var_1082,
            self.var_1083,
            self.var_1084,
            weight=self.var_1085,
            bias=self.var_1086,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1088 = paddle.nn.functional.activation.relu(var_1087)
        var_1090 = paddle.nn.functional.conv._conv_nd(
            var_1088,
            self.var_1089,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1095 = paddle.nn.functional.norm.batch_norm(
            var_1090,
            self.var_1091,
            self.var_1092,
            weight=self.var_1093,
            bias=self.var_1094,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1096 = paddle.nn.functional.activation.relu(var_1095)
        var_1097 = paddle.tensor.manipulation.concat(
            [var_1056, var_1072, var_1096], 1
        )
        var_1099 = paddle.nn.functional.conv._conv_nd(
            var_1097,
            self.var_1098,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1104 = paddle.nn.functional.norm.batch_norm(
            var_1099,
            self.var_1100,
            self.var_1101,
            weight=self.var_1102,
            bias=self.var_1103,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1105 = paddle.nn.functional.activation.relu(var_1104)
        var_1107 = paddle.nn.functional.conv._conv_nd(
            var_1105,
            self.var_1106,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1112 = paddle.nn.functional.norm.batch_norm(
            var_1107,
            self.var_1108,
            self.var_1109,
            weight=self.var_1110,
            bias=self.var_1111,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1113 = paddle.nn.functional.activation.relu(var_1112)
        var_1115 = paddle.nn.functional.conv._conv_nd(
            var_1097,
            self.var_1114,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1120 = paddle.nn.functional.norm.batch_norm(
            var_1115,
            self.var_1116,
            self.var_1117,
            weight=self.var_1118,
            bias=self.var_1119,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1121 = paddle.nn.functional.activation.relu(var_1120)
        var_1123 = paddle.nn.functional.conv._conv_nd(
            var_1121,
            self.var_1122,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1128 = paddle.nn.functional.norm.batch_norm(
            var_1123,
            self.var_1124,
            self.var_1125,
            weight=self.var_1126,
            bias=self.var_1127,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1129 = paddle.nn.functional.activation.relu(var_1128)
        var_1131 = paddle.nn.functional.conv._conv_nd(
            var_1129,
            self.var_1130,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1136 = paddle.nn.functional.norm.batch_norm(
            var_1131,
            self.var_1132,
            self.var_1133,
            weight=self.var_1134,
            bias=self.var_1135,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1137 = paddle.nn.functional.activation.relu(var_1136)
        var_1138 = paddle.tensor.manipulation.concat(
            [var_1097, var_1113, var_1137], 1
        )
        var_1140 = paddle.nn.functional.conv._conv_nd(
            var_1138,
            self.var_1139,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1145 = paddle.nn.functional.norm.batch_norm(
            var_1140,
            self.var_1141,
            self.var_1142,
            weight=self.var_1143,
            bias=self.var_1144,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1146 = paddle.nn.functional.activation.relu(var_1145)
        var_1148 = paddle.nn.functional.conv._conv_nd(
            var_1146,
            self.var_1147,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1153 = paddle.nn.functional.norm.batch_norm(
            var_1148,
            self.var_1149,
            self.var_1150,
            weight=self.var_1151,
            bias=self.var_1152,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1154 = paddle.nn.functional.activation.relu(var_1153)
        var_1156 = paddle.nn.functional.conv._conv_nd(
            var_1138,
            self.var_1155,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1161 = paddle.nn.functional.norm.batch_norm(
            var_1156,
            self.var_1157,
            self.var_1158,
            weight=self.var_1159,
            bias=self.var_1160,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1162 = paddle.nn.functional.activation.relu(var_1161)
        var_1164 = paddle.nn.functional.conv._conv_nd(
            var_1162,
            self.var_1163,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1169 = paddle.nn.functional.norm.batch_norm(
            var_1164,
            self.var_1165,
            self.var_1166,
            weight=self.var_1167,
            bias=self.var_1168,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1170 = paddle.nn.functional.activation.relu(var_1169)
        var_1172 = paddle.nn.functional.conv._conv_nd(
            var_1170,
            self.var_1171,
            bias=None,
            stride=[1, 1],
            padding=[1, 1],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1177 = paddle.nn.functional.norm.batch_norm(
            var_1172,
            self.var_1173,
            self.var_1174,
            weight=self.var_1175,
            bias=self.var_1176,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1178 = paddle.nn.functional.activation.relu(var_1177)
        var_1179 = paddle.tensor.manipulation.concat(
            [var_1138, var_1154, var_1178], 1
        )
        var_1181 = paddle.nn.functional.conv._conv_nd(
            var_1179,
            self.var_1180,
            bias=None,
            stride=[1, 1],
            padding=[0, 0],
            padding_algorithm='EXPLICIT',
            dilation=[1, 1],
            groups=1,
            data_format='NCHW',
            channel_dim=1,
            op_type='conv2d',
            use_cudnn=True,
        )
        var_1186 = paddle.nn.functional.norm.batch_norm(
            var_1181,
            self.var_1182,
            self.var_1183,
            weight=self.var_1184,
            bias=self.var_1185,
            training=False,
            momentum=0.9,
            epsilon=1e-05,
            data_format='NCHW',
            use_global_stats=None,
        )
        var_1187 = paddle.nn.functional.activation.relu(var_1186)
        return var_1187


class TestSIR80(unittest.TestCase):
    def setUp(self):
        self.inputs = (
            paddle.rand(shape=[86, 3, 224, 224], dtype=paddle.float32),
        )
        self.net = SIR80()

    def train(self, net, to_static, with_prim=False, with_cinn=False):
        paddle.set_flags({'FLAGS_prim_all': with_prim})
        if to_static:
            if with_cinn:
                build_strategy = paddle.static.BuildStrategy()
                build_strategy.build_cinn_pass = True
                net = paddle.jit.to_static(
                    net, build_strategy=build_strategy, full_graph=True
                )
            else:
                net = paddle.jit.to_static(net, full_graph=True)
        outs = net(*self.inputs)
        return outs

    def test_ast_prim_cinn(self):
        st_out = self.train(self.net, to_static=True)
        cinn_out = self.train(
            self.net, to_static=True, with_prim=True, with_cinn=True
        )
        for st, cinn in zip(
            paddle.utils.flatten(st_out), paddle.utils.flatten(cinn_out)
        ):
            np.testing.assert_allclose(st.numpy(), cinn.numpy(), atol=1e-8)


if __name__ == '__main__':
    unittest.main()
