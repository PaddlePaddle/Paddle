# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest

import numpy as np
from op_test import OpTest

from paddle import _C_ops


def round_c_single_element(val):
    dtype = type(val)
    if val >= 0:
        return dtype(np.floor(val + 0.5))
    return dtype(np.ceil(val - 0.5))


# rounding to nearest ties away from zero
round_c = np.vectorize(round_c_single_element)


def get_compute_type(dtype):
    assert dtype in [np.float16, np.float32, np.float64]
    if dtype == np.float16:
        return np.float32
    return dtype


def fake_quantize_dequantize_lsqplus_wrapper(
    x, alpha, beta, g_scale, bit_length, is_sign, round_type
):
    return _C_ops.fake_quantize_dequantize_lsqplus(
        x, alpha, beta, g_scale, bit_length, is_sign, round_type
    )


class TestFakeQuantizeDequantizeLsqplusOp(OpTest):
    def setUp(self):
        self.op_type = 'fake_quantize_dequantize_lsqplus'
        self.attrs = {
            'bit_length': 8,
        }
        self.python_api = fake_quantize_dequantize_lsqplus_wrapper

    def _cal_backward(
        self, out_grad, x, alpha, beta, g, Qn, Qp, round_type, dtype
    ):
        round_fn = round_c if round_type == 'TiesToEven' else np.round
        q_x = (x - beta) / alpha
        lower_flag = (q_x < Qn).astype(dtype)
        upper_flag = (q_x > Qp).astype(dtype)
        middle_flag = 1.0 - lower_flag - upper_flag
        grad_alpha = np.sum(
            (
                lower_flag * Qn
                + upper_flag * Qp
                + middle_flag * round_fn(q_x)
                - middle_flag * q_x
            )
            * out_grad
            * g
        )
        grad_beta = np.sum((lower_flag + upper_flag) * out_grad * g)
        grad_x = middle_flag * out_grad

        return grad_x, grad_alpha.reshape([1]), grad_beta.reshape([1])

    def _fake_quantize_dequantize_lsqplus(
        self,
        dtype,
        input_shape,
        distributions,
        round_type='TiesAwayFromZero',
        is_sign=False,
        dygraph=True,
    ):
        input_data = distributions[0](input_shape).astype(dtype)
        alpha = distributions[1]([1]).astype(dtype)
        beta = distributions[2]([1]).astype(dtype)
        g_scale = distributions[3]([1]).astype(dtype)

        # prepare for forward stage
        if is_sign:
            Qn, Qp = (
                -(2 ** (self.attrs['bit_length'] - 1)),
                2 ** (self.attrs['bit_length'] - 1) - 1,
            )
        else:
            Qn, Qp = 0, 2 ** (self.attrs['bit_length']) - 1

        if round_type == 'TiesToEven':
            # round then clip
            round_out = round_c((input_data - beta) / alpha)
            output_data = np.clip(round_out, Qn, Qp) * alpha + beta
            self.attrs['round_type'] = 0
        else:
            # clip then round
            data = np.clip((input_data - beta) / alpha, Qn, Qp)
            output_data = round_c(data) * alpha + beta
            self.attrs['round_type'] = 1

        self.attrs['is_sign'] = is_sign
        self.attrs['round_type'] = 0 if round_type == 'TiesToEven' else 1
        self.inputs = {
            'x': input_data,
            'alpha': alpha,
            'beta': beta,
            'g_scale': g_scale,
        }
        self.outputs = {'out': output_data}
        self.dtype = dtype

        # check forward stage
        self.check_output(check_dygraph=dygraph)
        # check backward stage
        out_grad = np.random.random(input_data.shape).astype(dtype)
        # get input gradient
        test_gradients = self._cal_backward(
            out_grad,
            input_data,
            alpha,
            beta,
            g_scale,
            Qn,
            Qp,
            round_type,
            dtype,
        )
        # use 'gradient' to verify gradient from actual operator(its gradient generated by out_grad)
        self._test_grad(
            ['x', 'alpha', 'beta'],
            test_gradients,
            [out_grad],
            dygraph,
            {'g_scale'},
        )

    def _test_grad(
        self, name, gradient, out_grads, check_dygraph=False, no_grad_set=set()
    ):
        self.check_grad(
            name,
            'out',
            user_defined_grads=gradient,
            user_defined_grad_outputs=out_grads,
            check_dygraph=check_dygraph,
            no_grad_set=no_grad_set,
        )

    def test_fake_quantize_dequantize(self):
        print('start testing')
        distributions = [
            np.random.random,
            np.random.random,
            np.random.random,
            np.random.random,
        ]
        self._fake_quantize_dequantize_lsqplus(
            np.float32,
            (128, 128),
            distributions,
            'TiesAwayFromZero',
            is_sign=False,
            dygraph=False,
        )

    def test_fake_quantize_dequantize_round1(self):
        distributions = [
            np.random.random,
            np.random.random,
            np.random.random,
            np.random.random,
        ]
        self._fake_quantize_dequantize_lsqplus(
            np.float32,
            (128, 128),
            distributions,
            'TiesToEven',
            is_sign=False,
            dygraph=False,
        )

    def test_fake_quantize_dequantize_large_scale(self):
        distributions = [
            np.random.random,
            np.random.random,
            np.random.random,
            np.random.random,
        ]
        self._fake_quantize_dequantize_lsqplus(
            np.float32,
            (3, 3, 1024, 1024),
            distributions,
            'TiesToEven',
            is_sign=False,
            dygraph=False,
        )


if __name__ == '__main__':
    unittest.main()
