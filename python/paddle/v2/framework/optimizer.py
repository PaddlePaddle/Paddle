class Optimizer(object):
    """Optimizer Base class.

    """

    def __init__(self):
        pass

    def create_backward_pass(self, loss, parameter_list=None):
        """
        Add gradient Operators into Block to Compute gradients of `loss`
        for parameters in parameter_list

        Args:
          loss: an variable generated by cost function.
          parameter_list: parameters that need to compute gradient and update to minimize the lost

        Returns:
          (parameters, gradients) pair list.
        """
        return None

    def create_optimization_pass(self, vars_grads):
        """Add Operators to Apply gradients to variables.

        Args:
          vars_grads: a list of (variable, gradient) pair to update.

        Returns:
          optmization_op_list: a list of optimization operator that will optimize parameter with gradient.
        """
        return None

    def minimize(self, loss, parameter_list):
        """Add operations to minimize `loss` by updating `parameter_list `.

        This method simply combines calls `create_backward_pass()` and
        `create_optimization_pass()`.
        """
        vars_grads = self.create_backward_pass(loss, parameter_list)
        update_ops = self.create_optimization_pass(vars_grads)
        return update_ops
