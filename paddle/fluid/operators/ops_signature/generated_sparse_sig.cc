// Copyright (c) 2023 PaddlePaddle Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// this file is generated by paddle/phi/api/yaml/generator/generate_op.py, do
// not edit.
#include "paddle/phi/core/compat/op_utils.h"
#include "paddle/utils/small_vector.h"

namespace phi {

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAbsOpArgumentMapping:

return KernelSignature("abs_coo", {"x"}, {}, {"out"});
return KernelSignature("abs_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAbsOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "abs_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "abs_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAcosOpArgumentMapping:

return KernelSignature("acos_coo", {"x"}, {}, {"out"});
return KernelSignature("acos_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAcosOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "acos_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "acos_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAcoshOpArgumentMapping:

return KernelSignature("acosh_coo", {"x"}, {}, {"out"});
return KernelSignature("acosh_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAcoshOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "acosh_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "acosh_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAddOpArgumentMapping:

return KernelSignature("add_coo_coo", {"x", "y"}, {}, {"out"});
return KernelSignature("add_csr_csr", {"x", "y"}, {}, {"out"});
return KernelSignature("add_coo_dense", {"x", "y"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAddOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y")) {
    kernel_name = "add_coo_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y")) {
    kernel_name = "add_csr_csr";
  }
  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("y")) {
    kernel_name = "add_coo_dense";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAsinOpArgumentMapping:

return KernelSignature("asin_coo", {"x"}, {}, {"out"});
return KernelSignature("asin_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAsinOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "asin_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "asin_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAsinhOpArgumentMapping:

return KernelSignature("asinh_coo", {"x"}, {}, {"out"});
return KernelSignature("asinh_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAsinhOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "asinh_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "asinh_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAtanOpArgumentMapping:

return KernelSignature("atan_coo", {"x"}, {}, {"out"});
return KernelSignature("atan_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAtanOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "atan_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "atan_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAtanhOpArgumentMapping:

return KernelSignature("atanh_coo", {"x"}, {}, {"out"});
return KernelSignature("atanh_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseAtanhOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "atanh_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "atanh_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseBatchNormOpArgumentMapping:

return KernelSignature("batch_norm_coo", {"x", "mean", "variance", "scale",
"bias"}, {"is_test", "momentum", "epsilon", "data_layout", "use_global_stats",
"trainable_statistics"}, {"out", "mean_out", "variance_out", "saved_mean",
"saved_variance", "reserve_space"});
******************************************************************
*/

KernelSignature SparseBatchNormOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{
      "x", "mean", "variance", "scale", "bias"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("is_test");
  attrs.emplace_back("momentum");
  attrs.emplace_back("epsilon");
  attrs.emplace_back("data_layout");
  attrs.emplace_back("use_global_stats");
  attrs.emplace_back("trainable_statistics");
  paddle::small_vector<const char*> outputs{"out",
                                            "mean_out",
                                            "variance_out",
                                            "saved_mean",
                                            "saved_variance",
                                            "reserve_space"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("mean") &&
      ctx.IsDenseTensorInput("variance") && ctx.IsDenseTensorInput("scale") &&
      ctx.IsDenseTensorInput("bias")) {
    kernel_name = "batch_norm_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseCastOpArgumentMapping:

return KernelSignature("cast_coo", {"x"}, {"index_dtype", "value_dtype"},
{"out"}); return KernelSignature("cast_csr", {"x"}, {"index_dtype",
"value_dtype"}, {"out"});
******************************************************************
*/

KernelSignature SparseCastOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("index_dtype");
  attrs.emplace_back("value_dtype");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "cast_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "cast_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseConv3dOpArgumentMapping:

return KernelSignature("conv3d_coo", {"x", "kernel"}, {"paddings", "dilations",
"strides", "groups", "subm", "key"}, {"out", "rulebook", "counter"});
******************************************************************
*/

KernelSignature SparseConv3dOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "kernel"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("paddings");
  attrs.emplace_back("dilations");
  attrs.emplace_back("strides");
  attrs.emplace_back("groups");
  attrs.emplace_back("subm");
  attrs.emplace_back("key");
  paddle::small_vector<const char*> outputs{"out", "rulebook", "counter"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("kernel")) {
    kernel_name = "conv3d_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseDivideOpArgumentMapping:

return KernelSignature("divide_coo_coo", {"x", "y"}, {}, {"out"});
return KernelSignature("divide_csr_csr", {"x", "y"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseDivideOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y")) {
    kernel_name = "divide_coo_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y")) {
    kernel_name = "divide_csr_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseDivideScalarOpArgumentMapping:

return KernelSignature("divide_scalar_coo", {"x"}, {"scalar"}, {"out"});
return KernelSignature("divide_scalar_csr", {"x"}, {"scalar"}, {"out"});
******************************************************************
*/

KernelSignature SparseDivideScalarOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("scalar");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "divide_scalar_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "divide_scalar_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseExpm1OpArgumentMapping:

return KernelSignature("expm1_coo", {"x"}, {}, {"out"});
return KernelSignature("expm1_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseExpm1OpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "expm1_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "expm1_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseIsnanOpArgumentMapping:

return KernelSignature("isnan_coo", {"x"}, {}, {"out"});
return KernelSignature("isnan_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseIsnanOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "isnan_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "isnan_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseLeakyReluOpArgumentMapping:

return KernelSignature("leaky_relu_coo", {"x"}, {"alpha"}, {"out"});
return KernelSignature("leaky_relu_csr", {"x"}, {"alpha"}, {"out"});
******************************************************************
*/

KernelSignature SparseLeakyReluOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("alpha");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "leaky_relu_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "leaky_relu_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseLog1pOpArgumentMapping:

return KernelSignature("log1p_coo", {"x"}, {}, {"out"});
return KernelSignature("log1p_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseLog1pOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "log1p_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "log1p_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMultiplyOpArgumentMapping:

return KernelSignature("multiply_coo_coo", {"x", "y"}, {}, {"out"});
return KernelSignature("multiply_csr_csr", {"x", "y"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseMultiplyOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y")) {
    kernel_name = "multiply_coo_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y")) {
    kernel_name = "multiply_csr_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparsePowOpArgumentMapping:

return KernelSignature("pow_coo", {"x"}, {"factor"}, {"out"});
return KernelSignature("pow_csr", {"x"}, {"factor"}, {"out"});
******************************************************************
*/

KernelSignature SparsePowOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("factor");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "pow_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "pow_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseReluOpArgumentMapping:

return KernelSignature("relu_coo", {"x"}, {}, {"out"});
return KernelSignature("relu_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseReluOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "relu_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "relu_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseRelu6OpArgumentMapping:

return KernelSignature("relu6_coo", {"x"}, {}, {"out"});
return KernelSignature("relu6_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseRelu6OpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "relu6_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "relu6_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseReshapeOpArgumentMapping:

return KernelSignature("reshape_coo", {"x"}, {"shape"}, {"out"});
return KernelSignature("reshape_coo", {"x"}, {"ShapeTensor"}, {"out"});
return KernelSignature("reshape_coo", {"x"}, {"ShapeTensorList"}, {"out"});
return KernelSignature("reshape_csr", {"x"}, {"shape"}, {"out"});
return KernelSignature("reshape_csr", {"x"}, {"ShapeTensor"}, {"out"});
return KernelSignature("reshape_csr", {"x"}, {"ShapeTensorList"}, {"out"});
******************************************************************
*/

KernelSignature SparseReshapeOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back(ctx.HasInput("ShapeTensor")            ? "ShapeTensor"
                     : ctx.InputSize("ShapeTensorList") > 0 ? "ShapeTensorList"
                                                            : "shape");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "reshape_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "reshape_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseScaleOpArgumentMapping:

return KernelSignature("scale_coo", {"x"}, {"scale", "bias",
"bias_after_scale"}, {"out"}); return KernelSignature("scale_csr", {"x"},
{"scale", "bias", "bias_after_scale"}, {"out"});
******************************************************************
*/

KernelSignature SparseScaleOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("scale");
  attrs.emplace_back("bias");
  attrs.emplace_back("bias_after_scale");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "scale_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "scale_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSinOpArgumentMapping:

return KernelSignature("sin_coo", {"x"}, {}, {"out"});
return KernelSignature("sin_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseSinOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "sin_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "sin_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSinhOpArgumentMapping:

return KernelSignature("sinh_coo", {"x"}, {}, {"out"});
return KernelSignature("sinh_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseSinhOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "sinh_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "sinh_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSoftmaxOpArgumentMapping:

return KernelSignature("softmax_coo", {"x"}, {"axis"}, {"out"});
return KernelSignature("softmax_csr", {"x"}, {"axis"}, {"out"});
******************************************************************
*/

KernelSignature SparseSoftmaxOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("axis");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "softmax_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "softmax_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by
SparseSparseCooTensorOpArgumentMapping:

return KernelSignature("sparse_coo_tensor", {"values", "indices"}, {"shape"},
{"out"});
******************************************************************
*/

KernelSignature SparseSparseCooTensorOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"values", "indices"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("shape");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("values") && ctx.IsDenseTensorInput("indices")) {
    kernel_name = "sparse_coo_tensor";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSqrtOpArgumentMapping:

return KernelSignature("sqrt_coo", {"x"}, {}, {"out"});
return KernelSignature("sqrt_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseSqrtOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "sqrt_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "sqrt_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSquareOpArgumentMapping:

return KernelSignature("square_coo", {"x"}, {}, {"out"});
return KernelSignature("square_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseSquareOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "square_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "square_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSubtractOpArgumentMapping:

return KernelSignature("subtract_coo_coo", {"x", "y"}, {}, {"out"});
return KernelSignature("subtract_csr_csr", {"x", "y"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseSubtractOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y")) {
    kernel_name = "subtract_coo_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y")) {
    kernel_name = "subtract_csr_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSumOpArgumentMapping:

return KernelSignature("sum_coo", {"x"}, {"axis", "dtype", "keepdim"}, {"out"});
return KernelSignature("sum_coo", {"x"}, {"AxisTensor", "dtype", "keepdim"},
{"out"}); return KernelSignature("sum_coo", {"x"}, {"AxisTensorList", "dtype",
"keepdim"}, {"out"}); return KernelSignature("sum_csr", {"x"}, {"axis", "dtype",
"keepdim"}, {"out"}); return KernelSignature("sum_csr", {"x"}, {"AxisTensor",
"dtype", "keepdim"}, {"out"}); return KernelSignature("sum_csr", {"x"},
{"AxisTensorList", "dtype", "keepdim"}, {"out"});
******************************************************************
*/

KernelSignature SparseSumOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back(ctx.HasInput("AxisTensor")            ? "AxisTensor"
                     : ctx.InputSize("AxisTensorList") > 0 ? "AxisTensorList"
                                                           : "axis");
  attrs.emplace_back("dtype");
  attrs.emplace_back("keepdim");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "sum_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "sum_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSyncBatchNormOpArgumentMapping:

return KernelSignature("sync_batch_norm_coo", {"x", "mean", "variance", "scale",
"bias"}, {"is_test", "momentum", "epsilon", "data_layout", "use_global_stats",
"trainable_statistics"}, {"out", "mean_out", "variance_out", "saved_mean",
"saved_variance", "reserve_space"});
******************************************************************
*/

KernelSignature SparseSyncBatchNormOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{
      "x", "mean", "variance", "scale", "bias"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("is_test");
  attrs.emplace_back("momentum");
  attrs.emplace_back("epsilon");
  attrs.emplace_back("data_layout");
  attrs.emplace_back("use_global_stats");
  attrs.emplace_back("trainable_statistics");
  paddle::small_vector<const char*> outputs{"out",
                                            "mean_out",
                                            "variance_out",
                                            "saved_mean",
                                            "saved_variance",
                                            "reserve_space"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("mean") &&
      ctx.IsDenseTensorInput("variance") && ctx.IsDenseTensorInput("scale") &&
      ctx.IsDenseTensorInput("bias")) {
    kernel_name = "sync_batch_norm_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseTanOpArgumentMapping:

return KernelSignature("tan_coo", {"x"}, {}, {"out"});
return KernelSignature("tan_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseTanOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "tan_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "tan_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseTanhOpArgumentMapping:

return KernelSignature("tanh_coo", {"x"}, {}, {"out"});
return KernelSignature("tanh_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseTanhOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "tanh_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "tanh_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseToDenseOpArgumentMapping:

return KernelSignature("coo_to_dense", {"x"}, {}, {"out"});
return KernelSignature("csr_to_dense", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseToDenseOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "coo_to_dense";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "csr_to_dense";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseToSparseCooOpArgumentMapping:

return KernelSignature("dense_to_coo", {"x"}, {"sparse_dim"}, {"out"});
return KernelSignature("csr_to_coo", {"x"}, {"sparse_dim"}, {"out"});
******************************************************************
*/

KernelSignature SparseToSparseCooOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("sparse_dim");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("x")) {
    kernel_name = "dense_to_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "csr_to_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseToSparseCsrOpArgumentMapping:

return KernelSignature("dense_to_csr", {"x"}, {}, {"out"});
return KernelSignature("coo_to_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseToSparseCsrOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("x")) {
    kernel_name = "dense_to_csr";
  }
  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "coo_to_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseTransposeOpArgumentMapping:

return KernelSignature("transpose_coo", {"x"}, {"perm"}, {"out"});
return KernelSignature("transpose_csr", {"x"}, {"perm"}, {"out"});
******************************************************************
*/

KernelSignature SparseTransposeOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("perm");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "transpose_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "transpose_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseValuesOpArgumentMapping:

return KernelSignature("values_coo", {"x"}, {}, {"out"});
return KernelSignature("values_csr", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseValuesOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "values_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "values_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAddmmOpArgumentMapping:

return KernelSignature("addmm_csr_dense", {"input", "x", "y"}, {"beta",
"alpha"}, {"out"}); return KernelSignature("addmm_csr_csr", {"input", "x", "y"},
{"beta", "alpha"}, {"out"}); return KernelSignature("addmm_coo_dense", {"input",
"x", "y"}, {"beta", "alpha"}, {"out"}); return KernelSignature("addmm_coo_coo",
{"input", "x", "y"}, {"beta", "alpha"}, {"out"});
******************************************************************
*/

KernelSignature SparseAddmmOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"input", "x", "y"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("beta");
  attrs.emplace_back("alpha");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("input") && ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsDenseTensorInput("y")) {
    kernel_name = "addmm_csr_dense";
  }
  if (ctx.IsSparseCsrTensorInput("input") && ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("y")) {
    kernel_name = "addmm_csr_csr";
  }
  if (ctx.IsDenseTensorInput("input") && ctx.IsSparseCooTensorInput("x") &&
      ctx.IsDenseTensorInput("y")) {
    kernel_name = "addmm_coo_dense";
  }
  if (ctx.IsSparseCooTensorInput("input") && ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("y")) {
    kernel_name = "addmm_coo_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseCoalesceOpArgumentMapping:

return KernelSignature("coalesce_coo", {"x"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseCoalesceOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "coalesce_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseFullLikeOpArgumentMapping:

return KernelSignature("full_like_coo", {"x"}, {"value", "dtype"}, {"out"});
return KernelSignature("full_like_coo", {"x"}, {"ValueTensor", "dtype"},
{"out"}); return KernelSignature("full_like_csr", {"x"}, {"value", "dtype"},
{"out"}); return KernelSignature("full_like_csr", {"x"}, {"ValueTensor",
"dtype"}, {"out"});
******************************************************************
*/

KernelSignature SparseFullLikeOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back(ctx.HasInput("ValueTensor") ? "ValueTensor" : "value");
  attrs.emplace_back("dtype");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "full_like_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "full_like_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseFusedAttentionOpArgumentMapping:

return KernelSignature("fused_attention_csr", {"query", "key", "value",
"sparse_mask", "key_padding_mask", "attn_mask"}, {}, {"out", "softmax"});
******************************************************************
*/

KernelSignature SparseFusedAttentionOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{
      "query", "key", "value", "sparse_mask", "key_padding_mask", "attn_mask"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out", "softmax"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("query") && ctx.IsDenseTensorInput("key") &&
      ctx.IsDenseTensorInput("value") &&
      ctx.IsSparseCsrTensorInput("sparse_mask") &&
      ctx.IsDenseTensorInput("key_padding_mask") &&
      ctx.IsDenseTensorInput("attn_mask")) {
    kernel_name = "fused_attention_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMaskedMatmulOpArgumentMapping:

return KernelSignature("masked_matmul_csr", {"x", "y", "mask"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseMaskedMatmulOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y", "mask"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("x") && ctx.IsDenseTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("mask")) {
    kernel_name = "masked_matmul_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMatmulOpArgumentMapping:

return KernelSignature("matmul_csr_dense", {"x", "y"}, {}, {"out"});
return KernelSignature("matmul_csr_csr", {"x", "y"}, {}, {"out"});
return KernelSignature("matmul_coo_dense", {"x", "y"}, {}, {"out"});
return KernelSignature("matmul_coo_coo", {"x", "y"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseMatmulOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsDenseTensorInput("y")) {
    kernel_name = "matmul_csr_dense";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y")) {
    kernel_name = "matmul_csr_csr";
  }
  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("y")) {
    kernel_name = "matmul_coo_dense";
  }
  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y")) {
    kernel_name = "matmul_coo_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMaxpoolOpArgumentMapping:

return KernelSignature("maxpool_coo", {"x"}, {"kernel_sizes", "paddings",
"dilations", "strides"}, {"out", "rulebook", "counter"});
******************************************************************
*/

KernelSignature SparseMaxpoolOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("kernel_sizes");
  attrs.emplace_back("paddings");
  attrs.emplace_back("dilations");
  attrs.emplace_back("strides");
  paddle::small_vector<const char*> outputs{"out", "rulebook", "counter"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "maxpool_coo";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMvOpArgumentMapping:

return KernelSignature("mv_coo", {"x", "vec"}, {}, {"out"});
return KernelSignature("mv_csr", {"x", "vec"}, {}, {"out"});
******************************************************************
*/

KernelSignature SparseMvOpArgumentMapping(const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "vec"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("vec")) {
    kernel_name = "mv_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsDenseTensorInput("vec")) {
    kernel_name = "mv_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSliceOpArgumentMapping:

return KernelSignature("slice_coo", {"x"}, {"axes", "starts", "ends"}, {"out"});
return KernelSignature("slice_coo", {"x"}, {"axes", "starts", "EndsTensor"},
{"out"}); return KernelSignature("slice_coo", {"x"}, {"axes", "starts",
"EndsTensorList"}, {"out"}); return KernelSignature("slice_coo", {"x"}, {"axes",
"StartsTensor", "ends"}, {"out"}); return KernelSignature("slice_coo", {"x"},
{"axes", "StartsTensor", "EndsTensor"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"axes", "StartsTensor", "EndsTensorList"},
{"out"}); return KernelSignature("slice_coo", {"x"}, {"axes",
"StartsTensorList", "ends"}, {"out"}); return KernelSignature("slice_coo",
{"x"}, {"axes", "StartsTensorList", "EndsTensor"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"axes", "StartsTensorList",
"EndsTensorList"}, {"out"}); return KernelSignature("slice_coo", {"x"},
{"AxesTensor", "starts", "ends"}, {"out"}); return KernelSignature("slice_coo",
{"x"}, {"AxesTensor", "starts", "EndsTensor"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"AxesTensor", "starts", "EndsTensorList"},
{"out"}); return KernelSignature("slice_coo", {"x"}, {"AxesTensor",
"StartsTensor", "ends"}, {"out"}); return KernelSignature("slice_coo", {"x"},
{"AxesTensor", "StartsTensor", "EndsTensor"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"AxesTensor", "StartsTensor",
"EndsTensorList"}, {"out"}); return KernelSignature("slice_coo", {"x"},
{"AxesTensor", "StartsTensorList", "ends"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"AxesTensor", "StartsTensorList",
"EndsTensor"}, {"out"}); return KernelSignature("slice_coo", {"x"},
{"AxesTensor", "StartsTensorList", "EndsTensorList"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"AxesTensorList", "starts", "ends"},
{"out"}); return KernelSignature("slice_coo", {"x"}, {"AxesTensorList",
"starts", "EndsTensor"}, {"out"}); return KernelSignature("slice_coo", {"x"},
{"AxesTensorList", "starts", "EndsTensorList"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"AxesTensorList", "StartsTensor", "ends"},
{"out"}); return KernelSignature("slice_coo", {"x"}, {"AxesTensorList",
"StartsTensor", "EndsTensor"}, {"out"}); return KernelSignature("slice_coo",
{"x"}, {"AxesTensorList", "StartsTensor", "EndsTensorList"}, {"out"}); return
KernelSignature("slice_coo", {"x"}, {"AxesTensorList", "StartsTensorList",
"ends"}, {"out"}); return KernelSignature("slice_coo", {"x"}, {"AxesTensorList",
"StartsTensorList", "EndsTensor"}, {"out"}); return KernelSignature("slice_coo",
{"x"}, {"AxesTensorList", "StartsTensorList", "EndsTensorList"}, {"out"});
return KernelSignature("slice_csr", {"x"}, {"axes", "starts", "ends"}, {"out"});
return KernelSignature("slice_csr", {"x"}, {"axes", "starts", "EndsTensor"},
{"out"}); return KernelSignature("slice_csr", {"x"}, {"axes", "starts",
"EndsTensorList"}, {"out"}); return KernelSignature("slice_csr", {"x"}, {"axes",
"StartsTensor", "ends"}, {"out"}); return KernelSignature("slice_csr", {"x"},
{"axes", "StartsTensor", "EndsTensor"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"axes", "StartsTensor", "EndsTensorList"},
{"out"}); return KernelSignature("slice_csr", {"x"}, {"axes",
"StartsTensorList", "ends"}, {"out"}); return KernelSignature("slice_csr",
{"x"}, {"axes", "StartsTensorList", "EndsTensor"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"axes", "StartsTensorList",
"EndsTensorList"}, {"out"}); return KernelSignature("slice_csr", {"x"},
{"AxesTensor", "starts", "ends"}, {"out"}); return KernelSignature("slice_csr",
{"x"}, {"AxesTensor", "starts", "EndsTensor"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"AxesTensor", "starts", "EndsTensorList"},
{"out"}); return KernelSignature("slice_csr", {"x"}, {"AxesTensor",
"StartsTensor", "ends"}, {"out"}); return KernelSignature("slice_csr", {"x"},
{"AxesTensor", "StartsTensor", "EndsTensor"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"AxesTensor", "StartsTensor",
"EndsTensorList"}, {"out"}); return KernelSignature("slice_csr", {"x"},
{"AxesTensor", "StartsTensorList", "ends"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"AxesTensor", "StartsTensorList",
"EndsTensor"}, {"out"}); return KernelSignature("slice_csr", {"x"},
{"AxesTensor", "StartsTensorList", "EndsTensorList"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"AxesTensorList", "starts", "ends"},
{"out"}); return KernelSignature("slice_csr", {"x"}, {"AxesTensorList",
"starts", "EndsTensor"}, {"out"}); return KernelSignature("slice_csr", {"x"},
{"AxesTensorList", "starts", "EndsTensorList"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"AxesTensorList", "StartsTensor", "ends"},
{"out"}); return KernelSignature("slice_csr", {"x"}, {"AxesTensorList",
"StartsTensor", "EndsTensor"}, {"out"}); return KernelSignature("slice_csr",
{"x"}, {"AxesTensorList", "StartsTensor", "EndsTensorList"}, {"out"}); return
KernelSignature("slice_csr", {"x"}, {"AxesTensorList", "StartsTensorList",
"ends"}, {"out"}); return KernelSignature("slice_csr", {"x"}, {"AxesTensorList",
"StartsTensorList", "EndsTensor"}, {"out"}); return KernelSignature("slice_csr",
{"x"}, {"AxesTensorList", "StartsTensorList", "EndsTensorList"}, {"out"});
******************************************************************
*/

KernelSignature SparseSliceOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back(ctx.HasInput("AxesTensor")            ? "AxesTensor"
                     : ctx.InputSize("AxesTensorList") > 0 ? "AxesTensorList"
                                                           : "axes");
  attrs.emplace_back(ctx.HasInput("StartsTensor") ? "StartsTensor"
                     : ctx.InputSize("StartsTensorList") > 0
                         ? "StartsTensorList"
                         : "starts");
  attrs.emplace_back(ctx.HasInput("EndsTensor")            ? "EndsTensor"
                     : ctx.InputSize("EndsTensorList") > 0 ? "EndsTensorList"
                                                           : "ends");
  paddle::small_vector<const char*> outputs{"out"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x")) {
    kernel_name = "slice_coo";
  }
  if (ctx.IsSparseCsrTensorInput("x")) {
    kernel_name = "slice_csr";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAbsGradOpArgumentMapping:

return KernelSignature("abs_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("abs_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseAbsGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "abs_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "abs_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAcosGradOpArgumentMapping:

return KernelSignature("acos_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("acos_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseAcosGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "acos_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "acos_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAcoshGradOpArgumentMapping:

return KernelSignature("acosh_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("acosh_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseAcoshGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "acosh_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "acosh_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAddGradOpArgumentMapping:

return KernelSignature("add_coo_coo_grad", {"x", "y", "out@GRAD"}, {},
{"x@GRAD", "y@GRAD"}); return KernelSignature("add_csr_csr_grad", {"x", "y",
"out@GRAD"}, {}, {"x@GRAD", "y@GRAD"}); return
KernelSignature("add_coo_dense_grad", {"x", "y", "out@GRAD"}, {}, {"x@GRAD",
"y@GRAD"});
******************************************************************
*/

KernelSignature SparseAddGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD", "y@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "add_coo_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "add_csr_csr_grad";
  }
  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("y") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "add_coo_dense_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAddmmGradOpArgumentMapping:

return KernelSignature("addmm_csr_dense_grad", {"input", "x", "y", "out@GRAD"},
{"alpha", "beta"}, {"input@GRAD", "x@GRAD", "y@GRAD"}); return
KernelSignature("addmm_csr_csr_grad", {"input", "x", "y", "out@GRAD"}, {"alpha",
"beta"}, {"input@GRAD", "x@GRAD", "y@GRAD"}); return
KernelSignature("addmm_coo_dense_grad", {"input", "x", "y", "out@GRAD"},
{"alpha", "beta"}, {"input@GRAD", "x@GRAD", "y@GRAD"}); return
KernelSignature("addmm_coo_coo_grad", {"input", "x", "y", "out@GRAD"}, {"alpha",
"beta"}, {"input@GRAD", "x@GRAD", "y@GRAD"});
******************************************************************
*/

KernelSignature SparseAddmmGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"input", "x", "y", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("alpha");
  attrs.emplace_back("beta");
  paddle::small_vector<const char*> outputs{"input@GRAD", "x@GRAD", "y@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("input") && ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsDenseTensorInput("y") && ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "addmm_csr_dense_grad";
  }
  if (ctx.IsSparseCsrTensorInput("input") && ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "addmm_csr_csr_grad";
  }
  if (ctx.IsDenseTensorInput("input") && ctx.IsSparseCooTensorInput("x") &&
      ctx.IsDenseTensorInput("y") && ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "addmm_coo_dense_grad";
  }
  if (ctx.IsSparseCooTensorInput("input") && ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("y") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "addmm_coo_coo_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAsinGradOpArgumentMapping:

return KernelSignature("asin_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("asin_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseAsinGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "asin_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "asin_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAsinhGradOpArgumentMapping:

return KernelSignature("asinh_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("asinh_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseAsinhGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "asinh_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "asinh_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAtanGradOpArgumentMapping:

return KernelSignature("atan_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("atan_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseAtanGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "atan_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "atan_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseAtanhGradOpArgumentMapping:

return KernelSignature("atanh_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("atanh_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseAtanhGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "atanh_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "atanh_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseBatchNormGradOpArgumentMapping:

return KernelSignature("batch_norm_coo_grad", {"x", "scale", "bias", "mean_out",
"variance_out", "saved_mean", "saved_variance", "reserve_space", "out@GRAD"},
{"momentum", "epsilon", "data_layout", "is_test", "use_global_stats",
"trainable_statistics"}, {"x@GRAD", "scale@GRAD", "bias@GRAD"});
******************************************************************
*/

KernelSignature SparseBatchNormGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x",
                                           "scale",
                                           "bias",
                                           "mean_out",
                                           "variance_out",
                                           "saved_mean",
                                           "saved_variance",
                                           "reserve_space",
                                           "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("momentum");
  attrs.emplace_back("epsilon");
  attrs.emplace_back("data_layout");
  attrs.emplace_back("is_test");
  attrs.emplace_back("use_global_stats");
  attrs.emplace_back("trainable_statistics");
  paddle::small_vector<const char*> outputs{
      "x@GRAD", "scale@GRAD", "bias@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("scale") &&
      ctx.IsDenseTensorInput("bias") && ctx.IsDenseTensorInput("mean_out") &&
      ctx.IsDenseTensorInput("variance_out") &&
      ctx.IsDenseTensorInput("saved_mean") &&
      ctx.IsDenseTensorInput("saved_variance") &&
      ctx.IsDenseTensorInput("reserve_space") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "batch_norm_coo_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseCastGradOpArgumentMapping:

return KernelSignature("cast_coo_grad", {"x", "out@GRAD"}, {"value_dtype"},
{"x@GRAD"}); return KernelSignature("cast_csr_grad", {"x", "out@GRAD"},
{"value_dtype"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseCastGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("value_dtype");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "cast_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "cast_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseConv3dGradOpArgumentMapping:

return KernelSignature("conv3d_coo_grad", {"x", "kernel", "out", "rulebook",
"counter", "out@GRAD"}, {"paddings", "dilations", "strides", "groups", "subm",
"key"}, {"x@GRAD", "kernel@GRAD"});
******************************************************************
*/

KernelSignature SparseConv3dGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{
      "x", "kernel", "out", "rulebook", "counter", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("paddings");
  attrs.emplace_back("dilations");
  attrs.emplace_back("strides");
  attrs.emplace_back("groups");
  attrs.emplace_back("subm");
  attrs.emplace_back("key");
  paddle::small_vector<const char*> outputs{"x@GRAD", "kernel@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("kernel") &&
      ctx.IsSparseCooTensorInput("out") && ctx.IsDenseTensorInput("rulebook") &&
      ctx.IsDenseTensorInput("counter") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "conv3d_coo_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseDivideGradOpArgumentMapping:

return KernelSignature("divide_coo_coo_grad", {"x", "y", "out", "out@GRAD"}, {},
{"x@GRAD", "y@GRAD"}); return KernelSignature("divide_csr_csr_grad", {"x", "y",
"out", "out@GRAD"}, {}, {"x@GRAD", "y@GRAD"});
******************************************************************
*/

KernelSignature SparseDivideGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y", "out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD", "y@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y") &&
      ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "divide_coo_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("out") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "divide_csr_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseExpm1GradOpArgumentMapping:

return KernelSignature("expm1_coo_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("expm1_csr_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseExpm1GradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "expm1_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("out") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "expm1_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseLeakyReluGradOpArgumentMapping:

return KernelSignature("leaky_relu_coo_grad", {"x", "out@GRAD"}, {"alpha"},
{"x@GRAD"}); return KernelSignature("leaky_relu_csr_grad", {"x", "out@GRAD"},
{"alpha"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseLeakyReluGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("alpha");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "leaky_relu_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "leaky_relu_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseLog1pGradOpArgumentMapping:

return KernelSignature("log1p_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("log1p_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseLog1pGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "log1p_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "log1p_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by
SparseMaskedMatmulGradOpArgumentMapping:

return KernelSignature("masked_matmul_csr_grad", {"x", "y", "out@GRAD"}, {},
{"x@GRAD", "y@GRAD"});
******************************************************************
*/

KernelSignature SparseMaskedMatmulGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD", "y@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("x") && ctx.IsDenseTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "masked_matmul_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMatmulGradOpArgumentMapping:

return KernelSignature("matmul_csr_dense_grad", {"x", "y", "out@GRAD"}, {},
{"x@GRAD", "y@GRAD"}); return KernelSignature("matmul_csr_csr_grad", {"x", "y",
"out@GRAD"}, {}, {"x@GRAD", "y@GRAD"}); return
KernelSignature("matmul_coo_dense_grad", {"x", "y", "out@GRAD"}, {}, {"x@GRAD",
"y@GRAD"}); return KernelSignature("matmul_coo_coo_grad", {"x", "y",
"out@GRAD"}, {}, {"x@GRAD", "y@GRAD"});
******************************************************************
*/

KernelSignature SparseMatmulGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD", "y@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsDenseTensorInput("y") &&
      ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "matmul_csr_dense_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "matmul_csr_csr_grad";
  }
  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("y") &&
      ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "matmul_coo_dense_grad";
  }
  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "matmul_coo_coo_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMaxpoolGradOpArgumentMapping:

return KernelSignature("maxpool_coo_grad", {"x", "rulebook", "counter", "out",
"out@GRAD"}, {"kernel_sizes"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseMaxpoolGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{
      "x", "rulebook", "counter", "out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("kernel_sizes");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("rulebook") &&
      ctx.IsDenseTensorInput("counter") && ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "maxpool_coo_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMultiplyGradOpArgumentMapping:

return KernelSignature("multiply_coo_coo_grad", {"x", "y", "out@GRAD"}, {},
{"x@GRAD", "y@GRAD"}); return KernelSignature("multiply_csr_csr_grad", {"x",
"y", "out@GRAD"}, {}, {"x@GRAD", "y@GRAD"});
******************************************************************
*/

KernelSignature SparseMultiplyGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD", "y@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "multiply_coo_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "multiply_csr_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseMvGradOpArgumentMapping:

return KernelSignature("mv_coo_grad", {"x", "vec", "out@GRAD"}, {}, {"x@GRAD",
"vec@GRAD"}); return KernelSignature("mv_csr_grad", {"x", "vec", "out@GRAD"},
{}, {"x@GRAD", "vec@GRAD"});
******************************************************************
*/

KernelSignature SparseMvGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "vec", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD", "vec@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("vec") &&
      ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "mv_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsDenseTensorInput("vec") &&
      ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "mv_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparsePowGradOpArgumentMapping:

return KernelSignature("pow_coo_grad", {"x", "out@GRAD"}, {"factor"},
{"x@GRAD"}); return KernelSignature("pow_csr_grad", {"x", "out@GRAD"},
{"factor"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparsePowGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("factor");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "pow_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "pow_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseRelu6GradOpArgumentMapping:

return KernelSignature("relu6_coo_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("relu6_csr_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseRelu6GradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "relu6_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("out") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "relu6_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseReluGradOpArgumentMapping:

return KernelSignature("relu_coo_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("relu_csr_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseReluGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "relu_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("out") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "relu_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseReshapeGradOpArgumentMapping:

return KernelSignature("reshape_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("reshape_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseReshapeGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "reshape_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "reshape_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSinGradOpArgumentMapping:

return KernelSignature("sin_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("sin_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseSinGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "sin_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "sin_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSinhGradOpArgumentMapping:

return KernelSignature("sinh_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("sinh_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseSinhGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "sinh_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "sinh_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSoftmaxGradOpArgumentMapping:

return KernelSignature("softmax_coo_grad", {"out", "out@GRAD"}, {"axis"},
{"x@GRAD"}); return KernelSignature("softmax_csr_grad", {"out", "out@GRAD"},
{"axis"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseSoftmaxGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("axis");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "softmax_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("out") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "softmax_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by
SparseSparseCooTensorGradOpArgumentMapping:

return KernelSignature("sparse_coo_tensor_grad", {"indices", "out@GRAD"}, {},
{"values@GRAD"});
******************************************************************
*/

KernelSignature SparseSparseCooTensorGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"indices", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"values@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("indices") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "sparse_coo_tensor_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSqrtGradOpArgumentMapping:

return KernelSignature("sqrt_coo_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("sqrt_csr_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseSqrtGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "sqrt_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("out") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "sqrt_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSquareGradOpArgumentMapping:

return KernelSignature("square_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("square_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseSquareGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "square_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "square_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSubtractGradOpArgumentMapping:

return KernelSignature("subtract_coo_coo_grad", {"x", "y", "out@GRAD"}, {},
{"x@GRAD", "y@GRAD"}); return KernelSignature("subtract_csr_csr_grad", {"x",
"y", "out@GRAD"}, {}, {"x@GRAD", "y@GRAD"});
******************************************************************
*/

KernelSignature SparseSubtractGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "y", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD", "y@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsSparseCooTensorInput("y") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "subtract_coo_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") && ctx.IsSparseCsrTensorInput("y") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "subtract_csr_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSumGradOpArgumentMapping:

return KernelSignature("sum_coo_grad", {"x", "out@GRAD"}, {"axis", "keepdim"},
{"x@GRAD"}); return KernelSignature("sum_coo_grad", {"x", "out@GRAD"},
{"AxisTensor", "keepdim"}, {"x@GRAD"}); return KernelSignature("sum_coo_grad",
{"x", "out@GRAD"}, {"AxisTensorList", "keepdim"}, {"x@GRAD"}); return
KernelSignature("sum_csr_grad", {"x", "out@GRAD"}, {"axis", "keepdim"},
{"x@GRAD"}); return KernelSignature("sum_csr_grad", {"x", "out@GRAD"},
{"AxisTensor", "keepdim"}, {"x@GRAD"}); return KernelSignature("sum_csr_grad",
{"x", "out@GRAD"}, {"AxisTensorList", "keepdim"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseSumGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back(ctx.HasInput("AxisTensor")            ? "AxisTensor"
                     : ctx.InputSize("AxisTensorList") > 0 ? "AxisTensorList"
                                                           : "axis");
  attrs.emplace_back("keepdim");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "sum_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "sum_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by
SparseSyncBatchNormGradOpArgumentMapping:

return KernelSignature("sync_batch_norm_coo_grad", {"x", "scale", "bias",
"saved_mean", "saved_variance", "reserve_space", "out@GRAD"}, {"momentum",
"epsilon", "data_layout", "is_test", "use_global_stats",
"trainable_statistics"}, {"x@GRAD", "scale@GRAD", "bias@GRAD"});
******************************************************************
*/

KernelSignature SparseSyncBatchNormGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x",
                                           "scale",
                                           "bias",
                                           "saved_mean",
                                           "saved_variance",
                                           "reserve_space",
                                           "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("momentum");
  attrs.emplace_back("epsilon");
  attrs.emplace_back("data_layout");
  attrs.emplace_back("is_test");
  attrs.emplace_back("use_global_stats");
  attrs.emplace_back("trainable_statistics");
  paddle::small_vector<const char*> outputs{
      "x@GRAD", "scale@GRAD", "bias@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("scale") &&
      ctx.IsDenseTensorInput("bias") && ctx.IsDenseTensorInput("saved_mean") &&
      ctx.IsDenseTensorInput("saved_variance") &&
      ctx.IsDenseTensorInput("reserve_space") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "sync_batch_norm_coo_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseTanGradOpArgumentMapping:

return KernelSignature("tan_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("tan_csr_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseTanGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "tan_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "tan_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseTanhGradOpArgumentMapping:

return KernelSignature("tanh_coo_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
return KernelSignature("tanh_csr_grad", {"out", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseTanhGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "tanh_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("out") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "tanh_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseToDenseGradOpArgumentMapping:

return KernelSignature("coo_to_dense_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseToDenseGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "coo_to_dense_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by
SparseToSparseCooGradOpArgumentMapping:

return KernelSignature("coo_to_dense", {"out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseToSparseCooGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "coo_to_dense";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseTransposeGradOpArgumentMapping:

return KernelSignature("transpose_coo_grad", {"out@GRAD"}, {"perm"},
{"x@GRAD"}); return KernelSignature("transpose_csr_grad", {"out@GRAD"},
{"perm"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseTransposeGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back("perm");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "transpose_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "transpose_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseValuesGradOpArgumentMapping:

return KernelSignature("values_coo_grad", {"x", "out@GRAD"}, {}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseValuesGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") && ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "values_coo_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by
SparseFusedAttentionGradOpArgumentMapping:

return KernelSignature("fused_attention_csr_grad", {"query", "key", "value",
"softmax", "out@GRAD"}, {}, {"query@GRAD", "key@GRAD", "value@GRAD"});
******************************************************************
*/

KernelSignature SparseFusedAttentionGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{
      "query", "key", "value", "softmax", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  paddle::small_vector<const char*> outputs{
      "query@GRAD", "key@GRAD", "value@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsDenseTensorInput("query") && ctx.IsDenseTensorInput("key") &&
      ctx.IsDenseTensorInput("value") &&
      ctx.IsSparseCsrTensorInput("softmax") &&
      ctx.IsDenseTensorInput("out_grad")) {
    kernel_name = "fused_attention_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

/*
******************************************************************
NOTE: The following codes are for 'get_compat_kernel_signature.py'
All possible KernelSignatures returned by SparseSliceGradOpArgumentMapping:

return KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"axes", "starts",
"ends"}, {"x@GRAD"}); return KernelSignature("slice_coo_grad", {"x",
"out@GRAD"}, {"axes", "starts", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"axes", "starts",
"EndsTensorList"}, {"x@GRAD"}); return KernelSignature("slice_coo_grad", {"x",
"out@GRAD"}, {"axes", "StartsTensor", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"axes", "StartsTensor",
"EndsTensor"}, {"x@GRAD"}); return KernelSignature("slice_coo_grad", {"x",
"out@GRAD"}, {"axes", "StartsTensor", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"axes",
"StartsTensorList", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"axes",
"StartsTensorList", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"axes",
"StartsTensorList", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensor", "starts",
"ends"}, {"x@GRAD"}); return KernelSignature("slice_coo_grad", {"x",
"out@GRAD"}, {"AxesTensor", "starts", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensor", "starts",
"EndsTensorList"}, {"x@GRAD"}); return KernelSignature("slice_coo_grad", {"x",
"out@GRAD"}, {"AxesTensor", "StartsTensor", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensor", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensor", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensorList", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensorList", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensorList", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"starts", "ends"}, {"x@GRAD"}); return KernelSignature("slice_coo_grad", {"x",
"out@GRAD"}, {"AxesTensorList", "starts", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"starts", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensor", "ends"}, {"x@GRAD"}); return KernelSignature("slice_coo_grad",
{"x", "out@GRAD"}, {"AxesTensorList", "StartsTensor", "EndsTensor"},
{"x@GRAD"}); return KernelSignature("slice_coo_grad", {"x", "out@GRAD"},
{"AxesTensorList", "StartsTensor", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensorList", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensorList", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_coo_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensorList", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"axes", "starts", "ends"},
{"x@GRAD"}); return KernelSignature("slice_csr_grad", {"x", "out@GRAD"},
{"axes", "starts", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"axes", "starts",
"EndsTensorList"}, {"x@GRAD"}); return KernelSignature("slice_csr_grad", {"x",
"out@GRAD"}, {"axes", "StartsTensor", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"axes", "StartsTensor",
"EndsTensor"}, {"x@GRAD"}); return KernelSignature("slice_csr_grad", {"x",
"out@GRAD"}, {"axes", "StartsTensor", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"axes",
"StartsTensorList", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"axes",
"StartsTensorList", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"axes",
"StartsTensorList", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensor", "starts",
"ends"}, {"x@GRAD"}); return KernelSignature("slice_csr_grad", {"x",
"out@GRAD"}, {"AxesTensor", "starts", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensor", "starts",
"EndsTensorList"}, {"x@GRAD"}); return KernelSignature("slice_csr_grad", {"x",
"out@GRAD"}, {"AxesTensor", "StartsTensor", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensor", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensor", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensorList", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensorList", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensor",
"StartsTensorList", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"starts", "ends"}, {"x@GRAD"}); return KernelSignature("slice_csr_grad", {"x",
"out@GRAD"}, {"AxesTensorList", "starts", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"starts", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensor", "ends"}, {"x@GRAD"}); return KernelSignature("slice_csr_grad",
{"x", "out@GRAD"}, {"AxesTensorList", "StartsTensor", "EndsTensor"},
{"x@GRAD"}); return KernelSignature("slice_csr_grad", {"x", "out@GRAD"},
{"AxesTensorList", "StartsTensor", "EndsTensorList"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensorList", "ends"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensorList", "EndsTensor"}, {"x@GRAD"}); return
KernelSignature("slice_csr_grad", {"x", "out@GRAD"}, {"AxesTensorList",
"StartsTensorList", "EndsTensorList"}, {"x@GRAD"});
******************************************************************
*/

KernelSignature SparseSliceGradOpArgumentMapping(
    const ArgumentMappingContext& ctx) {
  paddle::small_vector<const char*> inputs{"x", "out@GRAD"};
  paddle::small_vector<const char*> attrs;
  attrs.emplace_back(ctx.HasInput("AxesTensor")            ? "AxesTensor"
                     : ctx.InputSize("AxesTensorList") > 0 ? "AxesTensorList"
                                                           : "axes");
  attrs.emplace_back(ctx.HasInput("StartsTensor") ? "StartsTensor"
                     : ctx.InputSize("StartsTensorList") > 0
                         ? "StartsTensorList"
                         : "starts");
  attrs.emplace_back(ctx.HasInput("EndsTensor")            ? "EndsTensor"
                     : ctx.InputSize("EndsTensorList") > 0 ? "EndsTensorList"
                                                           : "ends");
  paddle::small_vector<const char*> outputs{"x@GRAD"};

  const char* kernel_name = "unregistered";

  if (ctx.IsSparseCooTensorInput("x") &&
      ctx.IsSparseCooTensorInput("out_grad")) {
    kernel_name = "slice_coo_grad";
  }
  if (ctx.IsSparseCsrTensorInput("x") &&
      ctx.IsSparseCsrTensorInput("out_grad")) {
    kernel_name = "slice_csr_grad";
  }
  KernelSignature sig(
      kernel_name, std::move(inputs), std::move(attrs), std::move(outputs));
  return sig;
}

}  // namespace phi

PD_REGISTER_ARG_MAPPING_FN(sparse_abs, phi::SparseAbsOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_acos, phi::SparseAcosOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_acosh, phi::SparseAcoshOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_add, phi::SparseAddOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_asin, phi::SparseAsinOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_asinh, phi::SparseAsinhOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_atan, phi::SparseAtanOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_atanh, phi::SparseAtanhOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_batch_norm,
                           phi::SparseBatchNormOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_cast, phi::SparseCastOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_conv3d, phi::SparseConv3dOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_divide, phi::SparseDivideOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_divide_scalar,
                           phi::SparseDivideScalarOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_expm1, phi::SparseExpm1OpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_isnan, phi::SparseIsnanOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_leaky_relu,
                           phi::SparseLeakyReluOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_log1p, phi::SparseLog1pOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_multiply,
                           phi::SparseMultiplyOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_pow, phi::SparsePowOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_relu, phi::SparseReluOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_relu6, phi::SparseRelu6OpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_reshape, phi::SparseReshapeOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_scale, phi::SparseScaleOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sin, phi::SparseSinOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sinh, phi::SparseSinhOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_softmax, phi::SparseSoftmaxOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sparse_coo_tensor,
                           phi::SparseSparseCooTensorOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sqrt, phi::SparseSqrtOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_square, phi::SparseSquareOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_subtract,
                           phi::SparseSubtractOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sum, phi::SparseSumOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sync_batch_norm,
                           phi::SparseSyncBatchNormOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_tan, phi::SparseTanOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_tanh, phi::SparseTanhOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_to_dense,
                           phi::SparseToDenseOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_to_sparse_coo,
                           phi::SparseToSparseCooOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_to_sparse_csr,
                           phi::SparseToSparseCsrOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_transpose,
                           phi::SparseTransposeOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_values, phi::SparseValuesOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_addmm, phi::SparseAddmmOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_coalesce,
                           phi::SparseCoalesceOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_full_like,
                           phi::SparseFullLikeOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_fused_attention,
                           phi::SparseFusedAttentionOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_masked_matmul,
                           phi::SparseMaskedMatmulOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_matmul, phi::SparseMatmulOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_maxpool, phi::SparseMaxpoolOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_mv, phi::SparseMvOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_slice, phi::SparseSliceOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_abs_grad,
                           phi::SparseAbsGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_acos_grad,
                           phi::SparseAcosGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_acosh_grad,
                           phi::SparseAcoshGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_add_grad,
                           phi::SparseAddGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_addmm_grad,
                           phi::SparseAddmmGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_asin_grad,
                           phi::SparseAsinGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_asinh_grad,
                           phi::SparseAsinhGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_atan_grad,
                           phi::SparseAtanGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_atanh_grad,
                           phi::SparseAtanhGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_batch_norm_grad,
                           phi::SparseBatchNormGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_cast_grad,
                           phi::SparseCastGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_conv3d_grad,
                           phi::SparseConv3dGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_divide_grad,
                           phi::SparseDivideGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_expm1_grad,
                           phi::SparseExpm1GradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_leaky_relu_grad,
                           phi::SparseLeakyReluGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_log1p_grad,
                           phi::SparseLog1pGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_masked_matmul_grad,
                           phi::SparseMaskedMatmulGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_matmul_grad,
                           phi::SparseMatmulGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_maxpool_grad,
                           phi::SparseMaxpoolGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_multiply_grad,
                           phi::SparseMultiplyGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_mv_grad, phi::SparseMvGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_pow_grad,
                           phi::SparsePowGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_relu6_grad,
                           phi::SparseRelu6GradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_relu_grad,
                           phi::SparseReluGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_reshape_grad,
                           phi::SparseReshapeGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sin_grad,
                           phi::SparseSinGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sinh_grad,
                           phi::SparseSinhGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_softmax_grad,
                           phi::SparseSoftmaxGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sparse_coo_tensor_grad,
                           phi::SparseSparseCooTensorGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sqrt_grad,
                           phi::SparseSqrtGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_square_grad,
                           phi::SparseSquareGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_subtract_grad,
                           phi::SparseSubtractGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sum_grad,
                           phi::SparseSumGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_sync_batch_norm_grad,
                           phi::SparseSyncBatchNormGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_tan_grad,
                           phi::SparseTanGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_tanh_grad,
                           phi::SparseTanhGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_to_dense_grad,
                           phi::SparseToDenseGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_to_sparse_coo_grad,
                           phi::SparseToSparseCooGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_transpose_grad,
                           phi::SparseTransposeGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_values_grad,
                           phi::SparseValuesGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_fused_attention_grad,
                           phi::SparseFusedAttentionGradOpArgumentMapping);
PD_REGISTER_ARG_MAPPING_FN(sparse_slice_grad,
                           phi::SparseSliceGradOpArgumentMapping);
