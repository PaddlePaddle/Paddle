// this file is generated by paddle/phi/api/yaml/generator/generate_op.py, do not edit.
#include <string>
#include "paddle/fluid/framework/convert_utils.h"
#include "paddle/fluid/framework/infershape_utils.h"
#include "paddle/fluid/framework/op_registry.h"
#include "paddle/fluid/framework/op_version_registry.h"
#include "paddle/fluid/prim/api/composite_backward/composite_backward_api.h"
#include "paddle/fluid/prim/utils/static/composite_grad_desc_maker.h"
#include "paddle/fluid/prim/utils/static/desc_tensor.h"
#include "paddle/fluid/operators/generator/get_expected_kernel_func.h"
#include "paddle/phi/core/infermeta_utils.h"
#include "paddle/phi/infermeta/backward.h"
#include "paddle/phi/infermeta/binary.h"
#include "paddle/phi/infermeta/fusion.h"
#include "paddle/phi/infermeta/multiary.h"
#include "paddle/phi/infermeta/nullary.h"
#include "paddle/phi/infermeta/ternary.h"
#include "paddle/phi/infermeta/unary.h"

namespace paddle {
namespace operators {

using paddle::framework::GradVarName;


class RmspropOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Param", "(Tensor), input 0 of rmsprop op.");
    AddInput("MeanSquare", "(Tensor), input 1 of rmsprop op.");
    AddInput("Grad", "(Tensor), input 2 of rmsprop op.");
    AddInput("Moment", "(Tensor), input 3 of rmsprop op.");
    AddInput("LearningRate", "(Tensor), input 4 of rmsprop op.");
    AddInput("MeanGrad", "(Tensor), input 5 of rmsprop op.")
        .AsDispensable();
    AddInput("MasterParam", "(Tensor), input 6 of rmsprop op.")
        .AsDispensable();
    AddOutput("ParamOut", "(Tensor), output 0 of rmsprop op.");
    AddOutput("MomentOut", "(Tensor), output 1 of rmsprop op.");
    AddOutput("MeanSquareOut", "(Tensor), output 2 of rmsprop op.");
    AddOutput("MeanGradOut", "(Tensor), output 3 of rmsprop op.");
    AddOutput("MasterParamOut", "(Tensor), output 4 of rmsprop op.")
        .AsDispensable();
    AddAttr<float>("epsilon", "(float), attribute 0 for rmsprop op.")
        .SetDefault(1.0e-10f);
    AddAttr<float>("decay", "(float), attribute 1 for rmsprop op.")
        .SetDefault(0.9f);
    AddAttr<float>("momentum", "(float), attribute 2 for rmsprop op.")
        .SetDefault(0.0f);
    AddAttr<bool>("centered", "(bool), attribute 3 for rmsprop op.")
        .SetDefault(false);
    AddAttr<bool>("multi_precision", "(bool), attribute 4 for rmsprop op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of rmsprop op.
)DOC");
  }
};


class RmspropOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Param");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(rmsprop, RmspropInferShapeFunctor,
                            PD_INFER_META(phi::RmspropInferMeta));



class RoiAlignOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of roi_align op.");
    AddInput("ROIs", "(Tensor), input 1 of roi_align op.");
    AddInput("RoisNum", "(Tensor), input 2 of roi_align op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of roi_align op.");
    AddAttr<int>("pooled_height", "(int), attribute 0 for roi_align op.")
        .SetDefault(1);
    AddAttr<int>("pooled_width", "(int), attribute 1 for roi_align op.")
        .SetDefault(1);
    AddAttr<float>("spatial_scale", "(float), attribute 2 for roi_align op.")
        .SetDefault(1.0);
    AddAttr<int>("sampling_ratio", "(int), attribute 3 for roi_align op.")
        .SetDefault(-1);
    AddAttr<bool>("aligned", "(bool), attribute 4 for roi_align op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of roi_align op.
)DOC");
  }
};


class RoiAlignOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(roi_align, RoiAlignInferShapeFunctor,
                            PD_INFER_META(phi::RoiAlignInferMeta));



class RoiPoolOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of roi_pool op.");
    AddInput("ROIs", "(Tensor), input 1 of roi_pool op.");
    AddInput("RoisNum", "(Tensor), input 2 of roi_pool op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of roi_pool op.");
    AddOutput("Argmax", "(Tensor), output 1 of roi_pool op.")
        .AsIntermediate();
    AddAttr<int>("pooled_height", "(int), attribute 0 for roi_pool op.")
        .SetDefault(1);
    AddAttr<int>("pooled_width", "(int), attribute 1 for roi_pool op.")
        .SetDefault(1);
    AddAttr<float>("spatial_scale", "(float), attribute 2 for roi_pool op.")
        .SetDefault(1.0);
    AddComment(R"DOC(
TODO: Documentation of roi_pool op.
)DOC");
  }
};


class RoiPoolOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(roi_pool, RoiPoolInferShapeFunctor,
                            PD_INFER_META(phi::RoiPoolInferMeta));



class RollOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of roll op.");
    AddOutput("Out", "(Tensor), output 0 of roll op.");
    AddInput("ShiftsTensor", "attribute 0 for roll op from 1D integer Tensor.")
        .AsDispensable();
      AddAttr<std::vector<int64_t>>("shifts", "(std::vector<int64_t>), attribute 0 for roll op.")
        .SetDefault({});
    AddAttr<std::vector<int64_t>>("axis", "(std::vector<int64_t>), attribute 1 for roll op.")
        .SetDefault({});
    AddComment(R"DOC(
TODO: Documentation of roll op.
)DOC");
  }
};


class RollOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(roll, RollInferShapeFunctor,
                            PD_INFER_META(phi::RollInferMeta));



class RoundOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of round op.");
    AddOutput("Out", "(Tensor), output 0 of round op.");
    AddComment(R"DOC(
TODO: Documentation of round op.
)DOC");
  }
};


class RoundOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(round, RoundInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(RoundInplaceInferer,
                           {"X", "Out"});



class RsqrtOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of rsqrt op.");
    AddOutput("Out", "(Tensor), output 0 of rsqrt op.");
    AddComment(R"DOC(
TODO: Documentation of rsqrt op.
)DOC");
  }
};


class RsqrtOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(rsqrt, RsqrtInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(RsqrtInplaceInferer,
                           {"X", "Out"});



class ScaleOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of scale op.");
    AddOutput("Out", "(Tensor), output 0 of scale op.");
    AddInput("ScaleTensor", "attribute 0 for scale op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("scale", "(float), attribute 0 for scale op.")
        .SetDefault(1.0);
    AddAttr<float>("bias", "(float), attribute 1 for scale op.")
        .SetDefault(0.0);
    AddAttr<bool>("bias_after_scale", "(bool), attribute 2 for scale op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of scale op.
)DOC");
  }
};


class ScaleOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(scale, ScaleInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(ScaleInplaceInferer,
                           {"X", "Out"});



class ScatterOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of scatter op.");
    AddInput("Ids", "(Tensor), input 1 of scatter op.");
    AddInput("Updates", "(Tensor), input 2 of scatter op.");
    AddOutput("Out", "(Tensor), output 0 of scatter op.");
    AddAttr<bool>("overwrite", "(bool), attribute 0 for scatter op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of scatter op.
)DOC");
  }
};


class ScatterOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(scatter, ScatterInferShapeFunctor,
                            PD_INFER_META(phi::ScatterInferMeta));
DECLARE_INPLACE_OP_INFERER(ScatterInplaceInferer,
                           {"X", "Out"});



class ScatterNdAddOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of scatter_nd_add op.");
    AddInput("Index", "(Tensor), input 1 of scatter_nd_add op.");
    AddInput("Updates", "(Tensor), input 2 of scatter_nd_add op.");
    AddOutput("Out", "(Tensor), output 0 of scatter_nd_add op.");
    AddComment(R"DOC(
TODO: Documentation of scatter_nd_add op.
)DOC");
  }
};


class ScatterNdAddOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(scatter_nd_add, ScatterNdAddInferShapeFunctor,
                            PD_INFER_META(phi::ScatterNdAddInferMeta));



class SearchsortedOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("SortedSequence", "(Tensor), input 0 of searchsorted op.");
    AddInput("Values", "(Tensor), input 1 of searchsorted op.");
    AddOutput("Out", "(Tensor), output 0 of searchsorted op.");
    AddAttr<bool>("out_int32", "(bool), attribute 0 for searchsorted op.")
        .SetDefault(false);
    AddAttr<bool>("right", "(bool), attribute 1 for searchsorted op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of searchsorted op.
)DOC");
  }
};


class SearchsortedOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "SortedSequence");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(searchsorted, SearchsortedInferShapeFunctor,
                            PD_INFER_META(phi::SearchsortedInferMeta));



class SegmentPoolOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of segment_pool op.");
    AddInput("SegmentIds", "(Tensor), input 1 of segment_pool op.");
    AddOutput("Out", "(Tensor), output 0 of segment_pool op.");
    AddOutput("SummedIds", "(Tensor), output 1 of segment_pool op.")
        .AsIntermediate();
    AddAttr<std::string>("pooltype", "(std::string), attribute 0 for segment_pool op.")
        .SetDefault("SUM");
    AddComment(R"DOC(
TODO: Documentation of segment_pool op.
)DOC");
  }
};


class SegmentPoolOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(segment_pool, SegmentPoolInferShapeFunctor,
                            PD_INFER_META(phi::SegmentPoolInferMeta));



class SeluOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of selu op.");
    AddOutput("Out", "(Tensor), output 0 of selu op.");
    AddAttr<float>("scale", "(float), attribute 0 for selu op.")
        .SetDefault(1.0507009873554804934193349852946);
    AddAttr<float>("alpha", "(float), attribute 1 for selu op.")
        .SetDefault(1.6732632423543772848170429916717);
    AddComment(R"DOC(
TODO: Documentation of selu op.
)DOC");
  }
};


class SeluOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(selu, SeluInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class GraphSendRecvOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of graph_send_recv op.");
    AddInput("Src_index", "(Tensor), input 1 of graph_send_recv op.");
    AddInput("Dst_index", "(Tensor), input 2 of graph_send_recv op.");
    AddOutput("Out", "(Tensor), output 0 of graph_send_recv op.");
    AddOutput("Dst_count", "(Tensor), output 1 of graph_send_recv op.")
        .AsIntermediate();
    AddAttr<std::string>("reduce_op", "(std::string), attribute 0 for graph_send_recv op.")
        .SetDefault("SUM");
    AddInput("Out_size", "attribute 1 for graph_send_recv op from 1D integer Tensor.")
        .AsDispensable();
      AddAttr<std::vector<int64_t>>("out_size", "(std::vector<int64_t>), attribute 1 for graph_send_recv op.")
        .SetDefault({0});
    AddComment(R"DOC(
TODO: Documentation of graph_send_recv op.
)DOC");
  }
};


class GraphSendRecvOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(graph_send_recv, GraphSendRecvInferShapeFunctor,
                            PD_INFER_META(phi::SendURecvInferMeta));



class GraphSendUeRecvOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of graph_send_ue_recv op.");
    AddInput("Y", "(Tensor), input 1 of graph_send_ue_recv op.");
    AddInput("Src_index", "(Tensor), input 2 of graph_send_ue_recv op.");
    AddInput("Dst_index", "(Tensor), input 3 of graph_send_ue_recv op.");
    AddOutput("Out", "(Tensor), output 0 of graph_send_ue_recv op.");
    AddOutput("Dst_count", "(Tensor), output 1 of graph_send_ue_recv op.")
        .AsIntermediate();
    AddAttr<std::string>("message_op", "(std::string), attribute 0 for graph_send_ue_recv op.")
        .SetDefault("ADD");
    AddAttr<std::string>("reduce_op", "(std::string), attribute 1 for graph_send_ue_recv op.")
        .SetDefault("SUM");
    AddInput("Out_size", "attribute 2 for graph_send_ue_recv op from 1D integer Tensor.")
        .AsDispensable();
      AddAttr<std::vector<int64_t>>("out_size", "(std::vector<int64_t>), attribute 2 for graph_send_ue_recv op.")
        .SetDefault({0});
    AddComment(R"DOC(
TODO: Documentation of graph_send_ue_recv op.
)DOC");
  }
};


class GraphSendUeRecvOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(graph_send_ue_recv, GraphSendUeRecvInferShapeFunctor,
                            PD_INFER_META(phi::SendUERecvInferMeta));



class GraphSendUvOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of graph_send_uv op.");
    AddInput("y", "(Tensor), input 1 of graph_send_uv op.");
    AddInput("src_index", "(Tensor), input 2 of graph_send_uv op.");
    AddInput("dst_index", "(Tensor), input 3 of graph_send_uv op.");
    AddOutput("out", "(Tensor), output 0 of graph_send_uv op.");
    AddAttr<std::string>("message_op", "(std::string), attribute 0 for graph_send_uv op.")
        .SetDefault("ADD");
    AddComment(R"DOC(
TODO: Documentation of graph_send_uv op.
)DOC");
  }
};


class GraphSendUvOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(graph_send_uv, GraphSendUvInferShapeFunctor,
                            PD_INFER_META(phi::SendUVInferMeta));



class SgdOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Param", "(Tensor), input 0 of sgd op.");
    AddInput("LearningRate", "(Tensor), input 1 of sgd op.");
    AddInput("Grad", "(Tensor), input 2 of sgd op.");
    AddInput("MasterParam", "(Tensor), input 3 of sgd op.")
        .AsDispensable();
    AddOutput("ParamOut", "(Tensor), output 0 of sgd op.");
    AddOutput("MasterParamOut", "(Tensor), output 1 of sgd op.")
        .AsDispensable();
    AddAttr<bool>("multi_precision", "(bool), attribute 0 for sgd op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of sgd op.
)DOC");
  }
};


class SgdOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetSgdExpectedKernelType(ctx, this);
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "LearningRate") {
         return phi::KernelKey(tensor.place(), tensor.layout(), tensor.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(sgd, SgdInferShapeFunctor,
                            PD_INFER_META(phi::SgdInferMeta));



class ShadowOutputOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of shadow_output op.");
    AddOutput("out", "(Tensor), output 0 of shadow_output op.");
    AddAttr<std::string>("name", "(std::string), attribute 0 for shadow_output op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of shadow_output op.
)DOC");
  }
};


class ShadowOutputOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(shadow_output, ShadowOutputInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class ShapeOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of shape op.");
    AddOutput("Out", "(Tensor), output 0 of shape op.");
    AddComment(R"DOC(
TODO: Documentation of shape op.
)DOC");
  }
};


class ShapeOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "Input") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(shape, ShapeInferShapeFunctor,
                            PD_INFER_META(phi::ShapeInferMeta));



class ShardIndexOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of shard_index op.");
    AddOutput("Out", "(Tensor), output 0 of shard_index op.");
    AddAttr<int>("index_num", "(int), attribute 0 for shard_index op.")
    ;
    AddAttr<int>("nshards", "(int), attribute 1 for shard_index op.")
    ;
    AddAttr<int>("shard_id", "(int), attribute 2 for shard_index op.")
    ;
    AddAttr<int>("ignore_value", "(int), attribute 3 for shard_index op.")
        .SetDefault(-1);
    AddComment(R"DOC(
TODO: Documentation of shard_index op.
)DOC");
  }
};


class ShardIndexOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(shard_index, ShardIndexInferShapeFunctor,
                            PD_INFER_META(phi::ShardIndexInferMeta));



class SigmoidOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of sigmoid op.");
    AddOutput("Out", "(Tensor), output 0 of sigmoid op.");
    AddComment(R"DOC(
TODO: Documentation of sigmoid op.
)DOC");
  }
};


class SigmoidOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sigmoid, SigmoidInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SigmoidInplaceInferer,
                           {"X", "Out"});



class SigmoidCrossEntropyWithLogitsOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of sigmoid_cross_entropy_with_logits op.");
    AddInput("Label", "(Tensor), input 1 of sigmoid_cross_entropy_with_logits op.");
    AddInput("pos_weight", "(Tensor), input 2 of sigmoid_cross_entropy_with_logits op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of sigmoid_cross_entropy_with_logits op.");
    AddAttr<bool>("normalize", "(bool), attribute 0 for sigmoid_cross_entropy_with_logits op.")
        .SetDefault(false);
    AddAttr<int>("ignore_index", "(int), attribute 1 for sigmoid_cross_entropy_with_logits op.")
        .SetDefault(-100);
    AddComment(R"DOC(
TODO: Documentation of sigmoid_cross_entropy_with_logits op.
)DOC");
  }
};


class SigmoidCrossEntropyWithLogitsOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sigmoid_cross_entropy_with_logits, SigmoidCrossEntropyWithLogitsInferShapeFunctor,
                            PD_INFER_META(phi::SigmoidCrossEntropyWithLogitsInferMeta));
DECLARE_INPLACE_OP_INFERER(SigmoidCrossEntropyWithLogitsInplaceInferer,
                           {"X", "Out"});



class SignOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of sign op.");
    AddOutput("Out", "(Tensor), output 0 of sign op.");
    AddComment(R"DOC(
TODO: Documentation of sign op.
)DOC");
  }
};


class SignOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sign, SignInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SiluOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of silu op.");
    AddOutput("Out", "(Tensor), output 0 of silu op.");
    AddComment(R"DOC(
TODO: Documentation of silu op.
)DOC");
  }
};


class SiluOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(silu, SiluInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SinOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of sin op.");
    AddOutput("Out", "(Tensor), output 0 of sin op.");
    AddComment(R"DOC(
TODO: Documentation of sin op.
)DOC");
  }
};


class SinOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sin, SinInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SinInplaceInferer,
                           {"X", "Out"});



class SinhOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of sinh op.");
    AddOutput("Out", "(Tensor), output 0 of sinh op.");
    AddComment(R"DOC(
TODO: Documentation of sinh op.
)DOC");
  }
};


class SinhOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sinh, SinhInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SinhInplaceInferer,
                           {"X", "Out"});



class SlogdeterminantOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of slogdeterminant op.");
    AddOutput("Out", "(Tensor), output 0 of slogdeterminant op.");
    AddComment(R"DOC(
TODO: Documentation of slogdeterminant op.
)DOC");
  }
};


class SlogdeterminantOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(slogdeterminant, SlogdeterminantInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SoftplusOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of softplus op.");
    AddOutput("Out", "(Tensor), output 0 of softplus op.");
    AddAttr<float>("beta", "(float), attribute 0 for softplus op.")
        .SetDefault(1.0);
    AddAttr<float>("threshold", "(float), attribute 1 for softplus op.")
        .SetDefault(20.0f);
    AddComment(R"DOC(
TODO: Documentation of softplus op.
)DOC");
  }
};


class SoftplusOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(softplus, SoftplusInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SoftshrinkOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of softshrink op.");
    AddOutput("Out", "(Tensor), output 0 of softshrink op.");
    AddAttr<float>("lambda", "(float), attribute 0 for softshrink op.")
        .SetDefault(0.5);
    AddComment(R"DOC(
TODO: Documentation of softshrink op.
)DOC");
  }
};


class SoftshrinkOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(softshrink, SoftshrinkInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SoftsignOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of softsign op.");
    AddOutput("Out", "(Tensor), output 0 of softsign op.");
    AddComment(R"DOC(
TODO: Documentation of softsign op.
)DOC");
  }
};


class SoftsignOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(softsign, SoftsignInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SolveOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of solve op.");
    AddInput("Y", "(Tensor), input 1 of solve op.");
    AddOutput("Out", "(Tensor), output 0 of solve op.");
    AddComment(R"DOC(
TODO: Documentation of solve op.
)DOC");
  }
};


class SolveOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(solve, SolveInferShapeFunctor,
                            PD_INFER_META(phi::SolveInferMeta));



class SpectralNormOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Weight", "(Tensor), input 0 of spectral_norm op.");
    AddInput("U", "(Tensor), input 1 of spectral_norm op.");
    AddInput("V", "(Tensor), input 2 of spectral_norm op.");
    AddOutput("Out", "(Tensor), output 0 of spectral_norm op.");
    AddAttr<int>("dim", "(int), attribute 0 for spectral_norm op.")
        .SetDefault(0);
    AddAttr<int>("power_iters", "(int), attribute 1 for spectral_norm op.")
        .SetDefault(1);
    AddAttr<float>("eps", "(float), attribute 2 for spectral_norm op.")
        .SetDefault(1e-12f);
    AddComment(R"DOC(
TODO: Documentation of spectral_norm op.
)DOC");
  }
};


class SpectralNormOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Weight");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(spectral_norm, SpectralNormInferShapeFunctor,
                            PD_INFER_META(phi::SpectralNormInferMeta));



class SqrtOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of sqrt op.");
    AddOutput("Out", "(Tensor), output 0 of sqrt op.");
    AddComment(R"DOC(
TODO: Documentation of sqrt op.
)DOC");
  }
};


class SqrtOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sqrt, SqrtInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SqrtInplaceInferer,
                           {"X", "Out"});



class SquareOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of square op.");
    AddOutput("Out", "(Tensor), output 0 of square op.");
    AddComment(R"DOC(
TODO: Documentation of square op.
)DOC");
  }
};


class SquareOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(square, SquareInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SquaredL2NormOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of squared_l2_norm op.");
    AddOutput("Out", "(Tensor), output 0 of squared_l2_norm op.");
    AddComment(R"DOC(
TODO: Documentation of squared_l2_norm op.
)DOC");
  }
};


class SquaredL2NormOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(squared_l2_norm, SquaredL2NormInferShapeFunctor,
                            PD_INFER_META(phi::SquaredL2NormInferMeta));



class Squeeze2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of squeeze2 op.");
    AddOutput("Out", "(Tensor), output 0 of squeeze2 op.");
    AddOutput("XShape", "(Tensor), output 1 of squeeze2 op.")
        .AsIntermediate()
        .AsExtra();
    AddAttr<std::vector<int>>("axes", "(std::vector<int>), attribute 0 for squeeze2 op.")
        .SetDefault({})
        .SupportTensor();
    AddComment(R"DOC(
TODO: Documentation of squeeze2 op.
)DOC");
  }
};


class Squeeze2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(squeeze2, Squeeze2InferShapeFunctor,
                            PD_INFER_META(phi::SqueezeWithXShapeInferMeta));
DECLARE_INPLACE_OP_INFERER(Squeeze2InplaceInferer,
                           {"X", "Out"});



class StackOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor[]), input 0 of stack op.")
        .AsDuplicable();
    AddOutput("Y", "(Tensor), output 0 of stack op.");
    AddAttr<int>("axis", "(int), attribute 0 for stack op.")
        .SetDefault(0);
    AddComment(R"DOC(
TODO: Documentation of stack op.
)DOC");
  }
};


class StackOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(stack, StackInferShapeFunctor,
                            PD_INFER_META(phi::StackInferMeta));



class StanhOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of stanh op.");
    AddOutput("Out", "(Tensor), output 0 of stanh op.");
    AddAttr<float>("scale_a", "(float), attribute 0 for stanh op.")
        .SetDefault(0.67f);
    AddAttr<float>("scale_b", "(float), attribute 1 for stanh op.")
        .SetDefault(1.7159f);
    AddComment(R"DOC(
TODO: Documentation of stanh op.
)DOC");
  }
};


class StanhOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(stanh, StanhInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class SvdOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of svd op.");
    AddOutput("U", "(Tensor), output 0 of svd op.");
    AddOutput("S", "(Tensor), output 1 of svd op.");
    AddOutput("VH", "(Tensor), output 2 of svd op.");
    AddAttr<bool>("full_matrices", "(bool), attribute 0 for svd op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of svd op.
)DOC");
  }
};


class SvdOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(svd, SvdInferShapeFunctor,
                            PD_INFER_META(phi::SvdInferMeta));



class TakeAlongAxisOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of take_along_axis op.");
    AddInput("Index", "(Tensor), input 1 of take_along_axis op.");
    AddOutput("Result", "(Tensor), output 0 of take_along_axis op.");
    AddAttr<int>("Axis", "(int), attribute 0 for take_along_axis op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of take_along_axis op.
)DOC");
  }
};


class TakeAlongAxisOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(take_along_axis, TakeAlongAxisInferShapeFunctor,
                            PD_INFER_META(phi::TakeAlongAxisInferMeta));



class TanOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of tan op.");
    AddOutput("Out", "(Tensor), output 0 of tan op.");
    AddComment(R"DOC(
TODO: Documentation of tan op.
)DOC");
  }
};


class TanOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tan, TanInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(TanInplaceInferer,
                           {"X", "Out"});



class TanhOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of tanh op.");
    AddOutput("Out", "(Tensor), output 0 of tanh op.");
    AddComment(R"DOC(
TODO: Documentation of tanh op.
)DOC");
  }
};


class TanhOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tanh, TanhInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(TanhInplaceInferer,
                           {"X", "Out"});



class TanhShrinkOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of tanh_shrink op.");
    AddOutput("Out", "(Tensor), output 0 of tanh_shrink op.");
    AddComment(R"DOC(
TODO: Documentation of tanh_shrink op.
)DOC");
  }
};


class TanhShrinkOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tanh_shrink, TanhShrinkInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class TemporalShiftOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of temporal_shift op.");
    AddOutput("Out", "(Tensor), output 0 of temporal_shift op.");
    AddAttr<int>("seg_num", "(int), attribute 0 for temporal_shift op.")
    ;
    AddAttr<float>("shift_ratio", "(float), attribute 1 for temporal_shift op.")
        .SetDefault(0.25f);
    AddAttr<std::string>("data_format", "(std::string), attribute 2 for temporal_shift op.")
        .SetDefault("NCHW");
    AddComment(R"DOC(
TODO: Documentation of temporal_shift op.
)DOC");
  }
};


class TemporalShiftOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(temporal_shift, TemporalShiftInferShapeFunctor,
                            PD_INFER_META(phi::TemporalShiftInferMeta));



class TensorUnfoldOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("input", "(Tensor), input 0 of tensor_unfold op.");
    AddOutput("out", "(Tensor), output 0 of tensor_unfold op.");
    AddAttr<int64_t>("axis", "(int64_t), attribute 0 for tensor_unfold op.")
    ;
    AddAttr<int64_t>("size", "(int64_t), attribute 1 for tensor_unfold op.")
    ;
    AddAttr<int64_t>("step", "(int64_t), attribute 2 for tensor_unfold op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of tensor_unfold op.
)DOC");
  }
};


class TensorUnfoldOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tensor_unfold, TensorUnfoldInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(TensorUnfoldNoNeedBufferVarInferer,
                                    "input");


class ThresholdedReluOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of thresholded_relu op.");
    AddOutput("Out", "(Tensor), output 0 of thresholded_relu op.");
    AddAttr<float>("threshold", "(float), attribute 0 for thresholded_relu op.")
        .SetDefault(1.0);
    AddComment(R"DOC(
TODO: Documentation of thresholded_relu op.
)DOC");
  }
};


class ThresholdedReluOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(thresholded_relu, ThresholdedReluInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(ThresholdedReluInplaceInferer,
                           {"X", "Out"});



class TopKV2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of top_k_v2 op.");
    AddOutput("Out", "(Tensor), output 0 of top_k_v2 op.");
    AddOutput("Indices", "(Tensor), output 1 of top_k_v2 op.");
    AddInput("K", "attribute 0 for top_k_v2 op from 0D Tensor.")
        .AsDispensable();
    AddAttr<int>("k", "(int), attribute 0 for top_k_v2 op.")
        .SetDefault(1);
    AddAttr<int>("axis", "(int), attribute 1 for top_k_v2 op.")
        .SetDefault(-1);
    AddAttr<bool>("largest", "(bool), attribute 2 for top_k_v2 op.")
        .SetDefault(true);
    AddAttr<bool>("sorted", "(bool), attribute 3 for top_k_v2 op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of top_k_v2 op.
)DOC");
  }
};


class TopKV2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(top_k_v2, TopKV2InferShapeFunctor,
                            PD_INFER_META(phi::TopKInferMeta));



class TraceOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of trace op.");
    AddOutput("Out", "(Tensor), output 0 of trace op.");
    AddAttr<int>("offset", "(int), attribute 0 for trace op.")
        .SetDefault(0);
    AddAttr<int>("axis1", "(int), attribute 1 for trace op.")
        .SetDefault(0);
    AddAttr<int>("axis2", "(int), attribute 2 for trace op.")
        .SetDefault(1);
    AddComment(R"DOC(
TODO: Documentation of trace op.
)DOC");
  }
};


class TraceOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(trace, TraceInferShapeFunctor,
                            PD_INFER_META(phi::TraceInferMeta));



class TriangularSolveOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of triangular_solve op.");
    AddInput("Y", "(Tensor), input 1 of triangular_solve op.");
    AddOutput("Out", "(Tensor), output 0 of triangular_solve op.");
    AddAttr<bool>("upper", "(bool), attribute 0 for triangular_solve op.")
        .SetDefault(true);
    AddAttr<bool>("transpose", "(bool), attribute 1 for triangular_solve op.")
        .SetDefault(false);
    AddAttr<bool>("unitriangular", "(bool), attribute 2 for triangular_solve op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of triangular_solve op.
)DOC");
  }
};


class TriangularSolveOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(triangular_solve, TriangularSolveInferShapeFunctor,
                            PD_INFER_META(phi::TriangularSolveInferMeta));



class TrilinearInterpV2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of trilinear_interp_v2 op.");
    AddInput("OutSize", "(Tensor), input 1 of trilinear_interp_v2 op.")
        .AsDispensable();
    AddInput("SizeTensor", "(Tensor[]), input 2 of trilinear_interp_v2 op.")
        .AsDuplicable()
        .AsDispensable();
    AddInput("Scale", "(Tensor), input 3 of trilinear_interp_v2 op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of trilinear_interp_v2 op.");
    AddAttr<std::string>("data_layout", "(std::string), attribute 0 for trilinear_interp_v2 op.")
        .SetDefault("NCHW");
    AddAttr<int>("out_d", "(int), attribute 1 for trilinear_interp_v2 op.")
        .SetDefault(0);
    AddAttr<int>("out_h", "(int), attribute 2 for trilinear_interp_v2 op.")
        .SetDefault(0);
    AddAttr<int>("out_w", "(int), attribute 3 for trilinear_interp_v2 op.")
        .SetDefault(0);
    AddAttr<std::vector<float>>("scale", "(std::vector<float>), attribute 4 for trilinear_interp_v2 op.")
        .SetDefault({});
    AddAttr<std::string>("interp_method", "(std::string), attribute 5 for trilinear_interp_v2 op.")
        .SetDefault("bilinear");
    AddAttr<bool>("align_corners", "(bool), attribute 6 for trilinear_interp_v2 op.")
        .SetDefault(true);
    AddAttr<int>("align_mode", "(int), attribute 7 for trilinear_interp_v2 op.")
        .SetDefault(1);
    AddComment(R"DOC(
TODO: Documentation of trilinear_interp_v2 op.
)DOC");
  }
};


class TrilinearInterpV2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "OutSize" || var_name == "SizeTensor" || var_name == "Scale") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(trilinear_interp_v2, TrilinearInterpV2InferShapeFunctor,
                            PD_INFER_META(phi::InterpolateInferMeta));



class TruncOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of trunc op.");
    AddOutput("Out", "(Tensor), output 0 of trunc op.");
    AddComment(R"DOC(
TODO: Documentation of trunc op.
)DOC");
  }
};


class TruncOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(trunc, TruncInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(TruncInplaceInferer,
                           {"X", "Out"});



class UnbindOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of unbind op.");
    AddOutput("Out", "(Tensor[]), output 0 of unbind op.")
        .AsDuplicable();
    AddAttr<int>("axis", "(int), attribute 0 for unbind op.")
        .SetDefault(0);
    AddComment(R"DOC(
TODO: Documentation of unbind op.
)DOC");
  }
};


class UnbindOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(unbind, UnbindInferShapeFunctor,
                            PD_INFER_META(phi::UnbindInferMeta));



class UnfoldOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of unfold op.");
    AddOutput("Y", "(Tensor), output 0 of unfold op.");
    AddAttr<std::vector<int>>("kernel_sizes", "(std::vector<int>), attribute 0 for unfold op.")
    ;
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 1 for unfold op.")
    ;
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 2 for unfold op.")
    ;
    AddAttr<std::vector<int>>("dilations", "(std::vector<int>), attribute 3 for unfold op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of unfold op.
)DOC");
  }
};


class UnfoldOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(unfold, UnfoldInferShapeFunctor,
                            PD_INFER_META(phi::UnfoldInferMeta));



class UniformRandomInplaceOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of uniform_random_inplace op.");
    AddOutput("Out", "(Tensor), output 0 of uniform_random_inplace op.");
    AddAttr<float>("min", "(float), attribute 0 for uniform_random_inplace op.")
        .SetDefault(-1.0);
    AddAttr<float>("max", "(float), attribute 1 for uniform_random_inplace op.")
        .SetDefault(1.0);
    AddAttr<int>("seed", "(int), attribute 2 for uniform_random_inplace op.")
        .SetDefault(0);
    AddAttr<int>("diag_num", "(int), attribute 3 for uniform_random_inplace op.")
        .SetDefault(0);
    AddAttr<int>("diag_step", "(int), attribute 4 for uniform_random_inplace op.")
        .SetDefault(0);
    AddAttr<float>("diag_val", "(float), attribute 5 for uniform_random_inplace op.")
        .SetDefault(1.0);
    AddComment(R"DOC(
TODO: Documentation of uniform_random_inplace op.
)DOC");
  }
};


class UniformRandomInplaceOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(uniform_random_inplace, UniformRandomInplaceInferShapeFunctor,
                            PD_INFER_META(phi::UniformRandomInplaceInferMeta));
DECLARE_INPLACE_OP_INFERER(UniformRandomInplaceInplaceInferer,
                           {"X", "Out"});



class UniqueConsecutiveOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of unique_consecutive op.");
    AddOutput("Out", "(Tensor), output 0 of unique_consecutive op.");
    AddOutput("Index", "(Tensor), output 1 of unique_consecutive op.")
        .AsDispensable();
    AddOutput("Counts", "(Tensor), output 2 of unique_consecutive op.")
        .AsDispensable();
    AddAttr<bool>("return_inverse", "(bool), attribute 0 for unique_consecutive op.")
        .SetDefault(false);
    AddAttr<bool>("return_counts", "(bool), attribute 1 for unique_consecutive op.")
        .SetDefault(false);
    AddAttr<std::vector<int>>("axis", "(std::vector<int>), attribute 2 for unique_consecutive op.")
        .SetDefault({});
    AddAttr<int>("dtype", "(int), attribute 3 for unique_consecutive op.")
        .SetDefault(5);
    AddComment(R"DOC(
TODO: Documentation of unique_consecutive op.
)DOC");
  }
};


class UniqueConsecutiveOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(unique_consecutive, UniqueConsecutiveInferShapeFunctor,
                            PD_INFER_META(phi::UniqueConsecutiveInferMeta));



class Unpool3dOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of unpool3d op.");
    AddInput("Indices", "(Tensor), input 1 of unpool3d op.");
    AddOutput("Out", "(Tensor), output 0 of unpool3d op.");
    AddAttr<std::vector<int>>("ksize", "(std::vector<int>), attribute 0 for unpool3d op.")
    ;
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 1 for unpool3d op.")
        .SetDefault({1,1,1});
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 2 for unpool3d op.")
        .SetDefault({0,0,0});
    AddAttr<std::vector<int>>("output_size", "(std::vector<int>), attribute 3 for unpool3d op.")
        .SetDefault({0,0,0});
    AddAttr<std::string>("data_format", "(std::string), attribute 4 for unpool3d op.")
        .SetDefault("NCDHW");
    AddComment(R"DOC(
TODO: Documentation of unpool3d op.
)DOC");
  }
};


class Unpool3dOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(unpool3d, Unpool3dInferShapeFunctor,
                            PD_INFER_META(phi::Unpool3dInferMeta));



class Unsqueeze2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of unsqueeze2 op.");
    AddOutput("Out", "(Tensor), output 0 of unsqueeze2 op.");
    AddOutput("XShape", "(Tensor), output 1 of unsqueeze2 op.")
        .AsIntermediate()
        .AsExtra();
    AddInput("AxesTensor", "attribute 0 for unsqueeze2 op from 1D integer Tensor.")
        .AsDispensable();
    AddInput("AxesTensorList", "attribute 0 for unsqueeze2 op from list fo 0D integer Tensors.")
        .AsDuplicable()
        .AsDispensable();
      AddAttr<std::vector<int>>("axes", "(std::vector<int>), attribute 0 for unsqueeze2 op.")
        .SetDefault({});
    AddComment(R"DOC(
TODO: Documentation of unsqueeze2 op.
)DOC");
  }
};


class Unsqueeze2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(unsqueeze2, Unsqueeze2InferShapeFunctor,
                            PD_INFER_META(phi::UnsqueezeWithXShapeInferMeta));
DECLARE_INPLACE_OP_INFERER(Unsqueeze2InplaceInferer,
                           {"X", "Out"});



class UnstackOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of unstack op.");
    AddOutput("Y", "(Tensor[]), output 0 of unstack op.")
        .AsDuplicable();
    AddAttr<int>("axis", "(int), attribute 0 for unstack op.")
        .SetDefault(0);
    AddAttr<int>("num", "(int), attribute 1 for unstack op.")
        .SetDefault(0);
    AddComment(R"DOC(
TODO: Documentation of unstack op.
)DOC");
  }
};


class UnstackOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(unstack, UnstackInferShapeFunctor,
                            PD_INFER_META(phi::UnStackInferMeta));



class UpdateLossScalingOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor[]), input 0 of update_loss_scaling op.")
        .AsDuplicable();
    AddInput("FoundInfinite", "(Tensor), input 1 of update_loss_scaling op.");
    AddInput("PrevLossScaling", "(Tensor), input 2 of update_loss_scaling op.");
    AddInput("InGoodSteps", "(Tensor), input 3 of update_loss_scaling op.");
    AddInput("InBadSteps", "(Tensor), input 4 of update_loss_scaling op.");
    AddOutput("Out", "(Tensor[]), output 0 of update_loss_scaling op.")
        .AsDuplicable();
    AddOutput("LossScaling", "(Tensor), output 1 of update_loss_scaling op.");
    AddOutput("OutGoodSteps", "(Tensor), output 2 of update_loss_scaling op.");
    AddOutput("OutBadSteps", "(Tensor), output 3 of update_loss_scaling op.");
    AddAttr<int>("incr_every_n_steps", "(int), attribute 0 for update_loss_scaling op.")
    ;
    AddAttr<int>("decr_every_n_nan_or_inf", "(int), attribute 1 for update_loss_scaling op.")
    ;
    AddAttr<float>("incr_ratio", "(float), attribute 2 for update_loss_scaling op.")
    ;
    AddAttr<float>("decr_ratio", "(float), attribute 3 for update_loss_scaling op.")
    ;
    AddInput("StopUpdate", "attribute 4 for update_loss_scaling op from 0D Tensor.")
        .AsDispensable();
    AddAttr<bool>("stop_update", "(bool), attribute 4 for update_loss_scaling op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of update_loss_scaling op.
)DOC");
  }
};


class UpdateLossScalingOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetUpdateLossScalingExpectedKernelType(ctx, this);
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "FoundInfinite") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(update_loss_scaling, UpdateLossScalingInferShapeFunctor,
                            PD_INFER_META(phi::UpdateLossScalingInferMeta));



class VariableLengthMemoryEfficientAttentionOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("query", "(Tensor), input 0 of variable_length_memory_efficient_attention op.");
    AddInput("key", "(Tensor), input 1 of variable_length_memory_efficient_attention op.");
    AddInput("value", "(Tensor), input 2 of variable_length_memory_efficient_attention op.");
    AddInput("seq_lens", "(Tensor), input 3 of variable_length_memory_efficient_attention op.");
    AddInput("kv_seq_lens", "(Tensor), input 4 of variable_length_memory_efficient_attention op.");
    AddInput("mask", "(Tensor), input 5 of variable_length_memory_efficient_attention op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of variable_length_memory_efficient_attention op.");
    AddAttr<float>("scale", "(float), attribute 0 for variable_length_memory_efficient_attention op.")
    ;
    AddAttr<bool>("causal", "(bool), attribute 1 for variable_length_memory_efficient_attention op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of variable_length_memory_efficient_attention op.
)DOC");
  }
};


class VariableLengthMemoryEfficientAttentionOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "query");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(variable_length_memory_efficient_attention, VariableLengthMemoryEfficientAttentionInferShapeFunctor,
                            PD_INFER_META(phi::VariableLengthMemoryEfficientAttentionInferMeta));



class ViewDtypeOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("input", "(Tensor), input 0 of view_dtype op.");
    AddOutput("out", "(Tensor), output 0 of view_dtype op.");
    AddAttr<int>("dtype", "(int), attribute 0 for view_dtype op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of view_dtype op.
)DOC");
  }
};


class ViewDtypeOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(view_dtype, ViewDtypeInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(ViewDtypeNoNeedBufferVarInferer,
                                    "input");


class ViewShapeOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("input", "(Tensor), input 0 of view_shape op.");
    AddOutput("out", "(Tensor), output 0 of view_shape op.");
    AddAttr<std::vector<int64_t>>("dims", "(std::vector<int64_t>), attribute 0 for view_shape op.")
        .SetDefault({});
    AddComment(R"DOC(
TODO: Documentation of view_shape op.
)DOC");
  }
};


class ViewShapeOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(view_shape, ViewShapeInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(ViewShapeNoNeedBufferVarInferer,
                                    "input");


class ViterbiDecodeOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of viterbi_decode op.");
    AddInput("Transition", "(Tensor), input 1 of viterbi_decode op.");
    AddInput("Length", "(Tensor), input 2 of viterbi_decode op.");
    AddOutput("Scores", "(Tensor), output 0 of viterbi_decode op.");
    AddOutput("Path", "(Tensor), output 1 of viterbi_decode op.");
    AddAttr<bool>("include_bos_eos_tag", "(bool), attribute 0 for viterbi_decode op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of viterbi_decode op.
)DOC");
  }
};


class ViterbiDecodeOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(viterbi_decode, ViterbiDecodeInferShapeFunctor,
                            PD_INFER_META(phi::ViterbiDecodeInferMeta));



class WarpctcOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Logits", "(Tensor), input 0 of warpctc op.");
    AddInput("Label", "(Tensor), input 1 of warpctc op.");
    AddInput("LogitsLength", "(Tensor), input 2 of warpctc op.")
        .AsDispensable();
    AddInput("LabelLength", "(Tensor), input 3 of warpctc op.")
        .AsDispensable();
    AddOutput("Loss", "(Tensor), output 0 of warpctc op.");
    AddOutput("WarpCTCGrad", "(Tensor), output 1 of warpctc op.")
        .AsIntermediate();
    AddAttr<int>("blank", "(int), attribute 0 for warpctc op.")
        .SetDefault(0);
    AddAttr<bool>("norm_by_times", "(bool), attribute 1 for warpctc op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of warpctc op.
)DOC");
  }
};


class WarpctcOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Logits");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(warpctc, WarpctcInferShapeFunctor,
                            PD_INFER_META(phi::WarpctcInferMeta));



class WarprnntOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("input", "(Tensor), input 0 of warprnnt op.");
    AddInput("label", "(Tensor), input 1 of warprnnt op.");
    AddInput("input_lengths", "(Tensor), input 2 of warprnnt op.");
    AddInput("label_lengths", "(Tensor), input 3 of warprnnt op.");
    AddOutput("loss", "(Tensor), output 0 of warprnnt op.");
    AddOutput("warprnntgrad", "(Tensor), output 1 of warprnnt op.")
        .AsIntermediate();
    AddAttr<int>("blank", "(int), attribute 0 for warprnnt op.")
        .SetDefault(0);
    AddAttr<float>("fastemit_lambda", "(float), attribute 1 for warprnnt op.")
        .SetDefault(0.0);
    AddComment(R"DOC(
TODO: Documentation of warprnnt op.
)DOC");
  }
};


class WarprnntOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(warprnnt, WarprnntInferShapeFunctor,
                            PD_INFER_META(phi::WarprnntInferMeta));



class WeightOnlyMatmulOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of weight_only_matmul op.");
    AddInput("weight", "(Tensor), input 1 of weight_only_matmul op.");
    AddInput("weight_scale", "(Tensor), input 2 of weight_only_matmul op.");
    AddOutput("out", "(Tensor), output 0 of weight_only_matmul op.");
    AddComment(R"DOC(
TODO: Documentation of weight_only_matmul op.
)DOC");
  }
};


class WeightOnlyMatmulOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(weight_only_matmul, WeightOnlyMatmulInferShapeFunctor,
                            PD_INFER_META(phi::WeightOnlyMatmulInferMeta));



class WeightedSampleNeighborsOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("row", "(Tensor), input 0 of weighted_sample_neighbors op.");
    AddInput("colptr", "(Tensor), input 1 of weighted_sample_neighbors op.");
    AddInput("edge_weight", "(Tensor), input 2 of weighted_sample_neighbors op.");
    AddInput("input_nodes", "(Tensor), input 3 of weighted_sample_neighbors op.");
    AddInput("eids", "(Tensor), input 4 of weighted_sample_neighbors op.")
        .AsDispensable();
    AddOutput("out_neighbors", "(Tensor), output 0 of weighted_sample_neighbors op.");
    AddOutput("out_count", "(Tensor), output 1 of weighted_sample_neighbors op.");
    AddOutput("out_eids", "(Tensor), output 2 of weighted_sample_neighbors op.");
    AddAttr<int>("sample_size", "(int), attribute 0 for weighted_sample_neighbors op.")
    ;
    AddAttr<bool>("return_eids", "(bool), attribute 1 for weighted_sample_neighbors op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of weighted_sample_neighbors op.
)DOC");
  }
};


class WeightedSampleNeighborsOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(weighted_sample_neighbors, WeightedSampleNeighborsInferShapeFunctor,
                            PD_INFER_META(phi::WeightedSampleNeighborsInferMeta));



class WhereOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Condition", "(Tensor), input 0 of where op.");
    AddInput("X", "(Tensor), input 1 of where op.");
    AddInput("Y", "(Tensor), input 2 of where op.");
    AddOutput("Out", "(Tensor), output 0 of where op.");
    AddComment(R"DOC(
TODO: Documentation of where op.
)DOC");
  }
};


class WhereOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(where, WhereInferShapeFunctor,
                            PD_INFER_META(phi::WhereInferMeta));



class YoloBoxOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of yolo_box op.");
    AddInput("ImgSize", "(Tensor), input 1 of yolo_box op.");
    AddOutput("Boxes", "(Tensor), output 0 of yolo_box op.");
    AddOutput("Scores", "(Tensor), output 1 of yolo_box op.");
    AddAttr<std::vector<int>>("anchors", "(std::vector<int>), attribute 0 for yolo_box op.")
        .SetDefault({});
    AddAttr<int>("class_num", "(int), attribute 1 for yolo_box op.")
        .SetDefault(1);
    AddAttr<float>("conf_thresh", "(float), attribute 2 for yolo_box op.")
        .SetDefault(0.01);
    AddAttr<int>("downsample_ratio", "(int), attribute 3 for yolo_box op.")
        .SetDefault(32);
    AddAttr<bool>("clip_bbox", "(bool), attribute 4 for yolo_box op.")
        .SetDefault(true);
    AddAttr<float>("scale_x_y", "(float), attribute 5 for yolo_box op.")
        .SetDefault(1.0);
    AddAttr<bool>("iou_aware", "(bool), attribute 6 for yolo_box op.")
        .SetDefault(false);
    AddAttr<float>("iou_aware_factor", "(float), attribute 7 for yolo_box op.")
        .SetDefault(0.5);
    AddComment(R"DOC(
TODO: Documentation of yolo_box op.
)DOC");
  }
};


class YoloBoxOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(yolo_box, YoloBoxInferShapeFunctor,
                            PD_INFER_META(phi::YoloBoxInferMeta));



class Yolov3LossOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of yolov3_loss op.");
    AddInput("GTBox", "(Tensor), input 1 of yolov3_loss op.");
    AddInput("GTLabel", "(Tensor), input 2 of yolov3_loss op.");
    AddInput("GTScore", "(Tensor), input 3 of yolov3_loss op.")
        .AsDispensable();
    AddOutput("Loss", "(Tensor), output 0 of yolov3_loss op.");
    AddOutput("ObjectnessMask", "(Tensor), output 1 of yolov3_loss op.")
        .AsIntermediate();
    AddOutput("GTMatchMask", "(Tensor), output 2 of yolov3_loss op.")
        .AsIntermediate();
    AddAttr<std::vector<int>>("anchors", "(std::vector<int>), attribute 0 for yolov3_loss op.")
        .SetDefault({});
    AddAttr<std::vector<int>>("anchor_mask", "(std::vector<int>), attribute 1 for yolov3_loss op.")
        .SetDefault({});
    AddAttr<int>("class_num", "(int), attribute 2 for yolov3_loss op.")
        .SetDefault(1);
    AddAttr<float>("ignore_thresh", "(float), attribute 3 for yolov3_loss op.")
        .SetDefault(0.7);
    AddAttr<int>("downsample_ratio", "(int), attribute 4 for yolov3_loss op.")
        .SetDefault(32);
    AddAttr<bool>("use_label_smooth", "(bool), attribute 5 for yolov3_loss op.")
        .SetDefault(true);
    AddAttr<float>("scale_x_y", "(float), attribute 6 for yolov3_loss op.")
        .SetDefault(1.0);
    AddComment(R"DOC(
TODO: Documentation of yolov3_loss op.
)DOC");
  }
};


class Yolov3LossOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetYoloLossExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(yolov3_loss, Yolov3LossInferShapeFunctor,
                            PD_INFER_META(phi::YoloLossInferMeta));




template <typename T>
class RoiAlignGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("roi_align_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("ROIs", this->Input("ROIs"));
    grad_op->SetInput("RoisNum", this->Input("RoisNum"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class RoiAlignGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "ROIs");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(roi_align_grad, RoiAlignGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(RoiAlignGradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class RoiPoolGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("roi_pool_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("ROIs", this->Input("ROIs"));
    grad_op->SetInput("RoisNum", this->Input("RoisNum"));
    grad_op->SetInput("Argmax", this->Output("Argmax"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class RoiPoolGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(roi_pool_grad, RoiPoolGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class RollGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("roll_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("ShiftsTensor")) {
      grad_op->SetInput("ShiftsTensor", this->Input("ShiftsTensor"));
    }
  }
};


class RollGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(roll_grad, RollGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(RollGradNoNeedBufferVarInferer,
                                    "X");

class RollCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto out_grad = this->GetSingleOutputGrad("Out");

    auto tensor_shifts = this->GetOptionalSingleForwardInput("ShiftsTensor");
    if (tensor_shifts) {
      PADDLE_THROW(platform::errors::Unimplemented(
          "We don't support dynamic tensor attribute ShiftsTensor for roll_grad composite"
          "for now. "));
    }
    //get attr
    const std::vector<int64_t> shifts = this->Attr<std::vector<int64_t>>("shifts");
    const std::vector<int64_t> axis = this->Attr<std::vector<int64_t>>("axis");

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing roll_grad composite func";
    prim::roll_grad<prim::DescTensor>(x, out_grad, shifts, axis, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class RoundGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("round_grad");

    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class RoundGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(round_grad, RoundGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(RoundGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class RsqrtGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("rsqrt_grad");

    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class RsqrtGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(rsqrt_grad, RsqrtGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(RsqrtGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class RsqrtGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("rsqrt_grad_grad");

    grad_op->SetInput("Out", this->Input("Out"));
    grad_op->SetInput("grad_x", this->Output(GradVarName("X")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("Out"), this->InputGrad("Out"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class RsqrtGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(rsqrt_grad_grad, RsqrtGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(RsqrtGradGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});


template <typename T>
class ScaleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("scale");

    grad_op->SetInput("X", this->OutputGrad("Out"));

    grad_op->SetOutput("Out", this->InputGrad("X"));

    if (this->HasInput("ScaleTensor")) {
      grad_op->SetInput("ScaleTensor", this->Input("ScaleTensor"));
    }

    grad_op->SetAttr("scale", this->GetAttr("scale"));
    grad_op->SetAttr("bias", 0.0f);
    grad_op->SetAttr("bias_after_scale", true);
  }
};


template <typename T>
class ScatterGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("scatter_grad");

    grad_op->SetInput("Ids", this->Input("Ids"));
    grad_op->SetInput("Updates", this->Input("Updates"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Updates"), this->InputGrad("Updates"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class ScatterGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(scatter_grad, ScatterGradInferShapeFunctor,
                            PD_INFER_META(phi::ScatterGradInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(ScatterGradNoNeedBufferVarInferer,
                                    "Updates");

class ScatterCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto index = this->GetSingleForwardInput("Ids");
    auto updates = this->GetSingleForwardInput("Updates");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr
    const bool overwrite = this->Attr<bool>("overwrite");

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");
    auto updates_grad_t = this->GetSingleInputGrad("Updates");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);
    auto updates_grad = this->GetOutputPtr(&updates_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);
    auto updates_grad_name = this->GetOutputName(updates_grad_t);

    //call composite backward func
    VLOG(6) << "Runing scatter_grad composite func";
    prim::scatter_grad<prim::DescTensor>(index, updates, out_grad, overwrite, x_grad, updates_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);
    this->RecoverOutputName(updates_grad_t, updates_grad_name);

  }
};

template <typename T>
class ScatterNdAddGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("scatter_nd_add_grad");

    grad_op->SetInput("Index", this->Input("Index"));
    grad_op->SetInput("Updates", this->Input("Updates"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Updates"), this->InputGrad("Updates"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class ScatterNdAddGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(scatter_nd_add_grad, ScatterNdAddGradInferShapeFunctor,
                            PD_INFER_META(phi::ScatterNdAddGradInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(ScatterNdAddGradNoNeedBufferVarInferer,
                                    "Updates");

class ScatterNdAddCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto index = this->GetSingleForwardInput("Index");
    auto updates = this->GetSingleForwardInput("Updates");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");
    auto updates_grad_t = this->GetSingleInputGrad("Updates");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);
    auto updates_grad = this->GetOutputPtr(&updates_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);
    auto updates_grad_name = this->GetOutputName(updates_grad_t);

    //call composite backward func
    VLOG(6) << "Runing scatter_nd_add_grad composite func";
    prim::scatter_nd_add_grad<prim::DescTensor>(index, updates, out_grad, x_grad, updates_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);
    this->RecoverOutputName(updates_grad_t, updates_grad_name);

  }
};

template <typename T>
class SegmentPoolGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("segment_pool_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("SegmentIds", this->Input("SegmentIds"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput("SummedIds", this->Output("SummedIds"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SegmentPoolGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(segment_pool_grad, SegmentPoolGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class SeluGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("selu_grad");

    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SeluGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Out");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(selu_grad, SeluGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class GraphSendRecvGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("graph_send_recv_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Src_index", this->Input("Src_index"));
    grad_op->SetInput("Dst_index", this->Input("Dst_index"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput("Dst_count", this->Output("Dst_count"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class GraphSendRecvGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(graph_send_recv_grad, GraphSendRecvGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralUnaryGradInferMeta));



template <typename T>
class GraphSendUeRecvGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("graph_send_ue_recv_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput("Src_index", this->Input("Src_index"));
    grad_op->SetInput("Dst_index", this->Input("Dst_index"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput("Dst_count", this->Output("Dst_count"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class GraphSendUeRecvGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(graph_send_ue_recv_grad, GraphSendUeRecvGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class GraphSendUvGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("graph_send_uv_grad");

    grad_op->SetInput("x", this->Input("x"));
    grad_op->SetInput("y", this->Input("y"));
    grad_op->SetInput("src_index", this->Input("src_index"));
    grad_op->SetInput("dst_index", this->Input("dst_index"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("x"), this->InputGrad("x"));
    grad_op->SetOutput(GradVarName("y"), this->InputGrad("y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class GraphSendUvGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(graph_send_uv_grad, GraphSendUvGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class SigmoidGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sigmoid_grad");

    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SigmoidGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sigmoid_grad, SigmoidGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SigmoidGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


class SigmoidCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto out = this->GetSingleForwardOutput("Out");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing sigmoid_grad composite func";
    prim::sigmoid_grad<prim::DescTensor>(out, out_grad, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class SigmoidGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sigmoid_grad_grad");

    grad_op->SetInput("Out", this->Input("Out"));
    grad_op->SetInput("fwd_grad_out", this->Input(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("Out"), this->InputGrad("Out"));
    grad_op->SetOutput(GradVarName("fwd_grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SigmoidGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sigmoid_grad_grad, SigmoidGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SigmoidGradGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("fwd_grad_out")});



template <typename T>
class SigmoidTripleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sigmoid_triple_grad");

    grad_op->SetInput("Out", this->Input("Out"));
    grad_op->SetInput("fwd_grad_out", this->Input("fwd_grad_out"));
    grad_op->SetInput("grad_grad_x", this->Input(GradVarName("grad_x")));
    grad_op->SetInput(GradVarName("grad_out"), this->OutputGrad(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_grad_out"), this->OutputGrad(GradVarName("fwd_grad_out")));

    grad_op->SetOutput(GradVarName("Out"), this->InputGrad("Out"));
    grad_op->SetOutput(GradVarName("fwd_grad_out"), this->InputGrad("fwd_grad_out"));
    grad_op->SetOutput(GradVarName("grad_grad_x"), this->InputGrad(GradVarName("grad_x")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SigmoidTripleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sigmoid_triple_grad, SigmoidTripleGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SigmoidTripleGradInplaceInferer,
                           {"grad_grad_x", GradVarName("fwd_grad_out")});



template <typename T>
class SigmoidCrossEntropyWithLogitsGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sigmoid_cross_entropy_with_logits_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Label", this->Input("Label"));
    grad_op->SetInput("pos_weight", this->Input("pos_weight"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SigmoidCrossEntropyWithLogitsGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sigmoid_cross_entropy_with_logits_grad, SigmoidCrossEntropyWithLogitsGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SigmoidCrossEntropyWithLogitsGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


template <typename T>
class SignGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("scale");

    grad_op->SetInput("X", this->OutputGrad("Out"));

    grad_op->SetOutput("Out", this->InputGrad("X"));


    grad_op->SetAttr("scale", 0.0f);
    grad_op->SetAttr("bias", 0.0f);
    grad_op->SetAttr("bias_after_scale", true);
  }
};


template <typename T>
class SiluGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("silu_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SiluGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(silu_grad, SiluGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SiluGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


class SiluCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto out = this->GetSingleForwardOutput("Out");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing silu_grad composite func";
    prim::silu_grad<prim::DescTensor>(x, out, out_grad, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

class SiluDoubleCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto out = this->GetSingleForwardInput("Out");
    auto grad_out = this->GetSingleForwardInput(GradVarName("Out"));
    auto grad_x_grad = this->GetSingleOutputGrad(GradVarName("X"));


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");
    auto grad_out_grad_t = this->GetSingleInputGrad(GradVarName("Out"));

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);
    auto grad_out_grad = this->GetOutputPtr(&grad_out_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);
    auto grad_out_grad_name = this->GetOutputName(grad_out_grad_t);

    //call composite backward func
    VLOG(6) << "Runing silu_double_grad composite func";
    prim::silu_double_grad<prim::DescTensor>(x, out, grad_out, grad_x_grad, x_grad, grad_out_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);
    this->RecoverOutputName(grad_out_grad_t, grad_out_grad_name);

  }
};

template <typename T>
class SinGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sin_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SinGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sin_grad, SinGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SinGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


class SinCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing sin_grad composite func";
    prim::sin_grad<prim::DescTensor>(x, out_grad, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class SinDoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sin_double_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SinDoubleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sin_double_grad, SinDoubleGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SinDoubleGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});



template <typename T>
class SinTripleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sin_triple_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("grad_out_forward", this->Input("grad_out"));
    grad_op->SetInput("grad_x_grad_forward", this->Input(GradVarName("grad_x")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));
    grad_op->SetInput(GradVarName("grad_out_grad"), this->OutputGrad(GradVarName("grad_out")));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("grad_out_forward"), this->InputGrad("grad_out"));
    grad_op->SetOutput(GradVarName("grad_x_grad_forward"), this->InputGrad(GradVarName("grad_x")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SinTripleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sin_triple_grad, SinTripleGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SinTripleGradInplaceInferer,
                           {"grad_x_grad_forward", GradVarName("grad_out_forward")});



template <typename T>
class SinhGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sinh_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SinhGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sinh_grad, SinhGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SinhGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class SlogdeterminantGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("slogdeterminant_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SlogdeterminantGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(slogdeterminant_grad, SlogdeterminantGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralUnaryGradInferMeta));



template <typename T>
class SoftplusGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("softplus_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SoftplusGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(softplus_grad, SoftplusGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SoftplusGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class SoftplusDoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("softplus_double_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SoftplusDoubleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(softplus_double_grad, SoftplusDoubleGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SoftplusDoubleGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});



template <typename T>
class SoftshrinkGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("softshrink_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SoftshrinkGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(softshrink_grad, SoftshrinkGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SoftshrinkGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class SoftsignGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("softsign_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SoftsignGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(softsign_grad, SoftsignGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SoftsignGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class SolveGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("solve_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SolveGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(solve_grad, SolveGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class SpectralNormGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("spectral_norm_grad");

    grad_op->SetInput("Weight", this->Input("Weight"));
    grad_op->SetInput("U", this->Input("U"));
    grad_op->SetInput("V", this->Input("V"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("Weight"), this->InputGrad("Weight"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SpectralNormGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Weight");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(spectral_norm_grad, SpectralNormGradInferShapeFunctor,
                            PD_INFER_META(phi::SpectralNormGradInferMeta));



template <typename T>
class SqrtGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sqrt_grad");

    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SqrtGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sqrt_grad, SqrtGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SqrtGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


class SqrtCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto out = this->GetSingleForwardOutput("Out");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing sqrt_grad composite func";
    prim::sqrt_grad<prim::DescTensor>(out, out_grad, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class SqrtGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("sqrt_grad_grad");

    grad_op->SetInput("Out", this->Input("Out"));
    grad_op->SetInput("grad_x", this->Output(GradVarName("X")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("Out"), this->InputGrad("Out"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SqrtGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(sqrt_grad_grad, SqrtGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SqrtGradGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});



template <typename T>
class SquareGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("square_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SquareGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(square_grad, SquareGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(SquareGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class SquareGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("square_grad_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SquareGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(square_grad_grad, SquareGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SquareGradGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});



template <typename T>
class SquaredL2NormGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("squared_l2_norm_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SquaredL2NormGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(squared_l2_norm_grad, SquaredL2NormGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class Squeeze2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("squeeze2_grad");

    grad_op->SetInput("XShape", this->Output("XShape"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("AxisTensor")) {
      grad_op->SetInput("AxisTensor", this->Input("AxisTensor"));
    }
    if (this->HasInput("AxisTensorList")) {
      grad_op->SetInput("AxisTensorList", this->Input("AxisTensorList"));
    }
  }
};


class Squeeze2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(squeeze2_grad, Squeeze2GradInferShapeFunctor,
                            PD_INFER_META(phi::KernelWithXShapeInferMeta));
DECLARE_INPLACE_OP_INFERER(Squeeze2GradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


template <typename T>
class Squeeze2DoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("squeeze2");

    grad_op->SetInput("X", this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput("Out", this->InputGrad(GradVarName("Out")));
    grad_op->SetOutput("XShape", this->Input("XShape"));

    if (this->HasInput("AxisTensor")) {
      grad_op->SetInput("AxisTensor", this->Input("AxisTensor"));
    }
    if (this->HasInput("AxisTensorList")) {
      grad_op->SetInput("AxisTensorList", this->Input("AxisTensorList"));
    }

    grad_op->SetAttr("axes", this->GetAttr("axes"));
  }
};


template <typename T>
class StackGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("stack_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Y"), this->OutputGrad("Y"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X", false));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class StackGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Y"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(stack_grad, StackGradInferShapeFunctor,
                            PD_INFER_META(phi::StackGradInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(StackGradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class StanhGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("stanh_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class StanhGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(stanh_grad, StanhGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class SvdGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("svd_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("U", this->Output("U"));
    grad_op->SetInput("VH", this->Output("VH"));
    grad_op->SetInput("S", this->Output("S"));
    grad_op->SetInput(GradVarName("U"), this->OutputGrad("U"));
    grad_op->SetInput(GradVarName("VH"), this->OutputGrad("VH"));
    grad_op->SetInput(GradVarName("S"), this->OutputGrad("S"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SvdGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(svd_grad, SvdGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class TakeAlongAxisGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("take_along_axis_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Index", this->Input("Index"));
    grad_op->SetInput(GradVarName("Result"), this->OutputGrad("Result"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TakeAlongAxisGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(take_along_axis_grad, TakeAlongAxisGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class TanGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("tan_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TanGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tan_grad, TanGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(TanGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class TanhGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("tanh_grad");

    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TanhGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tanh_grad, TanhGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(TanhGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


class TanhCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto out = this->GetSingleForwardOutput("Out");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing tanh_grad composite func";
    prim::tanh_grad<prim::DescTensor>(out, out_grad, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class TanhGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("tanh_grad_grad");

    grad_op->SetInput("Out", this->Input("Out"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("Out"), this->InputGrad("Out"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TanhGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tanh_grad_grad, TanhGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(TanhGradGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});


class TanhGradCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto out = this->GetSingleForwardInput("Out");
    auto grad_out = this->GetSingleForwardInput(GradVarName("Out"));
    auto grad_x_grad = this->GetSingleOutputGrad(GradVarName("X"));


    //get attr

    //get output
    auto out_grad_t = this->GetSingleInputGrad("Out");
    auto grad_out_grad_t = this->GetSingleInputGrad(GradVarName("Out"));

    //get output ptr
    auto out_grad = this->GetOutputPtr(&out_grad_t);
    auto grad_out_grad = this->GetOutputPtr(&grad_out_grad_t);

    //get output orginal name
    auto out_grad_name = this->GetOutputName(out_grad_t);
    auto grad_out_grad_name = this->GetOutputName(grad_out_grad_t);

    //call composite backward func
    VLOG(6) << "Runing tanh_double_grad composite func";
    prim::tanh_double_grad<prim::DescTensor>(out, grad_out, grad_x_grad, out_grad, grad_out_grad);
    //recover output name
    this->RecoverOutputName(out_grad_t, out_grad_name);
    this->RecoverOutputName(grad_out_grad_t, grad_out_grad_name);

  }
};

template <typename T>
class TanhTripleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("tanh_triple_grad");

    grad_op->SetInput("Out", this->Input("Out"));
    grad_op->SetInput("grad_out_forward", this->Input("grad_out"));
    grad_op->SetInput("grad_x_grad_forward", this->Input(GradVarName("grad_x")));
    grad_op->SetInput(GradVarName("grad_out_new"), this->OutputGrad(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_out_grad"), this->OutputGrad(GradVarName("grad_out")));

    grad_op->SetOutput(GradVarName("Out"), this->InputGrad("Out"));
    grad_op->SetOutput(GradVarName("grad_out_forward"), this->InputGrad("grad_out"));
    grad_op->SetOutput(GradVarName("grad_x_grad_forward"), this->InputGrad(GradVarName("grad_x")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TanhTripleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tanh_triple_grad, TanhTripleGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(TanhTripleGradInplaceInferer,
                           {"grad_x_grad_forward", GradVarName("grad_out_forward")});


class TanhTripleCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto out = this->GetSingleForwardInput("Out");
    auto grad_out_forward = this->GetSingleForwardInput("grad_out");
    auto grad_x_grad_forward = this->GetSingleForwardInput(GradVarName("grad_x"));
    auto grad_out_new_grad = this->GetOptionalSingleOutputGrad(GradVarName("Out"));
    auto grad_out_grad_grad = this->GetOptionalSingleOutputGrad(GradVarName("grad_out"));


    //get attr

    //get output
    auto out_grad_t = this->GetSingleInputGrad("Out");
    auto grad_out_forward_grad_t = this->GetSingleInputGrad("grad_out");
    auto grad_x_grad_forward_grad_t = this->GetSingleInputGrad(GradVarName("grad_x"));

    //get output ptr
    auto out_grad = this->GetOutputPtr(&out_grad_t);
    auto grad_out_forward_grad = this->GetOutputPtr(&grad_out_forward_grad_t);
    auto grad_x_grad_forward_grad = this->GetOutputPtr(&grad_x_grad_forward_grad_t);

    //get output orginal name
    auto out_grad_name = this->GetOutputName(out_grad_t);
    auto grad_out_forward_grad_name = this->GetOutputName(grad_out_forward_grad_t);
    auto grad_x_grad_forward_grad_name = this->GetOutputName(grad_x_grad_forward_grad_t);

    //call composite backward func
    VLOG(6) << "Runing tanh_triple_grad composite func";
    prim::tanh_triple_grad<prim::DescTensor>(out, grad_out_forward, grad_x_grad_forward, grad_out_new_grad, grad_out_grad_grad, out_grad, grad_out_forward_grad, grad_x_grad_forward_grad);
    //recover output name
    this->RecoverOutputName(out_grad_t, out_grad_name);
    this->RecoverOutputName(grad_out_forward_grad_t, grad_out_forward_grad_name);
    this->RecoverOutputName(grad_x_grad_forward_grad_t, grad_x_grad_forward_grad_name);

  }
};

template <typename T>
class TanhShrinkGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("tanh_shrink_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TanhShrinkGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tanh_shrink_grad, TanhShrinkGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(TanhShrinkGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class TemporalShiftGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("temporal_shift_grad");

    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TemporalShiftGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(temporal_shift_grad, TemporalShiftGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class TensorUnfoldGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("tensor_unfold_grad");

    grad_op->SetInput("input", this->Input("input"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("input"), this->InputGrad("input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TensorUnfoldGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(tensor_unfold_grad, TensorUnfoldGradInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));



template <typename T>
class ThresholdedReluGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("thresholded_relu_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class ThresholdedReluGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(thresholded_relu_grad, ThresholdedReluGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(ThresholdedReluGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class TopKV2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("top_k_v2_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Indices", this->Output("Indices"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("K")) {
      grad_op->SetInput("K", this->Input("K"));
    }
  }
};


class TopKV2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(top_k_v2_grad, TopKV2GradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));


class TopKV2CompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto indices = this->GetSingleForwardOutput("Indices");
    auto out_grad = this->GetSingleOutputGrad("Out");

    auto tensor_k = this->GetOptionalSingleForwardInput("K");
    if (tensor_k) {
      PADDLE_THROW(platform::errors::Unimplemented(
          "We don't support dynamic tensor attribute K for top_k_v2_grad composite"
          "for now. "));
    }
    //get attr
    const int k = this->Attr<int>("k");
    const int axis = this->Attr<int>("axis");
    const bool largest = this->Attr<bool>("largest");
    const bool sorted = this->Attr<bool>("sorted");

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing topk_grad composite func";
    prim::topk_grad<prim::DescTensor>(x, indices, out_grad, k, axis, largest, sorted, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class TraceGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("trace_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TraceGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(trace_grad, TraceGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(TraceGradNoNeedBufferVarInferer,
                                    "Input");


template <typename T>
class TriangularSolveGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("triangular_solve_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TriangularSolveGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(triangular_solve_grad, TriangularSolveGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class TrilinearInterpV2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("trilinear_interp_v2_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("OutSize", this->Input("OutSize"));
    grad_op->SetInput("SizeTensor", this->Input("SizeTensor"));
    grad_op->SetInput("Scale", this->Input("Scale"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TrilinearInterpV2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "OutSize" || var_name == "SizeTensor" || var_name == "Scale") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(trilinear_interp_v2_grad, TrilinearInterpV2GradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(TrilinearInterpV2GradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class TruncGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("trunc_grad");

    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class TruncGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(trunc_grad, TruncGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));


template <typename T>
class UnbindGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("stack");

    grad_op->SetInput("X", this->OutputGrad("Out"));

    grad_op->SetOutput("Y", this->InputGrad("X"));


    grad_op->SetAttr("axis", this->GetAttr("axis"));
  }
};


template <typename T>
class UnfoldGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("unfold_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Y"), this->OutputGrad("Y"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class UnfoldGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Y"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(unfold_grad, UnfoldGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(UnfoldGradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class UniformRandomInplaceGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("uniform_random_inplace_grad");

    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class UniformRandomInplaceGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(uniform_random_inplace_grad, UniformRandomInplaceGradInferShapeFunctor,
                            PD_INFER_META(phi::UniformRandomInplaceGradInferMeta));
DECLARE_INPLACE_OP_INFERER(UniformRandomInplaceGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class Unpool3dGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("unpool3d_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Indices", this->Input("Indices"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Unpool3dGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(unpool3d_grad, Unpool3dGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class Unsqueeze2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("unsqueeze2_grad");

    grad_op->SetInput("XShape", this->Output("XShape"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("AxesTensor")) {
      grad_op->SetInput("AxesTensor", this->Input("AxesTensor"));
    }
    if (this->HasInput("AxesTensorList")) {
      grad_op->SetInput("AxesTensorList", this->Input("AxesTensorList"));
    }
  }
};


class Unsqueeze2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(unsqueeze2_grad, Unsqueeze2GradInferShapeFunctor,
                            PD_INFER_META(phi::KernelWithXShapeInferMeta));
DECLARE_INPLACE_OP_INFERER(Unsqueeze2GradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


template <typename T>
class Unsqueeze2DoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("unsqueeze2");

    grad_op->SetInput("X", this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput("Out", this->InputGrad(GradVarName("Out")));
    grad_op->SetOutput("XShape", this->Input("XShape"));

    if (this->HasInput("AxesTensor")) {
      grad_op->SetInput("AxesTensor", this->Input("AxesTensor"));
    }
    if (this->HasInput("AxesTensorList")) {
      grad_op->SetInput("AxesTensorList", this->Input("AxesTensorList"));
    }

    grad_op->SetAttr("axes", this->GetAttr("axes"));
  }
};


template <typename T>
class UnstackGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("unstack_grad");

    grad_op->SetInput(GradVarName("Y"), this->OutputGrad("Y"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class UnstackGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(unstack_grad, UnstackGradInferShapeFunctor,
                            PD_INFER_META(phi::UnStackGradInferMeta));



template <typename T>
class ViewDtypeGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("view_dtype_grad");

    grad_op->SetInput("input", this->Input("input"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("input"), this->InputGrad("input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class ViewDtypeGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(view_dtype_grad, ViewDtypeGradInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));



template <typename T>
class ViewShapeGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("view_shape_grad");

    grad_op->SetInput("input", this->Input("input"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("input"), this->InputGrad("input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class ViewShapeGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(view_shape_grad, ViewShapeGradInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));



template <typename T>
class WarpctcGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("warpctc_grad");

    grad_op->SetInput("Logits", this->Input("Logits"));
    grad_op->SetInput("LogitsLength", this->Input("LogitsLength"));
    grad_op->SetInput("WarpCTCGrad", this->Output("WarpCTCGrad"));
    grad_op->SetInput(GradVarName("Loss"), this->OutputGrad("Loss"));

    grad_op->SetOutput(GradVarName("Logits"), this->InputGrad("Logits"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class WarpctcGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Loss"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(warpctc_grad, WarpctcGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(WarpctcGradNoNeedBufferVarInferer,
                                    "Logits");


template <typename T>
class WarprnntGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("warprnnt_grad");

    grad_op->SetInput("input", this->Input("input"));
    grad_op->SetInput("input_lengths", this->Input("input_lengths"));
    grad_op->SetInput("warprnntgrad", this->Output("warprnntgrad"));
    grad_op->SetInput(GradVarName("loss"), this->OutputGrad("loss"));

    grad_op->SetOutput(GradVarName("input"), this->InputGrad("input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class WarprnntGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(warprnnt_grad, WarprnntGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(WarprnntGradNoNeedBufferVarInferer,
                                    "input");


template <typename T>
class WhereGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("where_grad");

    grad_op->SetInput("Condition", this->Input("Condition"));
    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class WhereGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(where_grad, WhereGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(WhereGradNoNeedBufferVarInferer,
                                    "X", "Y");


template <typename T>
class Yolov3LossGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("yolov3_loss_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("GTBox", this->Input("GTBox"));
    grad_op->SetInput("GTLabel", this->Input("GTLabel"));
    grad_op->SetInput("GTScore", this->Input("GTScore"));
    grad_op->SetInput("ObjectnessMask", this->Output("ObjectnessMask"));
    grad_op->SetInput("GTMatchMask", this->Output("GTMatchMask"));
    grad_op->SetInput(GradVarName("Loss"), this->OutputGrad("Loss"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("GTBox"), this->InputGrad("GTBox"));
    grad_op->SetOutput(GradVarName("GTLabel"), this->InputGrad("GTLabel"));
    grad_op->SetOutput(GradVarName("GTScore"), this->InputGrad("GTScore"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Yolov3LossGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetYoloLossExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(yolov3_loss_grad, Yolov3LossGradInferShapeFunctor,
                            PD_INFER_META(phi::YoloLossGradInferMeta));


}  // namespace operators
}  // namespace paddle

namespace ops = paddle::operators;
REGISTER_OPERATOR(rmsprop, ops::RmspropOp,
                  ops::RmspropOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::RmspropInferShapeFunctor);


REGISTER_OPERATOR(roi_align, ops::RoiAlignOp,
                  ops::RoiAlignOpMaker,
                  ops::RoiAlignGradOpMaker<paddle::framework::OpDesc>,
                  ops::RoiAlignGradOpMaker<paddle::imperative::OpBase>,
                  ops::RoiAlignInferShapeFunctor);

REGISTER_OP_VERSION(roi_align)
  .AddCheckpoint(
    R"ROC(Incompatible upgrade of input [RpnRoisLod]))ROC",
      paddle::framework::compatible::OpVersionDesc()
        .DeleteInput("RpnRoisLod", "Delete RpnRoisLod due to incorrect input name and it is not used in object detection models yet"))
  .AddCheckpoint(
    R"ROC(Upgrade roi_pool add a new input [RoisNum])ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewInput("RoisNum", "The number of RoIs in each image. RoisNum is dispensable"))
  .AddCheckpoint(
    R"ROC(Upgrade roi_align add a new input [aligned])ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("aligned", "If true, pixel shift it by -0.5 for align more perfectly.", false))
;

REGISTER_OPERATOR(roi_pool, ops::RoiPoolOp,
                  ops::RoiPoolOpMaker,
                  ops::RoiPoolGradOpMaker<paddle::framework::OpDesc>,
                  ops::RoiPoolGradOpMaker<paddle::imperative::OpBase>,
                  ops::RoiPoolInferShapeFunctor);

REGISTER_OP_VERSION(roi_pool)
  .AddCheckpoint(
    R"ROC(Incompatible upgrade of input [RpnRoisLod])ROC",
      paddle::framework::compatible::OpVersionDesc()
        .DeleteInput("RpnRoisLod", "Delete RpnRoisLod due to incorrect input name and it is not used in object detection models yet."))
  .AddCheckpoint(
    R"ROC(Upgrade roi_pool add a new input [RoisNum])ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewInput("RoisNum", "The number of RoIs in each image. RoisNum is dispensable"))
;

REGISTER_OPERATOR(roll, ops::RollOp,
                  ops::RollOpMaker,
                  ops::RollGradOpMaker<paddle::framework::OpDesc>,
                  ops::RollGradOpMaker<paddle::imperative::OpBase>,
                  ops::RollCompositeGradOpMaker,
                  ops::RollInferShapeFunctor);

REGISTER_OP_VERSION(roll)
  .AddCheckpoint(
    R"ROC(Upgrade roll add 1 attribute [axis], delete 1 attribute[dims].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("axis", "Axis along which to roll. It must have the same size with shifts, or size = 0.", std::vector<float>())
        .DeleteAttr("dims", "Dims along which to roll. It must have the same size with shifts, or size = 0"))
  .AddCheckpoint(
    R"ROC(Upgrade roll add a dispensable input "ShiftsTensor")ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewInput("ShiftsTensor", "The number of places by which the elements of the tensor are shifted."))
;

REGISTER_OPERATOR(round, ops::RoundOp,
                  ops::RoundOpMaker,
                  ops::RoundGradOpMaker<paddle::framework::OpDesc>,
                  ops::RoundGradOpMaker<paddle::imperative::OpBase>,
                  ops::RoundInplaceInferer,
                  ops::RoundInferShapeFunctor);


REGISTER_OPERATOR(rsqrt, ops::RsqrtOp,
                  ops::RsqrtOpMaker,
                  ops::RsqrtGradOpMaker<paddle::framework::OpDesc>,
                  ops::RsqrtGradOpMaker<paddle::imperative::OpBase>,
                  ops::RsqrtInplaceInferer,
                  ops::RsqrtInferShapeFunctor);


REGISTER_OPERATOR(scale, ops::ScaleOp,
                  ops::ScaleOpMaker,
                  ops::ScaleGradOpMaker<paddle::framework::OpDesc>,
                  ops::ScaleGradOpMaker<paddle::imperative::OpBase>,
                  ops::ScaleInplaceInferer,
                  ops::ScaleInferShapeFunctor);


REGISTER_OPERATOR(scatter, ops::ScatterOp,
                  ops::ScatterOpMaker,
                  ops::ScatterGradOpMaker<paddle::framework::OpDesc>,
                  ops::ScatterGradOpMaker<paddle::imperative::OpBase>,
                  ops::ScatterInplaceInferer,
                  ops::ScatterCompositeGradOpMaker,
                  ops::ScatterInferShapeFunctor);


REGISTER_OPERATOR(scatter_nd_add, ops::ScatterNdAddOp,
                  ops::ScatterNdAddOpMaker,
                  ops::ScatterNdAddGradOpMaker<paddle::framework::OpDesc>,
                  ops::ScatterNdAddGradOpMaker<paddle::imperative::OpBase>,
                  ops::ScatterNdAddCompositeGradOpMaker,
                  ops::ScatterNdAddInferShapeFunctor);


REGISTER_OPERATOR(searchsorted, ops::SearchsortedOp,
                  ops::SearchsortedOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::SearchsortedInferShapeFunctor);


REGISTER_OPERATOR(segment_pool, ops::SegmentPoolOp,
                  ops::SegmentPoolOpMaker,
                  ops::SegmentPoolGradOpMaker<paddle::framework::OpDesc>,
                  ops::SegmentPoolGradOpMaker<paddle::imperative::OpBase>,
                  ops::SegmentPoolInferShapeFunctor);


REGISTER_OPERATOR(selu, ops::SeluOp,
                  ops::SeluOpMaker,
                  ops::SeluGradOpMaker<paddle::framework::OpDesc>,
                  ops::SeluGradOpMaker<paddle::imperative::OpBase>,
                  ops::SeluInferShapeFunctor);


REGISTER_OPERATOR(graph_send_recv, ops::GraphSendRecvOp,
                  ops::GraphSendRecvOpMaker,
                  ops::GraphSendRecvGradOpMaker<paddle::framework::OpDesc>,
                  ops::GraphSendRecvGradOpMaker<paddle::imperative::OpBase>,
                  ops::GraphSendRecvInferShapeFunctor);


REGISTER_OPERATOR(graph_send_ue_recv, ops::GraphSendUeRecvOp,
                  ops::GraphSendUeRecvOpMaker,
                  ops::GraphSendUeRecvGradOpMaker<paddle::framework::OpDesc>,
                  ops::GraphSendUeRecvGradOpMaker<paddle::imperative::OpBase>,
                  ops::GraphSendUeRecvInferShapeFunctor);


REGISTER_OPERATOR(graph_send_uv, ops::GraphSendUvOp,
                  ops::GraphSendUvOpMaker,
                  ops::GraphSendUvGradOpMaker<paddle::framework::OpDesc>,
                  ops::GraphSendUvGradOpMaker<paddle::imperative::OpBase>,
                  ops::GraphSendUvInferShapeFunctor);


REGISTER_OPERATOR(sgd, ops::SgdOp,
                  ops::SgdOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::SgdInferShapeFunctor);


REGISTER_OPERATOR(shadow_output, ops::ShadowOutputOp,
                  ops::ShadowOutputOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ShadowOutputInferShapeFunctor);


REGISTER_OPERATOR(shape, ops::ShapeOp,
                  ops::ShapeOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ShapeInferShapeFunctor);


REGISTER_OPERATOR(shard_index, ops::ShardIndexOp,
                  ops::ShardIndexOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ShardIndexInferShapeFunctor);


REGISTER_OPERATOR(sigmoid, ops::SigmoidOp,
                  ops::SigmoidOpMaker,
                  ops::SigmoidGradOpMaker<paddle::framework::OpDesc>,
                  ops::SigmoidGradOpMaker<paddle::imperative::OpBase>,
                  ops::SigmoidInplaceInferer,
                  ops::SigmoidCompositeGradOpMaker,
                  ops::SigmoidInferShapeFunctor);


REGISTER_OPERATOR(sigmoid_cross_entropy_with_logits, ops::SigmoidCrossEntropyWithLogitsOp,
                  ops::SigmoidCrossEntropyWithLogitsOpMaker,
                  ops::SigmoidCrossEntropyWithLogitsGradOpMaker<paddle::framework::OpDesc>,
                  ops::SigmoidCrossEntropyWithLogitsGradOpMaker<paddle::imperative::OpBase>,
                  ops::SigmoidCrossEntropyWithLogitsInplaceInferer,
                  ops::SigmoidCrossEntropyWithLogitsInferShapeFunctor);


REGISTER_OPERATOR(sign, ops::SignOp,
                  ops::SignOpMaker,
                  ops::SignGradOpMaker<paddle::framework::OpDesc>,
                  ops::SignGradOpMaker<paddle::imperative::OpBase>,
                  ops::SignInferShapeFunctor);


REGISTER_OPERATOR(silu, ops::SiluOp,
                  ops::SiluOpMaker,
                  ops::SiluGradOpMaker<paddle::framework::OpDesc>,
                  ops::SiluGradOpMaker<paddle::imperative::OpBase>,
                  ops::SiluCompositeGradOpMaker,
                  ops::SiluInferShapeFunctor);


REGISTER_OPERATOR(sin, ops::SinOp,
                  ops::SinOpMaker,
                  ops::SinGradOpMaker<paddle::framework::OpDesc>,
                  ops::SinGradOpMaker<paddle::imperative::OpBase>,
                  ops::SinInplaceInferer,
                  ops::SinCompositeGradOpMaker,
                  ops::SinInferShapeFunctor);


REGISTER_OPERATOR(sinh, ops::SinhOp,
                  ops::SinhOpMaker,
                  ops::SinhGradOpMaker<paddle::framework::OpDesc>,
                  ops::SinhGradOpMaker<paddle::imperative::OpBase>,
                  ops::SinhInplaceInferer,
                  ops::SinhInferShapeFunctor);


REGISTER_OPERATOR(slogdeterminant, ops::SlogdeterminantOp,
                  ops::SlogdeterminantOpMaker,
                  ops::SlogdeterminantGradOpMaker<paddle::framework::OpDesc>,
                  ops::SlogdeterminantGradOpMaker<paddle::imperative::OpBase>,
                  ops::SlogdeterminantInferShapeFunctor);


REGISTER_OPERATOR(softplus, ops::SoftplusOp,
                  ops::SoftplusOpMaker,
                  ops::SoftplusGradOpMaker<paddle::framework::OpDesc>,
                  ops::SoftplusGradOpMaker<paddle::imperative::OpBase>,
                  ops::SoftplusInferShapeFunctor);


REGISTER_OPERATOR(softshrink, ops::SoftshrinkOp,
                  ops::SoftshrinkOpMaker,
                  ops::SoftshrinkGradOpMaker<paddle::framework::OpDesc>,
                  ops::SoftshrinkGradOpMaker<paddle::imperative::OpBase>,
                  ops::SoftshrinkInferShapeFunctor);


REGISTER_OPERATOR(softsign, ops::SoftsignOp,
                  ops::SoftsignOpMaker,
                  ops::SoftsignGradOpMaker<paddle::framework::OpDesc>,
                  ops::SoftsignGradOpMaker<paddle::imperative::OpBase>,
                  ops::SoftsignInferShapeFunctor);


REGISTER_OPERATOR(solve, ops::SolveOp,
                  ops::SolveOpMaker,
                  ops::SolveGradOpMaker<paddle::framework::OpDesc>,
                  ops::SolveGradOpMaker<paddle::imperative::OpBase>,
                  ops::SolveInferShapeFunctor);


REGISTER_OPERATOR(spectral_norm, ops::SpectralNormOp,
                  ops::SpectralNormOpMaker,
                  ops::SpectralNormGradOpMaker<paddle::framework::OpDesc>,
                  ops::SpectralNormGradOpMaker<paddle::imperative::OpBase>,
                  ops::SpectralNormInferShapeFunctor);


REGISTER_OPERATOR(sqrt, ops::SqrtOp,
                  ops::SqrtOpMaker,
                  ops::SqrtGradOpMaker<paddle::framework::OpDesc>,
                  ops::SqrtGradOpMaker<paddle::imperative::OpBase>,
                  ops::SqrtInplaceInferer,
                  ops::SqrtCompositeGradOpMaker,
                  ops::SqrtInferShapeFunctor);


REGISTER_OPERATOR(square, ops::SquareOp,
                  ops::SquareOpMaker,
                  ops::SquareGradOpMaker<paddle::framework::OpDesc>,
                  ops::SquareGradOpMaker<paddle::imperative::OpBase>,
                  ops::SquareInferShapeFunctor);


REGISTER_OPERATOR(squared_l2_norm, ops::SquaredL2NormOp,
                  ops::SquaredL2NormOpMaker,
                  ops::SquaredL2NormGradOpMaker<paddle::framework::OpDesc>,
                  ops::SquaredL2NormGradOpMaker<paddle::imperative::OpBase>,
                  ops::SquaredL2NormInferShapeFunctor);


REGISTER_OPERATOR(squeeze2, ops::Squeeze2Op,
                  ops::Squeeze2OpMaker,
                  ops::Squeeze2GradOpMaker<paddle::framework::OpDesc>,
                  ops::Squeeze2GradOpMaker<paddle::imperative::OpBase>,
                  ops::Squeeze2InplaceInferer,
                  ops::Squeeze2InferShapeFunctor);


REGISTER_OPERATOR(stack, ops::StackOp,
                  ops::StackOpMaker,
                  ops::StackGradOpMaker<paddle::framework::OpDesc>,
                  ops::StackGradOpMaker<paddle::imperative::OpBase>,
                  ops::StackInferShapeFunctor);


REGISTER_OPERATOR(stanh, ops::StanhOp,
                  ops::StanhOpMaker,
                  ops::StanhGradOpMaker<paddle::framework::OpDesc>,
                  ops::StanhGradOpMaker<paddle::imperative::OpBase>,
                  ops::StanhInferShapeFunctor);


REGISTER_OPERATOR(svd, ops::SvdOp,
                  ops::SvdOpMaker,
                  ops::SvdGradOpMaker<paddle::framework::OpDesc>,
                  ops::SvdGradOpMaker<paddle::imperative::OpBase>,
                  ops::SvdInferShapeFunctor);


REGISTER_OPERATOR(take_along_axis, ops::TakeAlongAxisOp,
                  ops::TakeAlongAxisOpMaker,
                  ops::TakeAlongAxisGradOpMaker<paddle::framework::OpDesc>,
                  ops::TakeAlongAxisGradOpMaker<paddle::imperative::OpBase>,
                  ops::TakeAlongAxisInferShapeFunctor);


REGISTER_OPERATOR(tan, ops::TanOp,
                  ops::TanOpMaker,
                  ops::TanGradOpMaker<paddle::framework::OpDesc>,
                  ops::TanGradOpMaker<paddle::imperative::OpBase>,
                  ops::TanInplaceInferer,
                  ops::TanInferShapeFunctor);


REGISTER_OPERATOR(tanh, ops::TanhOp,
                  ops::TanhOpMaker,
                  ops::TanhGradOpMaker<paddle::framework::OpDesc>,
                  ops::TanhGradOpMaker<paddle::imperative::OpBase>,
                  ops::TanhInplaceInferer,
                  ops::TanhCompositeGradOpMaker,
                  ops::TanhInferShapeFunctor);


REGISTER_OPERATOR(tanh_shrink, ops::TanhShrinkOp,
                  ops::TanhShrinkOpMaker,
                  ops::TanhShrinkGradOpMaker<paddle::framework::OpDesc>,
                  ops::TanhShrinkGradOpMaker<paddle::imperative::OpBase>,
                  ops::TanhShrinkInferShapeFunctor);


REGISTER_OPERATOR(temporal_shift, ops::TemporalShiftOp,
                  ops::TemporalShiftOpMaker,
                  ops::TemporalShiftGradOpMaker<paddle::framework::OpDesc>,
                  ops::TemporalShiftGradOpMaker<paddle::imperative::OpBase>,
                  ops::TemporalShiftInferShapeFunctor);


REGISTER_OPERATOR(tensor_unfold, ops::TensorUnfoldOp,
                  ops::TensorUnfoldOpMaker,
                  ops::TensorUnfoldGradOpMaker<paddle::framework::OpDesc>,
                  ops::TensorUnfoldGradOpMaker<paddle::imperative::OpBase>,
                  ops::TensorUnfoldNoNeedBufferVarInferer,
                  ops::TensorUnfoldInferShapeFunctor);


REGISTER_OPERATOR(thresholded_relu, ops::ThresholdedReluOp,
                  ops::ThresholdedReluOpMaker,
                  ops::ThresholdedReluGradOpMaker<paddle::framework::OpDesc>,
                  ops::ThresholdedReluGradOpMaker<paddle::imperative::OpBase>,
                  ops::ThresholdedReluInplaceInferer,
                  ops::ThresholdedReluInferShapeFunctor);


REGISTER_OPERATOR(top_k_v2, ops::TopKV2Op,
                  ops::TopKV2OpMaker,
                  ops::TopKV2GradOpMaker<paddle::framework::OpDesc>,
                  ops::TopKV2GradOpMaker<paddle::imperative::OpBase>,
                  ops::TopKV2CompositeGradOpMaker,
                  ops::TopKV2InferShapeFunctor);


REGISTER_OPERATOR(trace, ops::TraceOp,
                  ops::TraceOpMaker,
                  ops::TraceGradOpMaker<paddle::framework::OpDesc>,
                  ops::TraceGradOpMaker<paddle::imperative::OpBase>,
                  ops::TraceInferShapeFunctor);

REGISTER_OP_VERSION(trace)
  .AddCheckpoint(
    R"ROC(Upgrade trace add a new attribute [axis2])ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("axis1", "The added attribute 'axis1' is not yet registered.", std::vector<float>{0.0f})
        .NewAttr("axis2", "The added attribute 'axis2' is not yet registered.", std::vector<float>{1.0f})
        .DeleteAttr("dim1", "The attribute 'dim1' is not recommend according to the specification 2.0.")
        .DeleteAttr("dim2", "The attribute 'dim2' is not recommend according to the specification 2.0."))
;

REGISTER_OPERATOR(triangular_solve, ops::TriangularSolveOp,
                  ops::TriangularSolveOpMaker,
                  ops::TriangularSolveGradOpMaker<paddle::framework::OpDesc>,
                  ops::TriangularSolveGradOpMaker<paddle::imperative::OpBase>,
                  ops::TriangularSolveInferShapeFunctor);


REGISTER_OPERATOR(trilinear_interp_v2, ops::TrilinearInterpV2Op,
                  ops::TrilinearInterpV2OpMaker,
                  ops::TrilinearInterpV2GradOpMaker<paddle::framework::OpDesc>,
                  ops::TrilinearInterpV2GradOpMaker<paddle::imperative::OpBase>,
                  ops::TrilinearInterpV2InferShapeFunctor);


REGISTER_OPERATOR(trunc, ops::TruncOp,
                  ops::TruncOpMaker,
                  ops::TruncGradOpMaker<paddle::framework::OpDesc>,
                  ops::TruncGradOpMaker<paddle::imperative::OpBase>,
                  ops::TruncInplaceInferer,
                  ops::TruncInferShapeFunctor);


REGISTER_OPERATOR(unbind, ops::UnbindOp,
                  ops::UnbindOpMaker,
                  ops::UnbindGradOpMaker<paddle::framework::OpDesc>,
                  ops::UnbindGradOpMaker<paddle::imperative::OpBase>,
                  ops::UnbindInferShapeFunctor);


REGISTER_OPERATOR(unfold, ops::UnfoldOp,
                  ops::UnfoldOpMaker,
                  ops::UnfoldGradOpMaker<paddle::framework::OpDesc>,
                  ops::UnfoldGradOpMaker<paddle::imperative::OpBase>,
                  ops::UnfoldInferShapeFunctor);


REGISTER_OPERATOR(uniform_random_inplace, ops::UniformRandomInplaceOp,
                  ops::UniformRandomInplaceOpMaker,
                  ops::UniformRandomInplaceGradOpMaker<paddle::framework::OpDesc>,
                  ops::UniformRandomInplaceGradOpMaker<paddle::imperative::OpBase>,
                  ops::UniformRandomInplaceInplaceInferer,
                  ops::UniformRandomInplaceInferShapeFunctor);


REGISTER_OPERATOR(unique_consecutive, ops::UniqueConsecutiveOp,
                  ops::UniqueConsecutiveOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::UniqueConsecutiveInferShapeFunctor);

REGISTER_OP_VERSION(unique_consecutive)
  .AddCheckpoint(
    R"ROC(Upgrade unique_consecutive, add 2 outputs [Indices, Counts] and 3 attribute [return_inverse, return_counts, axis].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewOutput("Counts", "The counts for each unique element.")
        .NewAttr("return_inverse", "If True, also return the indices for where elements in the original input ended up in the returned unique tensor.", false)
        .NewAttr("return_counts", "If True, also return the counts for each unique element.", false)
        .NewAttr("axis", "The axis to apply unique. If None, the input will be flattened.", std::vector<int>{}))
;

REGISTER_OPERATOR(unpool3d, ops::Unpool3dOp,
                  ops::Unpool3dOpMaker,
                  ops::Unpool3dGradOpMaker<paddle::framework::OpDesc>,
                  ops::Unpool3dGradOpMaker<paddle::imperative::OpBase>,
                  ops::Unpool3dInferShapeFunctor);


REGISTER_OPERATOR(unsqueeze2, ops::Unsqueeze2Op,
                  ops::Unsqueeze2OpMaker,
                  ops::Unsqueeze2GradOpMaker<paddle::framework::OpDesc>,
                  ops::Unsqueeze2GradOpMaker<paddle::imperative::OpBase>,
                  ops::Unsqueeze2InplaceInferer,
                  ops::Unsqueeze2InferShapeFunctor);


REGISTER_OPERATOR(unstack, ops::UnstackOp,
                  ops::UnstackOpMaker,
                  ops::UnstackGradOpMaker<paddle::framework::OpDesc>,
                  ops::UnstackGradOpMaker<paddle::imperative::OpBase>,
                  ops::UnstackInferShapeFunctor);


REGISTER_OPERATOR(update_loss_scaling, ops::UpdateLossScalingOp,
                  ops::UpdateLossScalingOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::UpdateLossScalingInferShapeFunctor);


REGISTER_OPERATOR(variable_length_memory_efficient_attention, ops::VariableLengthMemoryEfficientAttentionOp,
                  ops::VariableLengthMemoryEfficientAttentionOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::VariableLengthMemoryEfficientAttentionInferShapeFunctor);


REGISTER_OPERATOR(view_dtype, ops::ViewDtypeOp,
                  ops::ViewDtypeOpMaker,
                  ops::ViewDtypeGradOpMaker<paddle::framework::OpDesc>,
                  ops::ViewDtypeGradOpMaker<paddle::imperative::OpBase>,
                  ops::ViewDtypeNoNeedBufferVarInferer,
                  ops::ViewDtypeInferShapeFunctor);


REGISTER_OPERATOR(view_shape, ops::ViewShapeOp,
                  ops::ViewShapeOpMaker,
                  ops::ViewShapeGradOpMaker<paddle::framework::OpDesc>,
                  ops::ViewShapeGradOpMaker<paddle::imperative::OpBase>,
                  ops::ViewShapeNoNeedBufferVarInferer,
                  ops::ViewShapeInferShapeFunctor);


REGISTER_OPERATOR(viterbi_decode, ops::ViterbiDecodeOp,
                  ops::ViterbiDecodeOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ViterbiDecodeInferShapeFunctor);


REGISTER_OPERATOR(warpctc, ops::WarpctcOp,
                  ops::WarpctcOpMaker,
                  ops::WarpctcGradOpMaker<paddle::framework::OpDesc>,
                  ops::WarpctcGradOpMaker<paddle::imperative::OpBase>,
                  ops::WarpctcInferShapeFunctor);


REGISTER_OPERATOR(warprnnt, ops::WarprnntOp,
                  ops::WarprnntOpMaker,
                  ops::WarprnntGradOpMaker<paddle::framework::OpDesc>,
                  ops::WarprnntGradOpMaker<paddle::imperative::OpBase>,
                  ops::WarprnntInferShapeFunctor);


REGISTER_OPERATOR(weight_only_matmul, ops::WeightOnlyMatmulOp,
                  ops::WeightOnlyMatmulOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::WeightOnlyMatmulInferShapeFunctor);


REGISTER_OPERATOR(weighted_sample_neighbors, ops::WeightedSampleNeighborsOp,
                  ops::WeightedSampleNeighborsOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::WeightedSampleNeighborsInferShapeFunctor);


REGISTER_OPERATOR(where, ops::WhereOp,
                  ops::WhereOpMaker,
                  ops::WhereGradOpMaker<paddle::framework::OpDesc>,
                  ops::WhereGradOpMaker<paddle::imperative::OpBase>,
                  ops::WhereInferShapeFunctor);


REGISTER_OPERATOR(yolo_box, ops::YoloBoxOp,
                  ops::YoloBoxOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::YoloBoxInferShapeFunctor);

REGISTER_OP_VERSION(yolo_box)
  .AddCheckpoint(
    R"ROC(Upgrade yolo box to add new attribute [iou_aware, iou_aware_factor].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("iou_aware", "Whether use iou aware.", false)
        .NewAttr("iou_aware_factor", "iou aware factor.", 0.5f))
;

REGISTER_OPERATOR(yolov3_loss, ops::Yolov3LossOp,
                  ops::Yolov3LossOpMaker,
                  ops::Yolov3LossGradOpMaker<paddle::framework::OpDesc>,
                  ops::Yolov3LossGradOpMaker<paddle::imperative::OpBase>,
                  ops::Yolov3LossInferShapeFunctor);


REGISTER_OPERATOR(roi_align_grad, ops::RoiAlignGradOp,
                  ops::RoiAlignGradNoNeedBufferVarInferer,
                  ops::RoiAlignGradInferShapeFunctor);


REGISTER_OPERATOR(roi_pool_grad, ops::RoiPoolGradOp,
                  ops::RoiPoolGradInferShapeFunctor);


REGISTER_OPERATOR(roll_grad, ops::RollGradOp,
                  ops::RollGradNoNeedBufferVarInferer,
                  ops::RollGradInferShapeFunctor);


REGISTER_OPERATOR(round_grad, ops::RoundGradOp,
                  ops::RoundGradInplaceInferer,
                  ops::RoundGradInferShapeFunctor);


REGISTER_OPERATOR(rsqrt_grad, ops::RsqrtGradOp,
                  ops::RsqrtGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::RsqrtGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::RsqrtGradInplaceInferer,
                  ops::RsqrtGradInferShapeFunctor);


REGISTER_OPERATOR(rsqrt_grad_grad, ops::RsqrtGradGradOp,
                  ops::RsqrtGradGradInplaceInferer,
                  ops::RsqrtGradGradInferShapeFunctor);


REGISTER_OPERATOR(scatter_grad, ops::ScatterGradOp,
                  ops::ScatterGradNoNeedBufferVarInferer,
                  ops::ScatterGradInferShapeFunctor);


REGISTER_OPERATOR(scatter_nd_add_grad, ops::ScatterNdAddGradOp,
                  ops::ScatterNdAddGradNoNeedBufferVarInferer,
                  ops::ScatterNdAddGradInferShapeFunctor);


REGISTER_OPERATOR(segment_pool_grad, ops::SegmentPoolGradOp,
                  ops::SegmentPoolGradInferShapeFunctor);


REGISTER_OPERATOR(selu_grad, ops::SeluGradOp,
                  ops::SeluGradInferShapeFunctor);


REGISTER_OPERATOR(graph_send_recv_grad, ops::GraphSendRecvGradOp,
                  ops::GraphSendRecvGradInferShapeFunctor);


REGISTER_OPERATOR(graph_send_ue_recv_grad, ops::GraphSendUeRecvGradOp,
                  ops::GraphSendUeRecvGradInferShapeFunctor);


REGISTER_OPERATOR(graph_send_uv_grad, ops::GraphSendUvGradOp,
                  ops::GraphSendUvGradInferShapeFunctor);


REGISTER_OPERATOR(sigmoid_grad, ops::SigmoidGradOp,
                  ops::SigmoidGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::SigmoidGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::SigmoidGradInplaceInferer,
                  ops::SigmoidGradInferShapeFunctor);


REGISTER_OPERATOR(sigmoid_grad_grad, ops::SigmoidGradGradOp,
                  ops::SigmoidTripleGradOpMaker<paddle::framework::OpDesc>,
                  ops::SigmoidTripleGradOpMaker<paddle::imperative::OpBase>,
                  ops::SigmoidGradGradInplaceInferer,
                  ops::SigmoidGradGradInferShapeFunctor);


REGISTER_OPERATOR(sigmoid_triple_grad, ops::SigmoidTripleGradOp,
                  ops::SigmoidTripleGradInplaceInferer,
                  ops::SigmoidTripleGradInferShapeFunctor);


REGISTER_OPERATOR(sigmoid_cross_entropy_with_logits_grad, ops::SigmoidCrossEntropyWithLogitsGradOp,
                  ops::SigmoidCrossEntropyWithLogitsGradInplaceInferer,
                  ops::SigmoidCrossEntropyWithLogitsGradInferShapeFunctor);


REGISTER_OPERATOR(silu_grad, ops::SiluGradOp,
                  ops::SiluGradInplaceInferer,
                  ops::SiluDoubleCompositeGradOpMaker,
                  ops::SiluGradInferShapeFunctor);


REGISTER_OPERATOR(sin_grad, ops::SinGradOp,
                  ops::SinDoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::SinDoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::SinGradInplaceInferer,
                  ops::SinGradInferShapeFunctor);


REGISTER_OPERATOR(sin_double_grad, ops::SinDoubleGradOp,
                  ops::SinTripleGradOpMaker<paddle::framework::OpDesc>,
                  ops::SinTripleGradOpMaker<paddle::imperative::OpBase>,
                  ops::SinDoubleGradInplaceInferer,
                  ops::SinDoubleGradInferShapeFunctor);


REGISTER_OPERATOR(sin_triple_grad, ops::SinTripleGradOp,
                  ops::SinTripleGradInplaceInferer,
                  ops::SinTripleGradInferShapeFunctor);


REGISTER_OPERATOR(sinh_grad, ops::SinhGradOp,
                  ops::SinhGradInplaceInferer,
                  ops::SinhGradInferShapeFunctor);


REGISTER_OPERATOR(slogdeterminant_grad, ops::SlogdeterminantGradOp,
                  ops::SlogdeterminantGradInferShapeFunctor);


REGISTER_OPERATOR(softplus_grad, ops::SoftplusGradOp,
                  ops::SoftplusDoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::SoftplusDoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::SoftplusGradInplaceInferer,
                  ops::SoftplusGradInferShapeFunctor);


REGISTER_OPERATOR(softplus_double_grad, ops::SoftplusDoubleGradOp,
                  ops::SoftplusDoubleGradInplaceInferer,
                  ops::SoftplusDoubleGradInferShapeFunctor);


REGISTER_OPERATOR(softshrink_grad, ops::SoftshrinkGradOp,
                  ops::SoftshrinkGradInplaceInferer,
                  ops::SoftshrinkGradInferShapeFunctor);


REGISTER_OPERATOR(softsign_grad, ops::SoftsignGradOp,
                  ops::SoftsignGradInplaceInferer,
                  ops::SoftsignGradInferShapeFunctor);


REGISTER_OPERATOR(solve_grad, ops::SolveGradOp,
                  ops::SolveGradInferShapeFunctor);


REGISTER_OPERATOR(spectral_norm_grad, ops::SpectralNormGradOp,
                  ops::SpectralNormGradInferShapeFunctor);


REGISTER_OPERATOR(sqrt_grad, ops::SqrtGradOp,
                  ops::SqrtGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::SqrtGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::SqrtGradInplaceInferer,
                  ops::SqrtGradInferShapeFunctor);


REGISTER_OPERATOR(sqrt_grad_grad, ops::SqrtGradGradOp,
                  ops::SqrtGradGradInplaceInferer,
                  ops::SqrtGradGradInferShapeFunctor);


REGISTER_OPERATOR(square_grad, ops::SquareGradOp,
                  ops::SquareGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::SquareGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::SquareGradInplaceInferer,
                  ops::SquareGradInferShapeFunctor);


REGISTER_OPERATOR(square_grad_grad, ops::SquareGradGradOp,
                  ops::SquareGradGradInplaceInferer,
                  ops::SquareGradGradInferShapeFunctor);


REGISTER_OPERATOR(squared_l2_norm_grad, ops::SquaredL2NormGradOp,
                  ops::SquaredL2NormGradInferShapeFunctor);


REGISTER_OPERATOR(squeeze2_grad, ops::Squeeze2GradOp,
                  ops::Squeeze2DoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::Squeeze2DoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::Squeeze2GradInplaceInferer,
                  ops::Squeeze2GradInferShapeFunctor);


REGISTER_OPERATOR(stack_grad, ops::StackGradOp,
                  ops::StackGradNoNeedBufferVarInferer,
                  ops::StackGradInferShapeFunctor);


REGISTER_OPERATOR(stanh_grad, ops::StanhGradOp,
                  ops::StanhGradInferShapeFunctor);


REGISTER_OPERATOR(svd_grad, ops::SvdGradOp,
                  ops::SvdGradInferShapeFunctor);


REGISTER_OPERATOR(take_along_axis_grad, ops::TakeAlongAxisGradOp,
                  ops::TakeAlongAxisGradInferShapeFunctor);


REGISTER_OPERATOR(tan_grad, ops::TanGradOp,
                  ops::TanGradInplaceInferer,
                  ops::TanGradInferShapeFunctor);


REGISTER_OPERATOR(tanh_grad, ops::TanhGradOp,
                  ops::TanhGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::TanhGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::TanhGradInplaceInferer,
                  ops::TanhGradCompositeGradOpMaker,
                  ops::TanhGradInferShapeFunctor);


REGISTER_OPERATOR(tanh_grad_grad, ops::TanhGradGradOp,
                  ops::TanhTripleGradOpMaker<paddle::framework::OpDesc>,
                  ops::TanhTripleGradOpMaker<paddle::imperative::OpBase>,
                  ops::TanhGradGradInplaceInferer,
                  ops::TanhTripleCompositeGradOpMaker,
                  ops::TanhGradGradInferShapeFunctor);


REGISTER_OPERATOR(tanh_triple_grad, ops::TanhTripleGradOp,
                  ops::TanhTripleGradInplaceInferer,
                  ops::TanhTripleGradInferShapeFunctor);


REGISTER_OPERATOR(tanh_shrink_grad, ops::TanhShrinkGradOp,
                  ops::TanhShrinkGradInplaceInferer,
                  ops::TanhShrinkGradInferShapeFunctor);


REGISTER_OPERATOR(temporal_shift_grad, ops::TemporalShiftGradOp,
                  ops::TemporalShiftGradInferShapeFunctor);


REGISTER_OPERATOR(tensor_unfold_grad, ops::TensorUnfoldGradOp,
                  ops::TensorUnfoldGradInferShapeFunctor);


REGISTER_OPERATOR(thresholded_relu_grad, ops::ThresholdedReluGradOp,
                  ops::ThresholdedReluGradInplaceInferer,
                  ops::ThresholdedReluGradInferShapeFunctor);


REGISTER_OPERATOR(top_k_v2_grad, ops::TopKV2GradOp,
                  ops::TopKV2GradInferShapeFunctor);


REGISTER_OPERATOR(trace_grad, ops::TraceGradOp,
                  ops::TraceGradNoNeedBufferVarInferer,
                  ops::TraceGradInferShapeFunctor);


REGISTER_OPERATOR(triangular_solve_grad, ops::TriangularSolveGradOp,
                  ops::TriangularSolveGradInferShapeFunctor);


REGISTER_OPERATOR(trilinear_interp_v2_grad, ops::TrilinearInterpV2GradOp,
                  ops::TrilinearInterpV2GradNoNeedBufferVarInferer,
                  ops::TrilinearInterpV2GradInferShapeFunctor);


REGISTER_OPERATOR(trunc_grad, ops::TruncGradOp,
                  ops::TruncGradInferShapeFunctor);


REGISTER_OPERATOR(unfold_grad, ops::UnfoldGradOp,
                  ops::UnfoldGradNoNeedBufferVarInferer,
                  ops::UnfoldGradInferShapeFunctor);


REGISTER_OPERATOR(uniform_random_inplace_grad, ops::UniformRandomInplaceGradOp,
                  ops::UniformRandomInplaceGradInplaceInferer,
                  ops::UniformRandomInplaceGradInferShapeFunctor);


REGISTER_OPERATOR(unpool3d_grad, ops::Unpool3dGradOp,
                  ops::Unpool3dGradInferShapeFunctor);


REGISTER_OPERATOR(unsqueeze2_grad, ops::Unsqueeze2GradOp,
                  ops::Unsqueeze2DoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::Unsqueeze2DoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::Unsqueeze2GradInplaceInferer,
                  ops::Unsqueeze2GradInferShapeFunctor);


REGISTER_OPERATOR(unstack_grad, ops::UnstackGradOp,
                  ops::UnstackGradInferShapeFunctor);


REGISTER_OPERATOR(view_dtype_grad, ops::ViewDtypeGradOp,
                  ops::ViewDtypeGradInferShapeFunctor);


REGISTER_OPERATOR(view_shape_grad, ops::ViewShapeGradOp,
                  ops::ViewShapeGradInferShapeFunctor);


REGISTER_OPERATOR(warpctc_grad, ops::WarpctcGradOp,
                  ops::WarpctcGradNoNeedBufferVarInferer,
                  ops::WarpctcGradInferShapeFunctor);


REGISTER_OPERATOR(warprnnt_grad, ops::WarprnntGradOp,
                  ops::WarprnntGradNoNeedBufferVarInferer,
                  ops::WarprnntGradInferShapeFunctor);


REGISTER_OPERATOR(where_grad, ops::WhereGradOp,
                  ops::WhereGradNoNeedBufferVarInferer,
                  ops::WhereGradInferShapeFunctor);


REGISTER_OPERATOR(yolov3_loss_grad, ops::Yolov3LossGradOp,
                  ops::Yolov3LossGradInferShapeFunctor);


