include(operators)

add_subdirectory(math)
add_subdirectory(controlflow)
add_subdirectory(csp)
add_subdirectory(detection)
add_subdirectory(elementwise)
add_subdirectory(fused)
add_subdirectory(metrics)
add_subdirectory(optimizers)
add_subdirectory(reduce_ops)
add_subdirectory(sequence_ops)

if(WITH_DISTRIBUTE)
    add_subdirectory(distributed)
    add_subdirectory(distributed_ops)
endif()

if (NOT WIN32)
    add_subdirectory(reader)
endif()

if (NOT WIN32)
    add_subdirectory(nccl)
endif()

if (WITH_GPU AND TENSORRT_FOUND)
    add_subdirectory(tensorrt)
endif()

register_operators()

set(COMMON_OP_DEPS "")

set(COMMON_OP_DEPS ${COMMON_OP_DEPS} xxhash selected_rows_functor selected_rows lod_tensor maxouting unpooling pooling lod_rank_table context_project sequence_pooling executor dynload_warpctc sequence_padding sequence_scale cos_sim_functor memory jit_kernel concat_and_split cross_entropy softmax vol2col im2col)
if (NOT WIN32)
  set(COMMON_OP_DEPS ${COMMON_OP_DEPS} sequence2batch lstm_compute matrix_bit_code gru_compute)
endif()
if (WITH_GPU)
  set(COMMON_OP_DEPS ${COMMON_OP_DEPS} depthwise_conv cub)
endif()

# FIXME(typhoonzero): operator deps may not needed.
# op_library(lod_tensor_to_array_op DEPS lod_rank_table_op)
# op_library(array_to_lod_tensor_op DEPS lod_rank_table_op)
# op_library(unsqueeze_op DEPS reshape_op)
# op_library(squeeze_op DEPS reshape_op)
# op_library(flatten_op DEPS reshape_op)
# op_library(unstack_op DEPS stack_op)
# op_library(tensor_array_to_tensor_op DEPS concat_op)

set(OPERATOR_DEPS ${OPERATOR_DEPS} ${COMMON_OP_DEPS})
set(GLOB_OPERATOR_DEPS ${OPERATOR_DEPS} CACHE INTERNAL "Global Op dependencies")

cc_test(gather_test SRCS gather_test.cc DEPS tensor)
cc_test(scatter_test SRCS scatter_test.cc DEPS tensor)
cc_test(beam_search_decode_op_test SRCS beam_search_decode_op_test.cc DEPS lod_tensor)
cc_test(beam_search_op_test SRCS beam_search_op_test.cc DEPS lod_tensor beam_search_op)
cc_test(strided_memcpy_test SRCS strided_memcpy_test.cc DEPS tensor memory)
cc_test(save_load_op_test SRCS save_load_op_test.cc DEPS save_op load_op)
cc_test(save_load_combine_op_test SRCS save_load_combine_op_test.cc DEPS save_combine_op load_combine_op)
nv_test(dropout_op_test SRCS dropout_op_test.cc DEPS dropout_op tensor)


set(GLOB_OP_LIB ${OP_LIBRARY} CACHE INTERNAL "Global OP library")
# list(REMOVE_DUPLICATES OPS)
message("all op deps: ${GLOB_OPERATOR_DEPS}")

# file(GLOB GENERAL_OPS RELATIVE "${CMAKE_CURRENT_SOURCE_DIR}" "*_op.cc")
# string(REPLACE "_mkldnn" "" GENERAL_OPS "${GENERAL_OPS}")
# string(REPLACE ".cc" "" GENERAL_OPS "${GENERAL_OPS}")
# list(REMOVE_DUPLICATES GENERAL_OPS)


# set(DEPS_OPS "")
# set(GLOB pybind_file ${PADDLE_BINARY_DIR}/paddle/fluid/pybind/pybind.h)
# file(WRITE ${pybind_file} "// Generated by the paddle/fluid/operator/CMakeLists.txt.  DO NOT EDIT!\n\n")


# if (NOT WIN32)
# add_subdirectory(nccl)
# if(WITH_GPU)
#     op_library(nccl_op DEPS nccl_common)
#     file(APPEND ${pybind_file} "USE_CUDA_ONLY_OP(ncclAllReduce);\n")
# else()
#     set(DEPS_OPS ${DEPS_OPS} nccl_op)
# endif()
# endif() # NOT WIN32

# op_library(cross_entropy_op DEPS cross_entropy)
# if(WITH_GPU)
#   op_library(softmax_with_cross_entropy_op DEPS cross_entropy softmax cub)
#   op_library(sequence_softmax_op DEPS cub)
# else()
#   op_library(softmax_with_cross_entropy_op DEPS cross_entropy softmax)
# endif()

# op_library(softmax_op DEPS softmax)
# if (WITH_GPU AND TENSORRT_FOUND)
#     op_library(tensorrt_engine_op DEPS tensorrt_engine tensorrt_converter)
#     file(APPEND ${pybind_file} "USE_CUDA_ONLY_OP(tensorrt_engine);\n")
#     nv_test(test_tensorrt_engine_op SRCS tensorrt_engine_op_test.cc
#       DEPS tensorrt_engine_op
#       analysis)
# else()
#     set(DEPS_OPS ${DEPS_OPS} tensorrt_engine_op)
# endif()

# op_library(hash_op DEPS xxhash)
# op_library(clip_by_norm_op DEPS selected_rows_functor selected_rows)
# op_library(sum_op DEPS selected_rows_functor)
# op_library(sgd_op DEPS selected_rows_functor)
# op_library(print_op DEPS lod_tensor)
# op_library(adagrad_op DEPS selected_rows_functor)
# op_library(maxout_op DEPS maxouting)
# op_library(unpool_op DEPS unpooling)
# op_library(pool_op DEPS pooling)
# op_library(pool_with_index_op DEPS pooling)
# op_library(lod_rank_table_op DEPS lod_rank_table)
# op_library(lod_tensor_to_array_op DEPS lod_rank_table_op)
# op_library(array_to_lod_tensor_op DEPS lod_rank_table_op)
# op_library(max_sequence_len_op DEPS lod_rank_table)
# op_library(sequence_conv_op DEPS context_project)
# op_library(sequence_pool_op DEPS sequence_pooling)
# if (NOT WIN32)
#     op_library(lstm_op DEPS sequence2batch lstm_compute)
#     op_library(hierarchical_sigmoid_op DEPS matrix_bit_code)
#     op_library(lstmp_op DEPS sequence2batch lstm_compute)
#     op_library(gru_op DEPS sequence2batch gru_compute)
# endif(NOT WIN32)
# op_library(recurrent_op DEPS executor)
# op_library(warpctc_op DEPS dynload_warpctc sequence_padding sequence_scale)
# op_library(cos_sim_op DEPS cos_sim_functor)
# op_library(parallel_do_op DEPS executor)
# op_library(unsqueeze_op DEPS reshape_op)
# op_library(squeeze_op DEPS reshape_op)
# op_library(flatten_op DEPS reshape_op)
# op_library(sequence_pad_op DEPS sequence_padding)
# op_library(unstack_op DEPS stack_op)
# op_library(fake_quantize_op DEPS memory)
# op_library(crf_decoding_op DEPS jit_kernel)
# op_library(fusion_lstm_op DEPS jit_kernel)
# if (WITH_GPU)
#     op_library(conv_op DEPS vol2col depthwise_conv im2col)
#     op_library(layer_norm_op DEPS cub)
#     op_library(reduce_mean_op DEPS cub)
#     op_library(affine_channel_op DEPS cub)
# else()
#     op_library(conv_op DEPS vol2col im2col)
# endif()
# op_library(conv_transpose_op DEPS vol2col im2col)

# # FIXME(typhoonzero): save/load depends lodtensor serialization functions
# op_library(save_op DEPS lod_tensor)
# op_library(load_op DEPS lod_tensor)
# op_library(save_combine_op DEPS lod_tensor)
# op_library(load_combine_op DEPS lod_tensor)
# op_library(tensor_array_to_tensor_op DEPS concat_op)
# op_library(concat_op DEPS concat_and_split)

# list(REMOVE_ITEM GENERAL_OPS ${DEPS_OPS})

# foreach(src ${GENERAL_OPS})
#     op_library(${src})
# endforeach()

# file(APPEND ${pybind_file} "USE_OP(less_than);\nUSE_OP(logical_and);\nUSE_NO_KERNEL_OP(read_from_array);\n")


# if (NOT WIN32)
# add_subdirectory(reader)
# endif(NOT WIN32)
# foreach(src ${READER_LIBRARY})
#     set(OP_LIBRARY ${src} ${OP_LIBRARY})
# endforeach()

# add_subdirectory(detection)
# foreach(src ${DETECTION_LIBRARY})
#     set(OP_LIBRARY ${src} ${OP_LIBRARY})
# endforeach()

# set(GLOB_OP_LIB ${OP_LIBRARY} CACHE INTERNAL "Global OP library")
# set(GLOB_DISTRIBUTE_DEPS ${DISTRIBUTE_DEPS} CACHE INTERNAL "distributed dependency")

# cc_test(gather_test SRCS gather_test.cc DEPS tensor)
# cc_test(scatter_test SRCS scatter_test.cc DEPS tensor)
# cc_test(beam_search_decode_op_test SRCS beam_search_decode_op_test.cc DEPS lod_tensor)
# cc_test(beam_search_op_test SRCS beam_search_op_test.cc DEPS lod_tensor beam_search_op)
# cc_test(strided_memcpy_test SRCS strided_memcpy_test.cc DEPS tensor memory)
# cc_test(save_load_op_test SRCS save_load_op_test.cc DEPS save_op load_op)
# cc_test(save_load_combine_op_test SRCS save_load_combine_op_test.cc DEPS save_combine_op load_combine_op)
# if(NOT WIN32)
#     nv_test(nccl_op_test SRCS nccl_op_test.cu.cc DEPS nccl_op gpu_info device_context)
# endif()
# nv_test(dropout_op_test SRCS dropout_op_test.cc DEPS dropout_op tensor)

# if(WITH_GPU)
#     foreach(CUDA_KERNEL_FILE ${PART_CUDA_KERNEL_FILES})
#         file(READ ${CUDA_KERNEL_FILE} TARGET_CONTENT)
#         string(REGEX MATCH "REGISTER_OP_CUDA_KERNEL\\(\\n?([^,]+),.*" MATCHED ${TARGET_CONTENT})
#         if (MATCHED)
#             string(STRIP ${CMAKE_MATCH_1} MATCHED)
#             file(APPEND ${pybind_file} "USE_OP_DEVICE_KERNEL(${MATCHED}, CUDA);\n")
#         endif()
#     endforeach()
# endif()
