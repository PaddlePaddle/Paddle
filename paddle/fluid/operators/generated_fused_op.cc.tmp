// this file is generated by paddle/phi/api/yaml/generator/generate_op.py, do not edit.
#include <string>
#include "paddle/fluid/framework/convert_utils.h"
#include "paddle/fluid/framework/infershape_utils.h"
#include "paddle/fluid/framework/op_registry.h"
#include "paddle/fluid/framework/op_version_registry.h"
#include "paddle/fluid/prim/api/composite_backward/composite_backward_api.h"
#include "paddle/fluid/prim/utils/static/composite_grad_desc_maker.h"
#include "paddle/fluid/prim/utils/static/desc_tensor.h"
#include "paddle/fluid/operators/generator/get_expected_kernel_func.h"
#include "paddle/phi/core/infermeta_utils.h"
#include "paddle/phi/infermeta/backward.h"
#include "paddle/phi/infermeta/binary.h"
#include "paddle/phi/infermeta/fusion.h"
#include "paddle/phi/infermeta/multiary.h"
#include "paddle/phi/infermeta/nullary.h"
#include "paddle/phi/infermeta/ternary.h"
#include "paddle/phi/infermeta/unary.h"

namespace paddle {
namespace operators {

using paddle::framework::GradVarName;


class AddActXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of add_act_xpu op.");
    AddInput("x_max", "(Tensor), input 1 of add_act_xpu op.")
        .AsDispensable();
    AddInput("y", "(Tensor), input 2 of add_act_xpu op.");
    AddInput("y_max", "(Tensor), input 3 of add_act_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of add_act_xpu op.");
    AddOutput("out_max", "(Tensor), output 1 of add_act_xpu op.");
    AddAttr<int>("act_type", "(int), attribute 0 for add_act_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of add_act_xpu op.
)DOC");
  }
};


class AddActXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(add_act_xpu, AddActXpuInferShapeFunctor,
                            PD_INFER_META(phi::AddActXPUInferMeta));



class AddLayernormXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of add_layernorm_xpu op.");
    AddInput("y", "(Tensor), input 1 of add_layernorm_xpu op.");
    AddInput("scale", "(Tensor), input 2 of add_layernorm_xpu op.");
    AddInput("bias", "(Tensor), input 3 of add_layernorm_xpu op.");
    AddOutput("out", "(Tensor), output 0 of add_layernorm_xpu op.");
    AddOutput("mean", "(Tensor), output 1 of add_layernorm_xpu op.");
    AddOutput("variance", "(Tensor), output 2 of add_layernorm_xpu op.");
    AddOutput("z_add", "(Tensor), output 3 of add_layernorm_xpu op.");
    AddAttr<int>("begin_norm_axis", "(int), attribute 0 for add_layernorm_xpu op.")
    ;
    AddAttr<float>("epsilon", "(float), attribute 1 for add_layernorm_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of add_layernorm_xpu op.
)DOC");
  }
};


class AddLayernormXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(add_layernorm_xpu, AddLayernormXpuInferShapeFunctor,
                            PD_INFER_META(phi::AddLayernormXPUInferMeta));



class Conv1dXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of conv1d_xpu op.");
    AddInput("x_max", "(Tensor), input 1 of conv1d_xpu op.")
        .AsDispensable();
    AddInput("filter", "(Tensor), input 2 of conv1d_xpu op.");
    AddInput("filter_max", "(Tensor), input 3 of conv1d_xpu op.");
    AddInput("bias", "(Tensor), input 4 of conv1d_xpu op.")
        .AsDispensable();
    AddInput("branch", "(Tensor), input 5 of conv1d_xpu op.")
        .AsDispensable();
    AddInput("branch_max", "(Tensor), input 6 of conv1d_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of conv1d_xpu op.");
    AddOutput("out_max", "(Tensor), output 1 of conv1d_xpu op.");
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 0 for conv1d_xpu op.")
    ;
    AddAttr<std::string>("padding_algorithm", "(std::string), attribute 1 for conv1d_xpu op.")
    ;
    AddAttr<int>("dilations", "(int), attribute 2 for conv1d_xpu op.")
    ;
    AddAttr<int>("strides", "(int), attribute 3 for conv1d_xpu op.")
    ;
    AddAttr<int>("groups", "(int), attribute 4 for conv1d_xpu op.")
    ;
    AddAttr<int>("act_type", "(int), attribute 5 for conv1d_xpu op.")
    ;
    AddAttr<float>("act_param", "(float), attribute 6 for conv1d_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of conv1d_xpu op.
)DOC");
  }
};


class Conv1dXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv1d_xpu, Conv1dXpuInferShapeFunctor,
                            PD_INFER_META(phi::Conv1dXPUInferMeta));



class Conv2dTransposeXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of conv2d_transpose_xpu op.");
    AddInput("x_max", "(Tensor), input 1 of conv2d_transpose_xpu op.")
        .AsDispensable();
    AddInput("filter", "(Tensor), input 2 of conv2d_transpose_xpu op.");
    AddInput("filter_max", "(Tensor), input 3 of conv2d_transpose_xpu op.");
    AddInput("bias", "(Tensor), input 4 of conv2d_transpose_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of conv2d_transpose_xpu op.");
    AddOutput("out_max", "(Tensor), output 1 of conv2d_transpose_xpu op.");
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 0 for conv2d_transpose_xpu op.")
    ;
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 1 for conv2d_transpose_xpu op.")
    ;
    AddAttr<std::vector<int>>("output_padding", "(std::vector<int>), attribute 2 for conv2d_transpose_xpu op.")
    ;
    AddInput("OutputSizeTensor", "attribute 3 for conv2d_transpose_xpu op from 1D integer Tensor.")
        .AsDispensable();
    AddInput("OutputSizeTensorList", "attribute 3 for conv2d_transpose_xpu op from list fo 0D integer Tensors.")
        .AsDuplicable()
        .AsDispensable();
      AddAttr<std::vector<int64_t>>("output_size", "(std::vector<int64_t>), attribute 3 for conv2d_transpose_xpu op.")
    ;
    AddAttr<std::string>("padding_algorithm", "(std::string), attribute 4 for conv2d_transpose_xpu op.")
    ;
    AddAttr<int>("groups", "(int), attribute 5 for conv2d_transpose_xpu op.")
    ;
    AddAttr<std::vector<int>>("dilations", "(std::vector<int>), attribute 6 for conv2d_transpose_xpu op.")
    ;
    AddAttr<std::string>("data_format", "(std::string), attribute 7 for conv2d_transpose_xpu op.")
    ;
    AddAttr<bool>("has_bias", "(bool), attribute 8 for conv2d_transpose_xpu op.")
    ;
    AddAttr<bool>("with_act", "(bool), attribute 9 for conv2d_transpose_xpu op.")
    ;
    AddAttr<std::string>("act_type", "(std::string), attribute 10 for conv2d_transpose_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of conv2d_transpose_xpu op.
)DOC");
  }
};


class Conv2dTransposeXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv2d_transpose_xpu, Conv2dTransposeXpuInferShapeFunctor,
                            PD_INFER_META(phi::Conv2dTransposeXPUInferMeta));



class Conv2dXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of conv2d_xpu op.");
    AddInput("x_max", "(Tensor), input 1 of conv2d_xpu op.")
        .AsDispensable();
    AddInput("filter", "(Tensor), input 2 of conv2d_xpu op.");
    AddInput("filter_max", "(Tensor), input 3 of conv2d_xpu op.");
    AddInput("bias", "(Tensor), input 4 of conv2d_xpu op.")
        .AsDispensable();
    AddInput("branch", "(Tensor), input 5 of conv2d_xpu op.")
        .AsDispensable();
    AddInput("branch_max", "(Tensor), input 6 of conv2d_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of conv2d_xpu op.");
    AddOutput("out_max", "(Tensor), output 1 of conv2d_xpu op.");
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 0 for conv2d_xpu op.")
    ;
    AddAttr<std::vector<int>>("dilations", "(std::vector<int>), attribute 1 for conv2d_xpu op.")
    ;
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 2 for conv2d_xpu op.")
    ;
    AddAttr<std::string>("padding_algorithm", "(std::string), attribute 3 for conv2d_xpu op.")
    ;
    AddAttr<int>("groups", "(int), attribute 4 for conv2d_xpu op.")
    ;
    AddAttr<int>("act_type", "(int), attribute 5 for conv2d_xpu op.")
    ;
    AddAttr<float>("act_param", "(float), attribute 6 for conv2d_xpu op.")
    ;
    AddAttr<int>("out_dtype", "(int), attribute 7 for conv2d_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of conv2d_xpu op.
)DOC");
  }
};


class Conv2dXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv2d_xpu, Conv2dXpuInferShapeFunctor,
                            PD_INFER_META(phi::Conv2dXPUInferMeta));



class EmbeddingWithEltwiseAddXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("ids", "(Tensor[]), input 0 of embedding_with_eltwise_add_xpu op.")
        .AsDuplicable();
    AddInput("tables", "(Tensor[]), input 1 of embedding_with_eltwise_add_xpu op.")
        .AsDuplicable();
    AddInput("mask", "(Tensor), input 2 of embedding_with_eltwise_add_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of embedding_with_eltwise_add_xpu op.");
    AddOutput("seq_lod", "(Tensor), output 1 of embedding_with_eltwise_add_xpu op.")
        .AsDispensable();
    AddOutput("max_seq_len", "(Tensor), output 2 of embedding_with_eltwise_add_xpu op.")
        .AsDispensable();
    AddAttr<int64_t>("padding_idx", "(int64_t), attribute 0 for embedding_with_eltwise_add_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of embedding_with_eltwise_add_xpu op.
)DOC");
  }
};


class EmbeddingWithEltwiseAddXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "tables");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(embedding_with_eltwise_add_xpu, EmbeddingWithEltwiseAddXpuInferShapeFunctor,
                            PD_INFER_META(phi::EmbeddingWithEltwiseAddXPUInferMeta));



class FastWhereXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("condition", "(Tensor), input 0 of fast_where_xpu op.");
    AddInput("x", "(Tensor), input 1 of fast_where_xpu op.");
    AddInput("y", "(Tensor), input 2 of fast_where_xpu op.");
    AddOutput("out", "(Tensor), output 0 of fast_where_xpu op.");
    AddComment(R"DOC(
TODO: Documentation of fast_where_xpu op.
)DOC");
  }
};


class FastWhereXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fast_where_xpu, FastWhereXpuInferShapeFunctor,
                            PD_INFER_META(phi::FastWhereXPUInferMeta));



class FcXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of fc_xpu op.");
    AddInput("x_max", "(Tensor), input 1 of fc_xpu op.")
        .AsDispensable();
    AddInput("w", "(Tensor), input 2 of fc_xpu op.");
    AddInput("w_max", "(Tensor), input 3 of fc_xpu op.");
    AddInput("bias", "(Tensor), input 4 of fc_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of fc_xpu op.");
    AddOutput("out_max", "(Tensor), output 1 of fc_xpu op.");
    AddAttr<int>("in_num_col_dims", "(int), attribute 0 for fc_xpu op.")
    ;
    AddAttr<bool>("transpose_x", "(bool), attribute 1 for fc_xpu op.")
    ;
    AddAttr<float>("alpha", "(float), attribute 2 for fc_xpu op.")
    ;
    AddAttr<float>("beta", "(float), attribute 3 for fc_xpu op.")
    ;
    AddAttr<int>("act_type", "(int), attribute 4 for fc_xpu op.")
    ;
    AddAttr<float>("act_alpha", "(float), attribute 5 for fc_xpu op.")
    ;
    AddAttr<int>("out_dtype", "(int), attribute 6 for fc_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of fc_xpu op.
)DOC");
  }
};


class FcXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fc_xpu, FcXpuInferShapeFunctor,
                            PD_INFER_META(phi::FcXPUInferMeta));



class FusedBiasActOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of fused_bias_act op.");
    AddInput("bias", "(Tensor), input 1 of fused_bias_act op.")
        .AsDispensable();
    AddInput("dequant_scales", "(Tensor), input 2 of fused_bias_act op.")
        .AsDispensable();
    AddInput("shift", "(Tensor), input 3 of fused_bias_act op.")
        .AsDispensable();
    AddInput("smooth", "(Tensor), input 4 of fused_bias_act op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of fused_bias_act op.");
    AddAttr<std::string>("act_method", "(std::string), attribute 0 for fused_bias_act op.")
        .SetDefault("gelu");
    AddAttr<std::string>("compute_dtype", "(std::string), attribute 1 for fused_bias_act op.")
        .SetDefault("default");
    AddAttr<float>("quant_scale", "(float), attribute 2 for fused_bias_act op.")
        .SetDefault(-1);
    AddAttr<int>("quant_round_type", "(int), attribute 3 for fused_bias_act op.")
        .SetDefault(1);
    AddAttr<float>("quant_max_bound", "(float), attribute 4 for fused_bias_act op.")
        .SetDefault(127.0);
    AddAttr<float>("quant_min_bound", "(float), attribute 5 for fused_bias_act op.")
        .SetDefault(-127.0);
    AddComment(R"DOC(
TODO: Documentation of fused_bias_act op.
)DOC");
  }
};


class FusedBiasActOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fused_bias_act, FusedBiasActInferShapeFunctor,
                            PD_INFER_META(phi::FusedBiasActInferMeta));



class FusedDropoutAddOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of fused_dropout_add op.");
    AddInput("y", "(Tensor), input 1 of fused_dropout_add op.");
    AddInput("seed_tensor", "(Tensor), input 2 of fused_dropout_add op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of fused_dropout_add op.");
    AddOutput("seed_offset", "(Tensor), output 1 of fused_dropout_add op.");
    AddInput("PTensor", "attribute 0 for fused_dropout_add op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("p", "(float), attribute 0 for fused_dropout_add op.")
    ;
    AddAttr<bool>("is_test", "(bool), attribute 1 for fused_dropout_add op.")
    ;
    AddAttr<std::string>("mode", "(std::string), attribute 2 for fused_dropout_add op.")
    ;
    AddAttr<int>("seed", "(int), attribute 3 for fused_dropout_add op.")
        .SetDefault(0);
    AddAttr<bool>("fix_seed", "(bool), attribute 4 for fused_dropout_add op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of fused_dropout_add op.
)DOC");
  }
};


class FusedDropoutAddOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fused_dropout_add, FusedDropoutAddInferShapeFunctor,
                            PD_INFER_META(phi::FusedDropoutAddInferMeta));



class FusedLinearParamGradAddOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of fused_linear_param_grad_add op.");
    AddInput("dout", "(Tensor), input 1 of fused_linear_param_grad_add op.");
    AddInput("dweight", "(Tensor), input 2 of fused_linear_param_grad_add op.")
        .AsDispensable();
    AddInput("dbias", "(Tensor), input 3 of fused_linear_param_grad_add op.")
        .AsDispensable();
    AddOutput("dweight_out", "(Tensor), output 0 of fused_linear_param_grad_add op.");
    AddOutput("dbias_out", "(Tensor), output 1 of fused_linear_param_grad_add op.");
    AddAttr<bool>("multi_precision", "(bool), attribute 0 for fused_linear_param_grad_add op.")
        .SetDefault(true);
    AddAttr<bool>("has_bias", "(bool), attribute 1 for fused_linear_param_grad_add op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of fused_linear_param_grad_add op.
)DOC");
  }
};


class FusedLinearParamGradAddOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "dout");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fused_linear_param_grad_add, FusedLinearParamGradAddInferShapeFunctor,
                            PD_INFER_META(phi::FusedLinearParamGradAddInferMeta));



class FusedMultiTransformerXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of fused_multi_transformer_xpu op.");
    AddInput("ln_scale", "(Tensor[]), input 1 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ln_bias", "(Tensor[]), input 2 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("qkvw", "(Tensor[]), input 3 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("qkvw_max", "(Tensor[]), input 4 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("qkv_bias", "(Tensor[]), input 5 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("out_linear_w", "(Tensor[]), input 6 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("out_linear_wmax", "(Tensor[]), input 7 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("out_linear_bias", "(Tensor[]), input 8 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn_ln_scale", "(Tensor[]), input 9 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn_ln_bias", "(Tensor[]), input 10 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn1_weight", "(Tensor[]), input 11 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn1_weight_max", "(Tensor[]), input 12 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn1_bias", "(Tensor[]), input 13 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn2_weight", "(Tensor[]), input 14 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn2_weight_max", "(Tensor[]), input 15 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("ffn2_bias", "(Tensor[]), input 16 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddInput("cache_kv", "(Tensor[]), input 17 of fused_multi_transformer_xpu op.")
        .AsDuplicable()
        .AsDispensable();
    AddInput("pre_caches", "(Tensor[]), input 18 of fused_multi_transformer_xpu op.")
        .AsDuplicable()
        .AsDispensable();
    AddInput("rotary_pos_emb", "(Tensor), input 19 of fused_multi_transformer_xpu op.")
        .AsDispensable();
    AddInput("time_step", "(Tensor), input 20 of fused_multi_transformer_xpu op.")
        .AsDispensable();
    AddInput("seq_lengths", "(Tensor), input 21 of fused_multi_transformer_xpu op.")
        .AsDispensable();
    AddInput("src_mask", "(Tensor), input 22 of fused_multi_transformer_xpu op.")
        .AsDispensable();
    AddInput("gather_index", "(Tensor), input 23 of fused_multi_transformer_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of fused_multi_transformer_xpu op.");
    AddOutput("cache_kv_out", "(Tensor[]), output 1 of fused_multi_transformer_xpu op.")
        .AsDuplicable();
    AddAttr<bool>("pre_layer_norm", "(bool), attribute 0 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<int>("rotary_emb_dims", "(int), attribute 1 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<float>("epsilon", "(float), attribute 2 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<float>("dropout_rate", "(float), attribute 3 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<bool>("is_test", "(bool), attribute 4 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<std::string>("dropout_implementation", "(std::string), attribute 5 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<std::string>("act_method", "(std::string), attribute 6 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<bool>("trans_qkvw", "(bool), attribute 7 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<int>("ring_id", "(int), attribute 8 for fused_multi_transformer_xpu op.")
    ;
    AddAttr<int>("gather_axis", "(int), attribute 9 for fused_multi_transformer_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of fused_multi_transformer_xpu op.
)DOC");
  }
};


class FusedMultiTransformerXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fused_multi_transformer_xpu, FusedMultiTransformerXpuInferShapeFunctor,
                            PD_INFER_META(phi::FusedMultiTransformerXpuInferMeta));



class FusedRotaryPositionEmbeddingOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("q", "(Tensor), input 0 of fused_rotary_position_embedding op.");
    AddInput("k", "(Tensor), input 1 of fused_rotary_position_embedding op.")
        .AsDispensable();
    AddInput("v", "(Tensor), input 2 of fused_rotary_position_embedding op.")
        .AsDispensable();
    AddInput("sin", "(Tensor), input 3 of fused_rotary_position_embedding op.")
        .AsDispensable();
    AddInput("cos", "(Tensor), input 4 of fused_rotary_position_embedding op.")
        .AsDispensable();
    AddOutput("out_q", "(Tensor), output 0 of fused_rotary_position_embedding op.");
    AddOutput("out_k", "(Tensor), output 1 of fused_rotary_position_embedding op.")
        .AsDispensable();
    AddOutput("out_v", "(Tensor), output 2 of fused_rotary_position_embedding op.")
        .AsDispensable();
    AddComment(R"DOC(
TODO: Documentation of fused_rotary_position_embedding op.
)DOC");
  }
};


class FusedRotaryPositionEmbeddingOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "q");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fused_rotary_position_embedding, FusedRotaryPositionEmbeddingInferShapeFunctor,
                            PD_INFER_META(phi::FusedRopeInferMeta));



class GenerateSequenceXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of generate_sequence_xpu op.");
    AddOutput("out", "(Tensor), output 0 of generate_sequence_xpu op.");
    AddAttr<int>("dtype", "(int), attribute 0 for generate_sequence_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of generate_sequence_xpu op.
)DOC");
  }
};


class GenerateSequenceXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::proto::VarType::Type(ctx.Attr<int>("dtype"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(generate_sequence_xpu, GenerateSequenceXpuInferShapeFunctor,
                            PD_INFER_META(phi::GenerateSequenceXPUInferMeta));



class MultiEncoderXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of multi_encoder_xpu op.");
    AddInput("fc_weight", "(Tensor[]), input 1 of multi_encoder_xpu op.")
        .AsDuplicable();
    AddInput("fc_weight_max", "(Tensor[]), input 2 of multi_encoder_xpu op.")
        .AsDuplicable();
    AddInput("fc_bias", "(Tensor[]), input 3 of multi_encoder_xpu op.")
        .AsDuplicable();
    AddInput("ln_scale", "(Tensor[]), input 4 of multi_encoder_xpu op.")
        .AsDuplicable();
    AddInput("ln_bias", "(Tensor[]), input 5 of multi_encoder_xpu op.")
        .AsDuplicable();
    AddInput("mask", "(Tensor), input 6 of multi_encoder_xpu op.")
        .AsDispensable();
    AddInput("seq_lod", "(Tensor), input 7 of multi_encoder_xpu op.")
        .AsDispensable();
    AddInput("max_seq_len", "(Tensor), input 8 of multi_encoder_xpu op.")
        .AsDispensable();
    AddOutput("out", "(Tensor), output 0 of multi_encoder_xpu op.");
    AddOutput("x_fp16", "(Tensor), output 1 of multi_encoder_xpu op.")
        .AsDispensable();
    AddOutput("out_fp16", "(Tensor), output 2 of multi_encoder_xpu op.")
        .AsDispensable();
    AddAttr<int>("layer_num", "(int), attribute 0 for multi_encoder_xpu op.")
    ;
    AddAttr<bool>("norm_before", "(bool), attribute 1 for multi_encoder_xpu op.")
    ;
    AddAttr<int>("hidden_dim", "(int), attribute 2 for multi_encoder_xpu op.")
    ;
    AddAttr<int>("head_num", "(int), attribute 3 for multi_encoder_xpu op.")
    ;
    AddAttr<int>("size_per_head", "(int), attribute 4 for multi_encoder_xpu op.")
    ;
    AddAttr<int>("ffn_hidden_dim_scale", "(int), attribute 5 for multi_encoder_xpu op.")
    ;
    AddAttr<int>("act_type", "(int), attribute 6 for multi_encoder_xpu op.")
    ;
    AddAttr<int>("relative_type", "(int), attribute 7 for multi_encoder_xpu op.")
    ;
    AddAttr<int>("slice_idx", "(int), attribute 8 for multi_encoder_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of multi_encoder_xpu op.
)DOC");
  }
};


class MultiEncoderXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(multi_encoder_xpu, MultiEncoderXpuInferShapeFunctor,
                            PD_INFER_META(phi::MultiEncoderXPUInferMeta));



class YoloBoxXpuOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of yolo_box_xpu op.");
    AddInput("x_max", "(Tensor), input 1 of yolo_box_xpu op.")
        .AsDispensable();
    AddInput("grid", "(Tensor), input 2 of yolo_box_xpu op.");
    AddInput("stride", "(Tensor), input 3 of yolo_box_xpu op.");
    AddInput("anchor_grid", "(Tensor), input 4 of yolo_box_xpu op.");
    AddOutput("out", "(Tensor), output 0 of yolo_box_xpu op.");
    AddOutput("out_max", "(Tensor), output 1 of yolo_box_xpu op.");
    AddAttr<float>("offset", "(float), attribute 0 for yolo_box_xpu op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of yolo_box_xpu op.
)DOC");
  }
};


class YoloBoxXpuOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(yolo_box_xpu, YoloBoxXpuInferShapeFunctor,
                            PD_INFER_META(phi::YoloBoxXPUInferMeta));




template <typename T>
class FusedDropoutAddGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("fused_dropout_add_grad");

    grad_op->SetInput("seed_offset", this->Output("seed_offset"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("x"), this->InputGrad("x"));
    grad_op->SetOutput(GradVarName("y"), this->InputGrad("y"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("PTensor")) {
      grad_op->SetInput("PTensor", this->Input("PTensor"));
    }
  }
};


class FusedDropoutAddGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fused_dropout_add_grad, FusedDropoutAddGradInferShapeFunctor,
                            PD_INFER_META(phi::FusedDropoutAddGradInferMeta));



template <typename T>
class FusedRotaryPositionEmbeddingGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("fused_rotary_position_embedding_grad");

    grad_op->SetInput("sin", this->Input("sin"));
    grad_op->SetInput("cos", this->Input("cos"));
    grad_op->SetInput(GradVarName("out_q"), this->OutputGrad("out_q"));
    grad_op->SetInput(GradVarName("out_k"), this->OutputGrad("out_k"));
    grad_op->SetInput(GradVarName("out_v"), this->OutputGrad("out_v"));

    grad_op->SetOutput(GradVarName("q"), this->InputGrad("q"));
    grad_op->SetOutput(GradVarName("k"), this->InputGrad("k"));
    grad_op->SetOutput(GradVarName("v"), this->InputGrad("v"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class FusedRotaryPositionEmbeddingGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("out_q"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(fused_rotary_position_embedding_grad, FusedRotaryPositionEmbeddingGradInferShapeFunctor,
                            PD_INFER_META(phi::FusedRopeGradInferMeta));


}  // namespace operators
}  // namespace paddle

namespace ops = paddle::operators;
REGISTER_OPERATOR(add_act_xpu, ops::AddActXpuOp,
                  ops::AddActXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AddActXpuInferShapeFunctor);


REGISTER_OPERATOR(add_layernorm_xpu, ops::AddLayernormXpuOp,
                  ops::AddLayernormXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AddLayernormXpuInferShapeFunctor);


REGISTER_OPERATOR(conv1d_xpu, ops::Conv1dXpuOp,
                  ops::Conv1dXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv1dXpuInferShapeFunctor);


REGISTER_OPERATOR(conv2d_transpose_xpu, ops::Conv2dTransposeXpuOp,
                  ops::Conv2dTransposeXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv2dTransposeXpuInferShapeFunctor);


REGISTER_OPERATOR(conv2d_xpu, ops::Conv2dXpuOp,
                  ops::Conv2dXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv2dXpuInferShapeFunctor);


REGISTER_OPERATOR(embedding_with_eltwise_add_xpu, ops::EmbeddingWithEltwiseAddXpuOp,
                  ops::EmbeddingWithEltwiseAddXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::EmbeddingWithEltwiseAddXpuInferShapeFunctor);


REGISTER_OPERATOR(fast_where_xpu, ops::FastWhereXpuOp,
                  ops::FastWhereXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::FastWhereXpuInferShapeFunctor);


REGISTER_OPERATOR(fc_xpu, ops::FcXpuOp,
                  ops::FcXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::FcXpuInferShapeFunctor);


REGISTER_OPERATOR(fused_bias_act, ops::FusedBiasActOp,
                  ops::FusedBiasActOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::FusedBiasActInferShapeFunctor);


REGISTER_OPERATOR(fused_dropout_add, ops::FusedDropoutAddOp,
                  ops::FusedDropoutAddOpMaker,
                  ops::FusedDropoutAddGradOpMaker<paddle::framework::OpDesc>,
                  ops::FusedDropoutAddGradOpMaker<paddle::imperative::OpBase>,
                  ops::FusedDropoutAddInferShapeFunctor);


REGISTER_OPERATOR(fused_linear_param_grad_add, ops::FusedLinearParamGradAddOp,
                  ops::FusedLinearParamGradAddOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::FusedLinearParamGradAddInferShapeFunctor);


REGISTER_OPERATOR(fused_multi_transformer_xpu, ops::FusedMultiTransformerXpuOp,
                  ops::FusedMultiTransformerXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::FusedMultiTransformerXpuInferShapeFunctor);


REGISTER_OPERATOR(fused_rotary_position_embedding, ops::FusedRotaryPositionEmbeddingOp,
                  ops::FusedRotaryPositionEmbeddingOpMaker,
                  ops::FusedRotaryPositionEmbeddingGradOpMaker<paddle::framework::OpDesc>,
                  ops::FusedRotaryPositionEmbeddingGradOpMaker<paddle::imperative::OpBase>,
                  ops::FusedRotaryPositionEmbeddingInferShapeFunctor);


REGISTER_OPERATOR(generate_sequence_xpu, ops::GenerateSequenceXpuOp,
                  ops::GenerateSequenceXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::GenerateSequenceXpuInferShapeFunctor);


REGISTER_OPERATOR(multi_encoder_xpu, ops::MultiEncoderXpuOp,
                  ops::MultiEncoderXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::MultiEncoderXpuInferShapeFunctor);


REGISTER_OPERATOR(yolo_box_xpu, ops::YoloBoxXpuOp,
                  ops::YoloBoxXpuOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::YoloBoxXpuInferShapeFunctor);


REGISTER_OPERATOR(fused_dropout_add_grad, ops::FusedDropoutAddGradOp,
                  ops::FusedDropoutAddGradInferShapeFunctor);


REGISTER_OPERATOR(fused_rotary_position_embedding_grad, ops::FusedRotaryPositionEmbeddingGradOp,
                  ops::FusedRotaryPositionEmbeddingGradInferShapeFunctor);


