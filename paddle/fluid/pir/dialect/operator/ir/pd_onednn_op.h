// This file is generated by "paddle/fluid/pir/dialect/op_generator/op_gen.py"
#pragma once
#include <vector>

#include "paddle/pir/core/builder.h"
#include "paddle/pir/core/operation_utils.h"
#include "paddle/fluid/pir/dialect/operator/interface/infer_symbolic_shape.h"
#include "paddle/pir/core/op_base.h"
#include "paddle/pir/core/op_trait.h"
#include "paddle/fluid/pir/dialect/operator/utils/utils.h"
#include "paddle/fluid/pir/dialect/operator/utils/op_yaml_info_util.h"
#include "paddle/fluid/pir/dialect/operator/interface/op_yaml_info.h"
#include "paddle/fluid/pir/dialect/operator/interface/infermeta.h"
#include "paddle/fluid/pir/dialect/operator/interface/vjp.h"
#include "paddle/fluid/pir/dialect/operator/interface/parse_kernel_key.h"
#include "paddle/fluid/pir/dialect/operator/interface/decomp.h"
#include "paddle/fluid/pir/dialect/operator/trait/inplace.h"
#include "paddle/fluid/pir/dialect/operator/trait/onednn.h"
#include "paddle/fluid/pir/dialect/operator/trait/custom_vjp.h"
#include "paddle/fluid/framework/infershape_utils.h"
#include "paddle/phi/core/infermeta_utils.h"
#include "paddle/fluid/pir/dialect/operator/ir/manual_op.h"
#include "paddle/fluid/ir_adaptor/translator/utils.h"




namespace paddle {
namespace onednn {
namespace dialect {

class  QuantizeOp : public pir::Op<QuantizeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::OneDNNTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_onednn_op.quantize"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, bool is_negative_input=false, float scale=1.0, float shift=0.0, const std::string& output_format="NHWC", bool bfloat16=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult output() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dOp : public pir::Op<Conv2dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::OneDNNTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_onednn_op.conv2d"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& padding_algorithm="EXPLICIT", const std::vector<int>& dilations={1, 1}, int groups=1, const std::string& data_format="NCHW", bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dGradOp : public pir::Op<Conv2dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::OneDNNTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_onednn_op.conv2d_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, const std::vector<int>& dilations, int groups, const std::string& data_format, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

} // namespace dialect
} // namespace onednn
} // namespace paddle


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::onednn::dialect::QuantizeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::onednn::dialect::Conv2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::onednn::dialect::Conv2dGradOp)

