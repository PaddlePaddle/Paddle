- op : dequantize
  args : (Tensor input, float scale=1.0, float shift=0.0)
  output : Tensor(output)
  infer_meta :
    func : UnchangedExceptDtypeInferMeta
    param : [input]
  kernel :
    func : dequantize
    data_type : input

- op : fused_conv2d
  args : (Tensor input, Tensor filter, Tensor bias, Tensor residual_param, int[] strides={1, 1}, int[] paddings={0, 0}, str padding_algorithm="EXPLICIT", int[] dilations={1, 1}, int groups=1, str data_format="NCHW", str mkldnn_data_type="float32", str fuse_activation="", bool fuse_residual_connection=false, bool force_fp32_output=false)
  output : Tensor(output)
  infer_meta :
    func : FusedConvInferMeta
  kernel :
    func : fused_conv2d
    data_type : input
  optional : bias, residual_param

- op : fused_conv3d
  args : (Tensor input, Tensor filter, Tensor bias, Tensor residual_param, int[] strides={1, 1}, int[] paddings={0, 0}, str padding_algorithm="EXPLICIT", int[] dilations={1, 1}, int groups=1, str data_format="NCHW", str mkldnn_data_type="float32", str fuse_activation="", bool fuse_residual_connection=false, bool force_fp32_output=false)
  output : Tensor(output)
  infer_meta :
    func : FusedConvInferMeta
  kernel :
    func : fused_conv3d
    data_type : input
  optional : bias, residual_param

- op : fused_elementwise_add
  args : (Tensor x, Tensor y, int axis=-1, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0, float fused_output_scale=1.0, int[] fused_unsqueeze2_axes={}, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0)
  output : Tensor(out)
  infer_meta :
    func : ElementwiseInferMeta
    param : [x, y]
  kernel :
    func : fused_elementwise_add

- op : fused_elementwise_div
  args : (Tensor x, Tensor y, int axis=-1, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0, float fused_output_scale=1.0, int[] fused_unsqueeze2_axes={}, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0)
  output : Tensor(out)
  infer_meta :
    func : ElementwiseInferMeta
    param : [x, y]
  kernel :
    func : fused_elementwise_div

- op : fused_elementwise_mul
  args : (Tensor x, Tensor y, int axis=-1, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0, float fused_output_scale=1.0, int[] fused_unsqueeze2_axes={}, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0)
  output : Tensor(out)
  infer_meta :
    func : ElementwiseInferMeta
    param : [x, y]
  kernel :
    func : fused_elementwise_mul

- op : fused_elementwise_sub
  args : (Tensor x, Tensor y, int axis=-1, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0, float fused_output_scale=1.0, int[] fused_unsqueeze2_axes={}, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0)
  output : Tensor(out)
  infer_meta :
    func : ElementwiseInferMeta
    param : [x, y]
  kernel :
    func : fused_elementwise_sub

- op: multi_gru
  args: (Tensor x, Tensor[] weight_x, Tensor[] weight_h, Tensor[] bias, Tensor[] scale_weights, str activation="tanh", str gate_activation="sigmoid", int layers=1, bool origin_mode=false, str mkldnn_data_type="float32", float scale_data=1.0, float shift_data=1.0, bool force_fp32_output=false)
  output: Tensor(hidden)
  infer_meta:
     func: MultiGruInferMeta
  kernel:
     func: multi_gru
     data_type : x
  optional: bias, scale_weights

- op : quantize
  args : (Tensor input, bool is_negative_input=false, float scale=1.0, float shift=0.0, str output_format="NHWC", bool bfloat16=false)
  output : Tensor(output)
  infer_meta :
    func : UnchangedInferMeta
    param : [input]
  kernel :
    func : quantize
    data_type : input

- op : requantize
  args : (Tensor input, float scale_in=1.0, float scale_out=1.0, float shift_in=1.0, float shift_out=1.0)
  output : Tensor(output)
  infer_meta :
    func : UnchangedInferMeta
    param : [input]
  kernel :
    func : requantize
    data_type : input
