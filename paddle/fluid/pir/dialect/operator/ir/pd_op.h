// This file is generated by "paddle/fluid/pir/dialect/op_generator/op_gen.py"
#pragma once
#include <vector>

#include "paddle/pir/core/builder.h"
#include "paddle/pir/core/operation_utils.h"
#include "paddle/fluid/pir/dialect/operator/interface/infer_symbolic_shape.h"
#include "paddle/pir/core/op_base.h"
#include "paddle/pir/core/op_trait.h"
#include "paddle/fluid/pir/dialect/operator/utils/utils.h"
#include "paddle/fluid/pir/dialect/operator/utils/op_yaml_info_util.h"
#include "paddle/fluid/pir/dialect/operator/interface/op_yaml_info.h"
#include "paddle/fluid/pir/dialect/operator/interface/infermeta.h"
#include "paddle/fluid/pir/dialect/operator/interface/vjp.h"
#include "paddle/fluid/pir/dialect/operator/interface/parse_kernel_key.h"
#include "paddle/fluid/pir/dialect/operator/interface/decomp.h"
#include "paddle/fluid/pir/dialect/operator/trait/inplace.h"
#include "paddle/fluid/pir/dialect/operator/trait/onednn.h"
#include "paddle/fluid/pir/dialect/operator/trait/custom_vjp.h"
#include "paddle/fluid/framework/infershape_utils.h"
#include "paddle/phi/core/infermeta_utils.h"
#include "paddle/fluid/pir/dialect/operator/ir/manual_op.h"
#include "paddle/fluid/ir_adaptor/translator/utils.h"

#include "paddle/phi/common/data_type.h"
#include "paddle/fluid/pir/dialect/operator/interface/get_kernel_type_for_var.h"
            

namespace paddle {
namespace dialect {

extern std::unordered_map<std::string, std::vector<PdOpSig>> op_to_multi_kernels_map;

} // namespace dialect
} // namespace paddle

namespace paddle {
namespace dialect {

class TEST_API AbsOp : public pir::Op<AbsOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Abs_Op : public pir::Op<Abs_Op,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AccuracyOp : public pir::Op<AccuracyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.accuracy"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value label_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value label() { return operand_source(2); }
  pir::OpResult accuracy() { return result(0); }
  pir::OpResult correct() { return result(1); }
  pir::OpResult total() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AcosOp : public pir::Op<AcosOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Acos_Op : public pir::Op<Acos_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AcoshOp : public pir::Op<AcoshOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Acosh_Op : public pir::Op<Acosh_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Adagrad_Op : public pir::Op<Adagrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adagrad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, float epsilon=1.0e-6f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value moment() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AdagradDenseParamSparseGrad_Op : public pir::Op<AdagradDenseParamSparseGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adagrad_dense_param_sparse_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, float epsilon=1.0e-6f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value moment() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Adam_Op : public pir::Op<Adam_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adam_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::Value beta1() { return operand_source(9); }
  pir::Value beta2() { return operand_source(10); }
  pir::Value epsilon() { return operand_source(11); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment1_out() { return result(1); }
  pir::OpResult moment2_out() { return result(2); }
  pir::OpResult beta1_pow_out() { return result(3); }
  pir::OpResult beta2_pow_out() { return result(4); }
  pir::OpResult master_param_out() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AdamDenseParamSparseGrad_Op : public pir::Op<AdamDenseParamSparseGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adam_dense_param_sparse_grad_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::Value beta1() { return operand_source(9); }
  pir::Value beta2() { return operand_source(10); }
  pir::Value epsilon() { return operand_source(11); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment1_out() { return result(1); }
  pir::OpResult moment2_out() { return result(2); }
  pir::OpResult beta1_pow_out() { return result(3); }
  pir::OpResult beta2_pow_out() { return result(4); }
  pir::OpResult master_param_out() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Adamax_Op : public pir::Op<Adamax_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adamax_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment_, pir::Value inf_norm_, pir::Value beta1_pow_, pir::Value master_param_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment_, pir::Value inf_norm_, pir::Value beta1_pow_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment() { return operand_source(3); }
  pir::Value inf_norm() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value master_param() { return operand_source(6); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment_out() { return result(1); }
  pir::OpResult inf_norm_out() { return result(2); }
  pir::OpResult master_param_out() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Adamw_Op : public pir::Op<Adamw_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adamw_"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, float lr_ratio=1.0f, float coeff=0.01f, bool with_decay=false, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, float lr_ratio=1.0f, float coeff=0.01f, bool with_decay=false, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::Value beta1() { return operand_source(9); }
  pir::Value beta2() { return operand_source(10); }
  pir::Value epsilon() { return operand_source(11); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment1_out() { return result(1); }
  pir::OpResult moment2_out() { return result(2); }
  pir::OpResult beta1_pow_out() { return result(3); }
  pir::OpResult beta2_pow_out() { return result(4); }
  pir::OpResult master_param_out() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddmmOp : public pir::Op<AddmmOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Addmm_Op : public pir::Op<Addmm_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AffineGridOp : public pir::Op<AffineGridOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_grid"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int64_t>& output_shape={}, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_shape_, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value output_shape() { return operand_source(1); }
  pir::OpResult output() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AllcloseOp : public pir::Op<AllcloseOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.allclose"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, float rtol=1e-5, float atol=1e-8, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value rtol_, pir::Value atol_, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value rtol() { return operand_source(2); }
  pir::Value atol() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AngleOp : public pir::Op<AngleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.angle"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ArgmaxOp : public pir::Op<ArgmaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argmax"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t axis, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ArgminOp : public pir::Op<ArgminOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argmin"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t axis, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ArgsortOp : public pir::Op<ArgsortOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argsort"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool descending=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult indices() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsComplexOp : public pir::Op<AsComplexOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_complex"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsRealOp : public pir::Op<AsRealOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_real"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsStridedOp : public pir::Op<AsStridedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_strided"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int64_t>& dims={}, const std::vector<int64_t>& stride={}, int64_t offset=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsinOp : public pir::Op<AsinOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Asin_Op : public pir::Op<Asin_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsinhOp : public pir::Op<AsinhOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Asinh_Op : public pir::Op<Asinh_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AtanOp : public pir::Op<AtanOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Atan_Op : public pir::Op<Atan_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Atan2Op : public pir::Op<Atan2Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan2"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AtanhOp : public pir::Op<AtanhOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Atanh_Op : public pir::Op<Atanh_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AucOp : public pir::Op<AucOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.auc"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value stat_pos_, pir::Value stat_neg_, pir::Value ins_tag_weight_, const std::string& curve="ROC", int num_thresholds=(2 << 12) - 1, int slide_steps=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value stat_pos_, pir::Value stat_neg_, pir::Value ins_tag_weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value stat_pos() { return operand_source(2); }
  pir::Value stat_neg() { return operand_source(3); }
  pir::Value ins_tag_weight() { return operand_source(4); }
  pir::OpResult auc() { return result(0); }
  pir::OpResult stat_pos_out() { return result(1); }
  pir::OpResult stat_neg_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AverageAccumulates_Op : public pir::Op<AverageAccumulates_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.average_accumulates_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value in_sum_1_, pir::Value in_sum_2_, pir::Value in_sum_3_, pir::Value in_num_accumulates_, pir::Value in_old_num_accumulates_, pir::Value in_num_updates_, float average_window=0, int64_t max_average_window=INT64_MAX, int64_t min_average_window=10000L);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value in_sum_1_, pir::Value in_sum_2_, pir::Value in_sum_3_, pir::Value in_num_accumulates_, pir::Value in_old_num_accumulates_, pir::Value in_num_updates_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value in_sum_1() { return operand_source(1); }
  pir::Value in_sum_2() { return operand_source(2); }
  pir::Value in_sum_3() { return operand_source(3); }
  pir::Value in_num_accumulates() { return operand_source(4); }
  pir::Value in_old_num_accumulates() { return operand_source(5); }
  pir::Value in_num_updates() { return operand_source(6); }
  pir::OpResult out_sum_1() { return result(0); }
  pir::OpResult out_sum_2() { return result(1); }
  pir::OpResult out_sum_3() { return result(2); }
  pir::OpResult out_num_accumulates() { return result(3); }
  pir::OpResult out_old_num_accumulates() { return result(4); }
  pir::OpResult out_num_updates() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BceLossOp : public pir::Op<BceLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BceLoss_Op : public pir::Op<BceLoss_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BernoulliOp : public pir::Op<BernoulliOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bernoulli"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BicubicInterpOp : public pir::Op<BicubicInterpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bicubic_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_layout="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::OpResult output() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BilinearOp : public pir::Op<BilinearOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_, pir::Value bias_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BilinearInterpOp : public pir::Op<BilinearInterpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_layout="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::OpResult output() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BincountOp : public pir::Op<BincountOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bincount"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weights_, int minlength=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weights_, pir::Value minlength_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weights_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weights() { return operand_source(1); }
  pir::Value minlength() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BinomialOp : public pir::Op<BinomialOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.binomial"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value count_, pir::Value prob_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value count() { return operand_source(0); }
  pir::Value prob() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseAndOp : public pir::Op<BitwiseAndOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_and"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseAnd_Op : public pir::Op<BitwiseAnd_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_and_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseNotOp : public pir::Op<BitwiseNotOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_not"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseNot_Op : public pir::Op<BitwiseNot_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_not_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseOrOp : public pir::Op<BitwiseOrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_or"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseOr_Op : public pir::Op<BitwiseOr_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_or_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseXorOp : public pir::Op<BitwiseXorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_xor"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BitwiseXor_Op : public pir::Op<BitwiseXor_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_xor_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BmmOp : public pir::Op<BmmOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bmm"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BoxCoderOp : public pir::Op<BoxCoderOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.box_coder"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value prior_box_, pir::Value prior_box_var_, pir::Value target_box_, const std::string& code_type="encode_center_size", bool box_normalized=true, int axis=0, const std::vector<float>& variance={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value prior_box_, pir::Value prior_box_var_, pir::Value target_box_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value prior_box() { return operand_source(0); }
  pir::Value prior_box_var() { return operand_source(1); }
  pir::Value target_box() { return operand_source(2); }
  pir::OpResult output_box() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BroadcastTensorsOp : public pir::Op<BroadcastTensorsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.broadcast_tensors"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeilOp : public pir::Op<CeilOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Ceil_Op : public pir::Op<Ceil_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeluOp : public pir::Op<CeluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CheckFiniteAndUnscale_Op : public pir::Op<CheckFiniteAndUnscale_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.check_finite_and_unscale_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult found_infinite() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CheckNumericsOp : public pir::Op<CheckNumericsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.check_numerics"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value tensor_, const std::string& op_type="", const std::string& var_name="", int check_nan_inf_level=0, int stack_height_limit=-1, const std::string& output_dir="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value tensor() { return operand_source(0); }
  pir::OpResult stats() { return result(0); }
  pir::OpResult values() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CholeskyOp : public pir::Op<CholeskyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool upper=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CholeskySolveOp : public pir::Op<CholeskySolveOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky_solve"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool upper=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ClassCenterSampleOp : public pir::Op<ClassCenterSampleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.class_center_sample"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, int num_classes, int num_samples, int ring_id=0, int rank=0, int nranks=1, bool fix_seed=false, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value label() { return operand_source(0); }
  pir::OpResult remapped_label() { return result(0); }
  pir::OpResult sampled_local_class_center() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ClipOp : public pir::Op<ClipOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min, float max);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value min() { return operand_source(1); }
  pir::Value max() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Clip_Op : public pir::Op<Clip_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min, float max);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value min() { return operand_source(1); }
  pir::Value max() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ClipByNormOp : public pir::Op<ClipByNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_by_norm"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ClipByNormSrOp : public pir::Op<ClipByNormSrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_by_norm_sr"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CoalesceTensorOp : public pir::Op<CoalesceTensorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.coalesce_tensor"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, phi::DataType dtype, bool copy_data=false, bool set_constant=false, bool persist_output=false, float constant=0.0, bool use_align=true, int align_size=-1, int size_of_dtype=-1, const std::vector<int64_t>& concated_shapes={}, const std::vector<int64_t>& concated_ranks={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult output() { return result(0); }
  pir::OpResult fused_output() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ComplexOp : public pir::Op<ComplexOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.complex"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value real_, pir::Value imag_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value real() { return operand_source(0); }
  pir::Value imag() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ConcatOp : public pir::Op<ConcatOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.concat"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ConjOp : public pir::Op<ConjOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conj"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dOp : public pir::Op<Conv2dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& padding_algorithm="EXPLICIT", const std::vector<int>& dilations={1, 1}, int groups=1, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv3dOp : public pir::Op<Conv3dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, const std::vector<int>& strides={1, 1, 1}, const std::vector<int>& paddings={0, 0, 0}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1, 1}, const std::string& data_format="NCDHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv3dTransposeOp : public pir::Op<Conv3dTransposeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_transpose"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, const std::vector<int>& strides={1, 1, 1}, const std::vector<int>& paddings={0, 0, 0}, const std::vector<int>& output_padding={}, const std::vector<int>& output_size={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1, 1}, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CosOp : public pir::Op<CosOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Cos_Op : public pir::Op<Cos_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CoshOp : public pir::Op<CoshOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Cosh_Op : public pir::Op<Cosh_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CropOp : public pir::Op<CropOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.crop"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape={}, const std::vector<int64_t>& offsets={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_, pir::Value offsets_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value offsets() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CrossOp : public pir::Op<CrossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int axis=9);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CrossEntropyWithSoftmaxOp : public pir::Op<CrossEntropyWithSoftmaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, bool soft_label=false, bool use_softmax=true, bool numeric_stable_mode=true, int ignore_index=-100, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult softmax() { return result(0); }
  pir::OpResult loss() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CrossEntropyWithSoftmax_Op : public pir::Op<CrossEntropyWithSoftmax_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, bool soft_label=false, bool use_softmax=true, bool numeric_stable_mode=true, int ignore_index=-100, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult softmax() { return result(0); }
  pir::OpResult loss() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CummaxOp : public pir::Op<CummaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummax"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, phi::DataType dtype=phi::DataType::INT64);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult indices() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CumminOp : public pir::Op<CumminOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummin"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, phi::DataType dtype=phi::DataType::INT64);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult indices() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CumprodOp : public pir::Op<CumprodOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumprod"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Cumprod_Op : public pir::Op<Cumprod_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumprod_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CumsumOp : public pir::Op<CumsumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumsum"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Cumsum_Op : public pir::Op<Cumsum_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumsum_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DataOp : public pir::Op<DataOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.data"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::string& name, const std::vector<int64_t>& shape, phi::DataType dtype, const Place& place);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DepthwiseConv2dOp : public pir::Op<DepthwiseConv2dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DetOp : public pir::Op<DetOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.det"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DiagOp : public pir::Op<DiagOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diag"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int offset=0, float padding_value=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DiagEmbedOp : public pir::Op<DiagEmbedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diag_embed"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int offset=0, int dim1=-2, int dim2=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DiagonalOp : public pir::Op<DiagonalOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diagonal"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int offset=0, int axis1=0, int axis2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DigammaOp : public pir::Op<DigammaOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.digamma"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Digamma_Op : public pir::Op<Digamma_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.digamma_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DirichletOp : public pir::Op<DirichletOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dirichlet"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value alpha_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value alpha() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DistOp : public pir::Op<DistOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dist"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, float p=2.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DotOp : public pir::Op<DotOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dot"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EditDistanceOp : public pir::Op<EditDistanceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.edit_distance"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hyps_, pir::Value refs_, pir::Value hypslength_, pir::Value refslength_, bool normalized=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hyps_, pir::Value refs_, pir::Value hypslength_, pir::Value refslength_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value hyps() { return operand_source(0); }
  pir::Value refs() { return operand_source(1); }
  pir::Value hypslength() { return operand_source(2); }
  pir::Value refslength() { return operand_source(3); }
  pir::OpResult sequencenum() { return result(0); }
  pir::OpResult out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EigOp : public pir::Op<EigOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eig"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out_w() { return result(0); }
  pir::OpResult out_v() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EighOp : public pir::Op<EighOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigh"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& UPLO="L");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out_w() { return result(0); }
  pir::OpResult out_v() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EigvalsOp : public pir::Op<EigvalsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigvals"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EigvalshOp : public pir::Op<EigvalshOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigvalsh"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& uplo="L", bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult eigenvalues() { return result(0); }
  pir::OpResult eigenvectors() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EluOp : public pir::Op<EluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Elu_Op : public pir::Op<Elu_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EqualAllOp : public pir::Op<EqualAllOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.equal_all"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ErfOp : public pir::Op<ErfOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erf"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Erf_Op : public pir::Op<Erf_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erf_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ErfinvOp : public pir::Op<ErfinvOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erfinv"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Erfinv_Op : public pir::Op<Erfinv_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erfinv_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExpOp : public pir::Op<ExpOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Exp_Op : public pir::Op<Exp_Op,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExpandAsOp : public pir::Op<ExpandAsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_as"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<int>& target_shape={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Expm1Op : public pir::Op<Expm1Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Expm1_Op : public pir::Op<Expm1_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FftC2cOp : public pir::Op<FftC2cOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2c"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FftC2rOp : public pir::Op<FftC2rOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2r"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, int64_t last_dim_size=0L);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FftR2cOp : public pir::Op<FftR2cOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_r2c"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, bool onesided);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillOp : public pir::Op<FillOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Fill_Op : public pir::Op<Fill_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillDiagonalOp : public pir::Op<FillDiagonalOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0, int offset=0, bool wrap=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillDiagonal_Op : public pir::Op<FillDiagonal_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0, int offset=0, bool wrap=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillDiagonalTensorOp : public pir::Op<FillDiagonalTensorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int64_t offset=0, int dim1=0, int dim2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillDiagonalTensor_Op : public pir::Op<FillDiagonalTensor_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int64_t offset=0, int dim1=0, int dim2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlashAttnOp : public pir::Op<FlashAttnOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value fixed_seed_offset() { return operand_source(3); }
  pir::Value attn_mask() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult softmax() { return result(1); }
  pir::OpResult softmax_lse() { return result(2); }
  pir::OpResult seed_offset() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlashAttnUnpaddedOp : public pir::Op<FlashAttnUnpaddedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_unpadded"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, int64_t max_seqlen_q, int64_t max_seqlen_k, float scale, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value cu_seqlens_q() { return operand_source(3); }
  pir::Value cu_seqlens_k() { return operand_source(4); }
  pir::Value fixed_seed_offset() { return operand_source(5); }
  pir::Value attn_mask() { return operand_source(6); }
  pir::OpResult out() { return result(0); }
  pir::OpResult softmax() { return result(1); }
  pir::OpResult softmax_lse() { return result(2); }
  pir::OpResult seed_offset() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlattenOp : public pir::Op<FlattenOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int start_axis=1, int stop_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Flatten_Op : public pir::Op<Flatten_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int start_axis=1, int stop_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlipOp : public pir::Op<FlipOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flip"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FloorOp : public pir::Op<FloorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Floor_Op : public pir::Op<Floor_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FmaxOp : public pir::Op<FmaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmax"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FminOp : public pir::Op<FminOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmin"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FoldOp : public pir::Op<FoldOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fold"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& output_sizes, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FrameOp : public pir::Op<FrameOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frame"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int frame_length, int hop_length, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FullIntArrayOp : public pir::Op<FullIntArrayOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_int_array"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& value, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GammalnOp : public pir::Op<GammalnOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaln"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Gammaln_Op : public pir::Op<Gammaln_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaln_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GatherOp : public pir::Op<GatherOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GatherNdOp : public pir::Op<GatherNdOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_nd"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GatherTreeOp : public pir::Op<GatherTreeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_tree"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value parents_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value ids() { return operand_source(0); }
  pir::Value parents() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GaussianInplaceOp : public pir::Op<GaussianInplaceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GaussianInplace_Op : public pir::Op<GaussianInplace_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GeluOp : public pir::Op<GeluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gelu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool approximate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  GenerateProposalsOp : public pir::Op<GenerateProposalsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.generate_proposals"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value scores_, pir::Value bbox_deltas_, pir::Value im_shape_, pir::Value anchors_, pir::Value variances_, int pre_nms_top_n, int post_nms_top_n, float nms_thresh, float min_size, float eta, bool pixel_offset=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value scores_, pir::Value bbox_deltas_, pir::Value im_shape_, pir::Value anchors_, pir::Value variances_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value scores() { return operand_source(0); }
  pir::Value bbox_deltas() { return operand_source(1); }
  pir::Value im_shape() { return operand_source(2); }
  pir::Value anchors() { return operand_source(3); }
  pir::Value variances() { return operand_source(4); }
  pir::OpResult rpn_rois() { return result(0); }
  pir::OpResult rpn_roi_probs() { return result(1); }
  pir::OpResult rpn_rois_num() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GridSampleOp : public pir::Op<GridSampleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.grid_sample"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, const std::string& mode="bilinear", const std::string& padding_mode="zeros", bool align_corners=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grid() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GroupNormOp : public pir::Op<GroupNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.group_norm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, float epsilon=1e-5, int groups=-1, const std::string& data_layout="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult y() { return result(0); }
  pir::OpResult mean() { return result(1); }
  pir::OpResult variance() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GumbelSoftmaxOp : public pir::Op<GumbelSoftmaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gumbel_softmax"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float temperature=1.0, bool hard=false, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardshrinkOp : public pir::Op<HardshrinkOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardshrink"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardsigmoidOp : public pir::Op<HardsigmoidOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardsigmoid"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float slope=0.2, float offset=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardtanhOp : public pir::Op<HardtanhOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float t_min=0, float t_max=24);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Hardtanh_Op : public pir::Op<Hardtanh_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float t_min=0, float t_max=24);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HeavisideOp : public pir::Op<HeavisideOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.heaviside"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HistogramOp : public pir::Op<HistogramOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.histogram"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int64_t bins=100, int min=0, int max=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HuberLossOp : public pir::Op<HuberLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.huber_loss"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, float delta);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult residual() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I0Op : public pir::Op<I0Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I0_Op : public pir::Op<I0_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I0eOp : public pir::Op<I0eOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0e"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I1Op : public pir::Op<I1Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I1eOp : public pir::Op<I1eOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1e"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IdentityLossOp : public pir::Op<IdentityLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int reduction=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IdentityLoss_Op : public pir::Op<IdentityLoss_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int reduction=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ImagOp : public pir::Op<ImagOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.imag"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexAddOp : public pir::Op<IndexAddOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value add_value() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexAdd_Op : public pir::Op<IndexAdd_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value add_value() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexPutOp : public pir::Op<IndexPutOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_put"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, bool accumulate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexPut_Op : public pir::Op<IndexPut_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_put_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, bool accumulate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexSampleOp : public pir::Op<IndexSampleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_sample"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexSelectOp : public pir::Op<IndexSelectOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexSelectStridedOp : public pir::Op<IndexSelectStridedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select_strided"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t index, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  InstanceNormOp : public pir::Op<InstanceNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.instance_norm"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, float epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult y() { return result(0); }
  pir::OpResult saved_mean() { return result(1); }
  pir::OpResult saved_variance() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  InverseOp : public pir::Op<InverseOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.inverse"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IsEmptyOp : public pir::Op<IsEmptyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.is_empty"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IscloseOp : public pir::Op<IscloseOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isclose"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, double rtol=1e-5, double atol=1e-8, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value rtol_, pir::Value atol_, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value rtol() { return operand_source(2); }
  pir::Value atol() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IsfiniteOp : public pir::Op<IsfiniteOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isfinite"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IsfiniteSrOp : public pir::Op<IsfiniteSrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isfinite_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IsinfOp : public pir::Op<IsinfOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isinf"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IsinfSrOp : public pir::Op<IsinfSrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isinf_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IsnanOp : public pir::Op<IsnanOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isnan"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IsnanSrOp : public pir::Op<IsnanSrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isnan_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  KldivLossOp : public pir::Op<KldivLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kldiv_loss"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, const std::string& reduction="mean");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  KronOp : public pir::Op<KronOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kron"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  KthvalueOp : public pir::Op<KthvalueOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kthvalue"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int k=1, int axis=-1, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult indices() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LabelSmoothOp : public pir::Op<LabelSmoothOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.label_smooth"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value prior_dist_, float epsilon=0.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value prior_dist_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value label() { return operand_source(0); }
  pir::Value prior_dist() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Lamb_Op : public pir::Op<Lamb_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lamb_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float weight_decay, float beta1=0.9, float beta2=0.999, float epsilon=1.0e-6f, bool always_adapt=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment1_out() { return result(1); }
  pir::OpResult moment2_out() { return result(2); }
  pir::OpResult beta1_pow_out() { return result(3); }
  pir::OpResult beta2_pow_out() { return result(4); }
  pir::OpResult master_param_outs() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LambSr_Op : public pir::Op<LambSr_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lamb_sr_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float weight_decay, float beta1=0.9, float beta2=0.999, float epsilon=1.0e-6f, bool always_adapt=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment1_out() { return result(1); }
  pir::OpResult moment2_out() { return result(2); }
  pir::OpResult beta1_pow_out() { return result(3); }
  pir::OpResult beta2_pow_out() { return result(4); }
  pir::OpResult master_param_outs() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LayerNormOp : public pir::Op<LayerNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.layer_norm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, float epsilon=1e-5, int begin_norm_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean() { return result(1); }
  pir::OpResult variance() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  LeakyReluOp : public pir::Op<LeakyReluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float negative_slope=0.02f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  LeakyRelu_Op : public pir::Op<LeakyRelu_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float negative_slope=0.02f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LerpOp : public pir::Op<LerpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lerp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Lerp_Op : public pir::Op<Lerp_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lerp_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LgammaOp : public pir::Op<LgammaOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lgamma"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Lgamma_Op : public pir::Op<Lgamma_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lgamma_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LinearInterpOp : public pir::Op<LinearInterpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.linear_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_layout="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::OpResult output() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LlmInt8LinearOp : public pir::Op<LlmInt8LinearOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.llm_int8_linear"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, float threshold=6.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight_scale() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogOp : public pir::Op<LogOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log_Op : public pir::Op<Log_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log10Op : public pir::Op<Log10Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log10_Op : public pir::Op<Log10_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log1pOp : public pir::Op<Log1pOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log1p_Op : public pir::Op<Log1p_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log2Op : public pir::Op<Log2Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log2_Op : public pir::Op<Log2_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogLossOp : public pir::Op<LogLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_loss"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogSoftmaxOp : public pir::Op<LogSoftmaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_softmax"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogcumsumexpOp : public pir::Op<LogcumsumexpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logcumsumexp"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool flatten=false, bool exclusive=false, bool reverse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalAndOp : public pir::Op<LogicalAndOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_and"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalAnd_Op : public pir::Op<LogicalAnd_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_and_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalNotOp : public pir::Op<LogicalNotOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_not"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalNot_Op : public pir::Op<LogicalNot_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_not_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalOrOp : public pir::Op<LogicalOrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_or"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalOr_Op : public pir::Op<LogicalOr_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_or_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalXorOp : public pir::Op<LogicalXorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_xor"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogicalXor_Op : public pir::Op<LogicalXor_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_xor_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogitOp : public pir::Op<LogitOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logit"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float eps=1e-6f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Logit_Op : public pir::Op<Logit_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logit_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float eps=1e-6f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogsigmoidOp : public pir::Op<LogsigmoidOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsigmoid"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LstsqOp : public pir::Op<LstsqOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lstsq"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, float rcond=0.0f, const std::string& driver="gels");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value rcond_, const std::string& driver="gels");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value rcond() { return operand_source(2); }
  pir::OpResult solution() { return result(0); }
  pir::OpResult residuals() { return result(1); }
  pir::OpResult rank() { return result(2); }
  pir::OpResult singular_values() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LuOp : public pir::Op<LuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool pivot=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult pivots() { return result(1); }
  pir::OpResult infos() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Lu_Op : public pir::Op<Lu_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool pivot=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult pivots() { return result(1); }
  pir::OpResult infos() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LuUnpackOp : public pir::Op<LuUnpackOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_unpack"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool unpack_ludata=true, bool unpack_pivots=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult pmat() { return result(0); }
  pir::OpResult l() { return result(1); }
  pir::OpResult u() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MarginCrossEntropyOp : public pir::Op<MarginCrossEntropyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.margin_cross_entropy"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, bool return_softmax=false, int ring_id=0, int rank=0, int nranks=1, float margin1=1.0f, float margin2=0.5f, float margin3=0.0f, float scale=64.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult softmax() { return result(0); }
  pir::OpResult loss() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaskedMultiheadAttention_Op : public pir::Op<MaskedMultiheadAttention_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_multihead_attention_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cache_kv_, pir::Value bias_, pir::Value src_mask_, pir::Value cum_offsets_, pir::Value sequence_lengths_, pir::Value rotary_tensor_, pir::Value beam_cache_offset_, pir::Value qkv_out_scale_, pir::Value out_shift_, pir::Value out_smooth_, int seq_len, int rotary_emb_dims, bool use_neox_rotary_style=false, const std::string& compute_dtype="default", float out_scale=-1, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cache_kv_, pir::Value bias_, pir::Value src_mask_, pir::Value cum_offsets_, pir::Value sequence_lengths_, pir::Value rotary_tensor_, pir::Value beam_cache_offset_, pir::Value qkv_out_scale_, pir::Value out_shift_, pir::Value out_smooth_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value cache_kv() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value src_mask() { return operand_source(3); }
  pir::Value cum_offsets() { return operand_source(4); }
  pir::Value sequence_lengths() { return operand_source(5); }
  pir::Value rotary_tensor() { return operand_source(6); }
  pir::Value beam_cache_offset() { return operand_source(7); }
  pir::Value qkv_out_scale() { return operand_source(8); }
  pir::Value out_shift() { return operand_source(9); }
  pir::Value out_smooth() { return operand_source(10); }
  pir::OpResult out() { return result(0); }
  pir::OpResult cache_kv_out() { return result(1); }
  pir::OpResult beam_cache_offset_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaskedSelectOp : public pir::Op<MaskedSelectOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_select"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatrixNmsOp : public pir::Op<MatrixNmsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_nms"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, float score_threshold, int nms_top_k, int keep_top_k, float post_threshold=0., bool use_gaussian=false, float gaussian_sigma=2., int background_label=0, bool normalized=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value bboxes() { return operand_source(0); }
  pir::Value scores() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult index() { return result(1); }
  pir::OpResult roisnum() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatrixPowerOp : public pir::Op<MatrixPowerOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_power"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxPool2dWithIndexOp : public pir::Op<MaxPool2dWithIndexOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_with_index"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_size, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, bool global_pooling=false, bool adaptive=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mask() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxPool3dWithIndexOp : public pir::Op<MaxPool3dWithIndexOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool3d_with_index"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_size, const std::vector<int>& strides={1, 1, 1}, const std::vector<int>& paddings={0, 0, 0}, bool global_pooling=false, bool adaptive=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mask() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxoutOp : public pir::Op<MaxoutOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maxout"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int groups, int axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MeanAllOp : public pir::Op<MeanAllOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_all"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MemoryEfficientAttentionOp : public pir::Op<MemoryEfficientAttentionOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memory_efficient_attention"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value causal_diagonal_, pir::Value seqlen_k_, float max_seqlen_q, float max_seqlen_k, bool causal, double dropout_p, float scale, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value causal_diagonal_, pir::Value seqlen_k_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value cu_seqlens_q() { return operand_source(4); }
  pir::Value cu_seqlens_k() { return operand_source(5); }
  pir::Value causal_diagonal() { return operand_source(6); }
  pir::Value seqlen_k() { return operand_source(7); }
  pir::OpResult output() { return result(0); }
  pir::OpResult logsumexp() { return result(1); }
  pir::OpResult seed_and_offset() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MergeSelectedRowsOp : public pir::Op<MergeSelectedRowsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.merge_selected_rows"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MergedAdam_Op : public pir::Op<MergedAdam_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.merged_adam_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, bool multi_precision=false, bool use_global_beta_pow=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value beta1() { return operand_source(8); }
  pir::Value beta2() { return operand_source(9); }
  pir::Value epsilon() { return operand_source(10); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment1_out() { return result(1); }
  pir::OpResult moment2_out() { return result(2); }
  pir::OpResult beta1_pow_out() { return result(3); }
  pir::OpResult beta2_pow_out() { return result(4); }
  pir::OpResult master_param_out() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MergedMomentum_Op : public pir::Op<MergedMomentum_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.merged_momentum_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, bool use_nesterov=false, const std::vector<std::string>& regularization_method={}, const std::vector<float>& regularization_coeff={}, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult velocity_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MeshgridOp : public pir::Op<MeshgridOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.meshgrid"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value inputs() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ModeOp : public pir::Op<ModeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mode"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult indices() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Momentum_Op : public pir::Op<Momentum_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.momentum_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult velocity_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MomentumDenseParamSparseGrad_Op : public pir::Op<MomentumDenseParamSparseGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.momentum_dense_param_sparse_grad_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult velocity_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiDotOp : public pir::Op<MultiDotOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multi_dot"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MulticlassNms3Op : public pir::Op<MulticlassNms3Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiclass_nms3"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, pir::Value rois_num_, float score_threshold, int nms_top_k, int keep_top_k, float nms_threshold=0.3, bool normalized=true, float nms_eta=1.0, int background_label=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, pir::Value rois_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value bboxes() { return operand_source(0); }
  pir::Value scores() { return operand_source(1); }
  pir::Value rois_num() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult index() { return result(1); }
  pir::OpResult nms_rois_num() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultinomialOp : public pir::Op<MultinomialOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multinomial"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int num_samples=1, bool replacement=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value num_samples_, bool replacement=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value num_samples() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplexOp : public pir::Op<MultiplexOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiplex"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, pir::Value index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value inputs() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MvOp : public pir::Op<MvOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NanmedianOp : public pir::Op<NanmedianOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nanmedian"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult medians() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NearestInterpOp : public pir::Op<NearestInterpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nearest_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_layout="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::OpResult output() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NextafterOp : public pir::Op<NextafterOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nextafter"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NllLossOp : public pir::Op<NllLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nll_loss"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, int64_t ignore_index=-100, const std::string& reduction="mean");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult total_weight() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NmsOp : public pir::Op<NmsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nms"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NonzeroOp : public pir::Op<NonzeroOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nonzero"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value condition() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NpuIdentityOp : public pir::Op<NpuIdentityOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.npu_identity"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int format=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NumelOp : public pir::Op<NumelOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.numel"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult size() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  OverlapAddOp : public pir::Op<OverlapAddOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.overlap_add"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int hop_length, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PNormOp : public pir::Op<PNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.p_norm"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float porder=2, int axis=-1, float epsilon=1.0e-12f, bool keepdim=false, bool asvector=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pad3dOp : public pir::Op<Pad3dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad3d"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& paddings, const std::string& mode="constant", float pad_value=0.0, const std::string& data_format="NCDHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value paddings_, const std::string& mode="constant", float pad_value=0.0, const std::string& data_format="NCDHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value paddings() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PixelShuffleOp : public pir::Op<PixelShuffleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_shuffle"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int upscale_factor=1, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PixelUnshuffleOp : public pir::Op<PixelUnshuffleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_unshuffle"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int downscale_factor=1, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PoissonOp : public pir::Op<PoissonOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.poisson"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PolygammaOp : public pir::Op<PolygammaOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.polygamma"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Polygamma_Op : public pir::Op<Polygamma_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.polygamma_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PowOp : public pir::Op<PowOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float y=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  Pow_Op : public pir::Op<Pow_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float y=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PreluOp : public pir::Op<PreluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prelu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, const std::string& data_format="NCHW", const std::string& mode="all");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value alpha() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PriorBoxOp : public pir::Op<PriorBoxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prior_box"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value image_, const std::vector<float>& min_sizes, const std::vector<float>& max_sizes={}, const std::vector<float>& aspect_ratios={}, const std::vector<float>& variances={}, bool flip=true, bool clip=true, float step_w=0.0, float step_h=0.0, float offset=0.5, bool min_max_aspect_ratios_order=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value image_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value image() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult var() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PsroiPoolOp : public pir::Op<PsroiPoolOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.psroi_pool"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, int pooled_height=1, int pooled_width=1, int output_channels=1, float spatial_scale=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PutAlongAxisOp : public pir::Op<PutAlongAxisOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.put_along_axis"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, int axis, const std::string& reduce="assign", bool include_self=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value values() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PutAlongAxis_Op : public pir::Op<PutAlongAxis_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.put_along_axis_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, int axis, const std::string& reduce="assign", bool include_self=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value values() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  QrOp : public pir::Op<QrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.qr"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& mode="reduced");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult q() { return result(0); }
  pir::OpResult r() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RealOp : public pir::Op<RealOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.real"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReciprocalOp : public pir::Op<ReciprocalOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Reciprocal_Op : public pir::Op<Reciprocal_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReindexGraphOp : public pir::Op<ReindexGraphOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reindex_graph"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value neighbors_, pir::Value count_, pir::Value hashtable_value_, pir::Value hashtable_index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value neighbors() { return operand_source(1); }
  pir::Value count() { return operand_source(2); }
  pir::Value hashtable_value() { return operand_source(3); }
  pir::Value hashtable_index() { return operand_source(4); }
  pir::OpResult reindex_src() { return result(0); }
  pir::OpResult reindex_dst() { return result(1); }
  pir::OpResult out_nodes() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReluOp : public pir::Op<ReluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  Relu_Op : public pir::Op<Relu_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Relu6Op : public pir::Op<Relu6Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RenormOp : public pir::Op<RenormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.renorm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float p, int axis, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Renorm_Op : public pir::Op<Renorm_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.renorm_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float p, int axis, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReverseOp : public pir::Op<ReverseOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reverse"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RmsNormOp : public pir::Op<RmsNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rms_norm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, float epsilon, int begin_norm_axis, float quant_scale, int quant_round_type, float quant_max_bound, float quant_min_bound);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value bias() { return operand_source(1); }
  pir::Value residual() { return operand_source(2); }
  pir::Value norm_weight() { return operand_source(3); }
  pir::Value norm_bias() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult residual_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Rmsprop_Op : public pir::Op<Rmsprop_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rmsprop_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, float epsilon=1.0e-10f, float decay=0.9f, float momentum=0.0f, bool centered=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value mean_square() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value moment() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value mean_grad() { return operand_source(5); }
  pir::Value master_param() { return operand_source(6); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment_out() { return result(1); }
  pir::OpResult mean_square_out() { return result(2); }
  pir::OpResult mean_grad_out() { return result(3); }
  pir::OpResult master_param_outs() { return result(4); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RmspropDenseParamSparseGrad_Op : public pir::Op<RmspropDenseParamSparseGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rmsprop_dense_param_sparse_grad_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, float epsilon=1.0e-10f, float decay=0.9f, float momentum=0.0f, bool centered=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value mean_square() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value moment() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value mean_grad() { return operand_source(5); }
  pir::Value master_param() { return operand_source(6); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment_out() { return result(1); }
  pir::OpResult mean_square_out() { return result(2); }
  pir::OpResult mean_grad_out() { return result(3); }
  pir::OpResult master_param_outs() { return result(4); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RoiAlignOp : public pir::Op<RoiAlignOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_align"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, int pooled_height=1, int pooled_width=1, float spatial_scale=1.0, int sampling_ratio=-1, bool aligned=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RoiPoolOp : public pir::Op<RoiPoolOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_pool"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, int pooled_height=1, int pooled_width=1, float spatial_scale=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult arg_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RollOp : public pir::Op<RollOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roll"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shifts={}, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shifts_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value shifts() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RoundOp : public pir::Op<RoundOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Round_Op : public pir::Op<Round_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Rprop_Op : public pir::Op<Rprop_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rprop_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value prev_, pir::Value learning_rate_, pir::Value master_param_, pir::Value learning_rate_range_, pir::Value etas_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value prev_, pir::Value learning_rate_, pir::Value master_param_, pir::Value learning_rate_range_, pir::Value etas_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value prev() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value learning_rate_range() { return operand_source(5); }
  pir::Value etas() { return operand_source(6); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult prev_out() { return result(1); }
  pir::OpResult learning_rate_out() { return result(2); }
  pir::OpResult master_param_out() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RsqrtOp : public pir::Op<RsqrtOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  Rsqrt_Op : public pir::Op<Rsqrt_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScaleOp : public pir::Op<ScaleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScaleSrOp : public pir::Op<ScaleSrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_sr"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Scale_Op : public pir::Op<Scale_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScaleSr_Op : public pir::Op<ScaleSr_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_sr_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScatterOp : public pir::Op<ScatterOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, bool overwrite=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value updates() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Scatter_Op : public pir::Op<Scatter_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, bool overwrite=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value updates() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScatterNdAddOp : public pir::Op<ScatterNdAddOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_nd_add"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value updates() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SearchsortedOp : public pir::Op<SearchsortedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.searchsorted"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sorted_sequence_, pir::Value values_, bool out_int32=false, bool right=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sorted_sequence_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value sorted_sequence() { return operand_source(0); }
  pir::Value values() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SegmentPoolOp : public pir::Op<SegmentPoolOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.segment_pool"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, const std::string& pooltype="SUM");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value segment_ids() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult summed_ids() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SeluOp : public pir::Op<SeluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.selu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0507009873554804934193349852946, float alpha=1.6732632423543772848170429916717);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SendURecvOp : public pir::Op<SendURecvOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_u_recv"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, const std::string& reduce_op="SUM", const std::vector<int64_t>& out_size={0});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_size_, const std::string& reduce_op="SUM");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value src_index() { return operand_source(1); }
  pir::Value dst_index() { return operand_source(2); }
  pir::Value out_size() { return operand_source(3); }
  pir::OpResult out() { return result(0); }
  pir::OpResult dst_count() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SendUeRecvOp : public pir::Op<SendUeRecvOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_ue_recv"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, const std::string& message_op="ADD", const std::string& reduce_op="SUM", const std::vector<int64_t>& out_size={0});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_size_, const std::string& message_op="ADD", const std::string& reduce_op="SUM");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::Value out_size() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult dst_count() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SendUvOp : public pir::Op<SendUvOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_uv"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, const std::string& message_op="ADD");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Sgd_Op : public pir::Op<Sgd_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sgd_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value learning_rate() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value master_param() { return operand_source(3); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult master_param_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SgdDenseParamSparseGrad_Op : public pir::Op<SgdDenseParamSparseGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sgd_dense_param_sparse_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value learning_rate() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value master_param() { return operand_source(3); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult master_param_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SgdSparseParamSparseGrad_Op : public pir::Op<SgdSparseParamSparseGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sgd_sparse_param_sparse_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value learning_rate() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value master_param() { return operand_source(3); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult master_param_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ShapeOp : public pir::Op<ShapeOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shape"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ShapeSrOp : public pir::Op<ShapeSrOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shape_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ShardIndexOp : public pir::Op<ShardIndexOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shard_index"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int index_num, int nshards, int shard_id, int ignore_value=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidOp : public pir::Op<SigmoidOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  Sigmoid_Op : public pir::Op<Sigmoid_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidCrossEntropyWithLogitsOp : public pir::Op<SigmoidCrossEntropyWithLogitsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, bool normalize=false, int ignore_index=-100);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidCrossEntropyWithLogits_Op : public pir::Op<SigmoidCrossEntropyWithLogits_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, bool normalize=false, int ignore_index=-100);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SignOp : public pir::Op<SignOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sign"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SiluOp : public pir::Op<SiluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  SinOp : public pir::Op<SinOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Sin_Op : public pir::Op<Sin_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinhOp : public pir::Op<SinhOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Sinh_Op : public pir::Op<Sinh_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SlogdetOp : public pir::Op<SlogdetOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slogdet"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftplusOp : public pir::Op<SoftplusOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float beta=1.0, float threshold=20.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftshrinkOp : public pir::Op<SoftshrinkOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softshrink"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftsignOp : public pir::Op<SoftsignOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softsign"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SolveOp : public pir::Op<SolveOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.solve"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SpectralNormOp : public pir::Op<SpectralNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.spectral_norm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, int dim=0, int power_iters=1, float eps=1e-12f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value weight() { return operand_source(0); }
  pir::Value u() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqrtOp : public pir::Op<SqrtOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  SqrtSrOp : public pir::Op<SqrtSrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Sqrt_Op : public pir::Op<Sqrt_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqrtSr_Op : public pir::Op<SqrtSr_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_sr_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquareOp : public pir::Op<SquareOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquareSrOp : public pir::Op<SquareSrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquaredL2NormOp : public pir::Op<SquaredL2NormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squared_l2_norm"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqueezeOp : public pir::Op<SqueezeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  Squeeze_Op : public pir::Op<Squeeze_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  StackOp : public pir::Op<StackOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stack"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  StandardGammaOp : public pir::Op<StandardGammaOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.standard_gamma"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  StanhOp : public pir::Op<StanhOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stanh"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale_a=0.67f, float scale_b=1.7159f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SvdOp : public pir::Op<SvdOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.svd"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool full_matrices=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult u() { return result(0); }
  pir::OpResult s() { return result(1); }
  pir::OpResult vh() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TakeAlongAxisOp : public pir::Op<TakeAlongAxisOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.take_along_axis"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanOp : public pir::Op<TanOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Tan_Op : public pir::Op<Tan_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhOp : public pir::Op<TanhOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Tanh_Op : public pir::Op<Tanh_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhShrinkOp : public pir::Op<TanhShrinkOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_shrink"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TemporalShiftOp : public pir::Op<TemporalShiftOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.temporal_shift"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int seg_num, float shift_ratio=0.25f, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TensorUnfoldOp : public pir::Op<TensorUnfoldOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tensor_unfold"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int64_t axis, int64_t size, int64_t step);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ThresholdedReluOp : public pir::Op<ThresholdedReluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ThresholdedRelu_Op : public pir::Op<ThresholdedRelu_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TopPSamplingOp : public pir::Op<TopPSamplingOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.top_p_sampling"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ps_, pir::Value threshold_, int seed=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ps_, pir::Value threshold_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value ps() { return operand_source(1); }
  pir::Value threshold() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult ids() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TopkOp : public pir::Op<TopkOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.topk"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int k=1, int axis=-1, bool largest=true, bool sorted=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value k_, int axis=-1, bool largest=true, bool sorted=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult indices() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TraceOp : public pir::Op<TraceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trace"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int offset=0, int axis1=0, int axis2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TriangularSolveOp : public pir::Op<TriangularSolveOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triangular_solve"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool upper=true, bool transpose=false, bool unitriangular=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TrilinearInterpOp : public pir::Op<TrilinearInterpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trilinear_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_layout="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::OpResult output() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TruncOp : public pir::Op<TruncOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trunc"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Trunc_Op : public pir::Op<Trunc_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trunc_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnbindOp : public pir::Op<UnbindOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unbind"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnfoldOp : public pir::Op<UnfoldOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unfold"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UniformInplaceOp : public pir::Op<UniformInplaceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UniformInplace_Op : public pir::Op<UniformInplace_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UniqueConsecutiveOp : public pir::Op<UniqueConsecutiveOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unique_consecutive"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool return_inverse=false, bool return_counts=false, const std::vector<int>& axis={}, phi::DataType dtype=phi::DataType::FLOAT32);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult index() { return result(1); }
  pir::OpResult counts() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Unpool3dOp : public pir::Op<Unpool3dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool3d"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, const std::vector<int>& ksize, const std::vector<int>& strides={1,1,1}, const std::vector<int>& paddings={0,0,0}, const std::vector<int>& output_size={0,0,0}, const std::string& data_format="NCDHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnsqueezeOp : public pir::Op<UnsqueezeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  Unsqueeze_Op : public pir::Op<Unsqueeze_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnstackOp : public pir::Op<UnstackOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unstack"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=0, int num=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UpdateLossScaling_Op : public pir::Op<UpdateLossScaling_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.update_loss_scaling_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value found_infinite_, pir::Value prev_loss_scaling_, pir::Value in_good_steps_, pir::Value in_bad_steps_, int incr_every_n_steps, int decr_every_n_nan_or_inf, float incr_ratio, float decr_ratio, bool stop_update=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value found_infinite_, pir::Value prev_loss_scaling_, pir::Value in_good_steps_, pir::Value in_bad_steps_, pir::Value stop_update_, int incr_every_n_steps, int decr_every_n_nan_or_inf, float incr_ratio, float decr_ratio);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value found_infinite_, pir::Value prev_loss_scaling_, pir::Value in_good_steps_, pir::Value in_bad_steps_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value found_infinite() { return operand_source(1); }
  pir::Value prev_loss_scaling() { return operand_source(2); }
  pir::Value in_good_steps() { return operand_source(3); }
  pir::Value in_bad_steps() { return operand_source(4); }
  pir::Value stop_update() { return operand_source(5); }
  pir::OpResult out() { return result(0); }
  pir::OpResult loss_scaling() { return result(1); }
  pir::OpResult out_good_steps() { return result(2); }
  pir::OpResult out_bad_steps() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ViewDtypeOp : public pir::Op<ViewDtypeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.view_dtype"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ViewShapeOp : public pir::Op<ViewShapeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.view_shape"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int64_t>& dims={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ViterbiDecodeOp : public pir::Op<ViterbiDecodeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.viterbi_decode"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value potentials_, pir::Value transition_params_, pir::Value lengths_, bool include_bos_eos_tag=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value potentials_, pir::Value transition_params_, pir::Value lengths_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value potentials() { return operand_source(0); }
  pir::Value transition_params() { return operand_source(1); }
  pir::Value lengths() { return operand_source(2); }
  pir::OpResult scores() { return result(0); }
  pir::OpResult path() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WarpctcOp : public pir::Op<WarpctcOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warpctc"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value logits_length_, pir::Value labels_length_, int blank=0, bool norm_by_times=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value logits_length_, pir::Value labels_length_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value logits_length() { return operand_source(2); }
  pir::Value labels_length() { return operand_source(3); }
  pir::OpResult loss() { return result(0); }
  pir::OpResult warpctcgrad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WarprnntOp : public pir::Op<WarprnntOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warprnnt"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value input_lengths_, pir::Value label_lengths_, int blank=0, float fastemit_lambda=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value input_lengths_, pir::Value label_lengths_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value input_lengths() { return operand_source(2); }
  pir::Value label_lengths() { return operand_source(3); }
  pir::OpResult loss() { return result(0); }
  pir::OpResult warprnntgrad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WeightDequantizeOp : public pir::Op<WeightDequantizeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_dequantize"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, const std::string& algo="weight_only_int8", phi::DataType out_dtype=phi::DataType::FLOAT16, int group_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WeightOnlyLinearOp : public pir::Op<WeightOnlyLinearOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_only_linear"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, const std::string& weight_dtype, int arch=80, int group_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight_scale() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WeightQuantizeOp : public pir::Op<WeightQuantizeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_quantize"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& algo="weight_only_int8", int arch=80, int group_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult scale() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WeightedSampleNeighborsOp : public pir::Op<WeightedSampleNeighborsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weighted_sample_neighbors"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value edge_weight_, pir::Value input_nodes_, pir::Value eids_, int sample_size, bool return_eids);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value edge_weight_, pir::Value input_nodes_, pir::Value eids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value row() { return operand_source(0); }
  pir::Value colptr() { return operand_source(1); }
  pir::Value edge_weight() { return operand_source(2); }
  pir::Value input_nodes() { return operand_source(3); }
  pir::Value eids() { return operand_source(4); }
  pir::OpResult out_neighbors() { return result(0); }
  pir::OpResult out_count() { return result(1); }
  pir::OpResult out_eids() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WhereOp : public pir::Op<WhereOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.where"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Where_Op : public pir::Op<Where_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.where_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  YoloBoxOp : public pir::Op<YoloBoxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_box"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value img_size_, const std::vector<int>& anchors={}, int class_num=1, float conf_thresh=0.01, int downsample_ratio=32, bool clip_bbox=true, float scale_x_y=1.0, bool iou_aware=false, float iou_aware_factor=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value img_size_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value img_size() { return operand_source(1); }
  pir::OpResult boxes() { return result(0); }
  pir::OpResult scores() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  YoloLossOp : public pir::Op<YoloLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_loss"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, const std::vector<int>& anchors={}, const std::vector<int>& anchor_mask={}, int class_num=1, float ignore_thresh=0.7, int downsample_ratio=32, bool use_label_smooth=true, float scale_x_y=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value gt_box() { return operand_source(1); }
  pir::Value gt_label() { return operand_source(2); }
  pir::Value gt_score() { return operand_source(3); }
  pir::OpResult loss() { return result(0); }
  pir::OpResult objectness_mask() { return result(1); }
  pir::OpResult gt_match_mask() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};


class  AbsDoubleGradOp : public pir::Op<AbsDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AbsGradOp : public pir::Op<AbsGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AcosGradOp : public pir::Op<AcosGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AcosGrad_Op : public pir::Op<AcosGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AcoshGradOp : public pir::Op<AcoshGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AcoshGrad_Op : public pir::Op<AcoshGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddmmGradOp : public pir::Op<AddmmGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, float alpha, float beta);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult x_grad() { return result(1); }
  pir::OpResult y_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AffineGridGradOp : public pir::Op<AffineGridGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_grid_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_grad_, const std::vector<int64_t>& output_shape, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_grad_, pir::Value output_shape_, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value output_grad() { return operand_source(1); }
  pir::Value output_shape() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AngleGradOp : public pir::Op<AngleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.angle_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ArgsortGradOp : public pir::Op<ArgsortGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argsort_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value indices_, pir::Value x_, pir::Value out_grad_, int axis, bool descending);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value indices_, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value indices() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsComplexGradOp : public pir::Op<AsComplexGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_complex_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsRealGradOp : public pir::Op<AsRealGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_real_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsStridedGradOp : public pir::Op<AsStridedGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_strided_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, const std::vector<int64_t>& dims={}, const std::vector<int64_t>& stride={}, int64_t offset=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsinGradOp : public pir::Op<AsinGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsinGrad_Op : public pir::Op<AsinGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsinhGradOp : public pir::Op<AsinhGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AsinhGrad_Op : public pir::Op<AsinhGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Atan2GradOp : public pir::Op<Atan2GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan2_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AtanGradOp : public pir::Op<AtanGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AtanGrad_Op : public pir::Op<AtanGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AtanhGradOp : public pir::Op<AtanhGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AtanhGrad_Op : public pir::Op<AtanhGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BceLossGradOp : public pir::Op<BceLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BceLossGrad_Op : public pir::Op<BceLossGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BicubicInterpGradOp : public pir::Op<BicubicInterpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bicubic_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_layout, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BilinearGradOp : public pir::Op<BilinearGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }
  pir::OpResult weight_grad() { return result(2); }
  pir::OpResult bias_grad() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BilinearInterpGradOp : public pir::Op<BilinearInterpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_layout, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BmmGradOp : public pir::Op<BmmGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bmm_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BroadcastTensorsGradOp : public pir::Op<BroadcastTensorsGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.broadcast_tensors_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeilGradOp : public pir::Op<CeilGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeilGrad_Op : public pir::Op<CeilGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeluDoubleGradOp : public pir::Op<CeluDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeluDoubleGrad_Op : public pir::Op<CeluDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeluGradOp : public pir::Op<CeluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CeluGrad_Op : public pir::Op<CeluGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CholeskyGradOp : public pir::Op<CholeskyGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, bool upper);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CholeskySolveGradOp : public pir::Op<CholeskySolveGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky_solve_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, bool upper);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ClipDoubleGradOp : public pir::Op<ClipDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, float min=0., float max=0.);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value min() { return operand_source(2); }
  pir::Value max() { return operand_source(3); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ClipGradOp : public pir::Op<ClipGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float min=0., float max=0.);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value min() { return operand_source(2); }
  pir::Value max() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ClipGrad_Op : public pir::Op<ClipGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float min=0., float max=0.);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value min() { return operand_source(2); }
  pir::Value max() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ComplexGradOp : public pir::Op<ComplexGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.complex_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value real_, pir::Value imag_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value real() { return operand_source(0); }
  pir::Value imag() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult real_grad() { return result(0); }
  pir::OpResult imag_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ConcatDoubleGradOp : public pir::Op<ConcatDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.concat_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ConcatGradOp : public pir::Op<ConcatGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.concat_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ConjGradOp : public pir::Op<ConjGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conj_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dGradOp : public pir::Op<Conv2dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, const std::vector<int>& dilations, int groups, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dGradGradOp : public pir::Op<Conv2dGradGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_grad_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, const std::vector<int>& dilations, int groups, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_input_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv3dDoubleGradOp : public pir::Op<Conv3dDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_double_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_input_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv3dGradOp : public pir::Op<Conv3dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv3dTransposeGradOp : public pir::Op<Conv3dTransposeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_transpose_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CosDoubleGradOp : public pir::Op<CosDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CosDoubleGrad_Op : public pir::Op<CosDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CosGradOp : public pir::Op<CosGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CosGrad_Op : public pir::Op<CosGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CosTripleGradOp : public pir::Op<CosTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_forward_grad() { return result(1); }
  pir::OpResult grad_x_grad_forward_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CosTripleGrad_Op : public pir::Op<CosTripleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_forward_grad() { return result(1); }
  pir::OpResult grad_x_grad_forward_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CoshGradOp : public pir::Op<CoshGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CoshGrad_Op : public pir::Op<CoshGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CropGradOp : public pir::Op<CropGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.crop_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& offsets);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value offsets_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value offsets() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CrossEntropyWithSoftmaxGradOp : public pir::Op<CrossEntropyWithSoftmaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool soft_label, bool use_softmax, bool numeric_stable_mode, int ignore_index, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value label() { return operand_source(0); }
  pir::Value softmax() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CrossEntropyWithSoftmaxGrad_Op : public pir::Op<CrossEntropyWithSoftmaxGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax_grad_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool soft_label, bool use_softmax, bool numeric_stable_mode, int ignore_index, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value label() { return operand_source(0); }
  pir::Value softmax() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CrossGradOp : public pir::Op<CrossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CummaxGradOp : public pir::Op<CummaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummax_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int axis, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CumminGradOp : public pir::Op<CumminGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummin_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int axis, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CumprodGradOp : public pir::Op<CumprodGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumprod_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int dim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CumsumGradOp : public pir::Op<CumsumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumsum_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int axis, bool flatten, bool exclusive, bool reverse);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_, bool flatten, bool exclusive, bool reverse);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DepthwiseConv2dDoubleGradOp : public pir::Op<DepthwiseConv2dDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_double_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_input_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DepthwiseConv2dGradOp : public pir::Op<DepthwiseConv2dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DetGradOp : public pir::Op<DetGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.det_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DiagGradOp : public pir::Op<DiagGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diag_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DiagonalGradOp : public pir::Op<DiagonalGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diagonal_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int offset=0, int axis1=0, int axis2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DigammaGradOp : public pir::Op<DigammaGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.digamma_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DistGradOp : public pir::Op<DistGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dist_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, float p);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DotGradOp : public pir::Op<DotGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dot_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EigGradOp : public pir::Op<EigGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eig_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_w_, pir::Value out_v_, pir::Value out_w_grad_, pir::Value out_v_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_w() { return operand_source(0); }
  pir::Value out_v() { return operand_source(1); }
  pir::Value out_w_grad() { return operand_source(2); }
  pir::Value out_v_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EighGradOp : public pir::Op<EighGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_w_, pir::Value out_v_, pir::Value out_w_grad_, pir::Value out_v_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_w() { return operand_source(0); }
  pir::Value out_v() { return operand_source(1); }
  pir::Value out_w_grad() { return operand_source(2); }
  pir::Value out_v_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EigvalshGradOp : public pir::Op<EigvalshGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigvalsh_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value eigenvectors_, pir::Value eigenvalues_grad_, const std::string& uplo, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value eigenvectors_, pir::Value eigenvalues_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value eigenvectors() { return operand_source(0); }
  pir::Value eigenvalues_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EluDoubleGradOp : public pir::Op<EluDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EluDoubleGrad_Op : public pir::Op<EluDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EluGradOp : public pir::Op<EluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EluGrad_Op : public pir::Op<EluGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ErfGradOp : public pir::Op<ErfGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erf_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ErfinvGradOp : public pir::Op<ErfinvGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erfinv_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExpGradOp : public pir::Op<ExpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExpGrad_Op : public pir::Op<ExpGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExpandAsGradOp : public pir::Op<ExpandAsGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_as_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& target_shape);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExpandDoubleGradOp : public pir::Op<ExpandDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExpandGradOp : public pir::Op<ExpandGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value shape() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Expm1GradOp : public pir::Op<Expm1GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Expm1Grad_Op : public pir::Op<Expm1Grad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FftC2cGradOp : public pir::Op<FftC2cGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2c_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FftC2rGradOp : public pir::Op<FftC2rGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2r_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, int64_t last_dim_size);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FftR2cGradOp : public pir::Op<FftR2cGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_r2c_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, bool onesided);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillDiagonalGradOp : public pir::Op<FillDiagonalGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float value, int offset, bool wrap);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillDiagonalTensorGradOp : public pir::Op<FillDiagonalTensorGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int64_t offset, int dim1, int dim2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillDiagonalTensorGrad_Op : public pir::Op<FillDiagonalTensorGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor_grad_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int64_t offset, int dim1, int dim2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillGradOp : public pir::Op<FillGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FillGrad_Op : public pir::Op<FillGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlashAttnGradOp : public pir::Op<FlashAttnGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, float dropout=0.0, bool causal=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value softmax_lse() { return operand_source(4); }
  pir::Value seed_offset() { return operand_source(5); }
  pir::Value attn_mask() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::OpResult q_grad() { return result(0); }
  pir::OpResult k_grad() { return result(1); }
  pir::OpResult v_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlashAttnUnpaddedGradOp : public pir::Op<FlashAttnUnpaddedGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_unpadded_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, int64_t max_seqlen_q, int64_t max_seqlen_k, float scale, float dropout=0.0, bool causal=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value cu_seqlens_q() { return operand_source(3); }
  pir::Value cu_seqlens_k() { return operand_source(4); }
  pir::Value out() { return operand_source(5); }
  pir::Value softmax_lse() { return operand_source(6); }
  pir::Value seed_offset() { return operand_source(7); }
  pir::Value attn_mask() { return operand_source(8); }
  pir::Value out_grad() { return operand_source(9); }
  pir::OpResult q_grad() { return result(0); }
  pir::OpResult k_grad() { return result(1); }
  pir::OpResult v_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlattenGradOp : public pir::Op<FlattenGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlattenGrad_Op : public pir::Op<FlattenGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FlipGradOp : public pir::Op<FlipGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flip_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FloorGradOp : public pir::Op<FloorGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FloorGrad_Op : public pir::Op<FloorGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FmaxGradOp : public pir::Op<FmaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmax_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FminGradOp : public pir::Op<FminGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmin_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FoldGradOp : public pir::Op<FoldGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fold_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& output_sizes, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FrameGradOp : public pir::Op<FrameGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frame_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int frame_length, int hop_length, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GammalnGradOp : public pir::Op<GammalnGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaln_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GatherGradOp : public pir::Op<GatherGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GatherNdGradOp : public pir::Op<GatherNdGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_nd_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GaussianInplaceGradOp : public pir::Op<GaussianInplaceGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GaussianInplaceGrad_Op : public pir::Op<GaussianInplaceGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace_grad_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GeluGradOp : public pir::Op<GeluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gelu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, bool approximate);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GridSampleGradOp : public pir::Op<GridSampleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.grid_sample_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, pir::Value out_grad_, const std::string& mode, const std::string& padding_mode, bool align_corners);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grid() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grid_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GroupNormGradOp : public pir::Op<GroupNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.group_norm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, float epsilon, int groups, const std::string& data_layout);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value y() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::Value y_grad() { return operand_source(6); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GroupNormGrad_Op : public pir::Op<GroupNormGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.group_norm_grad_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, float epsilon, int groups, const std::string& data_layout);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value y() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::Value y_grad() { return operand_source(6); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GumbelSoftmaxGradOp : public pir::Op<GumbelSoftmaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gumbel_softmax_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardshrinkGradOp : public pir::Op<HardshrinkGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardshrink_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardshrinkGrad_Op : public pir::Op<HardshrinkGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardshrink_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardsigmoidGradOp : public pir::Op<HardsigmoidGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardsigmoid_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, float slope, float offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardsigmoidGrad_Op : public pir::Op<HardsigmoidGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardsigmoid_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, float slope, float offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardtanhGradOp : public pir::Op<HardtanhGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float t_min, float t_max);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardtanhGrad_Op : public pir::Op<HardtanhGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float t_min, float t_max);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HeavisideGradOp : public pir::Op<HeavisideGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.heaviside_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HuberLossGradOp : public pir::Op<HuberLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.huber_loss_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value residual_, pir::Value out_grad_, float delta);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value residual_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value residual() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult label_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I0GradOp : public pir::Op<I0GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I0eGradOp : public pir::Op<I0eGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0e_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I1GradOp : public pir::Op<I1GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  I1eGradOp : public pir::Op<I1eGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1e_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IdentityLossGradOp : public pir::Op<IdentityLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int reduction);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IdentityLossGrad_Op : public pir::Op<IdentityLossGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int reduction);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ImagGradOp : public pir::Op<ImagGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.imag_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexAddGradOp : public pir::Op<IndexAddGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value index() { return operand_source(0); }
  pir::Value add_value() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult add_value_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexAddGrad_Op : public pir::Op<IndexAddGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value index() { return operand_source(0); }
  pir::Value add_value() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult add_value_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexPutGradOp : public pir::Op<IndexPutGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_put_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::Value out_grad_, bool accumulate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult value_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexSampleGradOp : public pir::Op<IndexSampleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_sample_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexSelectGradOp : public pir::Op<IndexSelectGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  IndexSelectStridedGradOp : public pir::Op<IndexSelectStridedGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select_strided_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int64_t index, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  InstanceNormDoubleGradOp : public pir::Op<InstanceNormDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.instance_norm_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fwd_scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_y_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fwd_scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_y_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value fwd_scale() { return operand_source(1); }
  pir::Value saved_mean() { return operand_source(2); }
  pir::Value saved_variance() { return operand_source(3); }
  pir::Value grad_y() { return operand_source(4); }
  pir::Value grad_x_grad() { return operand_source(5); }
  pir::Value grad_scale_grad() { return operand_source(6); }
  pir::Value grad_bias_grad() { return operand_source(7); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult fwd_scale_grad() { return result(1); }
  pir::OpResult grad_y_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  InstanceNormGradOp : public pir::Op<InstanceNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.instance_norm_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value y_grad_, float epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value saved_mean() { return operand_source(2); }
  pir::Value saved_variance() { return operand_source(3); }
  pir::Value y_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  InverseGradOp : public pir::Op<InverseGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.inverse_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  KldivLossGradOp : public pir::Op<KldivLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kldiv_loss_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value out_grad_, const std::string& reduction);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  KronGradOp : public pir::Op<KronGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kron_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  KthvalueGradOp : public pir::Op<KthvalueGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kthvalue_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int k, int axis, bool keepdim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LabelSmoothGradOp : public pir::Op<LabelSmoothGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.label_smooth_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult label_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LayerNormGradOp : public pir::Op<LayerNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.layer_norm_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::Value out_grad_, float epsilon=1e-5, int begin_norm_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean() { return operand_source(3); }
  pir::Value variance() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LeakyReluDoubleGradOp : public pir::Op<LeakyReluDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LeakyReluDoubleGrad_Op : public pir::Op<LeakyReluDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LeakyReluGradOp : public pir::Op<LeakyReluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LeakyReluGrad_Op : public pir::Op<LeakyReluGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LerpGradOp : public pir::Op<LerpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lerp_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LgammaGradOp : public pir::Op<LgammaGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lgamma_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LinearInterpGradOp : public pir::Op<LinearInterpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.linear_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_layout, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log10GradOp : public pir::Op<Log10GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log10Grad_Op : public pir::Op<Log10Grad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log1pGradOp : public pir::Op<Log1pGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log1pGrad_Op : public pir::Op<Log1pGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log2GradOp : public pir::Op<Log2GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Log2Grad_Op : public pir::Op<Log2Grad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogDoubleGradOp : public pir::Op<LogDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogDoubleGrad_Op : public pir::Op<LogDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogGradOp : public pir::Op<LogGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogGrad_Op : public pir::Op<LogGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogLossGradOp : public pir::Op<LogLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_loss_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogSoftmaxGradOp : public pir::Op<LogSoftmaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_softmax_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogcumsumexpGradOp : public pir::Op<LogcumsumexpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logcumsumexp_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int axis, bool flatten, bool exclusive, bool reverse);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogitGradOp : public pir::Op<LogitGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logit_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float eps);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogsigmoidGradOp : public pir::Op<LogsigmoidGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsigmoid_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogsigmoidGrad_Op : public pir::Op<LogsigmoidGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsigmoid_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LuGradOp : public pir::Op<LuGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, bool pivot);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value pivots() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LuGrad_Op : public pir::Op<LuGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, bool pivot);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value pivots() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LuUnpackGradOp : public pir::Op<LuUnpackGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_unpack_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value l_, pir::Value u_, pir::Value pmat_, pir::Value l_grad_, pir::Value u_grad_, bool unpack_ludata, bool unpack_pivots);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value l_, pir::Value u_, pir::Value pmat_, pir::Value l_grad_, pir::Value u_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value l() { return operand_source(2); }
  pir::Value u() { return operand_source(3); }
  pir::Value pmat() { return operand_source(4); }
  pir::Value l_grad() { return operand_source(5); }
  pir::Value u_grad() { return operand_source(6); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MarginCrossEntropyGradOp : public pir::Op<MarginCrossEntropyGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.margin_cross_entropy_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool return_softmax, int ring_id, int rank, int nranks, float margin1, float margin2, float margin3, float scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::OpResult logits_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MarginCrossEntropyGrad_Op : public pir::Op<MarginCrossEntropyGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.margin_cross_entropy_grad_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool return_softmax, int ring_id, int rank, int nranks, float margin1, float margin2, float margin3, float scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::OpResult logits_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaskedSelectGradOp : public pir::Op<MaskedSelectGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_select_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatrixPowerGradOp : public pir::Op<MatrixPowerGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_power_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxPool2dWithIndexGradOp : public pir::Op<MaxPool2dWithIndexGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_with_index_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool global_pooling, bool adaptive);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxPool3dWithIndexGradOp : public pir::Op<MaxPool3dWithIndexGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool3d_with_index_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool global_pooling, bool adaptive);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxoutGradOp : public pir::Op<MaxoutGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maxout_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int groups, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MeanAllGradOp : public pir::Op<MeanAllGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_all_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MemoryEfficientAttentionGradOp : public pir::Op<MemoryEfficientAttentionGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memory_efficient_attention_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value output_, pir::Value logsumexp_, pir::Value seed_and_offset_, pir::Value output_grad_, float max_seqlen_q, float max_seqlen_k, bool causal, double dropout_p, float scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value output_, pir::Value logsumexp_, pir::Value seed_and_offset_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value cu_seqlens_q() { return operand_source(4); }
  pir::Value cu_seqlens_k() { return operand_source(5); }
  pir::Value output() { return operand_source(6); }
  pir::Value logsumexp() { return operand_source(7); }
  pir::Value seed_and_offset() { return operand_source(8); }
  pir::Value output_grad() { return operand_source(9); }
  pir::OpResult query_grad() { return result(0); }
  pir::OpResult key_grad() { return result(1); }
  pir::OpResult value_grad() { return result(2); }
  pir::OpResult bias_grad() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MeshgridGradOp : public pir::Op<MeshgridGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.meshgrid_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, pir::Value outputs_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value inputs() { return operand_source(0); }
  pir::Value outputs_grad() { return operand_source(1); }
  pir::OpResult inputs_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ModeGradOp : public pir::Op<ModeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mode_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int axis, bool keepdim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiDotGradOp : public pir::Op<MultiDotGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multi_dot_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplexGradOp : public pir::Op<MultiplexGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiplex_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, pir::Value index_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value inputs() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult inputs_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MvGradOp : public pir::Op<MvGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult vec_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NanmedianGradOp : public pir::Op<NanmedianGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nanmedian_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value medians_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keepdim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value medians_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value medians() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NearestInterpGradOp : public pir::Op<NearestInterpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nearest_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_layout, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NllLossGradOp : public pir::Op<NllLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nll_loss_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value total_weight_, pir::Value out_grad_, int64_t ignore_index, const std::string& reduction);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value total_weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value total_weight() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  OverlapAddGradOp : public pir::Op<OverlapAddGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.overlap_add_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int hop_length, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PNormGradOp : public pir::Op<PNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.p_norm_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, float porder, int axis, float epsilon, bool keepdim, bool asvector);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pad3dDoubleGradOp : public pir::Op<Pad3dDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad3d_double_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& paddings, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::Value paddings_, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value paddings() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pad3dGradOp : public pir::Op<Pad3dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad3d_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& paddings, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value paddings_, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value paddings() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PixelShuffleGradOp : public pir::Op<PixelShuffleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_shuffle_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int upscale_factor, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PixelUnshuffleGradOp : public pir::Op<PixelUnshuffleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_unshuffle_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int downscale_factor, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PoissonGradOp : public pir::Op<PoissonGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.poisson_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PolygammaGradOp : public pir::Op<PolygammaGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.polygamma_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PowDoubleGradOp : public pir::Op<PowDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PowDoubleGrad_Op : public pir::Op<PowDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PowGradOp : public pir::Op<PowGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float y=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PowGrad_Op : public pir::Op<PowGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float y=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PowTripleGradOp : public pir::Op<PowTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_triple_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_grad_x_, pir::Value grad_x_grad_, pir::Value grad_grad_out_grad_, float y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_grad_x_, pir::Value grad_x_grad_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_grad_x() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_grad_out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }
  pir::OpResult grad_grad_x_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PreluGradOp : public pir::Op<PreluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prelu_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, pir::Value out_grad_, const std::string& data_format, const std::string& mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value alpha() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult alpha_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PsroiPoolGradOp : public pir::Op<PsroiPoolGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.psroi_pool_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, int pooled_height, int pooled_width, int output_channels, float spatial_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PutAlongAxisGradOp : public pir::Op<PutAlongAxisGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.put_along_axis_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::Value out_, pir::Value out_grad_, int axis, const std::string& reduce, bool include_self);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value values() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult arr_grad() { return result(0); }
  pir::OpResult values_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  QrGradOp : public pir::Op<QrGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.qr_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value q_, pir::Value r_, pir::Value q_grad_, pir::Value r_grad_, const std::string& mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value q_, pir::Value r_, pir::Value q_grad_, pir::Value r_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value q() { return operand_source(1); }
  pir::Value r() { return operand_source(2); }
  pir::Value q_grad() { return operand_source(3); }
  pir::Value r_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RealGradOp : public pir::Op<RealGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.real_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReciprocalGradOp : public pir::Op<ReciprocalGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReciprocalGrad_Op : public pir::Op<ReciprocalGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Relu6GradOp : public pir::Op<Relu6GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Relu6Grad_Op : public pir::Op<Relu6Grad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReluDoubleGradOp : public pir::Op<ReluDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReluDoubleGrad_Op : public pir::Op<ReluDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReluGradOp : public pir::Op<ReluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReluGrad_Op : public pir::Op<ReluGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RenormGradOp : public pir::Op<RenormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.renorm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float p, int axis, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReverseGradOp : public pir::Op<ReverseGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reverse_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RoiAlignGradOp : public pir::Op<RoiAlignGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_align_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, int pooled_height, int pooled_width, float spatial_scale, int sampling_ratio, bool aligned);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RoiPoolGradOp : public pir::Op<RoiPoolGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_pool_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value arg_max_, pir::Value out_grad_, int pooled_height, int pooled_width, float spatial_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value arg_max_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value arg_max() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RollGradOp : public pir::Op<RollGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roll_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& shifts, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value shifts_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value shifts() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RoundGradOp : public pir::Op<RoundGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RoundGrad_Op : public pir::Op<RoundGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RsqrtDoubleGradOp : public pir::Op<RsqrtDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RsqrtDoubleGrad_Op : public pir::Op<RsqrtDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RsqrtGradOp : public pir::Op<RsqrtGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RsqrtGrad_Op : public pir::Op<RsqrtGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScaleGradOp : public pir::Op<ScaleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScatterGradOp : public pir::Op<ScatterGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value updates_, pir::Value out_grad_, bool overwrite);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value updates_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value index() { return operand_source(0); }
  pir::Value updates() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult updates_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ScatterNdAddGradOp : public pir::Op<ScatterNdAddGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_nd_add_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value updates_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value index() { return operand_source(0); }
  pir::Value updates() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult updates_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SegmentPoolGradOp : public pir::Op<SegmentPoolGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.segment_pool_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, pir::Value out_, pir::Value summed_ids_, pir::Value out_grad_, const std::string& pooltype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, pir::Value out_, pir::Value summed_ids_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value segment_ids() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value summed_ids() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SeluGradOp : public pir::Op<SeluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.selu_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, float scale, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SendURecvGradOp : public pir::Op<SendURecvGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_u_recv_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, const std::string& reduce_op="SUM");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value src_index() { return operand_source(1); }
  pir::Value dst_index() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value dst_count() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SendUeRecvGradOp : public pir::Op<SendUeRecvGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_ue_recv_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, const std::string& message_op, const std::string& reduce_op);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::Value out() { return operand_source(4); }
  pir::Value dst_count() { return operand_source(5); }
  pir::Value out_grad() { return operand_source(6); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SendUvGradOp : public pir::Op<SendUvGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_uv_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_grad_, const std::string& message_op="ADD");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidCrossEntropyWithLogitsGradOp : public pir::Op<SigmoidCrossEntropyWithLogitsGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, bool normalize, int ignore_index);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidCrossEntropyWithLogitsGrad_Op : public pir::Op<SigmoidCrossEntropyWithLogitsGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, bool normalize, int ignore_index);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidDoubleGradOp : public pir::Op<SigmoidDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value fwd_grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value fwd_grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult fwd_grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidDoubleGrad_Op : public pir::Op<SigmoidDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value fwd_grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value fwd_grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult fwd_grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidGradOp : public pir::Op<SigmoidGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidGrad_Op : public pir::Op<SigmoidGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidTripleGradOp : public pir::Op<SigmoidTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value fwd_grad_out_, pir::Value grad_grad_x_, pir::Value grad_out_grad_, pir::Value grad_grad_out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value fwd_grad_out() { return operand_source(1); }
  pir::Value grad_grad_x() { return operand_source(2); }
  pir::Value grad_out_grad() { return operand_source(3); }
  pir::Value grad_grad_out_grad() { return operand_source(4); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult fwd_grad_out_grad() { return result(1); }
  pir::OpResult grad_grad_x_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SigmoidTripleGrad_Op : public pir::Op<SigmoidTripleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value fwd_grad_out_, pir::Value grad_grad_x_, pir::Value grad_out_grad_, pir::Value grad_grad_out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value fwd_grad_out() { return operand_source(1); }
  pir::Value grad_grad_x() { return operand_source(2); }
  pir::Value grad_out_grad() { return operand_source(3); }
  pir::Value grad_grad_out_grad() { return operand_source(4); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult fwd_grad_out_grad() { return result(1); }
  pir::OpResult grad_grad_x_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SignGradOp : public pir::Op<SignGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sign_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SiluGradOp : public pir::Op<SiluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
};

class  SiluGrad_Op : public pir::Op<SiluGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
};

class  SinDoubleGradOp : public pir::Op<SinDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinDoubleGrad_Op : public pir::Op<SinDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinGradOp : public pir::Op<SinGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinGrad_Op : public pir::Op<SinGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinTripleGradOp : public pir::Op<SinTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_forward_grad() { return result(1); }
  pir::OpResult grad_x_grad_forward_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinTripleGrad_Op : public pir::Op<SinTripleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_forward_grad() { return result(1); }
  pir::OpResult grad_x_grad_forward_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinhGradOp : public pir::Op<SinhGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinhGrad_Op : public pir::Op<SinhGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SlogdetGradOp : public pir::Op<SlogdetGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slogdet_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftplusDoubleGradOp : public pir::Op<SoftplusDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_double_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftplusDoubleGrad_Op : public pir::Op<SoftplusDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_double_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftplusGradOp : public pir::Op<SoftplusGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftplusGrad_Op : public pir::Op<SoftplusGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftshrinkGradOp : public pir::Op<SoftshrinkGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softshrink_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftshrinkGrad_Op : public pir::Op<SoftshrinkGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softshrink_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftsignGradOp : public pir::Op<SoftsignGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softsign_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftsignGrad_Op : public pir::Op<SoftsignGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softsign_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SolveGradOp : public pir::Op<SolveGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.solve_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SpectralNormGradOp : public pir::Op<SpectralNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.spectral_norm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, pir::Value out_grad_, int dim, int power_iters, float eps);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value weight() { return operand_source(0); }
  pir::Value u() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult weight_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqrtDoubleGradOp : public pir::Op<SqrtDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqrtDoubleGrad_Op : public pir::Op<SqrtDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqrtGradOp : public pir::Op<SqrtGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqrtGrad_Op : public pir::Op<SqrtGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquareDoubleGradOp : public pir::Op<SquareDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquareDoubleGrad_Op : public pir::Op<SquareDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquareGradOp : public pir::Op<SquareGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquareGrad_Op : public pir::Op<SquareGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SquaredL2NormGradOp : public pir::Op<SquaredL2NormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squared_l2_norm_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqueezeDoubleGradOp : public pir::Op<SqueezeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }
  pir::OpResult xshape() { return result(1); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqueezeGradOp : public pir::Op<SqueezeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqueezeGrad_Op : public pir::Op<SqueezeGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  StackGradOp : public pir::Op<StackGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stack_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  StanhGradOp : public pir::Op<StanhGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stanh_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float scale_a, float scale_b);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SvdGradOp : public pir::Op<SvdGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.svd_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value u_, pir::Value vh_, pir::Value s_, pir::Value u_grad_, pir::Value vh_grad_, pir::Value s_grad_, bool full_matrices);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value u_, pir::Value vh_, pir::Value s_, pir::Value u_grad_, pir::Value vh_grad_, pir::Value s_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value u() { return operand_source(1); }
  pir::Value vh() { return operand_source(2); }
  pir::Value s() { return operand_source(3); }
  pir::Value u_grad() { return operand_source(4); }
  pir::Value vh_grad() { return operand_source(5); }
  pir::Value s_grad() { return operand_source(6); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TakeAlongAxisGradOp : public pir::Op<TakeAlongAxisGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.take_along_axis_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult arr_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanGradOp : public pir::Op<TanGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanGrad_Op : public pir::Op<TanGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhDoubleGradOp : public pir::Op<TanhDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhDoubleGrad_Op : public pir::Op<TanhDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhGradOp : public pir::Op<TanhGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhGrad_Op : public pir::Op<TanhGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhShrinkGradOp : public pir::Op<TanhShrinkGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_shrink_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhShrinkGrad_Op : public pir::Op<TanhShrinkGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_shrink_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhTripleGradOp : public pir::Op<TanhTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_out_new_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_out_new_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_forward_grad() { return result(1); }
  pir::OpResult grad_x_grad_forward_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TanhTripleGrad_Op : public pir::Op<TanhTripleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_out_new_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_out_new_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::OpResult out_grad() { return result(0); }
  pir::OpResult grad_out_forward_grad() { return result(1); }
  pir::OpResult grad_x_grad_forward_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TemporalShiftGradOp : public pir::Op<TemporalShiftGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.temporal_shift_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int seg_num, float shift_ratio, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TensorUnfoldGradOp : public pir::Op<TensorUnfoldGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tensor_unfold_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, int64_t axis, int64_t size, int64_t step);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ThresholdedReluGradOp : public pir::Op<ThresholdedReluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ThresholdedReluGrad_Op : public pir::Op<ThresholdedReluGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TopkGradOp : public pir::Op<TopkGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.topk_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int k, int axis, bool largest, bool sorted);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::Value k_, int axis, bool largest, bool sorted);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value k() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TraceGradOp : public pir::Op<TraceGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trace_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int offset, int axis1, int axis2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TriangularSolveGradOp : public pir::Op<TriangularSolveGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triangular_solve_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, bool upper, bool transpose, bool unitriangular);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TrilinearInterpGradOp : public pir::Op<TrilinearInterpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trilinear_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_layout, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TruncGradOp : public pir::Op<TruncGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trunc_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnbindGradOp : public pir::Op<UnbindGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unbind_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult input_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnfoldGradOp : public pir::Op<UnfoldGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unfold_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UniformInplaceGradOp : public pir::Op<UniformInplaceGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UniformInplaceGrad_Op : public pir::Op<UniformInplaceGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace_grad_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnsqueezeDoubleGradOp : public pir::Op<UnsqueezeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }
  pir::OpResult xshape() { return result(1); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnsqueezeGradOp : public pir::Op<UnsqueezeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnsqueezeGrad_Op : public pir::Op<UnsqueezeGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnstackGradOp : public pir::Op<UnstackGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unstack_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ViewDtypeGradOp : public pir::Op<ViewDtypeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.view_dtype_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ViewShapeGradOp : public pir::Op<ViewShapeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.view_shape_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, const std::vector<int64_t>& dims={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WarpctcGradOp : public pir::Op<WarpctcGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warpctc_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value logits_length_, pir::Value warpctcgrad_, pir::Value loss_grad_, int blank, bool norm_by_times);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value logits_length_, pir::Value warpctcgrad_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value logits() { return operand_source(0); }
  pir::Value logits_length() { return operand_source(1); }
  pir::Value warpctcgrad() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::OpResult logits_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WarprnntGradOp : public pir::Op<WarprnntGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warprnnt_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value input_lengths_, pir::Value warprnntgrad_, pir::Value loss_grad_, int blank=0, float fastemit_lambda=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value input_lengths_, pir::Value warprnntgrad_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value input_lengths() { return operand_source(1); }
  pir::Value warprnntgrad() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WeightOnlyLinearGradOp : public pir::Op<WeightOnlyLinearGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_only_linear_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::Value out_grad_, const std::string& weight_dtype, int arch, int group_size);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight_scale() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WhereGradOp : public pir::Op<WhereGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.where_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  YoloLossGradOp : public pir::Op<YoloLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_loss_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, pir::Value objectness_mask_, pir::Value gt_match_mask_, pir::Value loss_grad_, const std::vector<int>& anchors, const std::vector<int>& anchor_mask, int class_num, float ignore_thresh, int downsample_ratio, bool use_label_smooth, float scale_x_y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, pir::Value objectness_mask_, pir::Value gt_match_mask_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value gt_box() { return operand_source(1); }
  pir::Value gt_label() { return operand_source(2); }
  pir::Value gt_score() { return operand_source(3); }
  pir::Value objectness_mask() { return operand_source(4); }
  pir::Value gt_match_mask() { return operand_source(5); }
  pir::Value loss_grad() { return operand_source(6); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult gt_box_grad() { return result(1); }
  pir::OpResult gt_label_grad() { return result(2); }
  pir::OpResult gt_score_grad() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SiluDoubleGradOp : public pir::Op<SiluDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult grad_out_grad() { return result(1); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Unpool3dGradOp : public pir::Op<Unpool3dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool3d_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_size, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};


class  AddActXpuOp : public pir::Op<AddActXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_act_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value y_, pir::Value y_max_, int act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value y_, pir::Value y_max_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value y_max() { return operand_source(3); }
  pir::OpResult out() { return result(0); }
  pir::OpResult out_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddLayernormXpuOp : public pir::Op<AddLayernormXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_layernorm_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, int begin_norm_axis, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddcmulXpuOp : public pir::Op<AddcmulXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addcmul_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BlockMultiheadAttention_Op : public pir::Op<BlockMultiheadAttention_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.block_multihead_attention_"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, int max_seq_len, int block_size, bool use_neox_style, bool dynamic_cachekv_quant=false, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0, float out_scale=-1, const std::string& compute_dtype="default");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value qkv() { return operand_source(0); }
  pir::Value key_cache() { return operand_source(1); }
  pir::Value value_cache() { return operand_source(2); }
  pir::Value seq_lens_encoder() { return operand_source(3); }
  pir::Value seq_lens_decoder() { return operand_source(4); }
  pir::Value seq_lens_this_time() { return operand_source(5); }
  pir::Value padding_offsets() { return operand_source(6); }
  pir::Value cum_offsets() { return operand_source(7); }
  pir::Value cu_seqlens_q() { return operand_source(8); }
  pir::Value cu_seqlens_k() { return operand_source(9); }
  pir::Value block_tables() { return operand_source(10); }
  pir::Value pre_key_cache() { return operand_source(11); }
  pir::Value pre_value_cache() { return operand_source(12); }
  pir::Value rope_emb() { return operand_source(13); }
  pir::Value mask() { return operand_source(14); }
  pir::Value tgt_mask() { return operand_source(15); }
  pir::Value cache_k_quant_scales() { return operand_source(16); }
  pir::Value cache_v_quant_scales() { return operand_source(17); }
  pir::Value cache_k_dequant_scales() { return operand_source(18); }
  pir::Value cache_v_dequant_scales() { return operand_source(19); }
  pir::Value qkv_out_scale() { return operand_source(20); }
  pir::Value qkv_bias() { return operand_source(21); }
  pir::Value out_shift() { return operand_source(22); }
  pir::Value out_smooth() { return operand_source(23); }
  pir::OpResult fmha_out() { return result(0); }
  pir::OpResult qkv_out() { return result(1); }
  pir::OpResult key_cache_out() { return result(2); }
  pir::OpResult value_cache_out() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BnActXpuOp : public pir::Op<BnActXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bn_act_xpu"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, float momentum, float epsilon, const std::string& data_layout, int act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv1dXpuOp : public pir::Op<Conv1dXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv1d_xpu"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, const std::vector<int>& paddings, const std::string& padding_algorithm, int dilations, int strides, int groups, int act_type, float act_param);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value filter_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value branch() { return operand_source(5); }
  pir::Value branch_max() { return operand_source(6); }
  pir::OpResult out() { return result(0); }
  pir::OpResult out_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dTransposeXpuOp : public pir::Op<Conv2dTransposeXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose_xpu"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format, bool has_bias, bool with_act, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value filter_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult out_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dXpuOp : public pir::Op<Conv2dXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_xpu"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, pir::Value scale_max_, pir::Value out_max_in_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, const std::string& padding_algorithm, int groups, int act_type, float act_param, phi::DataType out_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, pir::Value scale_max_, pir::Value out_max_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value filter_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value branch() { return operand_source(5); }
  pir::Value branch_max() { return operand_source(6); }
  pir::Value scale_max() { return operand_source(7); }
  pir::Value out_max_in() { return operand_source(8); }
  pir::OpResult out() { return result(0); }
  pir::OpResult out_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DequantizeXpuOp : public pir::Op<DequantizeXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dequantize_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType out_dtype, float scale=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult y() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EmbeddingWithEltwiseAddXpuOp : public pir::Op<EmbeddingWithEltwiseAddXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_with_eltwise_add_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value tables_, pir::Value mask_, int64_t padding_idx);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value tables_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value ids() { return operand_source(0); }
  pir::Value tables() { return operand_source(1); }
  pir::Value mask() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult seq_lod() { return result(1); }
  pir::OpResult max_seq_len() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FastLayernormXpuOp : public pir::Op<FastLayernormXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fast_layernorm_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, int begin_norm_axis, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FastWhereXpuOp : public pir::Op<FastWhereXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fast_where_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FcOp : public pir::Op<FcOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fc"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, int in_num_col_dims=1, const std::string& activation_type="", bool padding_weights=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FcXpuOp : public pir::Op<FcXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fc_xpu"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value w_, pir::Value w_max_, pir::Value bias_, pir::Value scale_max_, pir::Value out_max_in_, int in_num_col_dims, bool transpose_x, float alpha, float beta, int act_type, float act_alpha, phi::DataType out_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value w_, pir::Value w_max_, pir::Value bias_, pir::Value scale_max_, pir::Value out_max_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value w_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value scale_max() { return operand_source(5); }
  pir::Value out_max_in() { return operand_source(6); }
  pir::OpResult out() { return result(0); }
  pir::OpResult out_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBiasActOp : public pir::Op<FusedBiasActOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_act"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value dequant_scales_, pir::Value shift_, pir::Value smooth_, const std::string& act_method="gelu", const std::string& compute_dtype="default", float quant_scale=-1, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value dequant_scales_, pir::Value shift_, pir::Value smooth_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value bias() { return operand_source(1); }
  pir::Value dequant_scales() { return operand_source(2); }
  pir::Value shift() { return operand_source(3); }
  pir::Value smooth() { return operand_source(4); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBiasDropoutResidualLayerNormOp : public pir::Op<FusedBiasDropoutResidualLayerNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_dropout_residual_layer_norm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, float dropout_rate=0.5f, bool is_test=false, bool dropout_fix_seed=true, int dropout_seed=true, const std::string& dropout_implementation="downgrade_in_infer", float ln_epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value residual() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value ln_scale() { return operand_source(3); }
  pir::Value ln_bias() { return operand_source(4); }
  pir::OpResult y() { return result(0); }
  pir::OpResult bias_dropout_residual_out() { return result(1); }
  pir::OpResult dropout_mask_out() { return result(2); }
  pir::OpResult ln_mean() { return result(3); }
  pir::OpResult ln_variance() { return result(4); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
};

class  FusedBiasResidualLayernormOp : public pir::Op<FusedBiasResidualLayernormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_residual_layernorm"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, float epsilon, float residual_alpha, int begin_norm_axis, float quant_scale, int quant_round_type, float quant_max_bound, float quant_min_bound);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value bias() { return operand_source(1); }
  pir::Value residual() { return operand_source(2); }
  pir::Value norm_weight() { return operand_source(3); }
  pir::Value norm_bias() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult residual_out() { return result(1); }
  pir::OpResult mean() { return result(2); }
  pir::OpResult variance() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedConv2dAddActOp : public pir::Op<FusedConv2dAddActOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_conv2d_add_act"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value bias_, pir::Value residual_data_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& padding_algorithm="EXPLICIT", const std::vector<int>& dilations={1, 1}, int groups=1, const std::string& data_format="NCHW", const std::string& activation="relu", const std::vector<int>& split_channels={}, bool exhaustive_search=false, int workspace_size_MB=32, float fuse_alpha=0.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value bias_, pir::Value residual_data_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value residual_data() { return operand_source(3); }
  pir::OpResult output() { return result(0); }
  pir::OpResult outputs() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedDconvDreluDbnOp : public pir::Op<FusedDconvDreluDbnOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dconv_drelu_dbn"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_output_, pir::Value weight_, pir::Value grad_output_add_, pir::Value residual_input_, pir::Value bn1_eqscale_, pir::Value bn1_eqbias_, pir::Value conv_input_, pir::Value bn1_mean_, pir::Value bn1_inv_std_, pir::Value bn1_gamma_, pir::Value bn1_beta_, pir::Value bn1_input_, pir::Value bn2_mean_, pir::Value bn2_inv_std_, pir::Value bn2_gamma_, pir::Value bn2_beta_, pir::Value bn2_input_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, const std::string& padding_algorithm, int groups, const std::string& data_format, bool fuse_shortcut, bool fuse_dual, bool fuse_add, bool exhaustive_search);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_output_, pir::Value weight_, pir::Value grad_output_add_, pir::Value residual_input_, pir::Value bn1_eqscale_, pir::Value bn1_eqbias_, pir::Value conv_input_, pir::Value bn1_mean_, pir::Value bn1_inv_std_, pir::Value bn1_gamma_, pir::Value bn1_beta_, pir::Value bn1_input_, pir::Value bn2_mean_, pir::Value bn2_inv_std_, pir::Value bn2_gamma_, pir::Value bn2_beta_, pir::Value bn2_input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_output() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value grad_output_add() { return operand_source(2); }
  pir::Value residual_input() { return operand_source(3); }
  pir::Value bn1_eqscale() { return operand_source(4); }
  pir::Value bn1_eqbias() { return operand_source(5); }
  pir::Value conv_input() { return operand_source(6); }
  pir::Value bn1_mean() { return operand_source(7); }
  pir::Value bn1_inv_std() { return operand_source(8); }
  pir::Value bn1_gamma() { return operand_source(9); }
  pir::Value bn1_beta() { return operand_source(10); }
  pir::Value bn1_input() { return operand_source(11); }
  pir::Value bn2_mean() { return operand_source(12); }
  pir::Value bn2_inv_std() { return operand_source(13); }
  pir::Value bn2_gamma() { return operand_source(14); }
  pir::Value bn2_beta() { return operand_source(15); }
  pir::Value bn2_input() { return operand_source(16); }
  pir::OpResult grad_weight() { return result(0); }
  pir::OpResult grad_bn1_input() { return result(1); }
  pir::OpResult grad_bn1_gamma() { return result(2); }
  pir::OpResult grad_bn1_beta() { return result(3); }
  pir::OpResult grad_bn2_input() { return result(4); }
  pir::OpResult grad_bn2_gamma() { return result(5); }
  pir::OpResult grad_bn2_beta() { return result(6); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedDotProductAttentionOp : public pir::Op<FusedDotProductAttentionOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dot_product_attention"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value mask_, float scaling_factor, float dropout_probability, bool is_training=false, bool is_causal_masking=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value mask() { return operand_source(3); }
  pir::OpResult out() { return result(0); }
  pir::OpResult softmax_out() { return result(1); }
  pir::OpResult rng_state() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
};

class  FusedDropoutAddOp : public pir::Op<FusedDropoutAddOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dropout_add"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value seed_tensor_, float p, bool is_test, const std::string& mode, int seed=0, bool fix_seed=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value seed_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value seed_tensor() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult seed_offset() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
};

class  FusedEmbeddingEltwiseLayernormOp : public pir::Op<FusedEmbeddingEltwiseLayernormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_embedding_eltwise_layernorm"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value embs_, pir::Value bias_, pir::Value scale_, float epsilon=0.00001f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value embs_, pir::Value bias_, pir::Value scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value ids() { return operand_source(0); }
  pir::Value embs() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedFcElementwiseLayernormOp : public pir::Op<FusedFcElementwiseLayernormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_fc_elementwise_layernorm"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value y_, pir::Value bias0_, pir::Value scale_, pir::Value bias1_, int x_num_col_dims=1, const std::string& activation_type="", float epsilon=0.00001f, int begin_norm_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value y_, pir::Value bias0_, pir::Value scale_, pir::Value bias1_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value bias0() { return operand_source(3); }
  pir::Value scale() { return operand_source(4); }
  pir::Value bias1() { return operand_source(5); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean() { return result(1); }
  pir::OpResult variance() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedLinearParamGradAddOp : public pir::Op<FusedLinearParamGradAddOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_linear_param_grad_add"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dout_, pir::Value dweight_, pir::Value dbias_, bool multi_precision=true, bool has_bias=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dout_, pir::Value dweight_, pir::Value dbias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value dout() { return operand_source(1); }
  pir::Value dweight() { return operand_source(2); }
  pir::Value dbias() { return operand_source(3); }
  pir::OpResult dweight_out() { return result(0); }
  pir::OpResult dbias_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedMultiTransformerInt8XpuOp : public pir::Op<FusedMultiTransformerInt8XpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_multi_transformer_int8_xpu"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_in_max_, pir::Value qkvw_, pir::Value qkv_bias_, pir::Value qkv_scales_, pir::Value out_linear_in_max_, pir::Value out_linear_w_, pir::Value out_linear_bias_, pir::Value out_linear_scales_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_in_max_, pir::Value ffn1_weight_, pir::Value ffn1_bias_, pir::Value ffn1_scales_, pir::Value ffn2_in_max_, pir::Value ffn2_weight_, pir::Value ffn2_bias_, pir::Value ffn2_scales_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, bool pre_layer_norm, int rotary_emb_dims, float epsilon, float dropout_rate, bool is_test, const std::string& dropout_implementation, const std::string& act_method, bool trans_qkvw, int ring_id, int gather_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_in_max_, pir::Value qkvw_, pir::Value qkv_bias_, pir::Value qkv_scales_, pir::Value out_linear_in_max_, pir::Value out_linear_w_, pir::Value out_linear_bias_, pir::Value out_linear_scales_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_in_max_, pir::Value ffn1_weight_, pir::Value ffn1_bias_, pir::Value ffn1_scales_, pir::Value ffn2_in_max_, pir::Value ffn2_weight_, pir::Value ffn2_bias_, pir::Value ffn2_scales_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value ln_scale() { return operand_source(1); }
  pir::Value ln_bias() { return operand_source(2); }
  pir::Value qkv_in_max() { return operand_source(3); }
  pir::Value qkvw() { return operand_source(4); }
  pir::Value qkv_bias() { return operand_source(5); }
  pir::Value qkv_scales() { return operand_source(6); }
  pir::Value out_linear_in_max() { return operand_source(7); }
  pir::Value out_linear_w() { return operand_source(8); }
  pir::Value out_linear_bias() { return operand_source(9); }
  pir::Value out_linear_scales() { return operand_source(10); }
  pir::Value ffn_ln_scale() { return operand_source(11); }
  pir::Value ffn_ln_bias() { return operand_source(12); }
  pir::Value ffn1_in_max() { return operand_source(13); }
  pir::Value ffn1_weight() { return operand_source(14); }
  pir::Value ffn1_bias() { return operand_source(15); }
  pir::Value ffn1_scales() { return operand_source(16); }
  pir::Value ffn2_in_max() { return operand_source(17); }
  pir::Value ffn2_weight() { return operand_source(18); }
  pir::Value ffn2_bias() { return operand_source(19); }
  pir::Value ffn2_scales() { return operand_source(20); }
  pir::Value cache_kv() { return operand_source(21); }
  pir::Value pre_caches() { return operand_source(22); }
  pir::Value rotary_pos_emb() { return operand_source(23); }
  pir::Value time_step() { return operand_source(24); }
  pir::Value seq_lengths() { return operand_source(25); }
  pir::Value src_mask() { return operand_source(26); }
  pir::Value gather_index() { return operand_source(27); }
  pir::Value max_buffer() { return operand_source(28); }
  pir::OpResult out() { return result(0); }
  pir::OpResult cache_kv_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedMultiTransformerXpuOp : public pir::Op<FusedMultiTransformerXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_multi_transformer_xpu"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkvw_, pir::Value qkvw_max_, pir::Value qkv_bias_, pir::Value out_linear_w_, pir::Value out_linear_wmax_, pir::Value out_linear_bias_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_weight_, pir::Value ffn1_weight_max_, pir::Value ffn1_bias_, pir::Value ffn2_weight_, pir::Value ffn2_weight_max_, pir::Value ffn2_bias_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, bool pre_layer_norm, int rotary_emb_dims, float epsilon, float dropout_rate, bool is_test, const std::string& dropout_implementation, const std::string& act_method, bool trans_qkvw, int ring_id, int gather_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkvw_, pir::Value qkvw_max_, pir::Value qkv_bias_, pir::Value out_linear_w_, pir::Value out_linear_wmax_, pir::Value out_linear_bias_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_weight_, pir::Value ffn1_weight_max_, pir::Value ffn1_bias_, pir::Value ffn2_weight_, pir::Value ffn2_weight_max_, pir::Value ffn2_bias_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value ln_scale() { return operand_source(1); }
  pir::Value ln_bias() { return operand_source(2); }
  pir::Value qkvw() { return operand_source(3); }
  pir::Value qkvw_max() { return operand_source(4); }
  pir::Value qkv_bias() { return operand_source(5); }
  pir::Value out_linear_w() { return operand_source(6); }
  pir::Value out_linear_wmax() { return operand_source(7); }
  pir::Value out_linear_bias() { return operand_source(8); }
  pir::Value ffn_ln_scale() { return operand_source(9); }
  pir::Value ffn_ln_bias() { return operand_source(10); }
  pir::Value ffn1_weight() { return operand_source(11); }
  pir::Value ffn1_weight_max() { return operand_source(12); }
  pir::Value ffn1_bias() { return operand_source(13); }
  pir::Value ffn2_weight() { return operand_source(14); }
  pir::Value ffn2_weight_max() { return operand_source(15); }
  pir::Value ffn2_bias() { return operand_source(16); }
  pir::Value cache_kv() { return operand_source(17); }
  pir::Value pre_caches() { return operand_source(18); }
  pir::Value rotary_pos_emb() { return operand_source(19); }
  pir::Value time_step() { return operand_source(20); }
  pir::Value seq_lengths() { return operand_source(21); }
  pir::Value src_mask() { return operand_source(22); }
  pir::Value gather_index() { return operand_source(23); }
  pir::Value max_buffer() { return operand_source(24); }
  pir::OpResult out() { return result(0); }
  pir::OpResult cache_kv_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedRotaryPositionEmbeddingOp : public pir::Op<FusedRotaryPositionEmbeddingOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_rotary_position_embedding"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, bool use_neox_rotary_style=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value sin() { return operand_source(3); }
  pir::Value cos() { return operand_source(4); }
  pir::Value position_ids() { return operand_source(5); }
  pir::OpResult out_q() { return result(0); }
  pir::OpResult out_k() { return result(1); }
  pir::OpResult out_v() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
};

class  FusedScaleBiasAddReluOp : public pir::Op<FusedScaleBiasAddReluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_scale_bias_add_relu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x1_, pir::Value scale1_, pir::Value bias1_, pir::Value x2_, pir::Value scale2_, pir::Value bias2_, bool fuse_dual, bool exhaustive_search);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x1_, pir::Value scale1_, pir::Value bias1_, pir::Value x2_, pir::Value scale2_, pir::Value bias2_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x1() { return operand_source(0); }
  pir::Value scale1() { return operand_source(1); }
  pir::Value bias1() { return operand_source(2); }
  pir::Value x2() { return operand_source(3); }
  pir::Value scale2() { return operand_source(4); }
  pir::Value bias2() { return operand_source(5); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedScaleBiasReluConvBnOp : public pir::Op<FusedScaleBiasReluConvBnOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_scale_bias_relu_conv_bn"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value scale_, pir::Value bias_, pir::Value bn_scale_, pir::Value bn_bias_, pir::Value input_running_mean_, pir::Value input_running_var_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, const std::string& padding_algorithm, int groups, const std::string& data_format, float momentum, float epsilon, bool fuse_prologue, bool exhaustive_search, int64_t accumulation_count=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value scale_, pir::Value bias_, pir::Value bn_scale_, pir::Value bn_bias_, pir::Value input_running_mean_, pir::Value input_running_var_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value bn_scale() { return operand_source(4); }
  pir::Value bn_bias() { return operand_source(5); }
  pir::Value input_running_mean() { return operand_source(6); }
  pir::Value input_running_var() { return operand_source(7); }
  pir::OpResult out() { return result(0); }
  pir::OpResult out_running_mean() { return result(1); }
  pir::OpResult out_running_var() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_var() { return result(4); }
  pir::OpResult eq_scale() { return result(5); }
  pir::OpResult eq_bias() { return result(6); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusionGruOp : public pir::Op<FusionGruOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_gru"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value h0_, pir::Value weight_x_, pir::Value weight_h_, pir::Value bias_, const std::string& activation="tanh", const std::string& gate_activation="sigmoid", bool is_reverse=false, bool use_seq=true, bool origin_mode=false, bool use_mkldnn=false, const std::string& mkldnn_data_type="float32", float scale_data=1.0f, float shift_data=0.0f, const std::vector<float>& scale_weights={1.0f}, bool force_fp32_output=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value h0_, pir::Value weight_x_, pir::Value weight_h_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value h0() { return operand_source(1); }
  pir::Value weight_x() { return operand_source(2); }
  pir::Value weight_h() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::OpResult reordered_h0() { return result(0); }
  pir::OpResult xx() { return result(1); }
  pir::OpResult batched_input() { return result(2); }
  pir::OpResult batched_out() { return result(3); }
  pir::OpResult hidden() { return result(4); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusionRepeatedFcReluOp : public pir::Op<FusionRepeatedFcReluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_repeated_fc_relu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value bias_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult relu_out() { return result(0); }
  pir::OpResult out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusionSeqconvEltaddReluOp : public pir::Op<FusionSeqconvEltaddReluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_seqconv_eltadd_relu"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value bias_, int context_length, int context_start=0, int context_stride=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult col_mat() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusionSeqexpandConcatFcOp : public pir::Op<FusionSeqexpandConcatFcOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_seqexpand_concat_fc"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fc_weight_, pir::Value fc_bias_, const std::string& fc_activation="identity");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fc_weight_, pir::Value fc_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value fc_weight() { return operand_source(1); }
  pir::Value fc_bias() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult fc_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusionSquaredMatSubOp : public pir::Op<FusionSquaredMatSubOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_squared_mat_sub"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, float scalar=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult squared_x() { return result(0); }
  pir::OpResult squared_y() { return result(1); }
  pir::OpResult squared_xy() { return result(2); }
  pir::OpResult out() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusionTransposeFlattenConcatOp : public pir::Op<FusionTransposeFlattenConcatOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_transpose_flatten_concat"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& trans_axis, int flatten_axis, int concat_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GenerateSequenceXpuOp : public pir::Op<GenerateSequenceXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.generate_sequence_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LayerNormActXpuOp : public pir::Op<LayerNormActXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.layer_norm_act_xpu"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, int begin_norm_axis, float epsilon, int act_type, float act_param);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxPool2dV2Op : public pir::Op<MaxPool2dV2Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_v2"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_size, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& data_format="NCHW", bool global_pooling=false, bool adaptive=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult saved_idx() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
};

class  MultiEncoderXpuOp : public pir::Op<MultiEncoderXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multi_encoder_xpu"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fc_weight_, pir::Value fc_weight_max_, pir::Value fc_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value mask_, pir::Value seq_lod_, pir::Value max_seq_len_, int layer_num, bool norm_before, int hidden_dim, int head_num, int size_per_head, int ffn_hidden_dim_scale, int act_type, int relative_type, int slice_idx);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fc_weight_, pir::Value fc_weight_max_, pir::Value fc_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value mask_, pir::Value seq_lod_, pir::Value max_seq_len_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value fc_weight() { return operand_source(1); }
  pir::Value fc_weight_max() { return operand_source(2); }
  pir::Value fc_bias() { return operand_source(3); }
  pir::Value ln_scale() { return operand_source(4); }
  pir::Value ln_bias() { return operand_source(5); }
  pir::Value mask() { return operand_source(6); }
  pir::Value seq_lod() { return operand_source(7); }
  pir::Value max_seq_len() { return operand_source(8); }
  pir::OpResult out() { return result(0); }
  pir::OpResult x_fp16() { return result(1); }
  pir::OpResult out_fp16() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiheadMatmulOp : public pir::Op<MultiheadMatmulOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multihead_matmul"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::Value bias_qk_, bool transpose_q=false, bool transpose_k=true, bool transpose_v=false, float alpha=1.0f, int head_number=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::Value bias_qk_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value bias_qk() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  QkvAttentionXpuOp : public pir::Op<QkvAttentionXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.qkv_attention_xpu"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value q_max_, pir::Value k_max_, pir::Value v_max_, float alpha, int head_num, int head_dim, bool qkv_fc_fusion, phi::DataType out_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value q_max_, pir::Value k_max_, pir::Value v_max_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value q_max() { return operand_source(3); }
  pir::Value k_max() { return operand_source(4); }
  pir::Value v_max() { return operand_source(5); }
  pir::OpResult qkv() { return result(0); }
  pir::OpResult qkv_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  QuantizeXpuOp : public pir::Op<QuantizeXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.quantize_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType out_dtype, float scale=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult y() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SelfDpAttentionOp : public pir::Op<SelfDpAttentionOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.self_dp_attention"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0f, int head_number=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SinePosXpuOp : public pir::Op<SinePosXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sine_pos_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SkipLayernormOp : public pir::Op<SkipLayernormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.skip_layernorm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, float epsilon, int begin_norm_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SqueezeExcitationBlockOp : public pir::Op<SqueezeExcitationBlockOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_excitation_block"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, const std::vector<int>& act_type, const std::vector<float>& act_param, const std::vector<int>& filter_dims);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value filter_max() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value branch() { return operand_source(4); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  VariableLengthMemoryEfficientAttentionOp : public pir::Op<VariableLengthMemoryEfficientAttentionOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.variable_length_memory_efficient_attention"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value seq_lens_, pir::Value kv_seq_lens_, pir::Value mask_, float scale, bool causal, int pre_cache_length);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value seq_lens_, pir::Value kv_seq_lens_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value seq_lens() { return operand_source(3); }
  pir::Value kv_seq_lens() { return operand_source(4); }
  pir::Value mask() { return operand_source(5); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  YoloBoxXpuOp : public pir::Op<YoloBoxXpuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_box_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value grid_, pir::Value stride_, pir::Value anchor_grid_, float offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value grid_, pir::Value stride_, pir::Value anchor_grid_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value grid() { return operand_source(2); }
  pir::Value stride() { return operand_source(3); }
  pir::Value anchor_grid() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult out_max() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};


class  FusedBiasDropoutResidualLayerNormGradOp : public pir::Op<FusedBiasDropoutResidualLayerNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_dropout_residual_layer_norm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_grad_, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_mean_, pir::Value ln_variance_, pir::Value bias_dropout_residual_out_, pir::Value dropout_mask_out_, float dropout_rate=0.5f, bool is_test=false, bool dropout_fix_seed=true, int dropout_seed=true, const std::string& dropout_implementation="downgrade_in_infer", float ln_epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_grad_, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_mean_, pir::Value ln_variance_, pir::Value bias_dropout_residual_out_, pir::Value dropout_mask_out_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value y_grad() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value residual() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value ln_scale() { return operand_source(4); }
  pir::Value ln_bias() { return operand_source(5); }
  pir::Value ln_mean() { return operand_source(6); }
  pir::Value ln_variance() { return operand_source(7); }
  pir::Value bias_dropout_residual_out() { return operand_source(8); }
  pir::Value dropout_mask_out() { return operand_source(9); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult residual_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }
  pir::OpResult ln_scale_grad() { return result(3); }
  pir::OpResult ln_bias_grad() { return result(4); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedDotProductAttentionGradOp : public pir::Op<FusedDotProductAttentionGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dot_product_attention_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_out_, pir::Value rng_state_, pir::Value mask_, pir::Value out_grad_, float scaling_factor, float dropout_probability, bool is_causal_masking=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_out_, pir::Value rng_state_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value softmax_out() { return operand_source(4); }
  pir::Value rng_state() { return operand_source(5); }
  pir::Value mask() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::OpResult q_grad() { return result(0); }
  pir::OpResult k_grad() { return result(1); }
  pir::OpResult v_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedDropoutAddGradOp : public pir::Op<FusedDropoutAddGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dropout_add_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value seed_offset_, pir::Value out_grad_, float p, bool is_test, const std::string& mode, bool fix_seed);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value seed_offset_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value seed_offset() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedRotaryPositionEmbeddingGradOp : public pir::Op<FusedRotaryPositionEmbeddingGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_rotary_position_embedding_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, pir::Value out_q_grad_, pir::Value out_k_grad_, pir::Value out_v_grad_, bool use_neox_rotary_style);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, pir::Value out_q_grad_, pir::Value out_k_grad_, pir::Value out_v_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value sin() { return operand_source(0); }
  pir::Value cos() { return operand_source(1); }
  pir::Value position_ids() { return operand_source(2); }
  pir::Value out_q_grad() { return operand_source(3); }
  pir::Value out_k_grad() { return operand_source(4); }
  pir::Value out_v_grad() { return operand_source(5); }
  pir::OpResult q_grad() { return result(0); }
  pir::OpResult k_grad() { return result(1); }
  pir::OpResult v_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxPool2dV2GradOp : public pir::Op<MaxPool2dV2GradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_v2_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value saved_idx_, pir::Value out_grad_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& data_format, bool global_pooling, bool adaptive);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value saved_idx_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value saved_idx() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};


class  Adadelta_Op : public pir::Op<Adadelta_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adadelta_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value avg_squared_grad_, pir::Value avg_squared_update_, pir::Value learning_rate_, pir::Value master_param_, float rho, float epsilon, bool multi_precision);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value avg_squared_grad_, pir::Value avg_squared_update_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value avg_squared_grad() { return operand_source(2); }
  pir::Value avg_squared_update() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value master_param() { return operand_source(5); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment_out() { return result(1); }
  pir::OpResult inf_norm_out() { return result(2); }
  pir::OpResult master_param_out() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddOp : public pir::Op<AddOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Add_Op : public pir::Op<Add_Op,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AllOp : public pir::Op<AllOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.all"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AmaxOp : public pir::Op<AmaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amax"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AminOp : public pir::Op<AminOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amin"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AnyOp : public pir::Op<AnyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.any"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AssignOp : public pir::Op<AssignOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Assign_Op : public pir::Op<Assign_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AssignOut_Op : public pir::Op<AssignOut_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_out_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value output_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value output() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AssignValueOp : public pir::Op<AssignValueOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_value"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int>& shape, phi::DataType dtype, std::vector<phi::Scalar> values, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AssignValue_Op : public pir::Op<AssignValue_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_value_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, const std::vector<int>& shape, phi::DataType dtype, std::vector<phi::Scalar> values, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value output() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BatchNormOp : public pir::Op<BatchNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_layout, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean_out() { return result(1); }
  pir::OpResult variance_out() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_variance() { return result(4); }
  pir::OpResult reserve_space() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  BatchNorm_Op : public pir::Op<BatchNorm_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_layout, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean_out() { return result(1); }
  pir::OpResult variance_out() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_variance() { return result(4); }
  pir::OpResult reserve_space() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CAllgatherOp : public pir::Op<CAllgatherOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_allgather"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, int nranks, bool use_calc_stream);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CAllreduceMaxOp : public pir::Op<CAllreduceMaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_allreduce_max"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CAllreduceMax_Op : public pir::Op<CAllreduceMax_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_allreduce_max_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CAllreduceSumOp : public pir::Op<CAllreduceSumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_allreduce_sum"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CAllreduceSum_Op : public pir::Op<CAllreduceSum_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_allreduce_sum_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CBroadcastOp : public pir::Op<CBroadcastOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_broadcast"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int root=0, bool use_calc_stream=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CBroadcast_Op : public pir::Op<CBroadcast_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_broadcast_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int root=0, bool use_calc_stream=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CConcatOp : public pir::Op<CConcatOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_concat"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int rank, int nranks, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CEmbeddingOp : public pir::Op<CEmbeddingOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_embedding"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, int64_t start_index=0, int64_t vocab_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value weight() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CIdentityOp : public pir::Op<CIdentityOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_identity"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CIdentity_Op : public pir::Op<CIdentity_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_identity_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CReduceMinOp : public pir::Op<CReduceMinOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_reduce_min"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, int root_id, bool use_calc_stream);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CReduceMin_Op : public pir::Op<CReduceMin_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_reduce_min_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, int root_id, bool use_calc_stream);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CReduceSumOp : public pir::Op<CReduceSumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_reduce_sum"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, int root_id, bool use_calc_stream);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CReduceSum_Op : public pir::Op<CReduceSum_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_reduce_sum_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, int root_id, bool use_calc_stream);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CReducescatterOp : public pir::Op<CReducescatterOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_reducescatter"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int nranks=1, bool use_calc_stream=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CSyncCalcStreamOp : public pir::Op<CSyncCalcStreamOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_sync_calc_stream"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CSyncCalcStream_Op : public pir::Op<CSyncCalcStream_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_sync_calc_stream_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CSyncCommStreamOp : public pir::Op<CSyncCommStreamOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_sync_comm_stream"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CSyncCommStream_Op : public pir::Op<CSyncCommStream_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_sync_comm_stream_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CastOp : public pir::Op<CastOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Cast_Op : public pir::Op<Cast_Op,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ChannelShuffleOp : public pir::Op<ChannelShuffleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.channel_shuffle"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int groups, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dTransposeOp : public pir::Op<Conv2dTransposeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::vector<int64_t>& output_size={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value output_size_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value output_size() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CopyToOp : public pir::Op<CopyToOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.copy_to"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DecayedAdagradOp : public pir::Op<DecayedAdagradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.decayed_adagrad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, float decay=0.95f, float epsilon=1.0e-6f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value moment() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult moment_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DecodeJpegOp : public pir::Op<DecodeJpegOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.decode_jpeg"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& mode, const Place& place);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DeformableConvOp : public pir::Op<DeformableConvOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.deformable_conv"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations, int deformable_groups, int groups, int im2col_step);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value offset() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value mask() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DepthwiseConv2dTransposeOp : public pir::Op<DepthwiseConv2dTransposeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_transpose"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::vector<int64_t>& output_size={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value output_size_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value output_size() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DisableCheckModelNanInfOp : public pir::Op<DisableCheckModelNanInfOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.disable_check_model_nan_inf"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int flag=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DistributeFpnProposalsOp : public pir::Op<DistributeFpnProposalsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.distribute_fpn_proposals"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value fpn_rois_, pir::Value rois_num_, int min_level, int max_level, int refer_level, int refer_scale, bool pixel_offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value fpn_rois_, pir::Value rois_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value fpn_rois() { return operand_source(0); }
  pir::Value rois_num() { return operand_source(1); }
  pir::OpResult multi_fpn_rois() { return result(0); }
  pir::OpResult multi_level_rois_num() { return result(1); }
  pir::OpResult restore_index() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DivideOp : public pir::Op<DivideOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Divide_Op : public pir::Op<Divide_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DropoutOp : public pir::Op<DropoutOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dropout"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_tensor_, float p, bool is_test, const std::string& mode, int seed, bool fix_seed);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value seed_tensor() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mask() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  EinsumOp : public pir::Op<EinsumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.einsum"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& equation);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult inner_cache() { return result(1); }
  pir::OpResult xshape() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ElementwisePowOp : public pir::Op<ElementwisePowOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elementwise_pow"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EmbeddingOp : public pir::Op<EmbeddingOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, int64_t padding_idx=-1, bool sparse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SparseWeightEmbeddingOp : public pir::Op<SparseWeightEmbeddingOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_weight_embedding"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, int64_t padding_idx=-1, bool sparse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EmptyOp : public pir::Op<EmptyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.empty"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value shape() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EmptyLikeOp : public pir::Op<EmptyLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.empty_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype=phi::DataType::UNDEFINED, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EnableCheckModelNanInfOp : public pir::Op<EnableCheckModelNanInfOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.enable_check_model_nan_inf"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int flag=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EqualOp : public pir::Op<EqualOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Equal_Op : public pir::Op<Equal_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Exponential_Op : public pir::Op<Exponential_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exponential_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float lam);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EyeOp : public pir::Op<EyeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eye"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, float num_rows, float num_columns, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value num_rows_, pir::Value num_columns_, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value num_rows() { return operand_source(0); }
  pir::Value num_columns() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FeedOp : public pir::Op<FeedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.feed"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FetchOp : public pir::Op<FetchOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fetch"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& name, int col);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FloorDivideOp : public pir::Op<FloorDivideOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_divide"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FloorDivide_Op : public pir::Op<FloorDivide_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_divide_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FrobeniusNormOp : public pir::Op<FrobeniusNormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frobenius_norm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class TEST_API FullOp : public pir::Op<FullOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, float value, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Full_Op : public pir::Op<Full_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, const std::vector<int64_t>& shape, float value, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value output() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FullBatchSizeLikeOp : public pir::Op<FullBatchSizeLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_batch_size_like"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int>& shape, phi::DataType dtype, float value, int input_dim_idx, int output_dim_idx, const Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FullLikeOp : public pir::Op<FullLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value, phi::DataType dtype=phi::DataType::UNDEFINED, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value value_, phi::DataType dtype=phi::DataType::UNDEFINED, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  FullWithTensorOp : public pir::Op<FullWithTensorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_with_tensor"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, pir::Value value_, phi::DataType dtype=phi::DataType::FLOAT32);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value shape() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedAdam_Op : public pir::Op<FusedAdam_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_adam_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value params_, pir::Value grads_, pir::Value learning_rate_, pir::Value moments1_, pir::Value moments2_, pir::Value beta1_pows_, pir::Value beta2_pows_, pir::Value master_params_, pir::Value skip_update_, float beta1, float beta2, float epsilon, int chunk_size, float weight_decay, bool use_adamw, bool multi_precision, bool use_global_beta_pow);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value params_, pir::Value grads_, pir::Value learning_rate_, pir::Value moments1_, pir::Value moments2_, pir::Value beta1_pows_, pir::Value beta2_pows_, pir::Value master_params_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value params() { return operand_source(0); }
  pir::Value grads() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moments1() { return operand_source(3); }
  pir::Value moments2() { return operand_source(4); }
  pir::Value beta1_pows() { return operand_source(5); }
  pir::Value beta2_pows() { return operand_source(6); }
  pir::Value master_params() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::OpResult params_out() { return result(0); }
  pir::OpResult moments1_out() { return result(1); }
  pir::OpResult moments2_out() { return result(2); }
  pir::OpResult beta1_pows_out() { return result(3); }
  pir::OpResult beta2_pows_out() { return result(4); }
  pir::OpResult master_params_out() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBatchNormActOp : public pir::Op<FusedBatchNormActOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_batch_norm_act"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean() { return operand_source(3); }
  pir::Value variance() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean_out() { return result(1); }
  pir::OpResult variance_out() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_variance() { return result(4); }
  pir::OpResult reserve_space() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBatchNormAct_Op : public pir::Op<FusedBatchNormAct_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_batch_norm_act_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean() { return operand_source(3); }
  pir::Value variance() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean_out() { return result(1); }
  pir::OpResult variance_out() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_variance() { return result(4); }
  pir::OpResult reserve_space() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBnAddActivationOp : public pir::Op<FusedBnAddActivationOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bn_add_activation"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value z() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean_out() { return result(1); }
  pir::OpResult variance_out() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_variance() { return result(4); }
  pir::OpResult reserve_space() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBnAddActivation_Op : public pir::Op<FusedBnAddActivation_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bn_add_activation_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value z() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean_out() { return result(1); }
  pir::OpResult variance_out() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_variance() { return result(4); }
  pir::OpResult reserve_space() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedSoftmaxMaskUpperTriangleOp : public pir::Op<FusedSoftmaxMaskUpperTriangleOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_softmax_mask_upper_triangle"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value X_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value X() { return operand_source(0); }
  pir::OpResult Out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GaussianOp : public pir::Op<GaussianOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, float mean, float std, int seed, phi::DataType dtype, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, float mean, float std, int seed, phi::DataType dtype, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value shape() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GetTensorFromSelectedRowsOp : public pir::Op<GetTensorFromSelectedRowsOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.get_tensor_from_selected_rows"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GreaterEqualOp : public pir::Op<GreaterEqualOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GreaterEqual_Op : public pir::Op<GreaterEqual_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GreaterThanOp : public pir::Op<GreaterThanOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_than"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  GreaterThan_Op : public pir::Op<GreaterThan_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_than_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardswishOp : public pir::Op<HardswishOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardswish"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HsigmoidLossOp : public pir::Op<HsigmoidLossOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hsigmoid_loss"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value w_, pir::Value bias_, pir::Value path_, pir::Value code_, int num_classes, bool is_sparse);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value w_, pir::Value bias_, pir::Value path_, pir::Value code_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value path() { return operand_source(4); }
  pir::Value code() { return operand_source(5); }
  pir::OpResult out() { return result(0); }
  pir::OpResult pre_out() { return result(1); }
  pir::OpResult w_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LessEqualOp : public pir::Op<LessEqualOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LessEqual_Op : public pir::Op<LessEqual_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LessThanOp : public pir::Op<LessThanOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_than"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LessThan_Op : public pir::Op<LessThan_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_than_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LinspaceOp : public pir::Op<LinspaceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.linspace"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value number_, phi::DataType dtype, const Place& place);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value number_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value start() { return operand_source(0); }
  pir::Value stop() { return operand_source(1); }
  pir::Value number() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LoadCombineOp : public pir::Op<LoadCombineOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.load_combine"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult Out() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LodArrayLengthOp : public pir::Op<LodArrayLengthOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lod_array_length"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogspaceOp : public pir::Op<LogspaceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logspace"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value num_, pir::Value base_, phi::DataType dtype, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value num_, pir::Value base_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value start() { return operand_source(0); }
  pir::Value stop() { return operand_source(1); }
  pir::Value num() { return operand_source(2); }
  pir::Value base() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogsumexpOp : public pir::Op<LogsumexpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsumexp"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis, bool keepdim, bool reduce_all);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatmulOp : public pir::Op<MatmulOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool transpose_x=false, bool transpose_y=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatrixRankOp : public pir::Op<MatrixRankOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_rank"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float tol, bool use_default_tol=true, bool hermitian=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatrixRankTolOp : public pir::Op<MatrixRankTolOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_rank_tol"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value atol_tensor_, bool use_default_tol=true, bool hermitian=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value atol_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value atol_tensor() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxOp : public pir::Op<MaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaximumOp : public pir::Op<MaximumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maximum"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MeanOp : public pir::Op<MeanOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  MemcpyOp : public pir::Op<MemcpyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memcpy"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MemcpyD2hOp : public pir::Op<MemcpyD2hOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memcpy_d2h"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MemcpyH2dOp : public pir::Op<MemcpyH2dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memcpy_h2d"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MinOp : public pir::Op<MinOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.min"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MinimumOp : public pir::Op<MinimumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.minimum"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MishOp : public pir::Op<MishOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mish"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float lambda);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplyOp : public pir::Op<MultiplyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplySrOp : public pir::Op<MultiplySrOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Multiply_Op : public pir::Op<Multiply_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplySr_Op : public pir::Op<MultiplySr_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_sr_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NormOp : public pir::Op<NormOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.norm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis, float epsilon, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult norm() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NotEqualOp : public pir::Op<NotEqualOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.not_equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NotEqual_Op : public pir::Op<NotEqual_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.not_equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  OneHotOp : public pir::Op<OneHotOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.one_hot"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int num_classes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value num_classes_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value num_classes() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  OnesOp : public pir::Op<OnesOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ones"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place=phi::CPUPlace());
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  OnesLikeOp : public pir::Op<OnesLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ones_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype=phi::DataType::UNDEFINED, const Place& place={});
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PadOp : public pir::Op<PadOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& paddings, float pad_value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pad_value_, const std::vector<int>& paddings);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value pad_value() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pool2dOp : public pir::Op<Pool2dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool2d"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_size_, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value kernel_size() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pool3dOp : public pir::Op<Pool3dOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool3d"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PrintOp : public pir::Op<PrintOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.print"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value in_, int first_n, const std::string& message, int summarize, bool print_tensor_name=true, bool print_tensor_type=true, bool print_tensor_shape=true, bool print_tensor_layout=true, bool print_tensor_lod=true, const std::string& print_phase="BOTH", bool is_forward=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value in() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ProdOp : public pir::Op<ProdOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prod"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& dims, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dims_, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value dims() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RandintOp : public pir::Op<RandintOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.randint"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int low, int high, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::INT64, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, int low, int high, phi::DataType dtype=phi::DataType::INT64, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value shape() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RandpermOp : public pir::Op<RandpermOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.randperm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int n, phi::DataType dtype, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReadFileOp : public pir::Op<ReadFileOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.read_file"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::string& filename="", phi::DataType dtype=phi::DataType::UINT8, const Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RecvV2Op : public pir::Op<RecvV2Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.recv_v2"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int>& out_shape={}, phi::DataType dtype=phi::DataType::FLOAT32, int peer=0, int ring_id=0, bool use_calc_stream=false, bool dynamic_shape=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RemainderOp : public pir::Op<RemainderOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.remainder"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Remainder_Op : public pir::Op<Remainder_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.remainder_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RepeatInterleaveOp : public pir::Op<RepeatInterleaveOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int repeats, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RepeatInterleaveWithTensorIndexOp : public pir::Op<RepeatInterleaveWithTensorIndexOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_with_tensor_index"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value repeats() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReshapeOp : public pir::Op<ReshapeOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Reshape_Op : public pir::Op<Reshape_Op,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult xshape() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RnnOp : public pir::Op<RnnOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rnn"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, float dropout_prob=0.0, bool is_bidirec=false, int input_size=10, int hidden_size=100, int num_layers=1, const std::string& mode="RNN_TANH", int seed=0, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value pre_state() { return operand_source(1); }
  pir::Value weight_list() { return operand_source(2); }
  pir::Value sequence_length() { return operand_source(3); }
  pir::Value dropout_state_in() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult dropout_state_out() { return result(1); }
  pir::OpResult state() { return result(2); }
  pir::OpResult reserve() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Rnn_Op : public pir::Op<Rnn_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rnn_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, float dropout_prob=0.0, bool is_bidirec=false, int input_size=10, int hidden_size=100, int num_layers=1, const std::string& mode="RNN_TANH", int seed=0, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value pre_state() { return operand_source(1); }
  pir::Value weight_list() { return operand_source(2); }
  pir::Value sequence_length() { return operand_source(3); }
  pir::Value dropout_state_in() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult dropout_state_out() { return result(1); }
  pir::OpResult state() { return result(2); }
  pir::OpResult reserve() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RowConvOp : public pir::Op<RowConvOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.row_conv"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RreluOp : public pir::Op<RreluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rrelu"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float lower, float upper, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult noise() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SaveCombineOp : public pir::Op<SaveCombineOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.save_combine"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SeedOp : public pir::Op<SeedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.seed"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int seed, bool deterministic, const std::string& rng_name, bool force_cpu);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SendV2Op : public pir::Op<SendV2Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_v2"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int peer=0, bool use_calc_stream=false, bool dynamic_shape=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SetValueOp : public pir::Op<SetValueOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value steps() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SetValue_Op : public pir::Op<SetValue_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value steps() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SetValueWithTensorOp : public pir::Op<SetValueWithTensorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_with_tensor"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value values() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value steps() { return operand_source(4); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SetValueWithTensor_Op : public pir::Op<SetValueWithTensor_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_with_tensor_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value values() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value steps() { return operand_source(4); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ShadowFeedOp : public pir::Op<ShadowFeedOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shadow_feed"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ShareDataOp : public pir::Op<ShareDataOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.share_data"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ShuffleBatchOp : public pir::Op<ShuffleBatchOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shuffle_batch"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_, int startup_seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value seed() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult shuffle_idx() { return result(1); }
  pir::OpResult seed_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SliceOp : public pir::Op<SliceOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value input() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftReluOp : public pir::Op<SoftReluOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.soft_relu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=20.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftmaxOp : public pir::Op<SoftmaxOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::OpResult>> Decomp(pir::Operation* op);
};

class  Softmax_Op : public pir::Op<Softmax_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SplitOp : public pir::Op<SplitOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.split"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& sections, int axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value sections_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value sections() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SplitWithNumOp : public pir::Op<SplitWithNumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.split_with_num"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int num, int axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, int num);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  StridedSliceOp : public pir::Op<StridedSliceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.strided_slice"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& strides);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, pir::Value strides_, const std::vector<int>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value strides() { return operand_source(3); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SubtractOp : public pir::Op<SubtractOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Subtract_Op : public pir::Op<Subtract_Op,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::ShapeConstraintIRAnalysis* shape_analysis);

  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SumOp : public pir::Op<SumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SwishOp : public pir::Op<SwishOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swish"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SyncBatchNorm_Op : public pir::Op<SyncBatchNorm_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_batch_norm_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_layout, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::OpResult out() { return result(0); }
  pir::OpResult mean_out() { return result(1); }
  pir::OpResult variance_out() { return result(2); }
  pir::OpResult saved_mean() { return result(3); }
  pir::OpResult saved_variance() { return result(4); }
  pir::OpResult reserve_space() { return result(5); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TileOp : public pir::Op<TileOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tile"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& repeat_times={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeat_times_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value repeat_times() { return operand_source(1); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TransLayoutOp : public pir::Op<TransLayoutOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trans_layout"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TransposeOp : public pir::Op<TransposeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Transpose_Op : public pir::Op<Transpose_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TrilOp : public pir::Op<TrilOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Tril_Op : public pir::Op<Tril_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TrilIndicesOp : public pir::Op<TrilIndicesOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril_indices"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int rows, int cols, int offset, phi::DataType dtype, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TriuOp : public pir::Op<TriuOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Triu_Op : public pir::Op<Triu_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TriuIndicesOp : public pir::Op<TriuIndicesOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu_indices"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int row, int col, int offset, phi::DataType dtype, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TruncatedGaussianRandomOp : public pir::Op<TruncatedGaussianRandomOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.truncated_gaussian_random"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int>& shape, float mean, float std, int seed, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class TEST_API UniformOp : public pir::Op<UniformOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype, float min, float max, int seed, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, pir::Value min_, pir::Value max_, phi::DataType dtype, int seed, const Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value shape() { return operand_source(0); }
  pir::Value min() { return operand_source(1); }
  pir::Value max() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UniformRandomBatchSizeLikeOp : public pir::Op<UniformRandomBatchSizeLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_random_batch_size_like"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int>& shape, int input_dim_idx=0, int output_dim_idx=0, float min=-1.0f, float max=1.0f, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0f, phi::DataType dtype=phi::DataType::FLOAT32);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UniqueOp : public pir::Op<UniqueOp,paddle::dialect::ParseKernelKeyInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unique"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool return_index=false, bool return_inverse=false, bool return_counts=false, const std::vector<int>& axis={}, phi::DataType dtype=phi::DataType::INT64, bool is_sorted=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);


  static std::tuple<phi::DataType, phi::Backend> ParseKernelKey(pir::Operation *op);


  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }
  pir::OpResult indices() { return result(1); }
  pir::OpResult inverse() { return result(2); }
  pir::OpResult counts() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnpoolOp : public pir::Op<UnpoolOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::vector<int64_t>& output_size, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value output_size_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value output_size() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  WriteToArrayOp : public pir::Op<WriteToArrayOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.write_to_array"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value i() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::OpResult out() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ZerosOp : public pir::Op<ZerosOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.zeros"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::FLOAT32, const Place& place=phi::CPUPlace());
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ZerosLikeOp : public pir::Op<ZerosLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.zeros_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype=phi::DataType::UNDEFINED, const Place& place={});
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CSoftmaxWithCrossEntropyOp : public pir::Op<CSoftmaxWithCrossEntropyOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_softmax_with_cross_entropy"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, int64_t ignore_index=-100, int ring_id=0, int rank=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::OpResult softmax() { return result(0); }
  pir::OpResult loss() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DpsgdOp : public pir::Op<DpsgdOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dpsgd"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, float clip=10.0f, float batch_size=16.0f, float sigma=1.0f, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::OpResult param_out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FtrlOp : public pir::Op<FtrlOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ftrl"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value squared_accumulator_, pir::Value linear_accumulator_, pir::Value grad_, pir::Value learning_rate_, float l1=0.0f, float l2=0.0f, float lr_power=-0.5f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value squared_accumulator_, pir::Value linear_accumulator_, pir::Value grad_, pir::Value learning_rate_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value squared_accumulator() { return operand_source(1); }
  pir::Value linear_accumulator() { return operand_source(2); }
  pir::Value grad() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult squared_accum_out() { return result(1); }
  pir::OpResult linear_accum_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedAttentionOp : public pir::Op<FusedAttentionOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_attention"; }
  static const char *attributes_name[16];
  static constexpr uint32_t attributes_num = 16;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value cache_kv_, pir::Value src_mask_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, int num_heads, bool transpose_qkv_wb, bool pre_layer_norm, float epsilon, float attn_dropout_rate, bool is_test, bool attn_dropout_fix_seed, int attn_dropout_seed, const std::string& attn_dropout_implementation, float dropout_rate, bool dropout_fix_seed, int dropout_seed, const std::string& dropout_implementation, float ln_epsilon, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value cache_kv_, pir::Value src_mask_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value ln_scale() { return operand_source(1); }
  pir::Value ln_bias() { return operand_source(2); }
  pir::Value qkv_weight() { return operand_source(3); }
  pir::Value qkv_bias() { return operand_source(4); }
  pir::Value cache_kv() { return operand_source(5); }
  pir::Value src_mask() { return operand_source(6); }
  pir::Value out_linear_weight() { return operand_source(7); }
  pir::Value out_linear_bias() { return operand_source(8); }
  pir::Value ln_scale_2() { return operand_source(9); }
  pir::Value ln_bias_2() { return operand_source(10); }
  pir::OpResult ln_mean() { return result(0); }
  pir::OpResult ln_var() { return result(1); }
  pir::OpResult ln_out() { return result(2); }
  pir::OpResult qkv_out() { return result(3); }
  pir::OpResult qkv_bias_out() { return result(4); }
  pir::OpResult transpose_out_2() { return result(5); }
  pir::OpResult qk_out() { return result(6); }
  pir::OpResult qktv_out() { return result(7); }
  pir::OpResult softmax_out() { return result(8); }
  pir::OpResult attn_dropout_mask_out() { return result(9); }
  pir::OpResult attn_dropout_out() { return result(10); }
  pir::OpResult src_mask_out() { return result(11); }
  pir::OpResult fmha_out() { return result(12); }
  pir::OpResult out_linear_out() { return result(13); }
  pir::OpResult dropout_mask_out() { return result(14); }
  pir::OpResult ln_mean_2() { return result(15); }
  pir::OpResult ln_var_2() { return result(16); }
  pir::OpResult bias_dropout_residual_out() { return result(17); }
  pir::OpResult cache_kv_out() { return result(18); }
  pir::OpResult out() { return result(19); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedElemwiseAddActivationOp : public pir::Op<FusedElemwiseAddActivationOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elemwise_add_activation"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<std::string>& functor_list, float scale=0.0, int axis=-1, bool save_intermediate_out=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::OpResult out() { return result(0); }
  pir::OpResult intermediate_out() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedFeedforwardOp : public pir::Op<FusedFeedforwardOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_feedforward"; }
  static const char *attributes_name[15];
  static constexpr uint32_t attributes_num = 15;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dropout1_seed_, pir::Value dropout2_seed_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value linear2_bias_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln2_scale_, pir::Value ln2_bias_, bool pre_layer_norm, float ln1_epsilon, float ln2_epsilon, const std::string& act_method, float dropout1_prob, float dropout2_prob, const std::string& dropout1_implementation, const std::string& dropout2_implementation, bool is_test, bool dropout1_fix_seed, bool dropout2_fix_seed, int dropout1_seed_val, int dropout2_seed_val, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dropout1_seed_, pir::Value dropout2_seed_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value linear2_bias_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln2_scale_, pir::Value ln2_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value dropout1_seed() { return operand_source(1); }
  pir::Value dropout2_seed() { return operand_source(2); }
  pir::Value linear1_weight() { return operand_source(3); }
  pir::Value linear1_bias() { return operand_source(4); }
  pir::Value linear2_weight() { return operand_source(5); }
  pir::Value linear2_bias() { return operand_source(6); }
  pir::Value ln1_scale() { return operand_source(7); }
  pir::Value ln1_bias() { return operand_source(8); }
  pir::Value ln2_scale() { return operand_source(9); }
  pir::Value ln2_bias() { return operand_source(10); }
  pir::OpResult out() { return result(0); }
  pir::OpResult dropout1_mask() { return result(1); }
  pir::OpResult dropout2_mask() { return result(2); }
  pir::OpResult ln1_mean() { return result(3); }
  pir::OpResult ln1_variance() { return result(4); }
  pir::OpResult ln2_mean() { return result(5); }
  pir::OpResult ln2_variance() { return result(6); }
  pir::OpResult linear1_out() { return result(7); }
  pir::OpResult ln1_out() { return result(8); }
  pir::OpResult dropout1_out() { return result(9); }
  pir::OpResult dropout2_out() { return result(10); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NceOp : public pir::Op<NceOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nce"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value bias_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, int num_total_classes, const std::vector<int>& custom_neg_classes={}, int num_neg_samples=10, int sampler=0, int seed=0, bool is_sparse=false, bool remote_prefetch=false, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value bias_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value sample_weight() { return operand_source(4); }
  pir::Value custom_dist_probs() { return operand_source(5); }
  pir::Value custom_dist_alias() { return operand_source(6); }
  pir::Value custom_dist_alias_probs() { return operand_source(7); }
  pir::OpResult cost() { return result(0); }
  pir::OpResult sample_logits() { return result(1); }
  pir::OpResult sample_labels() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NumberCountOp : public pir::Op<NumberCountOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.number_count"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value numbers_, int upper_range);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value numbers_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value numbers() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  OnednnToPaddleLayoutOp : public pir::Op<OnednnToPaddleLayoutOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.onednn_to_paddle_layout"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_layout);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SparseMomentumOp : public pir::Op<SparseMomentumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_momentum"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value index_, pir::Value learning_rate_, pir::Value master_param_, float mu, float axis=0, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value index_, pir::Value learning_rate_, pir::Value master_param_, pir::Value axis_, float mu, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value index_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value index() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value master_param() { return operand_source(5); }
  pir::Value axis() { return operand_source(6); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult velocity_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatchMatrixTensorOp : public pir::Op<MatchMatrixTensorOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.match_matrix_tensor"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, int dim_t=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::OpResult out() { return result(0); }
  pir::OpResult tmp() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LarsMomentumOp : public pir::Op<LarsMomentumOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lars_momentum"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, float lars_coeff=0.001f, const std::vector<float>& lars_weight_decay={0.0005f}, float epsilon=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult velocity_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LarsMomentum_Op : public pir::Op<LarsMomentum_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lars_momentum_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, float lars_coeff=0.001f, const std::vector<float>& lars_weight_decay={0.0005f}, float epsilon=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::OpResult param_out() { return result(0); }
  pir::OpResult velocity_out() { return result(1); }
  pir::OpResult master_param_out() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};


class  AddDoubleGradOp : public pir::Op<AddDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddDoubleGrad_Op : public pir::Op<AddDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddGradOp : public pir::Op<AddGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddGrad_Op : public pir::Op<AddGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddTripleGradOp : public pir::Op<AddTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_triple_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_grad_x() { return operand_source(0); }
  pir::Value grad_grad_y() { return operand_source(1); }
  pir::Value grad_grad_out_grad() { return operand_source(2); }
  pir::OpResult grad_grad_x_grad() { return result(0); }
  pir::OpResult grad_grad_y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AddTripleGrad_Op : public pir::Op<AddTripleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_triple_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_grad_x() { return operand_source(0); }
  pir::Value grad_grad_y() { return operand_source(1); }
  pir::Value grad_grad_out_grad() { return operand_source(2); }
  pir::OpResult grad_grad_x_grad() { return result(0); }
  pir::OpResult grad_grad_y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AmaxGradOp : public pir::Op<AmaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amax_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AminGradOp : public pir::Op<AminGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amin_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AssignGradOp : public pir::Op<AssignGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AssignOutGradOp : public pir::Op<AssignOutGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_out__grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  AssignOutGrad_Op : public pir::Op<AssignOutGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_out__grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BatchNormDoubleGradOp : public pir::Op<BatchNormDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_double_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, float momentum, float epsilon, const std::string& data_layout, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out_mean() { return operand_source(2); }
  pir::Value out_variance() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value grad_out() { return operand_source(6); }
  pir::Value grad_x_grad() { return operand_source(7); }
  pir::Value grad_scale_grad() { return operand_source(8); }
  pir::Value grad_bias_grad() { return operand_source(9); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BatchNormDoubleGrad_Op : public pir::Op<BatchNormDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_double_grad_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, float momentum, float epsilon, const std::string& data_layout, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out_mean() { return operand_source(2); }
  pir::Value out_variance() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value grad_out() { return operand_source(6); }
  pir::Value grad_x_grad() { return operand_source(7); }
  pir::Value grad_scale_grad() { return operand_source(8); }
  pir::Value grad_bias_grad() { return operand_source(9); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  BatchNormGradOp : public pir::Op<BatchNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_out_, pir::Value variance_out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& data_layout, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_out_, pir::Value variance_out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean_out() { return operand_source(3); }
  pir::Value variance_out() { return operand_source(4); }
  pir::Value saved_mean() { return operand_source(5); }
  pir::Value saved_variance() { return operand_source(6); }
  pir::Value reserve_space() { return operand_source(7); }
  pir::Value out_grad() { return operand_source(8); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CEmbeddingGradOp : public pir::Op<CEmbeddingGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_embedding_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, pir::Value out_grad_, int64_t start_index=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value weight() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult weight_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CSoftmaxWithCrossEntropyGradOp : public pir::Op<CSoftmaxWithCrossEntropyGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_softmax_with_cross_entropy_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value loss_grad_, int64_t ignore_index=-100, int ring_id=0, int rank=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value softmax() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::OpResult logits_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  CastGradOp : public pir::Op<CastGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ChannelShuffleGradOp : public pir::Op<ChannelShuffleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.channel_shuffle_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int groups, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dTransposeDoubleGradOp : public pir::Op<Conv2dTransposeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose_double_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_filter_grad_, pir::Value output_size_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::Value output_size() { return operand_source(5); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Conv2dTransposeGradOp : public pir::Op<Conv2dTransposeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::Value output_size_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value output_size() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DeformableConvGradOp : public pir::Op<DeformableConvGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.deformable_conv_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations, int deformable_groups, int groups, int im2col_step);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value offset() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value mask() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult offset_grad() { return result(1); }
  pir::OpResult filter_grad() { return result(2); }
  pir::OpResult mask_grad() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DepthwiseConv2dTransposeGradOp : public pir::Op<DepthwiseConv2dTransposeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_transpose_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::Value output_size_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value output_size() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DivideDoubleGradOp : public pir::Op<DivideDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value y() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value grad_x() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::OpResult y_grad() { return result(0); }
  pir::OpResult out_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DivideDoubleGrad_Op : public pir::Op<DivideDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value y() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value grad_x() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::OpResult y_grad() { return result(0); }
  pir::OpResult out_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DivideGradOp : public pir::Op<DivideGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DropoutGradOp : public pir::Op<DropoutGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dropout_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value mask_, pir::Value out_grad_, float p, bool is_test, const std::string& mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value mask() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EinsumGradOp : public pir::Op<EinsumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.einsum_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_shape_, pir::Value inner_cache_, pir::Value out_grad_, const std::string& equation);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_shape_, pir::Value inner_cache_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x_shape() { return operand_source(0); }
  pir::Value inner_cache() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ElementwisePowGradOp : public pir::Op<ElementwisePowGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elementwise_pow_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EmbeddingGradOp : public pir::Op<EmbeddingGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult weight_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EmbeddingSparseGradOp : public pir::Op<EmbeddingSparseGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_sparse_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult weight_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SparseWeightEmbeddingGradOp : public pir::Op<SparseWeightEmbeddingGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_weight_embedding_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult weight_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SparseWeightEmbeddingSparseGradOp : public pir::Op<SparseWeightEmbeddingSparseGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_weight_embedding_sparse_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult weight_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ExponentialGradOp : public pir::Op<ExponentialGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exponential__grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FrobeniusNormGradOp : public pir::Op<FrobeniusNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frobenius_norm_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value axis_, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedAttentionGradOp : public pir::Op<FusedAttentionGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_attention_grad"; }
  static const char *attributes_name[16];
  static constexpr uint32_t attributes_num = 16;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value qkv_bias_out_, pir::Value src_mask_, pir::Value src_mask_out_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, pir::Value ln_out_, pir::Value ln_mean_, pir::Value ln_var_, pir::Value ln_mean_2_, pir::Value ln_var_2_, pir::Value bias_dropout_residual_out_, pir::Value qkv_out_, pir::Value transpose_out_2_, pir::Value qk_out_, pir::Value qktv_out_, pir::Value softmax_out_, pir::Value attn_dropout_mask_out_, pir::Value attn_dropout_out_, pir::Value fmha_out_, pir::Value out_linear_out_, pir::Value dropout_mask_out_, int num_heads, bool transpose_qkv_wb, bool pre_layer_norm, float epsilon, float attn_dropout_rate, bool is_test, bool attn_dropout_fix_seed, int attn_dropout_seed, const std::string& attn_dropout_implementation, float dropout_rate, bool dropout_fix_seed, int dropout_seed, const std::string& dropout_implementation, float ln_epsilon, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value qkv_bias_out_, pir::Value src_mask_, pir::Value src_mask_out_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, pir::Value ln_out_, pir::Value ln_mean_, pir::Value ln_var_, pir::Value ln_mean_2_, pir::Value ln_var_2_, pir::Value bias_dropout_residual_out_, pir::Value qkv_out_, pir::Value transpose_out_2_, pir::Value qk_out_, pir::Value qktv_out_, pir::Value softmax_out_, pir::Value attn_dropout_mask_out_, pir::Value attn_dropout_out_, pir::Value fmha_out_, pir::Value out_linear_out_, pir::Value dropout_mask_out_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value qkv_weight() { return operand_source(2); }
  pir::Value qkv_bias() { return operand_source(3); }
  pir::Value qkv_bias_out() { return operand_source(4); }
  pir::Value src_mask() { return operand_source(5); }
  pir::Value src_mask_out() { return operand_source(6); }
  pir::Value out_linear_weight() { return operand_source(7); }
  pir::Value out_linear_bias() { return operand_source(8); }
  pir::Value ln_scale() { return operand_source(9); }
  pir::Value ln_bias() { return operand_source(10); }
  pir::Value ln_scale_2() { return operand_source(11); }
  pir::Value ln_bias_2() { return operand_source(12); }
  pir::Value ln_out() { return operand_source(13); }
  pir::Value ln_mean() { return operand_source(14); }
  pir::Value ln_var() { return operand_source(15); }
  pir::Value ln_mean_2() { return operand_source(16); }
  pir::Value ln_var_2() { return operand_source(17); }
  pir::Value bias_dropout_residual_out() { return operand_source(18); }
  pir::Value qkv_out() { return operand_source(19); }
  pir::Value transpose_out_2() { return operand_source(20); }
  pir::Value qk_out() { return operand_source(21); }
  pir::Value qktv_out() { return operand_source(22); }
  pir::Value softmax_out() { return operand_source(23); }
  pir::Value attn_dropout_mask_out() { return operand_source(24); }
  pir::Value attn_dropout_out() { return operand_source(25); }
  pir::Value fmha_out() { return operand_source(26); }
  pir::Value out_linear_out() { return operand_source(27); }
  pir::Value dropout_mask_out() { return operand_source(28); }
  pir::OpResult qkv_bias_grad() { return result(0); }
  pir::OpResult qkv_bias_out_grad() { return result(1); }
  pir::OpResult src_mask_out_grad() { return result(2); }
  pir::OpResult out_linear_bias_grad() { return result(3); }
  pir::OpResult ln_scale_grad() { return result(4); }
  pir::OpResult ln_bias_grad() { return result(5); }
  pir::OpResult ln_scale_2_grad() { return result(6); }
  pir::OpResult ln_bias_2_grad() { return result(7); }
  pir::OpResult x_grad() { return result(8); }
  pir::OpResult qkv_weight_grad() { return result(9); }
  pir::OpResult out_linear_weight_grad() { return result(10); }
  pir::OpResult ln_out_grad() { return result(11); }
  pir::OpResult bias_dropout_residual_out_grad() { return result(12); }
  pir::OpResult qkv_out_grad() { return result(13); }
  pir::OpResult qktv_out_grad() { return result(14); }
  pir::OpResult transpose_out_2_grad() { return result(15); }
  pir::OpResult qk_out_grad() { return result(16); }
  pir::OpResult softmax_out_grad() { return result(17); }
  pir::OpResult attn_dropout_out_grad() { return result(18); }
  pir::OpResult fmha_out_grad() { return result(19); }
  pir::OpResult out_linear_out_grad() { return result(20); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBatchNormActGradOp : public pir::Op<FusedBatchNormActGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_batch_norm_act_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value reserve_space() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedBnAddActivationGradOp : public pir::Op<FusedBnAddActivationGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bn_add_activation_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value reserve_space() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult z_grad() { return result(1); }
  pir::OpResult scale_grad() { return result(2); }
  pir::OpResult bias_grad() { return result(3); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedFeedforwardGradOp : public pir::Op<FusedFeedforwardGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_feedforward_grad"; }
  static const char *attributes_name[15];
  static constexpr uint32_t attributes_num = 15;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value dropout1_mask_, pir::Value dropout2_mask_, pir::Value linear1_out_, pir::Value dropout1_out_, pir::Value dropout2_out_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln1_out_, pir::Value ln1_mean_, pir::Value ln1_variance_, pir::Value ln2_scale_, pir::Value ln2_bias_, pir::Value ln2_mean_, pir::Value ln2_variance_, pir::Value linear2_bias_, bool pre_layer_norm, float ln1_epsilon, float ln2_epsilon, const std::string& act_method, float dropout1_prob, float dropout2_prob, const std::string& dropout1_implementation, const std::string& dropout2_implementation, bool is_test, bool dropout1_fix_seed, bool dropout2_fix_seed, int dropout1_seed_val, int dropout2_seed_val, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value dropout1_mask_, pir::Value dropout2_mask_, pir::Value linear1_out_, pir::Value dropout1_out_, pir::Value dropout2_out_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln1_out_, pir::Value ln1_mean_, pir::Value ln1_variance_, pir::Value ln2_scale_, pir::Value ln2_bias_, pir::Value ln2_mean_, pir::Value ln2_variance_, pir::Value linear2_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value linear1_weight() { return operand_source(2); }
  pir::Value linear1_bias() { return operand_source(3); }
  pir::Value linear2_weight() { return operand_source(4); }
  pir::Value dropout1_mask() { return operand_source(5); }
  pir::Value dropout2_mask() { return operand_source(6); }
  pir::Value linear1_out() { return operand_source(7); }
  pir::Value dropout1_out() { return operand_source(8); }
  pir::Value dropout2_out() { return operand_source(9); }
  pir::Value ln1_scale() { return operand_source(10); }
  pir::Value ln1_bias() { return operand_source(11); }
  pir::Value ln1_out() { return operand_source(12); }
  pir::Value ln1_mean() { return operand_source(13); }
  pir::Value ln1_variance() { return operand_source(14); }
  pir::Value ln2_scale() { return operand_source(15); }
  pir::Value ln2_bias() { return operand_source(16); }
  pir::Value ln2_mean() { return operand_source(17); }
  pir::Value ln2_variance() { return operand_source(18); }
  pir::Value linear2_bias() { return operand_source(19); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult ln1_scale_grad() { return result(1); }
  pir::OpResult ln1_bias_grad() { return result(2); }
  pir::OpResult ln2_scale_grad() { return result(3); }
  pir::OpResult ln2_bias_grad() { return result(4); }
  pir::OpResult linear1_weight_grad() { return result(5); }
  pir::OpResult linear1_bias_grad() { return result(6); }
  pir::OpResult linear2_weight_grad() { return result(7); }
  pir::OpResult linear2_bias_grad() { return result(8); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedSoftmaxMaskUpperTriangleGradOp : public pir::Op<FusedSoftmaxMaskUpperTriangleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_softmax_mask_upper_triangle_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value Out_, pir::Value Out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value Out() { return operand_source(0); }
  pir::Value Out_grad() { return operand_source(1); }
  pir::OpResult X_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardswishGradOp : public pir::Op<HardswishGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardswish_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HardswishGrad_Op : public pir::Op<HardswishGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardswish_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  HsigmoidLossGradOp : public pir::Op<HsigmoidLossGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hsigmoid_loss_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value label_, pir::Value path_, pir::Value code_, pir::Value bias_, pir::Value pre_out_, pir::Value out_grad_, int num_classes, bool is_sparse);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value label_, pir::Value path_, pir::Value code_, pir::Value bias_, pir::Value pre_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value label() { return operand_source(2); }
  pir::Value path() { return operand_source(3); }
  pir::Value code() { return operand_source(4); }
  pir::Value bias() { return operand_source(5); }
  pir::Value pre_out() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult w_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  LogsumexpGradOp : public pir::Op<LogsumexpGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsumexp_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keepdim, bool reduce_all);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatmulDoubleGradOp : public pir::Op<MatmulDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_double_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, bool transpose_x=false, bool transpose_y=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatmulGradOp : public pir::Op<MatmulGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, bool transpose_x=false, bool transpose_y=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaxGradOp : public pir::Op<MaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value axis_, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MaximumGradOp : public pir::Op<MaximumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maximum_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MeanDoubleGradOp : public pir::Op<MeanDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_double_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::OpResult grad_out_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MeanGradOp : public pir::Op<MeanGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MinGradOp : public pir::Op<MinGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.min_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value axis_, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MinimumGradOp : public pir::Op<MinimumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.minimum_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MishGradOp : public pir::Op<MishGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mish_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float lambda);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MishGrad_Op : public pir::Op<MishGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mish_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float lambda);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplyDoubleGradOp : public pir::Op<MultiplyDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplyDoubleGrad_Op : public pir::Op<MultiplyDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }
  pir::OpResult grad_out_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplyGradOp : public pir::Op<MultiplyGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MultiplyTripleGradOp : public pir::Op<MultiplyTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_triple_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value fwd_grad_out_, pir::Value fwd_grad_grad_x_, pir::Value fwd_grad_grad_y_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::Value grad_grad_out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value fwd_grad_out_, pir::Value fwd_grad_grad_x_, pir::Value fwd_grad_grad_y_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value fwd_grad_out() { return operand_source(2); }
  pir::Value fwd_grad_grad_x() { return operand_source(3); }
  pir::Value fwd_grad_grad_y() { return operand_source(4); }
  pir::Value grad_x_grad() { return operand_source(5); }
  pir::Value grad_y_grad() { return operand_source(6); }
  pir::Value grad_grad_out_grad() { return operand_source(7); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }
  pir::OpResult fwd_grad_out_grad() { return result(2); }
  pir::OpResult fwd_grad_grad_x_grad() { return result(3); }
  pir::OpResult fwd_grad_grad_y_grad() { return result(4); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NceGradOp : public pir::Op<NceGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nce_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value bias_, pir::Value weight_, pir::Value sample_logits_, pir::Value sample_labels_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::Value cost_grad_, int num_total_classes, const std::vector<int>& custom_neg_classes={}, int num_neg_samples=10, int sampler=0, int seed=0, bool is_sparse=false, bool remote_prefetch=false, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value bias_, pir::Value weight_, pir::Value sample_logits_, pir::Value sample_labels_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::Value cost_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight() { return operand_source(3); }
  pir::Value sample_logits() { return operand_source(4); }
  pir::Value sample_labels() { return operand_source(5); }
  pir::Value sample_weight() { return operand_source(6); }
  pir::Value custom_dist_probs() { return operand_source(7); }
  pir::Value custom_dist_alias() { return operand_source(8); }
  pir::Value custom_dist_alias_probs() { return operand_source(9); }
  pir::Value cost_grad() { return operand_source(10); }
  pir::OpResult input_grad() { return result(0); }
  pir::OpResult bias_grad() { return result(1); }
  pir::OpResult weight_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  NormGradOp : public pir::Op<NormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.norm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value norm_, pir::Value out_grad_, int axis, float epsilon, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value norm_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value norm() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PadDoubleGradOp : public pir::Op<PadDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int>& paddings, float pad_value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::Value pad_value_, const std::vector<int>& paddings);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value pad_value() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  PadGradOp : public pir::Op<PadGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& paddings, float pad_value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value pad_value_, const std::vector<int>& paddings);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value pad_value() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pool2dDoubleGradOp : public pir::Op<Pool2dDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool2d_double_grad"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, const std::vector<int64_t>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::Value kernel_size_, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value kernel_size() { return operand_source(2); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pool2dGradOp : public pir::Op<Pool2dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool2d_grad"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value kernel_size_, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value kernel_size() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  Pool3dGradOp : public pir::Op<Pool3dGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool3d_grad"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ProdGradOp : public pir::Op<ProdGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prod_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& dims, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value dims_, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value dims() { return operand_source(3); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RepeatInterleaveGradOp : public pir::Op<RepeatInterleaveGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int repeats, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RepeatInterleaveWithTensorIndexGradOp : public pir::Op<RepeatInterleaveWithTensorIndexGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_with_tensor_index_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value repeats() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReshapeDoubleGradOp : public pir::Op<ReshapeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReshapeDoubleGrad_Op : public pir::Op<ReshapeDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReshapeGradOp : public pir::Op<ReshapeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ReshapeGrad_Op : public pir::Op<ReshapeGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xshape_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value xshape() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RnnGradOp : public pir::Op<RnnGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rnn_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value out_, pir::Value dropout_state_out_, pir::Value reserve_, pir::Value out_grad_, pir::Value state_grad_, float dropout_prob, bool is_bidirec, int input_size, int hidden_size, int num_layers, const std::string& mode, int seed, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value out_, pir::Value dropout_state_out_, pir::Value reserve_, pir::Value out_grad_, pir::Value state_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value pre_state() { return operand_source(1); }
  pir::Value weight_list() { return operand_source(2); }
  pir::Value sequence_length() { return operand_source(3); }
  pir::Value out() { return operand_source(4); }
  pir::Value dropout_state_out() { return operand_source(5); }
  pir::Value reserve() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value state_grad() { return operand_source(8); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult pre_state_grad() { return result(1); }
  pir::OpResult weight_list_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RowConvGradOp : public pir::Op<RowConvGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.row_conv_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult filter_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  RreluGradOp : public pir::Op<RreluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rrelu_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value noise_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value noise() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SetValueGradOp : public pir::Op<SetValueGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SetValueWithTensorGradOp : public pir::Op<SetValueWithTensorGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_with_tensor_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value out_grad_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value values() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value steps() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult values_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SliceDoubleGradOp : public pir::Op<SliceDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_double_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_input_grad() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::OpResult grad_out_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SliceGradOp : public pir::Op<SliceGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::OpResult input_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftReluGradOp : public pir::Op<SoftReluGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.soft_relu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SoftmaxGradOp : public pir::Op<SoftmaxGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SplitWithNumGradOp : public pir::Op<SplitWithNumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.split_with_num_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  StridedSliceGradOp : public pir::Op<StridedSliceGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.strided_slice_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& strides);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, pir::Value strides_, const std::vector<int>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value strides() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SubtractDoubleGradOp : public pir::Op<SubtractDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SubtractDoubleGrad_Op : public pir::Op<SubtractDoubleGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::OpResult grad_out_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SubtractGradOp : public pir::Op<SubtractGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SubtractGrad_Op : public pir::Op<SubtractGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SumDoubleGradOp : public pir::Op<SumDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SumGradOp : public pir::Op<SumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keepdim, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_, bool keepdim, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SwishGradOp : public pir::Op<SwishGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swish_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SwishGrad_Op : public pir::Op<SwishGrad_Op,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swish_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SyncBatchNormGradOp : public pir::Op<SyncBatchNormGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_batch_norm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& data_layout, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value saved_mean() { return operand_source(3); }
  pir::Value saved_variance() { return operand_source(4); }
  pir::Value reserve_space() { return operand_source(5); }
  pir::Value out_grad() { return operand_source(6); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult scale_grad() { return result(1); }
  pir::OpResult bias_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TileDoubleGradOp : public pir::Op<TileDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tile_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value repeat_times() { return operand_source(1); }
  pir::OpResult grad_out_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TileGradOp : public pir::Op<TileGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tile_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& repeat_times);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value repeat_times_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value repeat_times() { return operand_source(2); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TransLayoutGradOp : public pir::Op<TransLayoutGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trans_layout_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TransposeDoubleGradOp : public pir::Op<TransposeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value grad_x_grad() { return operand_source(0); }
  pir::OpResult grad_out_grad() { return result(0); }


  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TransposeGradOp : public pir::Op<TransposeGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TrilGradOp : public pir::Op<TrilGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  TriuGradOp : public pir::Op<TriuGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  DisableCheckModelNanInfGradOp : public pir::Op<DisableCheckModelNanInfGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.disable_check_model_nan_inf_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int unsetflag=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  EnableCheckModelNanInfGradOp : public pir::Op<EnableCheckModelNanInfGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.enable_check_model_nan_inf_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int unsetflag=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value out_grad() { return operand_source(0); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  FusedElemwiseAddActivationGradOp : public pir::Op<FusedElemwiseAddActivationGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elemwise_add_activation_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value intermediate_out_, pir::Value out_grad_, const std::vector<std::string>& functor_list, float scale=0.0, int axis=-1, bool save_intermediate_out=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value intermediate_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value intermediate_out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  ShuffleBatchGradOp : public pir::Op<ShuffleBatchGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shuffle_batch_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shuffle_idx_, pir::Value out_grad_, int startup_seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shuffle_idx_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value shuffle_idx() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  UnpoolGradOp : public pir::Op<UnpoolGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::vector<int64_t>& output_size, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, pir::Value output_size_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value output_size() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  MatchMatrixTensorGradOp : public pir::Op<MatchMatrixTensorGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.match_matrix_tensor_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, pir::Value tmp_, pir::Value out_grad_, int dim_t=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, pir::Value tmp_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value tmp() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::OpResult x_grad() { return result(0); }
  pir::OpResult y_grad() { return result(1); }
  pir::OpResult w_grad() { return result(2); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};


class  ArangeOp : public pir::Op<ArangeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.arange"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, float start, float end, float step, phi::DataType dtype=phi::DataType::FLOAT64, const Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value end_, pir::Value step_, phi::DataType dtype=phi::DataType::FLOAT64, const Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value start() { return operand_source(0); }
  pir::Value end() { return operand_source(1); }
  pir::Value step() { return operand_source(2); }
  pir::OpResult out() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

class  SequenceMaskOp : public pir::Op<SequenceMaskOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::InferMetaInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_mask"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int max_len, int out_dtype);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value max_len_, int out_dtype);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  pir::Value x() { return operand_source(0); }
  pir::Value max_len() { return operand_source(1); }
  pir::OpResult y() { return result(0); }

  static void InferMeta( phi::InferMetaContext *infer_meta );
  static std::vector<std::vector<pir::OpResult>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
};

} // namespace dialect
} // namespace paddle


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Abs_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AccuracyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Acos_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Acosh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adagrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AdagradDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AdamDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adamax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adamw_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Addmm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineGridOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllcloseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AngleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgsortOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsComplexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsRealOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsStridedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Asin_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Asinh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atan2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atanh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AucOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AverageAccumulates_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLoss_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BernoulliOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BicubicInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BincountOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BinomialOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseAndOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseAnd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseNotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseNot_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseOrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseOr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseXorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseXor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BmmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BoxCoderOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BroadcastTensorsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeilOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Ceil_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CheckFiniteAndUnscale_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CheckNumericsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskySolveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClassCenterSampleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Clip_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipByNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipByNormSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoalesceTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ComplexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConjOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dTransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cos_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoshOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cosh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CropOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CummaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumprodOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cumprod_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumsumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cumsum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DataOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DetOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagEmbedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagonalOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DigammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Digamma_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DirichletOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EditDistanceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EighOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigvalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigvalshOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Elu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EqualAllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Erf_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfinvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Erfinv_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Exp_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandAsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2cOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2rOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftR2cOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Fill_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonal_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnUnpaddedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlattenOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Flatten_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlipOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Floor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FoldOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrameOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullIntArrayOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GammalnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Gammaln_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherNdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherTreeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplace_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GeluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GenerateProposalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GridSampleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GroupNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GumbelSoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardshrinkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardsigmoidOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardtanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Hardtanh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HeavisideOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HistogramOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HuberLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0eOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1eOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLoss_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ImagOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAdd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexPutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexPut_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSampleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectStridedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InstanceNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InverseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsEmptyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IscloseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsfiniteOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsfiniteSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsinfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsinfSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsnanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsnanSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KldivLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KronOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KthvalueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LabelSmoothOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lamb_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LambSr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LayerNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyRelu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LerpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lerp_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LgammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lgamma_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LinearInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LlmInt8LinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1p_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogSoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogcumsumexpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalAndOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalAnd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalNotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalNot_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalOrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalOr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalXorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalXor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Logit_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsigmoidOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LstsqOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuUnpackOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MarginCrossEntropyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedMultiheadAttention_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedSelectOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixNmsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixPowerOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dWithIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool3dWithIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxoutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanAllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemoryEfficientAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MergeSelectedRowsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MergedAdam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MergedMomentum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeshgridOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ModeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Momentum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MomentumDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiDotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MulticlassNms3Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultinomialOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NanmedianOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NearestInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NextafterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NllLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NmsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NonzeroOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NpuIdentityOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NumelOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OverlapAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pad3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelShuffleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelUnshuffleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PoissonOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PolygammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Polygamma_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pow_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PreluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PriorBoxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PsroiPoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PutAlongAxisOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PutAlongAxis_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RealOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReciprocalOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Reciprocal_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReindexGraphOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RenormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Renorm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReverseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RmsNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rmsprop_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RmspropDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiAlignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiPoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RollOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoundOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Round_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rprop_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rsqrt_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Scale_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleSr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Scatter_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterNdAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SearchsortedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SegmentPoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SeluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendURecvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUeRecvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sgd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SgdDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SgdSparseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShapeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShapeSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShardIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sigmoid_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogitsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogits_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sin_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sinh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SlogdetOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftshrinkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftsignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SolveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SpectralNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sqrt_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtSr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquaredL2NormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Squeeze_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StackOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StandardGammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SvdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TakeAlongAxisOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Tan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Tanh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhShrinkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TemporalShiftOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TensorUnfoldOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedRelu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TopPSamplingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TopkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TraceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriangularSolveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilinearInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TruncOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Trunc_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnbindOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnfoldOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplace_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniqueConsecutiveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Unpool3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Unsqueeze_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnstackOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UpdateLossScaling_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViewDtypeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViewShapeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViterbiDecodeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarpctcOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarprnntOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightDequantizeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightOnlyLinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightQuantizeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightedSampleNeighborsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WhereOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Where_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloBoxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloLossOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineGridGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AngleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgsortGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsComplexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsRealGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsStridedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atan2GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLossGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BicubicInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BmmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BroadcastTensorsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeilGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeilGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskySolveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ComplexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConcatDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConcatGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConjGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dGradGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dTransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoshGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoshGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CropGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmaxGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CummaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumminGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumprodGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumsumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DetGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagonalGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DigammaGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DotGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EighGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigvalshGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfinvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandAsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2cGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2rGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftR2cGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensorGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnUnpaddedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlattenGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlattenGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlipGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FminGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FoldGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrameGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GammalnGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherNdGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplaceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplaceGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GeluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GridSampleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GroupNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GroupNormGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GumbelSoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardshrinkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardshrinkGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardsigmoidGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardsigmoidGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardtanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardtanhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HeavisideGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HuberLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0eGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1eGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLossGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ImagGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAddGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexPutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSampleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectStridedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InstanceNormDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InstanceNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InverseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KldivLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KronGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KthvalueGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LabelSmoothGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LayerNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LerpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LgammaGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LinearInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogSoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogcumsumexpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogitGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsigmoidGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsigmoidGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuUnpackGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MarginCrossEntropyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MarginCrossEntropyGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedSelectGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixPowerGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dWithIndexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool3dWithIndexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxoutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanAllGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemoryEfficientAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeshgridGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ModeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiDotGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NanmedianGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NearestInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NllLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OverlapAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pad3dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pad3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelShuffleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelUnshuffleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PoissonGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PolygammaGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PreluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PsroiPoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PutAlongAxisGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QrGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RealGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReciprocalGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReciprocalGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RenormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReverseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiAlignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiPoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RollGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoundGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoundGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterNdAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SegmentPoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SeluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendURecvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUeRecvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogitsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogitsGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SlogdetGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftshrinkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftshrinkGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftsignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftsignGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SolveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SpectralNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquaredL2NormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StackGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SvdGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TakeAlongAxisGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhShrinkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhShrinkGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TemporalShiftGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TensorUnfoldGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedReluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TopkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TraceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriangularSolveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilinearInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TruncGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnbindGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnfoldGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplaceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplaceGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnstackGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViewDtypeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViewShapeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarpctcGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarprnntGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightOnlyLinearGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WhereGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Unpool3dGradOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddActXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddLayernormXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddcmulXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BlockMultiheadAttention_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BnActXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv1dXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DequantizeXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingWithEltwiseAddXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FastLayernormXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FastWhereXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FcOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FcXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasActOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasDropoutResidualLayerNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasResidualLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedConv2dAddActOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDconvDreluDbnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDotProductAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDropoutAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedEmbeddingEltwiseLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedFcElementwiseLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedLinearParamGradAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedMultiTransformerInt8XpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedMultiTransformerXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedRotaryPositionEmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedScaleBiasAddReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedScaleBiasReluConvBnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionGruOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionRepeatedFcReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionSeqconvEltaddReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionSeqexpandConcatFcOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionSquaredMatSubOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionTransposeFlattenConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GenerateSequenceXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LayerNormActXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dV2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiEncoderXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiheadMatmulOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QkvAttentionXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QuantizeXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SelfDpAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinePosXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SkipLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeExcitationBlockOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::VariableLengthMemoryEfficientAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloBoxXpuOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasDropoutResidualLayerNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDotProductAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDropoutAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedRotaryPositionEmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dV2GradOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adadelta_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Add_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AnyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Assign_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignOut_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignValueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignValue_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNorm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CAllgatherOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CAllreduceMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CAllreduceMax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CAllreduceSumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CAllreduceSum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CBroadcastOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CBroadcast_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CEmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CIdentityOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CIdentity_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CReduceMinOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CReduceMin_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CReduceSumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CReduceSum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CReducescatterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSyncCalcStreamOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSyncCalcStream_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSyncCommStreamOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSyncCommStream_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cast_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ChannelShuffleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CopyToOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DecayedAdagradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DecodeJpegOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DeformableConvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dTransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DisableCheckModelNanInfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistributeFpnProposalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Divide_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DropoutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EinsumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ElementwisePowOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseWeightEmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmptyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmptyLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EnableCheckModelNanInfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Equal_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Exponential_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EyeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FeedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FetchOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorDivideOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorDivide_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrobeniusNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Full_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullBatchSizeLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullWithTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAdam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBatchNormActOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBatchNormAct_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBnAddActivationOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBnAddActivation_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSoftmaxMaskUpperTriangleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GetTensorFromSelectedRowsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterEqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterEqual_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterThanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterThan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardswishOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HsigmoidLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessEqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessEqual_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessThanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessThan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LinspaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LoadCombineOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LodArrayLengthOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogspaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsumexpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixRankOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixRankTolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaximumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemcpyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemcpyD2hOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemcpyH2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinimumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MishOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplySrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Multiply_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplySr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NotEqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NotEqual_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OneHotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OnesOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OnesLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PadOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PrintOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ProdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RandintOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RandpermOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReadFileOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RecvV2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RemainderOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Remainder_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveWithTensorIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Reshape_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RnnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rnn_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RowConvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RreluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SaveCombineOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SeedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendV2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValue_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueWithTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueWithTensor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShadowFeedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShareDataOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShuffleBatchOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Softmax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SplitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SplitWithNumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StridedSliceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Subtract_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwishOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncBatchNorm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TileOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransLayoutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Transpose_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Tril_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilIndicesOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Triu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriuIndicesOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TruncatedGaussianRandomOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformRandomBatchSizeLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniqueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnpoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WriteToArrayOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ZerosOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ZerosLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSoftmaxWithCrossEntropyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DpsgdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FtrlOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElemwiseAddActivationOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedFeedforwardOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NumberCountOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OnednnToPaddleLayoutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseMomentumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatchMatrixTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LarsMomentumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LarsMomentum_Op)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AminGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignOutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignOutGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CEmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSoftmaxWithCrossEntropyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ChannelShuffleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DeformableConvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dTransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DropoutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EinsumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ElementwisePowGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingSparseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseWeightEmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseWeightEmbeddingSparseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExponentialGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrobeniusNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBatchNormActGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBnAddActivationGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedFeedforwardGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSoftmaxMaskUpperTriangleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardswishGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardswishGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HsigmoidLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsumexpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaximumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinimumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MishGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MishGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PadDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PadGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool2dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ProdGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveWithTensorIndexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RnnGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RowConvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RreluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueWithTensorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SplitWithNumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StridedSliceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwishGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwishGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncBatchNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TileDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TileGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransLayoutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriuGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DisableCheckModelNanInfGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EnableCheckModelNanInfGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElemwiseAddActivationGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShuffleBatchGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnpoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatchMatrixTensorGradOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArangeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceMaskOp)

