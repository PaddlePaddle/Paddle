
- op : add
  extra_args : str mkldnn_data_type="float32", bool use_quantizer=false, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0

- op : add_grad
  extra_args : str mkldnn_data_type="float32", bool use_quantizer=false, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0

- op : add_double_grad
  extra_args : str mkldnn_data_type="float32", bool use_quantizer=false, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0

- op : add_triple_grad
  extra_args : str mkldnn_data_type="float32", bool use_quantizer=false, float scale_x=1.0, float scale_y=1.0, float scale_out=1.0

- op : abs

- op : abs_grad

# - op : add_n

- op : batch_norm
  extra_args : bool fuse_with_relu=false
  data_format_tensors : x

- op : batch_norm_grad
  extra_args : bool fuse_with_relu=false
  data_format_tensors : x, out_grad

# - op : bilinear_interp

- op : cast
  dynamic_fallback : True

- op : clip
  extra_args : str mkldnn_data_type="float32"

- op : clip_grad
  extra_args : str mkldnn_data_type="float32"

# - op : concat

# - op : concat_grad

- op : conv2d
  extra_args : bool is_test=false
  data_format_tensors : input

- op : conv2d_grad
  extra_args : bool is_test=false
  data_format_tensors : input, out_grad

- op : conv3d
  extra_args : bool is_test=false
  data_format_tensors : input

- op : conv3d_grad
  extra_args : bool is_test=false
  data_format_tensors : input, out_grad

- op : depthwise_conv2d
  extra_args : bool is_test=false, bool fuse_relu_before_depthwise_conv=false, bool use_quantizer=false, str mkldnn_data_type="float32", bool fuse_relu=false, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0, bool use_addto=false, bool fuse_residual_connection=false, float scale_in=1.0, float scale_out=1.0, float scale_in_eltwise=1.0, float[] scale_weights={1.0f}, bool force_fp32_output=false

- op : depthwise_conv2d_grad
  extra_args : bool is_test=false, bool fuse_relu_before_depthwise_conv=false, bool use_quantizer=false, str mkldnn_data_type="float32", bool fuse_relu=false, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0, bool use_addto=false, bool fuse_residual_connection=false, float scale_in=1.0, float scale_out=1.0, float scale_in_eltwise=1.0, float[] scale_weights={1.0f}, bool force_fp32_output=false

- op : divide

- op : divide_grad

- op : elu

- op : elu_grad

- op : exp

- op : exp_grad

# - op : expand

# - op : expand_grad

- op : fc
  extra_args : bool ALL_KERNELS_MUST_COMPUTE_RUNTIME_SHAPE=true, bool use_quantizer=false, str mkldnn_data_type="float32", float scale_in=1.0, float[] scale_weights={1.0f}, float scale_out=1.0, bool force_fp32_output=false

# - op : flatten

# - op : flatten_grad

# - op : flatten2

# - op : flatten2_grad

- op : full

- op : fused_conv2d
  extra_args : float fuse_alpha = 0.0, float fuse_beta = 0.0, float scale_in=1.0, float scale_out=1.0, float scale_in_eltwise=1.0, float[] scale_weights={1.0f}
  data_format_tensors : input

- op : fused_conv3d
  extra_args : float fuse_alpha = 0.0, float fuse_beta = 0.0, float scale_in=1.0, float scale_out=1.0, float scale_in_eltwise=1.0, float[] scale_weights={1.0f}
  data_format_tensors : input

# - op : fused_elementwise_add

# - op : fused_elementwise_div

# - op : fused_elementwise_mul

# - op : fused_elementwise_sub

# - op : fused_matmul

# - op : fused_softplus

# - op : fused_transpose

# - op : fusion_gru

# - op : fusion_lstm

- op : gaussian

- op : gelu
  extra_args : str mkldnn_data_type="float32"

- op : gelu_grad
  extra_args : str mkldnn_data_type="float32"

- op : hardswish

- op : hardswish_grad

# - op : layer_norm

- op : leaky_relu

- op : leaky_relu_grad

- op : log_softmax

- op : lrn
  extra_args : bool is_test=false
  data_format_tensors : x

- op : lrn_grad
  extra_args : bool is_test=false
  data_format_tensors : x, out, mid_out, out_grad

# - op : matmul
#   extra_args : str mkldnn_data_type="float32"
#   layout_transform :
#     arg_name: cur_paddle_data_layout
#     tensors: x, y

# - op : matmul_grad

# - op : matmul_with_flatten

# - op : matmul_with_flatten_grad

- op : max

- op : mean

- op : mean_grad

- op : min

- op : mish

- op : mish_grad

# - op : multi_gru

- op : multiply

- op : multiply_grad

- op : nearest_interp

# - op : pad

- op : pad3d
  extra_args :
  data_format_tensors : x
  dynamic_fallback : True

# - op : pool2d

# - op : pool2d_grad

- op : prelu
  extra_args : bool is_test=false, str mkldnn_data_type="float32"

- op : prelu_grad
  extra_args : bool is_test=false, str mkldnn_data_type="float32"

- op : prior_box
  extra_args : bool use_quantizer=false, str mkldnn_data_type="float32"

- op : relu

- op : relu_grad

- op : relu6
  extra_args : float threshold=6.0

- op : relu6_grad
  extra_args : float threshold=6.0

# - op : reshape

# - op : reshape_grad

# - op : reshape_infer

# - op : reshape2_grad

- op : round

- op : scale

- op : sgd

# - op : sgd_dense_param_sparse_grad

# - op : shape
#   extra_args : str mkldnn_data_type="float32"

- op : shuffle_channel

- op : sigmoid

- op : sigmoid_grad

# - op : slice

# - op : slice_grad

# - op : softmax

# - op : softmax_grad

- op : softplus

# - op : split

# - op : split_with_num

- op : sqrt

- op : sqrt_grad

# - op : squeeze

# - op : squeeze_grad

# - op : squeeze_infer

# - op : stack

- op : subtract

- op : subtract_grad

- op : sum

- op : sum_grad

# - op : swish

# - op : swish_grad

- op : tanh

- op : tanh_grad

# - op : transpose

# - op : transpose_grad
