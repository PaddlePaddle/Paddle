/* Copyright (c) 2022 PaddlePaddle Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License. */

#ifdef PADDLE_WITH_HETERPS
#include "paddle/fluid/framework/fleet/heter_ps/hashtable.h"
#include "paddle/fluid/framework/fleet/heter_ps/optimizer_conf.h"

namespace paddle {
namespace framework {

#if defined(PADDLE_WITH_XPU_KP)

template <typename KeyType, typename ValType, typename Table>
__global__ void search_kernel(Table& table, const KeyType* const keys,
                              ValType* const vals, long long len) {
  int cid = core_id();
  int ncores = core_num();
  if (cid >= ncores) {
    return;
  }
  int thread_id = ncores * cluster_id() + cid;
  int nthreads = ncores * cluster_num();

  const int buf_size = 150;
  __local__ KeyType local_keys[buf_size];
  __local__ ValType local_vals[buf_size];

  int len_per_loop = min(buf_size, roundup_div(len, nthreads));
  for (int i = thread_id * len_per_loop; i < len;
       i += nthreads * len_per_loop) {
    int read_len = min(len_per_loop, len - i);
    GM2LM(keys, local_keys, read_len * sizeof(KeyType));
    for (int k = 0; k < read_len; k++) {
      // ValType* val = table.find(local_keys[k]);
      // if (val != NULL) {
      //   local_vals[k] = *val;
      // }
    }
    LM2GM(local_vals, vals + i, read_len * sizeof(ValType));
  }
}


template <typename KeyType, typename ValType>
HashTable<KeyType, ValType>::HashTable(size_t capacity, DevPlace& place) {
  container_ = new XPUCacheArray<KeyType, ValType>(capacity, place);
  OptimizerConfigAutoPtr_ = memory::Alloc(place, sizeof(OptimizerConfig));
  device_optimizer_config_ = reinterpret_cast<OptimizerConfig*>(OptimizerConfigAutoPtr_->ptr());
  // xpu_malloc(reinterpret_cast<void**>(&device_optimizer_config_),
  //           sizeof(OptimizerConfig));
  xpu_memcpy((void*)device_optimizer_config_, &host_optimizer_config_,
             sizeof(OptimizerConfig), XPU_HOST_TO_DEVICE);

  rwlock_.reset(new phi::RWLock);
}

template <typename KeyType, typename ValType>
HashTable<KeyType, ValType>::~HashTable() {
  delete container_;
  container_ = nullptr;
  xpu_free((void*)device_optimizer_config_);
}

template <typename KeyType, typename ValType>
void HashTable<KeyType, ValType>::show() {
  container_->print();
}

template <typename KeyType, typename ValType>
void HashTable<KeyType, ValType>::set_sparse_sgd(
    const OptimizerConfig& optimizer_config) {
  host_optimizer_config_.set_sparse_sgd(optimizer_config);
  xpu_memcpy((void*)device_optimizer_config_, &host_optimizer_config_,
             sizeof(OptimizerConfig), XPU_HOST_TO_DEVICE);
}

template <typename KeyType, typename ValType>
void HashTable<KeyType, ValType>::set_embedx_sgd(
    const OptimizerConfig& optimizer_config) {
  host_optimizer_config_.set_embedx_sgd(optimizer_config);
  xpu_memcpy((void*)device_optimizer_config_, &host_optimizer_config_,
             sizeof(OptimizerConfig), XPU_HOST_TO_DEVICE);
}

template <typename KeyType, typename ValType>
template <typename StreamType>
void HashTable<KeyType, ValType>::get(const paddle::platform::Place& place,
                                      const KeyType* d_keys, ValType* d_vals,
                                      size_t len, StreamType stream) {
  if (len == 0) {
    return;
  }
#if defined(PADDLE_WITH_XPU_CACHE_BFID)
  ValType* d_vals_in = container_->get_vals();
  uint32_t xpu_idx = container_->get_xpu_idx();
  uint32_t xpu_num = container_->get_xpu_num();
  uint32_t xpu_size = container_->size();
  PADDLE_ENFORCE_GE(
      xpu_size, len,
      platform::errors::External("XPU get kernel len size %d is greate than xpu_size %d", len, xpu_size));
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();
  int r = xpu::get_pairs<KeyType, ValType>(
      ctx_xpu, d_keys, d_vals_in, len,  d_vals,
      xpu_idx, xpu_num
     );
  PADDLE_ENFORCE_EQ(
      r, XPU_SUCCESS,
      platform::errors::External("XPU get kernel return wrong value[%d %s]",
                                  r, XPUAPIErrorMsg[r]));
#else
    return;
#endif
}

template <>
template <>
void HashTable<uint32_t, FeatureValue>::get(const paddle::platform::Place& place,
                                     const uint32_t* d_keys, FeatureValue* d_vals,
                                      size_t len, XPUStream stream) {
  if (len == 0) {
    return;
  }

#if defined(PADDLE_WITH_XPU_CACHE_BFID)
  FeatureValue* d_vals_in = container_->get_vals();
  uint32_t xpu_idx = container_->get_xpu_idx();
  uint32_t xpu_num = container_->get_xpu_num();
  uint32_t xpu_size = container_->size();
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();
  int r = xpu::get_pairs<uint32_t, xpu::FeatureValue>(
      ctx_xpu,
      d_keys,
      reinterpret_cast<xpu::FeatureValue*>(d_vals_in),
      len,
      reinterpret_cast<xpu::FeatureValue*>(d_vals),
      xpu_idx, xpu_num
     );
  PADDLE_ENFORCE_EQ(
      r, XPU_SUCCESS,
      platform::errors::External("XPU get kernel return wrong value[%d %s]",
                                  r, XPUAPIErrorMsg[r]));
#else
    uint32_t* k_vals_in = container_->get_keys();
    FeatureValue* d_vals_in = container_->get_vals();
    uint32_t xpu_size = container_->size();
    PADDLE_ENFORCE_GE(
        xpu_size, len,
        platform::errors::External("XPU get kernel len size %d is greate than xpu_size %d", len, xpu_size
        ));
    auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
    auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();
   int r = xpu::get_pairs<uint32_t, xpu::FeatureValue>(
        ctx_xpu, k_vals_in,
        reinterpret_cast<xpu::FeatureValue*>(d_vals_in),
        xpu_size,
        const_cast<uint32_t *>(d_keys),
        reinterpret_cast<xpu::FeatureValue*>(d_vals),
        len
       );
   PADDLE_ENFORCE_EQ(
        r, XPU_SUCCESS,
        platform::errors::External("XPU get kernel return wrong value[%d %s]",
                                    r, XPUAPIErrorMsg[r]));
        return;
#endif
}

template <typename KeyType, typename ValType>
template <typename StreamType>
void HashTable<KeyType, ValType>::get(const paddle::platform::Place& place, const KeyType* d_keys, char* d_vals,
                                      size_t len, StreamType stream) {
  if (len == 0) {
    return;
  }
  // TODO(zhangminxu): to be implemented
}

template <typename KeyType, typename ValType>
template <typename StreamType>
void HashTable<KeyType, ValType>::insert(const paddle::platform::Place& place,
                                         const KeyType* d_keys,
                                         const ValType* d_vals, size_t len,
                                         StreamType stream) {
  if (len == 0) {
    return;
  }
  #if defined(PADDLE_WITH_XPU_CACHE_BFID)
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();
  KeyType* d_keys_out = container_->get_keys();
  ValType* d_vals_out = container_->get_vals();

  uint32_t xpu_idx = container_->get_xpu_idx();
  uint32_t xpu_num = container_->get_xpu_num();
  int r = xpu::insert<KeyType, ValType>(
      ctx_xpu,
      d_keys,
      d_vals,
      d_keys_out,
      d_vals_out,
      len,
      xpu_idx,
      xpu_num);
  PADDLE_ENFORCE_EQ(
      r, XPU_SUCCESS,
      platform::errors::External("XPU insert kernel return wrong value[%d %s]",
                                  r, XPUAPIErrorMsg[r]));
  #else
    return;
  #endif
}

template <>
template <>
void HashTable<uint32_t, FeatureValue>::insert(const paddle::platform::Place& place,
                                         const uint32_t* d_keys,
                                         const FeatureValue* d_vals, size_t len,
                                         XPUStream stream) {
  if (len == 0) {
      return;
  }
  PADDLE_ENFORCE_LE(len, container_->capacity(), platform::errors::External("XPU insert len[%d] must less than capacity[%d]", len, container_->capacity()));

  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();
  uint32_t* d_keys_out = container_->get_keys();
  FeatureValue* d_vals_out = container_->get_vals();
  uint32_t xpu_idx = container_->get_xpu_idx();
  uint32_t xpu_num = container_->get_xpu_num();
  // TODO: remove cast.
  //xpu::ctx_guard RAII_GUARD(ctx_xpu);
  //uint32_t* d_keys_in_cast = RAII_GUARD.alloc_l3_or_gm<uint32_t>(len);
  //PADDLE_ENFORCE_NOT_NULL(
  //    d_keys_in_cast, paddle::platform::errors::Fatal("XPU memory is not enough"));
  //uint32_t* d_keys_out_in_cast = RAII_GUARD.alloc_l3_or_gm<uint32_t>(len);
  //PADDLE_ENFORCE_NOT_NULL(
  //    d_keys_out_in_cast, paddle::platform::errors::Fatal("XPU memory is not enough"));
  //xpu::cast_v2<int64_t, int32_t>(ctx_xpu, reinterpret_cast<const int64_t*>(d_keys),
  //    reinterpret_cast<int32_t*>(d_keys_in_cast), len);

  int r = xpu::insert<uint32_t, xpu::FeatureValue>(
      ctx_xpu,
      d_keys,
      reinterpret_cast<const xpu::FeatureValue*>(d_vals),
      d_keys_out,
      reinterpret_cast<xpu::FeatureValue*>(d_vals_out),
      len,
      xpu_idx,
      xpu_num);
  PADDLE_ENFORCE_EQ(
      r, XPU_SUCCESS,
      platform::errors::External("XPU insert kernel return wrong value[%d %s]",
                                  r, XPUAPIErrorMsg[r]));
  //xpu::cast_v2<int32_t, int64_t>(ctx_xpu, reinterpret_cast<int32_t*>(d_keys_out_in_cast),
  //  reinterpret_cast<int64_t*>(d_keys_out), len);

  container_->set_size(len);
}

template <typename KeyType, typename ValType>
template <typename StreamType>
void HashTable<KeyType, ValType>::dump_to_cpu(int devid, StreamType stream) {
  std::vector<std::thread> threads;
  size_t num = container_->size();
  ValType* h_vals = container_->get_cpu_vals();

  int thread_num = 8;
  int len_per_thread = num / thread_num;
  int remain = num % thread_num;
  int begin = 0;

  auto dump_func = [h_vals](int left, int right) {
    for (int i = left; i < right; i++) {
      ValType& xpu_val = h_vals[i];
      auto* downpour_value =
          (paddle::ps::DownpourFixedFeatureValue*)(xpu_val.cpu_ptr);
      int downpour_value_size = downpour_value->size();
      int real_mf_size = sizeof(xpu_val.mf) / sizeof(float);
      PADDLE_ENFORCE_GE(real_mf_size, xpu_val.mf_size,
        platform::errors::PreconditionNotMet(
            "sizeof(xpu_val.mf) / sizeof(float) must be equal or greater than xpu_val.mf_size, but real_mf_size is: %d, xpu_val.mf_size is: %d", real_mf_size, xpu_val.mf_size));
      if (xpu_val.mf_size > 0 && downpour_value_size == 7) {
        downpour_value->resize(xpu_val.mf_size + downpour_value_size);
      }
      float* cpu_val = downpour_value->data();
      // cpu_val[0] = 0;
      cpu_val[1] = xpu_val.delta_score;
      cpu_val[2] = xpu_val.show;
      cpu_val[3] = xpu_val.clk;
      cpu_val[4] = xpu_val.lr;
      cpu_val[5] = xpu_val.lr_g2sum;
      cpu_val[6] = xpu_val.slot;
      if (xpu_val.mf_size > 0) {
        for (int x = 0; x < xpu_val.mf_size; x++) {
          cpu_val[x + 7] = xpu_val.mf[x];
        }
      }
    }
  };

  for (int i = 0; i < thread_num; i++) {
    threads.push_back(std::thread(
        dump_func, begin, begin + len_per_thread + (i < remain ? 1 : 0)));
    begin += len_per_thread + (i < remain ? 1 : 0);
  }
  for (std::thread& t : threads) {
    t.join();
  }

}

template <typename KeyType, typename ValType>
template <typename GradType, typename StreamType>
void HashTable<KeyType, ValType>::update(const paddle::platform::Place& place,
                                         const KeyType* d_keys,
                                         const GradType* d_grads, size_t len,
                                         StreamType stream) {
  if (len == 0) {
    return;
  }
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();

  KeyType* d_keys_out = container_->get_keys();
  ValType* d_vals_out = container_->get_vals();
  uint32_t xpu_idx = container_->get_xpu_idx();
  uint32_t xpu_num = container_->get_xpu_num();
  size_t len2 = container_->size();
  int r = xpu::update<KeyType, GradType, ValType>(
      ctx_xpu,
      reinterpret_cast<const xpu::OptimizerConfig*>(device_optimizer_config_),
      d_keys,
      d_grads,
      len,
      d_keys_out,
      d_vals_out,
      len2,
      xpu_idx,
      xpu_num);
  PADDLE_ENFORCE_EQ(
      r, XPU_SUCCESS,
      platform::errors::External("XPU update kernel return wrong value[%d %s]",
                                  r, XPUAPIErrorMsg[r]));
}

template <>
template <>
void HashTable<uint32_t, FeatureValue>::update(const paddle::platform::Place& place,
                                         const uint32_t* d_keys,
                                         const FeaturePushValue* d_grads, size_t len,
                                         XPUStream stream) {
  if (len == 0) {
    return;
  }
  auto dev_ctx = platform::DeviceContextPool::Instance().Get(place);
  auto ctx_xpu = static_cast<platform::XPUDeviceContext*>(dev_ctx)->x_context();

  uint32_t* d_keys_out = container_->get_keys();
  FeatureValue* d_vals_out = container_->get_vals();
  uint32_t xpu_idx = container_->get_xpu_idx();
  uint32_t xpu_num = container_->get_xpu_num();
  size_t len2 = container_->size();
  // TODO: remove cast.
  //xpu::ctx_guard RAII_GUARD(ctx_xpu);
  //uint32_t* d_keys_in_cast = RAII_GUARD.alloc_l3_or_gm<uint32_t>(len);
  //PADDLE_ENFORCE_NOT_NULL(
  //    d_keys_in_cast, paddle::platform::errors::Fatal("XPU memory is not enough"));
  //uint32_t* d_keys_out_in_cast = RAII_GUARD.alloc_l3_or_gm<uint32_t>(len2);
  //PADDLE_ENFORCE_NOT_NULL(
  //    d_keys_out_in_cast, paddle::platform::errors::Fatal("XPU memory is not enough"));
  //xpu::cast_v2<int64_t, int32_t>(ctx_xpu, reinterpret_cast<const int64_t*>(d_keys),
  //    reinterpret_cast<int32_t*>(d_keys_in_cast), len);
  //xpu::cast_v2<int64_t, int32_t>(ctx_xpu, reinterpret_cast<const int64_t*>(d_keys_out),
  //    reinterpret_cast<int32_t*>(d_keys_out_in_cast), len2);

  int r = xpu::update<uint32_t, xpu::FeaturePushValue, xpu::FeatureValue>(
      ctx_xpu,
      reinterpret_cast<const xpu::OptimizerConfig*>(device_optimizer_config_),
      d_keys,
      reinterpret_cast<const xpu::FeaturePushValue*>(d_grads),
      len,
      d_keys_out,
      reinterpret_cast<xpu::FeatureValue*>(d_vals_out),
      len2,
      xpu_idx,
      xpu_num);
  PADDLE_ENFORCE_EQ(
      r, XPU_SUCCESS,
      platform::errors::External("XPU update kernel return wrong value[%d %s]",
                                  r, XPUAPIErrorMsg[r]));
  //xpu::cast_v2<int32_t, int64_t>(ctx_xpu, reinterpret_cast<int32_t*>(d_keys_out_in_cast),
  //reinterpret_cast<int64_t*>(d_keys_out), len2);
}

template <typename KeyType, typename ValType>
template <typename StreamType>
void HashTable<KeyType, ValType>::update(const paddle::platform::Place& place,
                                         const KeyType* d_keys,
                                         const char* d_grads, size_t len,
                                         StreamType stream) {
  if (len == 0) {
    return;
  }
  // TODO(zhangminxu): to be implemented
}

template class HashTable<FidKey, paddle::framework::FeatureValue>;

template void HashTable<FidKey, paddle::framework::FeatureValue>::get<
    XPUStream>(const paddle::platform::Place& place, const uint32_t* d_keys,
               paddle::framework::FeatureValue* d_vals, size_t len,
               XPUStream stream);

// template void
// HashTable<unsigned long, paddle::framework::FeatureValue>::get<XPUStream>(
//    const unsigned long* d_keys, char* d_vals, size_t len, XPUStream stream);

template void HashTable<FidKey, paddle::framework::FeatureValue>::insert<
    XPUStream>(const paddle::platform::Place& place,
               const uint32_t* d_keys,
               const paddle::framework::FeatureValue* d_vals, size_t len,
               XPUStream stream);

// template void HashTable<unsigned long,
// paddle::framework::FeatureValue>::insert<
//    XPUStream>(const unsigned long* d_keys, size_t len, char* pool,
//               size_t start_index, XPUStream stream);

template void HashTable<FidKey, paddle::framework::FeatureValue>::
    dump_to_cpu<XPUStream>(int devid, XPUStream stream);

template void HashTable<FidKey, paddle::framework::FeatureValue>::update<
    paddle::framework::FeaturePushValue, XPUStream>(
    const paddle::platform::Place& place,
    const uint32_t* d_keys,
    const paddle::framework::FeaturePushValue* d_grads, size_t len,
    XPUStream stream);

// template void HashTable<unsigned long,
// paddle::framework::FeatureValue>::update<
//    XPUStream>(const unsigned long* d_keys, const char* d_grads,
//                          size_t len, XPUStream stream);

#endif
}  // end namespace framework
}  // end namespace paddle
#endif
