// Copyright (c) 2023 PaddlePaddle Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Generated by conv2d_depthwise_bias_act.py - Do not edit.

#include <stdio.h>
#include <algorithm>
#include <mutex>
#include "cutlass/conv/device/direct_convolution.h"
#include "cutlass/conv/kernel/default_depthwise_fprop.h"
#include "cutlass/cutlass.h"
#include "cutlass/epilogue/thread/linear_combination_silu.h"
#include "cutlass/gemm/device/gemm.h"
#include "paddle/phi/kernels/fusion/cutlass/conv2d/conv2d_util.h"

#include "cutlass/conv/device/implicit_gemm_convolution.h"
#include "cutlass/conv/kernel/default_conv2d_fprop.h"
namespace phi {
namespace fusion {
namespace cutlass_internal {

cutlass::Status conv2d_depthwise_bias_0(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_1(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_2(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_3(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_4(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_5(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_6(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_7(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombination<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

std::vector<std::function<cutlass::Status(const ConvAllParams)>>
    Conv2dDepthwiseBias_all_func = {
        conv2d_depthwise_bias_0,
        conv2d_depthwise_bias_1,
        conv2d_depthwise_bias_2,
        conv2d_depthwise_bias_3,
        conv2d_depthwise_bias_4,
        conv2d_depthwise_bias_5,
        conv2d_depthwise_bias_6,
        conv2d_depthwise_bias_7,
};

std::map<std::vector<int>, int> map_problem_Conv2dDepthwiseBias;
std::mutex Conv2dDepthwiseBias_mutex;

void Conv2dDepthwiseBias(const ConvAllParams &params) {
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  // int pad_h0 = params.pad_h0;
  // int pad_w0 = params.pad_w0;
  int groups = params.groups;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;

  std::vector<int> problem_size = {
      batch, ic, ih, iw, kh, kw, oc, groups, stride_h, stride_w};

  if (map_problem_Conv2dDepthwiseBias.count(problem_size)) {
    Conv2dDepthwiseBias_all_func[map_problem_Conv2dDepthwiseBias.at(
        problem_size)](params);
    return;
  }

  int best_config_index = ProfileToGetBestConfig(
      Conv2dDepthwiseBias_all_func, params, CONV2D_DEPTHWISE_BIAS);

  std::lock_guard<std::mutex> guard(Conv2dDepthwiseBias_mutex);

  map_problem_Conv2dDepthwiseBias[problem_size] = best_config_index;
  Conv2dDepthwiseBias_all_func[best_config_index](params);
}

cutlass::Status conv2d_depthwise_bias_relu_0(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_relu_1(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_relu_2(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_relu_3(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_relu_4(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_relu_5(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_relu_6(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_relu_7(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationRelu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

std::vector<std::function<cutlass::Status(const ConvAllParams)>>
    Conv2dDepthwiseBiasRelu_all_func = {
        conv2d_depthwise_bias_relu_0,
        conv2d_depthwise_bias_relu_1,
        conv2d_depthwise_bias_relu_2,
        conv2d_depthwise_bias_relu_3,
        conv2d_depthwise_bias_relu_4,
        conv2d_depthwise_bias_relu_5,
        conv2d_depthwise_bias_relu_6,
        conv2d_depthwise_bias_relu_7,
};

std::map<std::vector<int>, int> map_problem_Conv2dDepthwiseBiasRelu;
std::mutex Conv2dDepthwiseBiasRelu_mutex;

void Conv2dDepthwiseBiasRelu(const ConvAllParams &params) {
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  // int pad_h0 = params.pad_h0;
  // int pad_w0 = params.pad_w0;
  int groups = params.groups;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;

  std::vector<int> problem_size = {
      batch, ic, ih, iw, kh, kw, oc, groups, stride_h, stride_w};

  if (map_problem_Conv2dDepthwiseBiasRelu.count(problem_size)) {
    Conv2dDepthwiseBiasRelu_all_func[map_problem_Conv2dDepthwiseBiasRelu.at(
        problem_size)](params);
    return;
  }

  int best_config_index = ProfileToGetBestConfig(
      Conv2dDepthwiseBiasRelu_all_func, params, CONV2D_DEPTHWISE_BIAS_RELU);

  std::lock_guard<std::mutex> guard(Conv2dDepthwiseBiasRelu_mutex);

  map_problem_Conv2dDepthwiseBiasRelu[problem_size] = best_config_index;
  Conv2dDepthwiseBiasRelu_all_func[best_config_index](params);
}

cutlass::Status conv2d_depthwise_bias_sigmoid_0(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_sigmoid_1(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_sigmoid_2(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_sigmoid_3(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_sigmoid_4(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_sigmoid_5(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_sigmoid_6(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_sigmoid_7(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::LinearCombinationSigmoid<cutlass::half_t,
                                                              8,
                                                              cutlass::half_t,
                                                              float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

std::vector<std::function<cutlass::Status(const ConvAllParams)>>
    Conv2dDepthwiseBiasSigmoid_all_func = {
        conv2d_depthwise_bias_sigmoid_0,
        conv2d_depthwise_bias_sigmoid_1,
        conv2d_depthwise_bias_sigmoid_2,
        conv2d_depthwise_bias_sigmoid_3,
        conv2d_depthwise_bias_sigmoid_4,
        conv2d_depthwise_bias_sigmoid_5,
        conv2d_depthwise_bias_sigmoid_6,
        conv2d_depthwise_bias_sigmoid_7,
};

std::map<std::vector<int>, int> map_problem_Conv2dDepthwiseBiasSigmoid;
std::mutex Conv2dDepthwiseBiasSigmoid_mutex;

void Conv2dDepthwiseBiasSigmoid(const ConvAllParams &params) {
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  // int pad_h0 = params.pad_h0;
  // int pad_w0 = params.pad_w0;
  int groups = params.groups;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;

  std::vector<int> problem_size = {
      batch, ic, ih, iw, kh, kw, oc, groups, stride_h, stride_w};

  if (map_problem_Conv2dDepthwiseBiasSigmoid.count(problem_size)) {
    Conv2dDepthwiseBiasSigmoid_all_func[map_problem_Conv2dDepthwiseBiasSigmoid
                                            .at(problem_size)](params);
    return;
  }

  int best_config_index =
      ProfileToGetBestConfig(Conv2dDepthwiseBiasSigmoid_all_func,
                             params,
                             CONV2D_DEPTHWISE_BIAS_SIGMOID);

  std::lock_guard<std::mutex> guard(Conv2dDepthwiseBiasSigmoid_mutex);

  map_problem_Conv2dDepthwiseBiasSigmoid[problem_size] = best_config_index;
  Conv2dDepthwiseBiasSigmoid_all_func[best_config_index](params);
}

cutlass::Status conv2d_depthwise_bias_silu_0(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_silu_1(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_silu_2(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 16, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_silu_3(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 9>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<3, 3>,

          cutlass::gemm::GemmShape<16, 32, 9>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_silu_4(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_silu_5(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<1, 1>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_silu_6(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 16, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 16>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 16, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

cutlass::Status conv2d_depthwise_bias_silu_7(const ConvAllParams &params) {
  using kernel_base =
      typename cutlass::conv::kernel::DefaultDepthwiseDirect2dConvFprop<
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::layout::TensorNHWC,
          cutlass::half_t,
          cutlass::arch::OpClassSimt,
          cutlass::arch::Sm70,
          cutlass::gemm::GemmShape<64, 32, 25>,
          cutlass::conv::TensorNHWCShape<1, 8, 8, 32>,
          cutlass::MatrixShape<5, 5>,

          cutlass::gemm::GemmShape<16, 32, 25>,
          cutlass::gemm::GemmShape<1, 1, 1>,
          cutlass::epilogue::thread::
              LinearCombinationSilu<cutlass::half_t, 8, cutlass::half_t, float>,
          cutlass::conv::threadblock::
              DepthwiseDirect2dConvIdentityThreadblockSwizzle<1, 1, 8, 8>,
          2,
          cutlass::arch::OpMultiplyAdd,
          cutlass::conv::IteratorAlgorithm::kFixedStrideDilation,
          cutlass::conv::StrideSupport::kStrided,
          cutlass::MatrixShape<2, 2>,
          cutlass::MatrixShape<1, 1>>::Kernel;

  using ImplicitGemm = cutlass::conv::device::DirectConvolution<kernel_base>;
  const half *input = params.input;
  const half *weight = params.weight;
  const half *bias = params.bias;
  half *output = params.output;
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  int pad_h0 = params.pad_h0;
  int pad_w0 = params.pad_w0;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;
  int groups = params.groups;
  int kc = ic / groups;

  int oh = params.oh;
  int ow = params.ow;
  int dilation_h = params.dilation_h;
  int dilation_w = params.dilation_w;
  int split_k_slices = (oh * ow + 63) / 64;

  cutlass::conv::Conv2dProblemSize problem_size(
      {batch, ih, iw, ic},
      {oc, kh, kw, ic / groups},
      {pad_h0, 0, pad_w0, 0},
      {stride_h, stride_w},
      {dilation_h, dilation_w},
      {batch, oh, ow, oc},
      cutlass::conv::Mode::kCrossCorrelation,
      split_k_slices,
      groups);

  size_t filter_size = oc * kh * kw * kc * sizeof(half);
  phi::Allocator::AllocationPtr filter_gpu_ptrs_data = phi::memory_utils::Alloc(
      params.ctx->GetPlace(),
      filter_size,
      phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));
  void *filter_workspace = filter_gpu_ptrs_data->ptr();

  typename ImplicitGemm::Arguments arguments{
      problem_size,
      {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},
      {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},
      {(cutlass::half_t *)bias, {0, 0, 0}},
      {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},
      {1.f, 1.f},
      {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},
  };

  ImplicitGemm implicit_gemm_op;
  size_t bytes = implicit_gemm_op.get_workspace_size(arguments);

  auto ctx = params.ctx;
  auto stream = ctx->stream();
  phi::Allocator::AllocationPtr tmp_gpu_ptrs_data = phi::memory_utils::Alloc(
      ctx->GetPlace(),
      bytes,
      phi::Stream(reinterpret_cast<phi::StreamId>(stream)));
  void *workspace = tmp_gpu_ptrs_data->ptr();

  cutlass::Status status = implicit_gemm_op.can_implement(arguments);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op.initialize(arguments, workspace);
  CUTLASS_CHECK(status);
  status = implicit_gemm_op(stream);
  CUTLASS_CHECK(status);
  return status;
}

std::vector<std::function<cutlass::Status(const ConvAllParams)>>
    Conv2dDepthwiseBiasSilu_all_func = {
        conv2d_depthwise_bias_silu_0,
        conv2d_depthwise_bias_silu_1,
        conv2d_depthwise_bias_silu_2,
        conv2d_depthwise_bias_silu_3,
        conv2d_depthwise_bias_silu_4,
        conv2d_depthwise_bias_silu_5,
        conv2d_depthwise_bias_silu_6,
        conv2d_depthwise_bias_silu_7,
};

std::map<std::vector<int>, int> map_problem_Conv2dDepthwiseBiasSilu;
std::mutex Conv2dDepthwiseBiasSilu_mutex;

void Conv2dDepthwiseBiasSilu(const ConvAllParams &params) {
  int batch = params.batch;
  int ic = params.ic;
  int ih = params.ih;
  int iw = params.iw;
  int kh = params.kh;
  int kw = params.kw;
  int oc = params.oc;
  // int pad_h0 = params.pad_h0;
  // int pad_w0 = params.pad_w0;
  int groups = params.groups;
  int stride_h = params.stride_h;
  int stride_w = params.stride_w;

  std::vector<int> problem_size = {
      batch, ic, ih, iw, kh, kw, oc, groups, stride_h, stride_w};

  if (map_problem_Conv2dDepthwiseBiasSilu.count(problem_size)) {
    Conv2dDepthwiseBiasSilu_all_func[map_problem_Conv2dDepthwiseBiasSilu.at(
        problem_size)](params);
    return;
  }

  int best_config_index = ProfileToGetBestConfig(
      Conv2dDepthwiseBiasSilu_all_func, params, CONV2D_DEPTHWISE_BIAS_SILU);

  std::lock_guard<std::mutex> guard(Conv2dDepthwiseBiasSilu_mutex);

  map_problem_Conv2dDepthwiseBiasSilu[problem_size] = best_config_index;
  Conv2dDepthwiseBiasSilu_all_func[best_config_index](params);
}

}  // namespace cutlass_internal
}  // namespace fusion
}  // namespace phi
