- op : dequantize
  args : (Tensor input, float scale=1.0, float shift=0.0)
  output : Tensor(output)
  infer_meta :
    func : UnchangedExceptDtypeInferMeta
    param : [input]
  kernel :
    func : dequantize
    data_type : input

- op : fused_conv2d
  args : (Tensor input, Tensor filter, Tensor bias, Tensor residual_param, int[] strides={1, 1}, int[] paddings={0, 0}, str padding_algorithm="EXPLICIT", int[] dilations={1, 1}, int groups=1, str data_format="NCHW", str mkldnn_data_type="float32", str fuse_activation="", bool fuse_residual_connection=false, bool force_fp32_output=false)
  output : Tensor(output)
  infer_meta :
    func : FusedConvInferMeta
  kernel :
    func : fused_conv2d
    data_type : input
  optional : bias, residual_param

- op : fused_conv3d
  args : (Tensor input, Tensor filter, Tensor bias, Tensor residual_param, int[] strides={1, 1}, int[] paddings={0, 0}, str padding_algorithm="EXPLICIT", int[] dilations={1, 1}, int groups=1, str data_format="NCHW", str mkldnn_data_type="float32", str fuse_activation="", bool fuse_residual_connection=false, bool force_fp32_output=false)
  output : Tensor(output)
  infer_meta :
    func : FusedConvInferMeta
  kernel :
    func : fused_conv3d
    data_type : input
  optional : bias, residual_param

- op : fused_matmul
  args : (Tensor x, Tensor y, Tensor residual_data, bool trans_x=false, bool trans_y=false, float matmul_alpha=1.0, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0, float fused_output_scale=1.0, int[] fused_reshape_x={}, int[] fused_transpose_x={}, int[] fused_reshape_y={}, int[] fused_transpose_y={}, int[] fused_reshape_out={}, int[] fused_transpose_out={}, str mkldnn_data_type="float32", float scale_x=1.0, float scale_y=1.0, float scale_in_eltwise=0.0, float scale_out=1.0,bool force_fp32_output=false)
  output : Tensor(out)
  infer_meta :
    func : FusedMatmulInferMeta
  kernel :
    func : fused_matmul
  optional : residual_data

- op : fused_softplus
  args : (Tensor x, float beta=1.0, float threshold=20.0, str fuse_activation="", float fuse_alpha=0.0, float fuse_beta=0.0)
  output : Tensor(out)
  infer_meta :
    func : UnchangedExceptDtypeInferMeta
    param : [x]
  kernel :
    func : fused_softplus

- op : fused_transpose
  args : (Tensor x, int[] axis={}, int[] fused_squeeze2_axes={}, int[] fused_unsqueeze2_axes={}, int[] fused_reshape2_shape={}, float scale=1.0, float shift=0.0, str output_data_type="")
  output : Tensor(out)
  infer_meta :
    func : TransposeInferMeta
    param : [x, axis]
  kernel :
    func : fused_transpose

- op: multi_gru
  args: (Tensor x, Tensor[] weight_x, Tensor[] weight_h, Tensor[] bias, Tensor[] scale_weights, str activation="tanh", str gate_activation="sigmoid", int layers=1, bool origin_mode=false, str mkldnn_data_type="float32", float scale_data=1.0, float shift_data=1.0, bool force_fp32_output=false)
  output: Tensor(hidden)
  infer_meta:
     func: MultiGruInferMeta
  kernel:
     func: multi_gru
     data_type : x
  optional: bias, scale_weights

- op : quantize
  args : (Tensor input, bool is_negative_input=false, float scale=1.0, float shift=0.0, str output_format="NHWC", bool bfloat16=false)
  output : Tensor(output)
  infer_meta :
    func : UnchangedInferMeta
    param : [input]
  kernel :
    func : quantize
    data_type : input

- op : requantize
  args : (Tensor input, float scale_in=1.0, float scale_out=1.0, float shift_in=1.0, float shift_out=1.0)
  output : Tensor(output)
  infer_meta :
    func : UnchangedInferMeta
    param : [input]
  kernel :
    func : requantize
    data_type : input
