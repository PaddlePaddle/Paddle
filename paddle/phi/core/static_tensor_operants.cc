// Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Generated by paddle/fluid/prim/api/auto_code_generated/tensor_operants_gen.py

#include "paddle/phi/core/static_tensor_operants.h"

#include "paddle/fluid/prim/api/generated_prim/prim_generated_api.h"
#include "paddle/fluid/prim/api/manual_prim/prim_manual_api.h"
#include "paddle/fluid/prim/utils/static/desc_tensor.h"

#include "paddle/fluid/primitive/backend/backend.h"
#include "paddle/fluid/primitive/type/lazy_tensor.h"

COMMON_DECLARE_bool(enable_pir_api);
COMMON_DECLARE_bool(enable_pir_in_executor);

namespace paddle {

namespace prim {
using DescTensor = paddle::prim::DescTensor;
using LazyTensor = paddle::primitive::LazyTensor;

Tensor StaticTensorOperants::add(const Tensor& x, const Scalar& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::add<LazyTensor>(
        x,
        paddle::primitive::backend::full<LazyTensor>(
            x.shape(), y, x.dtype(), x.place()));
  } else {
    return paddle::prim::add<DescTensor>(
        x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));
  }
}

Tensor StaticTensorOperants::subtract(const Tensor& x, const Scalar& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::subtract<LazyTensor>(
        x,
        paddle::primitive::backend::full<LazyTensor>(
            x.shape(), y, x.dtype(), x.place()));
  } else {
    return paddle::prim::subtract<DescTensor>(
        x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));
  }
}

Tensor StaticTensorOperants::multiply(const Tensor& x, const Scalar& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::scale<LazyTensor>(x, y, 0.0f, true);
  } else {
    return paddle::prim::scale<DescTensor>(x, y, 0.0f, true);
  }
}

Tensor StaticTensorOperants::divide(const Tensor& x, const Scalar& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::divide<LazyTensor>(
        x,
        paddle::primitive::backend::full<LazyTensor>(
            x.shape(), y, x.dtype(), x.place()));
  } else {
    return paddle::prim::divide<DescTensor>(
        x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));
  }
}

Tensor StaticTensorOperants::add(const Scalar& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::add<LazyTensor>(
        paddle::primitive::backend::full<LazyTensor>(
            y.shape(), x, y.dtype(), y.place()),
        y);
  } else {
    return paddle::prim::add<DescTensor>(
        paddle::prim::full<DescTensor>(y.shape(), x, y.dtype(), y.place()), y);
  }
}

Tensor StaticTensorOperants::subtract(const Scalar& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::subtract<LazyTensor>(
        paddle::primitive::backend::full<LazyTensor>(
            y.shape(), x, y.dtype(), y.place()),
        y);
  } else {
    return paddle::prim::subtract<DescTensor>(
        paddle::prim::full<DescTensor>(y.shape(), x, y.dtype(), y.place()), y);
  }
}

Tensor StaticTensorOperants::multiply(const Scalar& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::scale<LazyTensor>(y, x, 0.0f, true);
  } else {
    return paddle::prim::scale<DescTensor>(y, x, 0.0f, true);
  }
}

Tensor StaticTensorOperants::divide(const Scalar& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::divide<LazyTensor>(
        paddle::primitive::backend::full<LazyTensor>(
            y.shape(), x, y.dtype(), y.place()),
        y);
  } else {
    return paddle::prim::divide<DescTensor>(
        paddle::prim::full<DescTensor>(y.shape(), x, y.dtype(), y.place()), y);
  }
}

Tensor StaticTensorOperants::pow(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::elementwise_pow<LazyTensor>(x, y);
  } else {
    return paddle::prim::elementwise_pow<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::pow(const Tensor& x, const Scalar& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::elementwise_pow<LazyTensor>(
        x,
        paddle::primitive::backend::full<LazyTensor>(
            x.shape(), y, x.dtype(), x.place()));
  } else {
    return paddle::prim::elementwise_pow<DescTensor>(
        x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));
  }
}
Tensor StaticTensorOperants::add(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::add<LazyTensor>(x, y);
  } else {
    return paddle::prim::add<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::assign(const Tensor& x) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::assign<LazyTensor>(x);
  } else {
    return paddle::prim::assign<DescTensor>(x);
  }
}

Tensor StaticTensorOperants::divide(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::divide<LazyTensor>(x, y);
  } else {
    return paddle::prim::divide<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::elementwise_pow(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::elementwise_pow<LazyTensor>(x, y);
  } else {
    return paddle::prim::elementwise_pow<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::equal(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::equal<LazyTensor>(x, y);
  } else {
    return paddle::prim::equal<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::greater_equal(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::greater_equal<LazyTensor>(x, y);
  } else {
    return paddle::prim::greater_equal<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::greater_than(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::greater_than<LazyTensor>(x, y);
  } else {
    return paddle::prim::greater_than<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::less_equal(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::less_equal<LazyTensor>(x, y);
  } else {
    return paddle::prim::less_equal<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::less_than(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::less_than<LazyTensor>(x, y);
  } else {
    return paddle::prim::less_than<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::matmul(const Tensor& x,
                                    const Tensor& y,
                                    bool transpose_x,
                                    bool transpose_y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::matmul<LazyTensor>(
        x, y, transpose_x, transpose_y);
  } else {
    return paddle::prim::matmul<DescTensor>(x, y, transpose_x, transpose_y);
  }
}

Tensor StaticTensorOperants::maximum(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::maximum<LazyTensor>(x, y);
  } else {
    return paddle::prim::maximum<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::minimum(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::minimum<LazyTensor>(x, y);
  } else {
    return paddle::prim::minimum<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::multiply(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::multiply<LazyTensor>(x, y);
  } else {
    return paddle::prim::multiply<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::not_equal(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::not_equal<LazyTensor>(x, y);
  } else {
    return paddle::prim::not_equal<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::subtract(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::subtract<LazyTensor>(x, y);
  } else {
    return paddle::prim::subtract<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::tile(const Tensor& x,
                                  const IntArray& repeat_times) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::tile<LazyTensor>(x, repeat_times);
  } else {
    return paddle::prim::tile<DescTensor>(x, repeat_times);
  }
}

Tensor StaticTensorOperants::abs(const Tensor& x) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::abs<LazyTensor>(x);
  } else {
    return paddle::prim::abs<DescTensor>(x);
  }
}

Tensor StaticTensorOperants::bitwise_and(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::bitwise_and<LazyTensor>(x, y);
  } else {
    return paddle::prim::bitwise_and<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::bitwise_not(const Tensor& x) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::bitwise_not<LazyTensor>(x);
  } else {
    return paddle::prim::bitwise_not<DescTensor>(x);
  }
}

Tensor StaticTensorOperants::bitwise_or(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::bitwise_or<LazyTensor>(x, y);
  } else {
    return paddle::prim::bitwise_or<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::bitwise_xor(const Tensor& x, const Tensor& y) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::bitwise_xor<LazyTensor>(x, y);
  } else {
    return paddle::prim::bitwise_xor<DescTensor>(x, y);
  }
}

Tensor StaticTensorOperants::exp(const Tensor& x) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::exp<LazyTensor>(x);
  } else {
    return paddle::prim::exp<DescTensor>(x);
  }
}

Tensor StaticTensorOperants::expand(const Tensor& x, const IntArray& shape) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::expand<LazyTensor>(x, shape);
  } else {
    return paddle::prim::expand<DescTensor>(x, shape);
  }
}

Tensor StaticTensorOperants::floor(const Tensor& x) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::floor<LazyTensor>(x);
  } else {
    return paddle::prim::floor<DescTensor>(x);
  }
}

Tensor StaticTensorOperants::gather_nd(const Tensor& x, const Tensor& index) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::gather_nd<LazyTensor>(x, index);
  } else {
    return paddle::prim::gather_nd<DescTensor>(x, index);
  }
}

Tensor StaticTensorOperants::log(const Tensor& x) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::log<LazyTensor>(x);
  } else {
    return paddle::prim::log<DescTensor>(x);
  }
}

Tensor StaticTensorOperants::max(const Tensor& x,
                                 const IntArray& axis,
                                 bool keepdim) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::max<LazyTensor>(x, axis, keepdim);
  } else {
    return paddle::prim::max<DescTensor>(x, axis, keepdim);
  }
}

Tensor StaticTensorOperants::roll(const Tensor& x,
                                  const IntArray& shifts,
                                  const std::vector<int64_t>& axis) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::roll<LazyTensor>(x, shifts, axis);
  } else {
    return paddle::prim::roll<DescTensor>(x, shifts, axis);
  }
}

Tensor StaticTensorOperants::scale(const Tensor& x,
                                   const Scalar& scale,
                                   const Scalar& bias,
                                   bool bias_after_scale) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::scale<LazyTensor>(
        x, scale, bias, bias_after_scale);
  } else {
    return paddle::prim::scale<DescTensor>(x, scale, bias, bias_after_scale);
  }
}

Tensor StaticTensorOperants::scatter(const Tensor& x,
                                     const Tensor& index,
                                     const Tensor& updates,
                                     bool overwrite) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::scatter<LazyTensor>(
        x, index, updates, overwrite);
  } else {
    return paddle::prim::scatter<DescTensor>(x, index, updates, overwrite);
  }
}

Tensor StaticTensorOperants::scatter_nd_add(const Tensor& x,
                                            const Tensor& index,
                                            const Tensor& updates) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::scatter_nd_add<LazyTensor>(
        x, index, updates);
  } else {
    return paddle::prim::scatter_nd_add<DescTensor>(x, index, updates);
  }
}

Tensor StaticTensorOperants::sum(const Tensor& x,
                                 const IntArray& axis,
                                 DataType dtype,
                                 bool keepdim) {
  if (FLAGS_enable_pir_api || FLAGS_enable_pir_in_executor) {
    return paddle::primitive::backend::sum<LazyTensor>(x, axis, dtype, keepdim);
  } else {
    return paddle::prim::sum<DescTensor>(x, axis, dtype, keepdim);
  }
}

}  // namespace prim
}  // namespace paddle
