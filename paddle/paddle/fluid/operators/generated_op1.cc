// this file is generated by paddle/phi/api/yaml/generator/generate_op.py, do not edit.
#include <string>
#include "paddle/fluid/framework/convert_utils.h"
#include "paddle/fluid/framework/infershape_utils.h"
#include "paddle/fluid/framework/op_registry.h"
#include "paddle/fluid/framework/op_version_registry.h"
#include "paddle/fluid/prim/api/composite_backward/composite_backward_api.h"
#include "paddle/fluid/prim/utils/static/composite_grad_desc_maker.h"
#include "paddle/fluid/prim/utils/static/desc_tensor.h"
#include "paddle/fluid/operators/generator/get_expected_kernel_func.h"
#include "paddle/phi/core/infermeta_utils.h"
#include "paddle/phi/infermeta/backward.h"
#include "paddle/phi/infermeta/binary.h"
#include "paddle/phi/infermeta/fusion.h"
#include "paddle/phi/infermeta/multiary.h"
#include "paddle/phi/infermeta/nullary.h"
#include "paddle/phi/infermeta/ternary.h"
#include "paddle/phi/infermeta/unary.h"

namespace paddle {
namespace operators {

using paddle::framework::GradVarName;


class AbsOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of abs op.");
    AddOutput("Out", "(Tensor), output 0 of abs op.");
    AddComment(R"DOC(
TODO: Documentation of abs op.
)DOC");
  }
};


class AbsOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(abs, AbsInferShapeFunctor,
                            PD_INFER_META(phi::RealAndImagInferMeta));
DECLARE_INPLACE_OP_INFERER(AbsInplaceInferer,
                           {"X", "Out"});



class AccuracyOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Out", "(Tensor), input 0 of accuracy op.");
    AddInput("Indices", "(Tensor), input 1 of accuracy op.");
    AddInput("Label", "(Tensor), input 2 of accuracy op.");
    AddOutput("Accuracy", "(Tensor), output 0 of accuracy op.");
    AddOutput("Correct", "(Tensor), output 1 of accuracy op.");
    AddOutput("Total", "(Tensor), output 2 of accuracy op.");
    AddComment(R"DOC(
TODO: Documentation of accuracy op.
)DOC");
  }
};


class AccuracyOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Out");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(accuracy, AccuracyInferShapeFunctor,
                            PD_INFER_META(phi::AccuracyInferMeta));



class AcosOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of acos op.");
    AddOutput("Out", "(Tensor), output 0 of acos op.");
    AddComment(R"DOC(
TODO: Documentation of acos op.
)DOC");
  }
};


class AcosOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(acos, AcosInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AcosInplaceInferer,
                           {"X", "Out"});



class AcoshOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of acosh op.");
    AddOutput("Out", "(Tensor), output 0 of acosh op.");
    AddComment(R"DOC(
TODO: Documentation of acosh op.
)DOC");
  }
};


class AcoshOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(acosh, AcoshInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AcoshInplaceInferer,
                           {"X", "Out"});



class AdagradOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Param", "(Tensor), input 0 of adagrad op.");
    AddInput("Grad", "(Tensor), input 1 of adagrad op.");
    AddInput("Moment", "(Tensor), input 2 of adagrad op.");
    AddInput("LearningRate", "(Tensor), input 3 of adagrad op.");
    AddInput("MasterParam", "(Tensor), input 4 of adagrad op.")
        .AsDispensable();
    AddOutput("ParamOut", "(Tensor), output 0 of adagrad op.");
    AddOutput("MomentOut", "(Tensor), output 1 of adagrad op.");
    AddOutput("MasterParamOut", "(Tensor), output 2 of adagrad op.")
        .AsDispensable();
    AddAttr<float>("epsilon", "(float), attribute 0 for adagrad op.")
        .SetDefault(1.0e-6f);
    AddAttr<bool>("multi_precision", "(bool), attribute 1 for adagrad op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of adagrad op.
)DOC");
  }
};


class AdagradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Param");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(adagrad, AdagradInferShapeFunctor,
                            PD_INFER_META(phi::AdagradInferMeta));



class AdamOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Param", "(Tensor), input 0 of adam op.");
    AddInput("Grad", "(Tensor), input 1 of adam op.");
    AddInput("LearningRate", "(Tensor), input 2 of adam op.");
    AddInput("Moment1", "(Tensor), input 3 of adam op.");
    AddInput("Moment2", "(Tensor), input 4 of adam op.");
    AddInput("Beta1Pow", "(Tensor), input 5 of adam op.");
    AddInput("Beta2Pow", "(Tensor), input 6 of adam op.");
    AddInput("MasterParam", "(Tensor), input 7 of adam op.")
        .AsDispensable();
    AddInput("SkipUpdate", "(Tensor), input 8 of adam op.")
        .AsDispensable();
    AddOutput("ParamOut", "(Tensor), output 0 of adam op.");
    AddOutput("Moment1Out", "(Tensor), output 1 of adam op.");
    AddOutput("Moment2Out", "(Tensor), output 2 of adam op.");
    AddOutput("Beta1PowOut", "(Tensor), output 3 of adam op.");
    AddOutput("Beta2PowOut", "(Tensor), output 4 of adam op.");
    AddOutput("MasterParamOut", "(Tensor), output 5 of adam op.")
        .AsDispensable();
    AddInput("Beta1Tensor", "attribute 0 for adam op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("beta1", "(float), attribute 0 for adam op.")
        .SetDefault(0.9f);
    AddInput("Beta2Tensor", "attribute 1 for adam op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("beta2", "(float), attribute 1 for adam op.")
        .SetDefault(0.999f);
    AddInput("EpsilonTensor", "attribute 2 for adam op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("epsilon", "(float), attribute 2 for adam op.")
        .SetDefault(1.0e-8f);
    AddAttr<bool>("lazy_mode", "(bool), attribute 3 for adam op.")
        .SetDefault(false);
    AddAttr<int64_t>("min_row_size_to_use_multithread", "(int64_t), attribute 4 for adam op.")
        .SetDefault(1000);
    AddAttr<bool>("multi_precision", "(bool), attribute 5 for adam op.")
        .SetDefault(false);
    AddAttr<bool>("use_global_beta_pow", "(bool), attribute 6 for adam op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of adam op.
)DOC");
  }
};


class AdamOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Param");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(adam, AdamInferShapeFunctor,
                            PD_INFER_META(phi::AdamInferMeta));



class AdamaxOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Param", "(Tensor), input 0 of adamax op.");
    AddInput("Grad", "(Tensor), input 1 of adamax op.");
    AddInput("LearningRate", "(Tensor), input 2 of adamax op.");
    AddInput("Moment", "(Tensor), input 3 of adamax op.");
    AddInput("InfNorm", "(Tensor), input 4 of adamax op.");
    AddInput("Beta1Pow", "(Tensor), input 5 of adamax op.");
    AddInput("MasterParam", "(Tensor), input 6 of adamax op.")
        .AsDispensable();
    AddOutput("ParamOut", "(Tensor), output 0 of adamax op.");
    AddOutput("MomentOut", "(Tensor), output 1 of adamax op.");
    AddOutput("InfNormOut", "(Tensor), output 2 of adamax op.");
    AddOutput("MasterParamOut", "(Tensor), output 3 of adamax op.")
        .AsDispensable();
    AddAttr<float>("beta1", "(float), attribute 0 for adamax op.")
        .SetDefault(0.9f);
    AddAttr<float>("beta2", "(float), attribute 1 for adamax op.")
        .SetDefault(0.999f);
    AddAttr<float>("epsilon", "(float), attribute 2 for adamax op.")
        .SetDefault(1.0e-8f);
    AddAttr<bool>("multi_precision", "(bool), attribute 3 for adamax op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of adamax op.
)DOC");
  }
};


class AdamaxOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Param");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(adamax, AdamaxInferShapeFunctor,
                            PD_INFER_META(phi::AdamaxInferMeta));



class AdamwOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Param", "(Tensor), input 0 of adamw op.");
    AddInput("Grad", "(Tensor), input 1 of adamw op.");
    AddInput("LearningRate", "(Tensor), input 2 of adamw op.");
    AddInput("Moment1", "(Tensor), input 3 of adamw op.");
    AddInput("Moment2", "(Tensor), input 4 of adamw op.");
    AddInput("Beta1Pow", "(Tensor), input 5 of adamw op.");
    AddInput("Beta2Pow", "(Tensor), input 6 of adamw op.");
    AddInput("MasterParam", "(Tensor), input 7 of adamw op.")
        .AsDispensable();
    AddInput("SkipUpdate", "(Tensor), input 8 of adamw op.")
        .AsDispensable();
    AddOutput("ParamOut", "(Tensor), output 0 of adamw op.");
    AddOutput("Moment1Out", "(Tensor), output 1 of adamw op.");
    AddOutput("Moment2Out", "(Tensor), output 2 of adamw op.");
    AddOutput("Beta1PowOut", "(Tensor), output 3 of adamw op.");
    AddOutput("Beta2PowOut", "(Tensor), output 4 of adamw op.");
    AddOutput("MasterParamOut", "(Tensor), output 5 of adamw op.")
        .AsDispensable();
    AddInput("Beta1Tensor", "attribute 0 for adamw op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("beta1", "(float), attribute 0 for adamw op.")
        .SetDefault(0.9f);
    AddInput("Beta2Tensor", "attribute 1 for adamw op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("beta2", "(float), attribute 1 for adamw op.")
        .SetDefault(0.999f);
    AddInput("EpsilonTensor", "attribute 2 for adamw op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("epsilon", "(float), attribute 2 for adamw op.")
        .SetDefault(1.0e-8f);
    AddAttr<float>("lr_ratio", "(float), attribute 3 for adamw op.")
        .SetDefault(1.0f);
    AddAttr<float>("coeff", "(float), attribute 4 for adamw op.")
        .SetDefault(0.01f);
    AddAttr<bool>("with_decay", "(bool), attribute 5 for adamw op.")
        .SetDefault(false);
    AddAttr<bool>("lazy_mode", "(bool), attribute 6 for adamw op.")
        .SetDefault(false);
    AddAttr<int64_t>("min_row_size_to_use_multithread", "(int64_t), attribute 7 for adamw op.")
        .SetDefault(1000);
    AddAttr<bool>("multi_precision", "(bool), attribute 8 for adamw op.")
        .SetDefault(false);
    AddAttr<bool>("use_global_beta_pow", "(bool), attribute 9 for adamw op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of adamw op.
)DOC");
  }
};


class AdamwOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Param");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(adamw, AdamwInferShapeFunctor,
                            PD_INFER_META(phi::AdamwInferMeta));



class AddmmOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of addmm op.");
    AddInput("X", "(Tensor), input 1 of addmm op.");
    AddInput("Y", "(Tensor), input 2 of addmm op.");
    AddOutput("Out", "(Tensor), output 0 of addmm op.");
    AddAttr<float>("Beta", "(float), attribute 0 for addmm op.")
        .SetDefault(1.0);
    AddAttr<float>("Alpha", "(float), attribute 1 for addmm op.")
        .SetDefault(1.0);
    AddComment(R"DOC(
TODO: Documentation of addmm op.
)DOC");
  }
};


class AddmmOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(addmm, AddmmInferShapeFunctor,
                            PD_INFER_META(phi::AddmmInferMeta));
DECLARE_INPLACE_OP_INFERER(AddmmInplaceInferer,
                           {"Input", "Out"});



class AffineGridOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Theta", "(Tensor), input 0 of affine_grid op.");
    AddOutput("Output", "(Tensor), output 0 of affine_grid op.");
    AddInput("OutputShape", "attribute 0 for affine_grid op from 1D integer Tensor.")
        .AsDispensable();
      AddAttr<std::vector<int>>("output_shape", "(std::vector<int>), attribute 0 for affine_grid op.")
        .SetDefault({});
    AddAttr<bool>("align_corners", "(bool), attribute 1 for affine_grid op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of affine_grid op.
)DOC");
  }
};


class AffineGridOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Theta");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(affine_grid, AffineGridInferShapeFunctor,
                            PD_INFER_META(phi::AffineGridInferMeta));



class AllcloseOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of allclose op.");
    AddInput("Other", "(Tensor), input 1 of allclose op.");
    AddOutput("Out", "(Tensor), output 0 of allclose op.");
    AddInput("Rtol", "attribute 0 for allclose op from 0D Tensor.")
        .AsDispensable();
    AddAttr<std::string>("rtol", "(std::string), attribute 0 for allclose op.")
        .SetDefault("1e-5");
    AddInput("Atol", "attribute 1 for allclose op from 0D Tensor.")
        .AsDispensable();
    AddAttr<std::string>("atol", "(std::string), attribute 1 for allclose op.")
        .SetDefault("1e-8");
    AddAttr<bool>("equal_nan", "(bool), attribute 2 for allclose op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of allclose op.
)DOC");
  }
};


class AllcloseOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(allclose, AllcloseInferShapeFunctor,
                            PD_INFER_META(phi::AllValueCompareInferMeta));



class AngleOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of angle op.");
    AddOutput("Out", "(Tensor), output 0 of angle op.");
    AddComment(R"DOC(
TODO: Documentation of angle op.
)DOC");
  }
};


class AngleOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(angle, AngleInferShapeFunctor,
                            PD_INFER_META(phi::RealAndImagInferMeta));



class ApplyPerChannelScaleOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of apply_per_channel_scale op.");
    AddInput("scales", "(Tensor), input 1 of apply_per_channel_scale op.");
    AddOutput("out", "(Tensor), output 0 of apply_per_channel_scale op.");
    AddComment(R"DOC(
TODO: Documentation of apply_per_channel_scale op.
)DOC");
  }
};


class ApplyPerChannelScaleOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(apply_per_channel_scale, ApplyPerChannelScaleInferShapeFunctor,
                            PD_INFER_META(phi::ApplyPerChannelScaleInferMeta));



class ArgMaxOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of arg_max op.");
    AddOutput("Out", "(Tensor), output 0 of arg_max op.");
    AddAttr<int64_t>("axis", "(int64_t), attribute 0 for arg_max op.")

        .SupportTensor();
    AddAttr<bool>("keepdims", "(bool), attribute 1 for arg_max op.")
        .SetDefault(false);
    AddAttr<bool>("flatten", "(bool), attribute 2 for arg_max op.")
        .SetDefault(false);
    AddAttr<int>("dtype", "(int), attribute 3 for arg_max op.")
        .SetDefault(static_cast<int>(framework::TransToProtoVarType(phi::DataType::INT64)));
    AddComment(R"DOC(
TODO: Documentation of arg_max op.
)DOC");
  }
};


class ArgMaxOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(arg_max, ArgMaxInferShapeFunctor,
                            PD_INFER_META(phi::ArgMinMaxInferMeta));



class ArgMinOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of arg_min op.");
    AddOutput("Out", "(Tensor), output 0 of arg_min op.");
    AddAttr<int64_t>("axis", "(int64_t), attribute 0 for arg_min op.")

        .SupportTensor();
    AddAttr<bool>("keepdims", "(bool), attribute 1 for arg_min op.")
        .SetDefault(false);
    AddAttr<bool>("flatten", "(bool), attribute 2 for arg_min op.")
        .SetDefault(false);
    AddAttr<int>("dtype", "(int), attribute 3 for arg_min op.")
        .SetDefault(static_cast<int>(framework::TransToProtoVarType(phi::DataType::INT64)));
    AddComment(R"DOC(
TODO: Documentation of arg_min op.
)DOC");
  }
};


class ArgMinOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(arg_min, ArgMinInferShapeFunctor,
                            PD_INFER_META(phi::ArgMinMaxInferMeta));



class ArgsortOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of argsort op.");
    AddOutput("Out", "(Tensor), output 0 of argsort op.");
    AddOutput("Indices", "(Tensor), output 1 of argsort op.");
    AddAttr<int>("axis", "(int), attribute 0 for argsort op.")
        .SetDefault(-1);
    AddAttr<bool>("descending", "(bool), attribute 1 for argsort op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of argsort op.
)DOC");
  }
};


class ArgsortOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(argsort, ArgsortInferShapeFunctor,
                            PD_INFER_META(phi::ArgsortInferMeta));



class AsComplexOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of as_complex op.");
    AddOutput("Out", "(Tensor), output 0 of as_complex op.");
    AddComment(R"DOC(
TODO: Documentation of as_complex op.
)DOC");
  }
};


class AsComplexOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(as_complex, AsComplexInferShapeFunctor,
                            PD_INFER_META(phi::AsComplexInferMeta));



class AsRealOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of as_real op.");
    AddOutput("Out", "(Tensor), output 0 of as_real op.");
    AddComment(R"DOC(
TODO: Documentation of as_real op.
)DOC");
  }
};


class AsRealOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(as_real, AsRealInferShapeFunctor,
                            PD_INFER_META(phi::AsRealInferMeta));



class AsStridedOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("input", "(Tensor), input 0 of as_strided op.");
    AddOutput("out", "(Tensor), output 0 of as_strided op.");
    AddAttr<std::vector<int64_t>>("dims", "(std::vector<int64_t>), attribute 0 for as_strided op.")
        .SetDefault({});
    AddAttr<std::vector<int64_t>>("stride", "(std::vector<int64_t>), attribute 1 for as_strided op.")
        .SetDefault({});
    AddAttr<int64_t>("offset", "(int64_t), attribute 2 for as_strided op.")
        .SetDefault(0);
    AddComment(R"DOC(
TODO: Documentation of as_strided op.
)DOC");
  }
};


class AsStridedOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(as_strided, AsStridedInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(AsStridedNoNeedBufferVarInferer,
                                    "input");


class AsgdOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("param", "(Tensor), input 0 of asgd op.");
    AddInput("grad", "(Tensor), input 1 of asgd op.");
    AddInput("learning_rate", "(Tensor), input 2 of asgd op.");
    AddInput("d", "(Tensor), input 3 of asgd op.");
    AddInput("y", "(Tensor), input 4 of asgd op.");
    AddInput("n", "(Tensor), input 5 of asgd op.");
    AddInput("master_param", "(Tensor), input 6 of asgd op.")
        .AsDispensable();
    AddOutput("param_out", "(Tensor), output 0 of asgd op.");
    AddOutput("d_out", "(Tensor), output 1 of asgd op.");
    AddOutput("y_out", "(Tensor), output 2 of asgd op.");
    AddOutput("master_param_out", "(Tensor), output 3 of asgd op.")
        .AsDispensable();
    AddAttr<bool>("multi_precision", "(bool), attribute 0 for asgd op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of asgd op.
)DOC");
  }
};


class AsgdOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "param");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "learning_rate" || var_name == "n") {
         return phi::KernelKey(tensor.place(), tensor.layout(), tensor.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(asgd, AsgdInferShapeFunctor,
                            PD_INFER_META(phi::ASGDInferMeta));



class AsinOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of asin op.");
    AddOutput("Out", "(Tensor), output 0 of asin op.");
    AddComment(R"DOC(
TODO: Documentation of asin op.
)DOC");
  }
};


class AsinOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(asin, AsinInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AsinInplaceInferer,
                           {"X", "Out"});



class AsinhOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of asinh op.");
    AddOutput("Out", "(Tensor), output 0 of asinh op.");
    AddComment(R"DOC(
TODO: Documentation of asinh op.
)DOC");
  }
};


class AsinhOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(asinh, AsinhInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AsinhInplaceInferer,
                           {"X", "Out"});



class AtanOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of atan op.");
    AddOutput("Out", "(Tensor), output 0 of atan op.");
    AddComment(R"DOC(
TODO: Documentation of atan op.
)DOC");
  }
};


class AtanOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(atan, AtanInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AtanInplaceInferer,
                           {"X", "Out"});



class Atan2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X1", "(Tensor), input 0 of atan2 op.");
    AddInput("X2", "(Tensor), input 1 of atan2 op.");
    AddOutput("Out", "(Tensor), output 0 of atan2 op.");
    AddComment(R"DOC(
TODO: Documentation of atan2 op.
)DOC");
  }
};


class Atan2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(atan2, Atan2InferShapeFunctor,
                            PD_INFER_META(phi::Atan2InferMeta));



class AtanhOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of atanh op.");
    AddOutput("Out", "(Tensor), output 0 of atanh op.");
    AddComment(R"DOC(
TODO: Documentation of atanh op.
)DOC");
  }
};


class AtanhOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(atanh, AtanhInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AtanhInplaceInferer,
                           {"X", "Out"});



class AucOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Predict", "(Tensor), input 0 of auc op.");
    AddInput("Label", "(Tensor), input 1 of auc op.");
    AddInput("StatPos", "(Tensor), input 2 of auc op.");
    AddInput("StatNeg", "(Tensor), input 3 of auc op.");
    AddInput("InsTagWeight", "(Tensor), input 4 of auc op.")
        .AsDispensable();
    AddOutput("AUC", "(Tensor), output 0 of auc op.");
    AddOutput("StatPosOut", "(Tensor), output 1 of auc op.");
    AddOutput("StatNegOut", "(Tensor), output 2 of auc op.");
    AddAttr<std::string>("curve", "(std::string), attribute 0 for auc op.")
        .SetDefault("ROC");
    AddAttr<int>("num_thresholds", "(int), attribute 1 for auc op.")
        .SetDefault((2 << 12) - 1);
    AddAttr<int>("slide_steps", "(int), attribute 2 for auc op.")
        .SetDefault(1);
    AddComment(R"DOC(
TODO: Documentation of auc op.
)DOC");
  }
};


class AucOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Predict");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(auc, AucInferShapeFunctor,
                            PD_INFER_META(phi::AucInferMeta));



class AverageAccumulatesOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("param", "(Tensor), input 0 of average_accumulates op.");
    AddInput("in_sum_1", "(Tensor), input 1 of average_accumulates op.");
    AddInput("in_sum_2", "(Tensor), input 2 of average_accumulates op.");
    AddInput("in_sum_3", "(Tensor), input 3 of average_accumulates op.");
    AddInput("in_num_accumulates", "(Tensor), input 4 of average_accumulates op.");
    AddInput("in_old_num_accumulates", "(Tensor), input 5 of average_accumulates op.");
    AddInput("in_num_updates", "(Tensor), input 6 of average_accumulates op.");
    AddOutput("out_sum_1", "(Tensor), output 0 of average_accumulates op.");
    AddOutput("out_sum_2", "(Tensor), output 1 of average_accumulates op.");
    AddOutput("out_sum_3", "(Tensor), output 2 of average_accumulates op.");
    AddOutput("out_num_accumulates", "(Tensor), output 3 of average_accumulates op.");
    AddOutput("out_old_num_accumulates", "(Tensor), output 4 of average_accumulates op.");
    AddOutput("out_num_updates", "(Tensor), output 5 of average_accumulates op.");
    AddAttr<float>("average_window", "(float), attribute 0 for average_accumulates op.")
        .SetDefault(0);
    AddAttr<int64_t>("max_average_window", "(int64_t), attribute 1 for average_accumulates op.")
        .SetDefault(INT64_MAX);
    AddAttr<int64_t>("min_average_window", "(int64_t), attribute 2 for average_accumulates op.")
        .SetDefault(10000L);
    AddComment(R"DOC(
TODO: Documentation of average_accumulates op.
)DOC");
  }
};


class AverageAccumulatesOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "param");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(average_accumulates, AverageAccumulatesInferShapeFunctor,
                            PD_INFER_META(phi::AverageAccumulatesInferMeta));



class BceLossOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bce_loss op.");
    AddInput("Label", "(Tensor), input 1 of bce_loss op.");
    AddOutput("Out", "(Tensor), output 0 of bce_loss op.");
    AddComment(R"DOC(
TODO: Documentation of bce_loss op.
)DOC");
  }
};


class BceLossOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bce_loss, BceLossInferShapeFunctor,
                            PD_INFER_META(phi::BCELossInferMeta));
DECLARE_INPLACE_OP_INFERER(BceLossInplaceInferer,
                           {"X", "Out"});



class BernoulliOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bernoulli op.");
    AddOutput("Out", "(Tensor), output 0 of bernoulli op.");
    AddComment(R"DOC(
TODO: Documentation of bernoulli op.
)DOC");
  }
};


class BernoulliOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(bernoulli, BernoulliInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class BicubicInterpV2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bicubic_interp_v2 op.");
    AddInput("OutSize", "(Tensor), input 1 of bicubic_interp_v2 op.")
        .AsDispensable();
    AddInput("SizeTensor", "(Tensor[]), input 2 of bicubic_interp_v2 op.")
        .AsDuplicable()
        .AsDispensable();
    AddInput("Scale", "(Tensor), input 3 of bicubic_interp_v2 op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of bicubic_interp_v2 op.");
    AddAttr<std::string>("data_layout", "(std::string), attribute 0 for bicubic_interp_v2 op.")
        .SetDefault("NCHW");
    AddAttr<int>("out_d", "(int), attribute 1 for bicubic_interp_v2 op.")
        .SetDefault(0);
    AddAttr<int>("out_h", "(int), attribute 2 for bicubic_interp_v2 op.")
        .SetDefault(0);
    AddAttr<int>("out_w", "(int), attribute 3 for bicubic_interp_v2 op.")
        .SetDefault(0);
    AddAttr<std::vector<float>>("scale", "(std::vector<float>), attribute 4 for bicubic_interp_v2 op.")
        .SetDefault({});
    AddAttr<std::string>("interp_method", "(std::string), attribute 5 for bicubic_interp_v2 op.")
        .SetDefault("bilinear");
    AddAttr<bool>("align_corners", "(bool), attribute 6 for bicubic_interp_v2 op.")
        .SetDefault(true);
    AddAttr<int>("align_mode", "(int), attribute 7 for bicubic_interp_v2 op.")
        .SetDefault(1);
    AddComment(R"DOC(
TODO: Documentation of bicubic_interp_v2 op.
)DOC");
  }
};


class BicubicInterpV2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "OutSize" || var_name == "SizeTensor" || var_name == "Scale") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(bicubic_interp_v2, BicubicInterpV2InferShapeFunctor,
                            PD_INFER_META(phi::InterpolateInferMeta));



class BilinearTensorProductOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bilinear_tensor_product op.");
    AddInput("Y", "(Tensor), input 1 of bilinear_tensor_product op.");
    AddInput("Weight", "(Tensor), input 2 of bilinear_tensor_product op.");
    AddInput("Bias", "(Tensor), input 3 of bilinear_tensor_product op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of bilinear_tensor_product op.");
    AddComment(R"DOC(
TODO: Documentation of bilinear_tensor_product op.
)DOC");
  }
};


class BilinearTensorProductOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(bilinear_tensor_product, BilinearTensorProductInferShapeFunctor,
                            PD_INFER_META(phi::BilinearInferMeta));



class BilinearInterpV2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bilinear_interp_v2 op.");
    AddInput("OutSize", "(Tensor), input 1 of bilinear_interp_v2 op.")
        .AsDispensable();
    AddInput("SizeTensor", "(Tensor[]), input 2 of bilinear_interp_v2 op.")
        .AsDuplicable()
        .AsDispensable();
    AddInput("Scale", "(Tensor), input 3 of bilinear_interp_v2 op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of bilinear_interp_v2 op.");
    AddAttr<std::string>("data_layout", "(std::string), attribute 0 for bilinear_interp_v2 op.")
        .SetDefault("NCHW");
    AddAttr<int>("out_d", "(int), attribute 1 for bilinear_interp_v2 op.")
        .SetDefault(0);
    AddAttr<int>("out_h", "(int), attribute 2 for bilinear_interp_v2 op.")
        .SetDefault(0);
    AddAttr<int>("out_w", "(int), attribute 3 for bilinear_interp_v2 op.")
        .SetDefault(0);
    AddAttr<std::vector<float>>("scale", "(std::vector<float>), attribute 4 for bilinear_interp_v2 op.")
        .SetDefault({});
    AddAttr<std::string>("interp_method", "(std::string), attribute 5 for bilinear_interp_v2 op.")
        .SetDefault("bilinear");
    AddAttr<bool>("align_corners", "(bool), attribute 6 for bilinear_interp_v2 op.")
        .SetDefault(true);
    AddAttr<int>("align_mode", "(int), attribute 7 for bilinear_interp_v2 op.")
        .SetDefault(1);
    AddComment(R"DOC(
TODO: Documentation of bilinear_interp_v2 op.
)DOC");
  }
};


class BilinearInterpV2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "OutSize" || var_name == "SizeTensor" || var_name == "Scale") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(bilinear_interp_v2, BilinearInterpV2InferShapeFunctor,
                            PD_INFER_META(phi::InterpolateInferMeta));



class BincountOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bincount op.");
    AddInput("Weights", "(Tensor), input 1 of bincount op.")
        .AsDispensable();
    AddOutput("Out", "(Tensor), output 0 of bincount op.");
    AddAttr<int>("minlength", "(int), attribute 0 for bincount op.")
        .SetDefault(0)
        .SupportTensor();
    AddComment(R"DOC(
TODO: Documentation of bincount op.
)DOC");
  }
};


class BincountOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetBincountExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bincount, BincountInferShapeFunctor,
                            PD_INFER_META(phi::BincountInferMeta));



class BinomialOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("count", "(Tensor), input 0 of binomial op.");
    AddInput("prob", "(Tensor), input 1 of binomial op.");
    AddOutput("out", "(Tensor), output 0 of binomial op.");
    AddComment(R"DOC(
TODO: Documentation of binomial op.
)DOC");
  }
};


class BinomialOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(binomial, BinomialInferShapeFunctor,
                            PD_INFER_META(phi::BinomialInferMeta));



class BitwiseAndOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bitwise_and op.");
    AddInput("Y", "(Tensor), input 1 of bitwise_and op.");
    AddOutput("Out", "(Tensor), output 0 of bitwise_and op.");
    AddComment(R"DOC(
TODO: Documentation of bitwise_and op.
)DOC");
  }
};


class BitwiseAndOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
      kt = OperatorWithKernel::GetExpectedKernelType(ctx);
      kt.set_backend(
          phi::TransToPhiBackend(ctx.Input<phi::DenseTensor>("X")->place()));
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bitwise_and, BitwiseAndInferShapeFunctor,
                            PD_INFER_META(phi::ElementwiseInferMeta));
DECLARE_INPLACE_OP_INFERER(BitwiseAndInplaceInferer,
                           {"X", "Out"});



class BitwiseLeftShiftOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of bitwise_left_shift op.");
    AddInput("y", "(Tensor), input 1 of bitwise_left_shift op.");
    AddOutput("out", "(Tensor), output 0 of bitwise_left_shift op.");
    AddAttr<bool>("is_arithmetic", "(bool), attribute 0 for bitwise_left_shift op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of bitwise_left_shift op.
)DOC");
  }
};


class BitwiseLeftShiftOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
      kt = OperatorWithKernel::GetExpectedKernelType(ctx);
      kt.set_backend(
          phi::TransToPhiBackend(ctx.Input<phi::DenseTensor>("x")->place()));
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bitwise_left_shift, BitwiseLeftShiftInferShapeFunctor,
                            PD_INFER_META(phi::BitwiseShiftInferMeta));
DECLARE_INPLACE_OP_INFERER(BitwiseLeftShiftInplaceInferer,
                           {"x", "out"});



class BitwiseNotOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bitwise_not op.");
    AddOutput("Out", "(Tensor), output 0 of bitwise_not op.");
    AddComment(R"DOC(
TODO: Documentation of bitwise_not op.
)DOC");
  }
};


class BitwiseNotOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
      kt = OperatorWithKernel::GetExpectedKernelType(ctx);
      kt.set_backend(
          phi::TransToPhiBackend(ctx.Input<phi::DenseTensor>("X")->place()));
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bitwise_not, BitwiseNotInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(BitwiseNotInplaceInferer,
                           {"X", "Out"});



class BitwiseOrOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bitwise_or op.");
    AddInput("Y", "(Tensor), input 1 of bitwise_or op.");
    AddOutput("Out", "(Tensor), output 0 of bitwise_or op.");
    AddComment(R"DOC(
TODO: Documentation of bitwise_or op.
)DOC");
  }
};


class BitwiseOrOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
      kt = OperatorWithKernel::GetExpectedKernelType(ctx);
      kt.set_backend(
          phi::TransToPhiBackend(ctx.Input<phi::DenseTensor>("X")->place()));
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bitwise_or, BitwiseOrInferShapeFunctor,
                            PD_INFER_META(phi::ElementwiseInferMeta));
DECLARE_INPLACE_OP_INFERER(BitwiseOrInplaceInferer,
                           {"X", "Out"});



class BitwiseRightShiftOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of bitwise_right_shift op.");
    AddInput("y", "(Tensor), input 1 of bitwise_right_shift op.");
    AddOutput("out", "(Tensor), output 0 of bitwise_right_shift op.");
    AddAttr<bool>("is_arithmetic", "(bool), attribute 0 for bitwise_right_shift op.")
        .SetDefault(true);
    AddComment(R"DOC(
TODO: Documentation of bitwise_right_shift op.
)DOC");
  }
};


class BitwiseRightShiftOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
      kt = OperatorWithKernel::GetExpectedKernelType(ctx);
      kt.set_backend(
          phi::TransToPhiBackend(ctx.Input<phi::DenseTensor>("x")->place()));
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bitwise_right_shift, BitwiseRightShiftInferShapeFunctor,
                            PD_INFER_META(phi::BitwiseShiftInferMeta));
DECLARE_INPLACE_OP_INFERER(BitwiseRightShiftInplaceInferer,
                           {"x", "out"});



class BitwiseXorOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bitwise_xor op.");
    AddInput("Y", "(Tensor), input 1 of bitwise_xor op.");
    AddOutput("Out", "(Tensor), output 0 of bitwise_xor op.");
    AddComment(R"DOC(
TODO: Documentation of bitwise_xor op.
)DOC");
  }
};


class BitwiseXorOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
      kt = OperatorWithKernel::GetExpectedKernelType(ctx);
      kt.set_backend(
          phi::TransToPhiBackend(ctx.Input<phi::DenseTensor>("X")->place()));
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bitwise_xor, BitwiseXorInferShapeFunctor,
                            PD_INFER_META(phi::ElementwiseInferMeta));
DECLARE_INPLACE_OP_INFERER(BitwiseXorInplaceInferer,
                           {"X", "Out"});



class BmmOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of bmm op.");
    AddInput("Y", "(Tensor), input 1 of bmm op.");
    AddOutput("Out", "(Tensor), output 0 of bmm op.");
    AddComment(R"DOC(
TODO: Documentation of bmm op.
)DOC");
  }
};


class BmmOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(bmm, BmmInferShapeFunctor,
                            PD_INFER_META(phi::BmmInferMeta));



class BoxCoderOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("PriorBox", "(Tensor), input 0 of box_coder op.");
    AddInput("PriorBoxVar", "(Tensor), input 1 of box_coder op.")
        .AsDispensable();
    AddInput("TargetBox", "(Tensor), input 2 of box_coder op.");
    AddOutput("OutputBox", "(Tensor), output 0 of box_coder op.");
    AddAttr<std::string>("code_type", "(std::string), attribute 0 for box_coder op.")
        .SetDefault("encode_center_size");
    AddAttr<bool>("box_normalized", "(bool), attribute 1 for box_coder op.")
        .SetDefault(true);
    AddAttr<int>("axis", "(int), attribute 2 for box_coder op.")
        .SetDefault(0);
    AddAttr<std::vector<float>>("variance", "(std::vector<float>), attribute 3 for box_coder op.")
        .SetDefault({});
    AddComment(R"DOC(
TODO: Documentation of box_coder op.
)DOC");
  }
};


class BoxCoderOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(box_coder, BoxCoderInferShapeFunctor,
                            PD_INFER_META(phi::BoxCoderInferMeta));



class BroadcastTensorsOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor[]), input 0 of broadcast_tensors op.")
        .AsDuplicable();
    AddOutput("Out", "(Tensor[]), output 0 of broadcast_tensors op.")
        .AsDuplicable();
    AddComment(R"DOC(
TODO: Documentation of broadcast_tensors op.
)DOC");
  }
};


class BroadcastTensorsOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(broadcast_tensors, BroadcastTensorsInferShapeFunctor,
                            PD_INFER_META(phi::BroadcastTensorsInferMeta));



class CeilOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of ceil op.");
    AddOutput("Out", "(Tensor), output 0 of ceil op.");
    AddComment(R"DOC(
TODO: Documentation of ceil op.
)DOC");
  }
};


class CeilOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(ceil, CeilInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(CeilInplaceInferer,
                           {"X", "Out"});



class CeluOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of celu op.");
    AddOutput("Out", "(Tensor), output 0 of celu op.");
    AddAttr<float>("alpha", "(float), attribute 0 for celu op.")
        .SetDefault(1.0);
    AddComment(R"DOC(
TODO: Documentation of celu op.
)DOC");
  }
};


class CeluOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(celu, CeluInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class CheckFiniteAndUnscaleOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor[]), input 0 of check_finite_and_unscale op.")
        .AsDuplicable();
    AddInput("Scale", "(Tensor), input 1 of check_finite_and_unscale op.");
    AddOutput("Out", "(Tensor[]), output 0 of check_finite_and_unscale op.")
        .AsDuplicable();
    AddOutput("FoundInfinite", "(Tensor), output 1 of check_finite_and_unscale op.");
    AddComment(R"DOC(
TODO: Documentation of check_finite_and_unscale op.
)DOC");
  }
};


class CheckFiniteAndUnscaleOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetCheckFiniteAndUnscaleExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(check_finite_and_unscale, CheckFiniteAndUnscaleInferShapeFunctor,
                            PD_INFER_META(phi::CheckFiniteAndUnscaleInferMeta));
DECLARE_INPLACE_OP_INFERER(CheckFiniteAndUnscaleInplaceInferer,
                           {"X", "Out"});



class CheckNumericsOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("tensor", "(Tensor), input 0 of check_numerics op.");
    AddOutput("stats", "(Tensor), output 0 of check_numerics op.");
    AddOutput("values", "(Tensor), output 1 of check_numerics op.");
    AddAttr<std::string>("op_type", "(std::string), attribute 0 for check_numerics op.")
        .SetDefault("");
    AddAttr<std::string>("var_name", "(std::string), attribute 1 for check_numerics op.")
        .SetDefault("");
    AddAttr<int>("check_nan_inf_level", "(int), attribute 2 for check_numerics op.")
        .SetDefault(0);
    AddAttr<int>("stack_height_limit", "(int), attribute 3 for check_numerics op.")
        .SetDefault(-1);
    AddAttr<std::string>("output_dir", "(std::string), attribute 4 for check_numerics op.")
        .SetDefault("");
    AddComment(R"DOC(
TODO: Documentation of check_numerics op.
)DOC");
  }
};


class CheckNumericsOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(check_numerics, CheckNumericsInferShapeFunctor,
                            PD_INFER_META(phi::CheckNumericsInferMeta));



class CholeskyOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of cholesky op.");
    AddOutput("Out", "(Tensor), output 0 of cholesky op.");
    AddAttr<bool>("upper", "(bool), attribute 0 for cholesky op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of cholesky op.
)DOC");
  }
};


class CholeskyOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cholesky, CholeskyInferShapeFunctor,
                            PD_INFER_META(phi::CholeskyInferMeta));



class CholeskySolveOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of cholesky_solve op.");
    AddInput("Y", "(Tensor), input 1 of cholesky_solve op.");
    AddOutput("Out", "(Tensor), output 0 of cholesky_solve op.");
    AddAttr<bool>("upper", "(bool), attribute 0 for cholesky_solve op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of cholesky_solve op.
)DOC");
  }
};


class CholeskySolveOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cholesky_solve, CholeskySolveInferShapeFunctor,
                            PD_INFER_META(phi::CholeskySolveInferMeta));



class ClassCenterSampleOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Label", "(Tensor), input 0 of class_center_sample op.");
    AddOutput("RemappedLabel", "(Tensor), output 0 of class_center_sample op.");
    AddOutput("SampledLocalClassCenter", "(Tensor), output 1 of class_center_sample op.");
    AddAttr<int>("num_classes", "(int), attribute 0 for class_center_sample op.")
    ;
    AddAttr<int>("num_samples", "(int), attribute 1 for class_center_sample op.")
    ;
    AddAttr<int>("ring_id", "(int), attribute 2 for class_center_sample op.")
        .SetDefault(0);
    AddAttr<int>("rank", "(int), attribute 3 for class_center_sample op.")
        .SetDefault(0);
    AddAttr<int>("nranks", "(int), attribute 4 for class_center_sample op.")
        .SetDefault(1);
    AddAttr<bool>("fix_seed", "(bool), attribute 5 for class_center_sample op.")
        .SetDefault(false);
    AddAttr<int>("seed", "(int), attribute 6 for class_center_sample op.")
        .SetDefault(0);
    AddComment(R"DOC(
TODO: Documentation of class_center_sample op.
)DOC");
  }
};


class ClassCenterSampleOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Label");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(class_center_sample, ClassCenterSampleInferShapeFunctor,
                            PD_INFER_META(phi::ClassCenterSampleInferMeta));



class ClipOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of clip op.");
    AddOutput("Out", "(Tensor), output 0 of clip op.");
    AddInput("Min", "attribute 0 for clip op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("min", "(float), attribute 0 for clip op.")
    ;
    AddInput("Max", "attribute 1 for clip op from 0D Tensor.")
        .AsDispensable();
    AddAttr<float>("max", "(float), attribute 1 for clip op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of clip op.
)DOC");
  }
};


class ClipOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(clip, ClipInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(ClipInplaceInferer,
                           {"X", "Out"});



class ClipByNormOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of clip_by_norm op.");
    AddOutput("Out", "(Tensor), output 0 of clip_by_norm op.");
    AddAttr<float>("max_norm", "(float), attribute 0 for clip_by_norm op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of clip_by_norm op.
)DOC");
  }
};


class ClipByNormOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(clip_by_norm, ClipByNormInferShapeFunctor,
                            PD_INFER_META(phi::ClipByNormInferMeta));



class CoalesceTensorOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor[]), input 0 of coalesce_tensor op.")
        .AsDuplicable();
    AddOutput("Output", "(Tensor[]), output 0 of coalesce_tensor op.")
        .AsDuplicable();
    AddOutput("FusedOutput", "(Tensor), output 1 of coalesce_tensor op.");
    AddAttr<int>("dtype", "(int), attribute 0 for coalesce_tensor op.")
    ;
    AddAttr<bool>("copy_data", "(bool), attribute 1 for coalesce_tensor op.")
        .SetDefault(false);
    AddAttr<bool>("set_constant", "(bool), attribute 2 for coalesce_tensor op.")
        .SetDefault(false);
    AddAttr<bool>("persist_output", "(bool), attribute 3 for coalesce_tensor op.")
        .SetDefault(false);
    AddAttr<float>("constant", "(float), attribute 4 for coalesce_tensor op.")
        .SetDefault(0.0);
    AddAttr<bool>("use_align", "(bool), attribute 5 for coalesce_tensor op.")
        .SetDefault(true);
    AddAttr<int>("align_size", "(int), attribute 6 for coalesce_tensor op.")
        .SetDefault(-1);
    AddAttr<int>("user_defined_size_of_dtype", "(int), attribute 7 for coalesce_tensor op.")
        .SetDefault(-1);
    AddAttr<std::vector<int64_t>>("concated_shapes", "(std::vector<int64_t>), attribute 8 for coalesce_tensor op.")
        .SetDefault({});
    AddAttr<std::vector<int64_t>>("concated_ranks", "(std::vector<int64_t>), attribute 9 for coalesce_tensor op.")
        .SetDefault({});
    AddComment(R"DOC(
TODO: Documentation of coalesce_tensor op.
)DOC");
  }
};


class CoalesceTensorOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::proto::VarType::Type(ctx.Attr<int>("dtype"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(coalesce_tensor, CoalesceTensorInferShapeFunctor,
                            PD_INFER_META(phi::CoalesceTensorInferMeta));



class ComplexOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of complex op.");
    AddInput("Y", "(Tensor), input 1 of complex op.");
    AddOutput("Out", "(Tensor), output 0 of complex op.");
    AddComment(R"DOC(
TODO: Documentation of complex op.
)DOC");
  }
};


class ComplexOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(complex, ComplexInferShapeFunctor,
                            PD_INFER_META(phi::ComplexInferMeta));



class ConcatOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor[]), input 0 of concat op.")
        .AsDuplicable();
    AddOutput("Out", "(Tensor), output 0 of concat op.");
    AddInput("AxisTensor", "attribute 0 for concat op from 0D Tensor.")
        .AsDispensable();
    AddAttr<int>("axis", "(int), attribute 0 for concat op.")
        .SetDefault(0);
    AddComment(R"DOC(
TODO: Documentation of concat op.
)DOC");
  }
};


class ConcatOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetConcatExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(concat, ConcatInferShapeFunctor,
                            PD_INFER_META(phi::ConcatInferMeta));



class ConjOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of conj op.");
    AddOutput("Out", "(Tensor), output 0 of conj op.");
    AddComment(R"DOC(
TODO: Documentation of conj op.
)DOC");
  }
};


class ConjOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(conj, ConjInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class Conv2dOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of conv2d op.");
    AddInput("Filter", "(Tensor), input 1 of conv2d op.");
    AddOutput("Output", "(Tensor), output 0 of conv2d op.");
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 0 for conv2d op.")
        .SetDefault({1, 1});
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 1 for conv2d op.")
        .SetDefault({0, 0});
    AddAttr<std::string>("padding_algorithm", "(std::string), attribute 2 for conv2d op.")
        .SetDefault("EXPLICIT");
    AddAttr<std::vector<int>>("dilations", "(std::vector<int>), attribute 3 for conv2d op.")
        .SetDefault({1, 1});
    AddAttr<int>("groups", "(int), attribute 4 for conv2d op.")
        .SetDefault(1);
    AddAttr<std::string>("data_format", "(std::string), attribute 5 for conv2d op.")
        .SetDefault("NCHW");
    AddComment(R"DOC(
TODO: Documentation of conv2d op.
)DOC");
  }
};


class Conv2dOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetConvExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv2d, Conv2dInferShapeFunctor,
                            PD_INFER_META(phi::ConvInferMeta));



class Conv3dOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of conv3d op.");
    AddInput("Filter", "(Tensor), input 1 of conv3d op.");
    AddOutput("Output", "(Tensor), output 0 of conv3d op.");
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 0 for conv3d op.")
        .SetDefault({1, 1, 1});
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 1 for conv3d op.")
        .SetDefault({0, 0, 0});
    AddAttr<std::string>("padding_algorithm", "(std::string), attribute 2 for conv3d op.")
        .SetDefault("EXPLICIT");
    AddAttr<int>("groups", "(int), attribute 3 for conv3d op.")
        .SetDefault(1);
    AddAttr<std::vector<int>>("dilations", "(std::vector<int>), attribute 4 for conv3d op.")
        .SetDefault({1, 1, 1});
    AddAttr<std::string>("data_format", "(std::string), attribute 5 for conv3d op.")
        .SetDefault("NCDHW");
    AddComment(R"DOC(
TODO: Documentation of conv3d op.
)DOC");
  }
};


class Conv3dOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetConvExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv3d, Conv3dInferShapeFunctor,
                            PD_INFER_META(phi::Conv3DInferMeta));



class Conv3dTransposeOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of conv3d_transpose op.");
    AddInput("Filter", "(Tensor), input 1 of conv3d_transpose op.");
    AddOutput("Output", "(Tensor), output 0 of conv3d_transpose op.");
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 0 for conv3d_transpose op.")
        .SetDefault({1, 1, 1});
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 1 for conv3d_transpose op.")
        .SetDefault({0, 0, 0});
    AddAttr<std::vector<int>>("output_padding", "(std::vector<int>), attribute 2 for conv3d_transpose op.")
        .SetDefault({});
    AddAttr<std::vector<int>>("output_size", "(std::vector<int>), attribute 3 for conv3d_transpose op.")
        .SetDefault({});
    AddAttr<std::string>("padding_algorithm", "(std::string), attribute 4 for conv3d_transpose op.")
        .SetDefault("EXPLICIT");
    AddAttr<int>("groups", "(int), attribute 5 for conv3d_transpose op.")
        .SetDefault(1);
    AddAttr<std::vector<int>>("dilations", "(std::vector<int>), attribute 6 for conv3d_transpose op.")
        .SetDefault({1, 1, 1});
    AddAttr<std::string>("data_format", "(std::string), attribute 7 for conv3d_transpose op.")
        .SetDefault("NCHW");
    AddComment(R"DOC(
TODO: Documentation of conv3d_transpose op.
)DOC");
  }
};


class Conv3dTransposeOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv3d_transpose, Conv3dTransposeInferShapeFunctor,
                            PD_INFER_META(phi::ConvTransposeInferMeta));



class CopysignOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of copysign op.");
    AddInput("y", "(Tensor), input 1 of copysign op.");
    AddOutput("out", "(Tensor), output 0 of copysign op.");
    AddComment(R"DOC(
TODO: Documentation of copysign op.
)DOC");
  }
};


class CopysignOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(copysign, CopysignInferShapeFunctor,
                            PD_INFER_META(phi::ElementwiseInferMeta));
DECLARE_INPLACE_OP_INFERER(CopysignInplaceInferer,
                           {"x", "out"});



class CosOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of cos op.");
    AddOutput("Out", "(Tensor), output 0 of cos op.");
    AddComment(R"DOC(
TODO: Documentation of cos op.
)DOC");
  }
};


class CosOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cos, CosInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(CosInplaceInferer,
                           {"X", "Out"});



class CoshOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of cosh op.");
    AddOutput("Out", "(Tensor), output 0 of cosh op.");
    AddComment(R"DOC(
TODO: Documentation of cosh op.
)DOC");
  }
};


class CoshOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cosh, CoshInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(CoshInplaceInferer,
                           {"X", "Out"});



class CropTensorOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of crop_tensor op.");
    AddOutput("Out", "(Tensor), output 0 of crop_tensor op.");
    AddInput("Shape", "attribute 0 for crop_tensor op from 1D integer Tensor.")
        .AsDispensable();
    AddInput("ShapeTensor", "attribute 0 for crop_tensor op from list fo 0D integer Tensors.")
        .AsDuplicable()
        .AsDispensable();
      AddAttr<std::vector<int>>("shape", "(std::vector<int>), attribute 0 for crop_tensor op.")
        .SetDefault({});
    AddInput("Offsets", "attribute 1 for crop_tensor op from 1D integer Tensor.")
        .AsDispensable();
    AddInput("OffsetsTensor", "attribute 1 for crop_tensor op from list fo 0D integer Tensors.")
        .AsDuplicable()
        .AsDispensable();
      AddAttr<std::vector<int>>("offsets", "(std::vector<int>), attribute 1 for crop_tensor op.")
        .SetDefault({});
    AddComment(R"DOC(
TODO: Documentation of crop_tensor op.
)DOC");
  }
};


class CropTensorOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(crop_tensor, CropTensorInferShapeFunctor,
                            PD_INFER_META(phi::CropInferMeta));



class CrossOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of cross op.");
    AddInput("Y", "(Tensor), input 1 of cross op.");
    AddOutput("Out", "(Tensor), output 0 of cross op.");
    AddAttr<int>("dim", "(int), attribute 0 for cross op.")
        .SetDefault(9);
    AddComment(R"DOC(
TODO: Documentation of cross op.
)DOC");
  }
};


class CrossOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cross, CrossInferShapeFunctor,
                            PD_INFER_META(phi::CrossInferMeta));



class SoftmaxWithCrossEntropyOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Logits", "(Tensor), input 0 of softmax_with_cross_entropy op.");
    AddInput("Label", "(Tensor), input 1 of softmax_with_cross_entropy op.");
    AddOutput("Softmax", "(Tensor), output 0 of softmax_with_cross_entropy op.");
    AddOutput("Loss", "(Tensor), output 1 of softmax_with_cross_entropy op.");
    AddAttr<bool>("soft_label", "(bool), attribute 0 for softmax_with_cross_entropy op.")
        .SetDefault(false);
    AddAttr<bool>("use_softmax", "(bool), attribute 1 for softmax_with_cross_entropy op.")
        .SetDefault(true);
    AddAttr<bool>("numeric_stable_mode", "(bool), attribute 2 for softmax_with_cross_entropy op.")
        .SetDefault(true);
    AddAttr<int>("ignore_index", "(int), attribute 3 for softmax_with_cross_entropy op.")
        .SetDefault(-100);
    AddAttr<int>("axis", "(int), attribute 4 for softmax_with_cross_entropy op.")
        .SetDefault(-1);
    AddComment(R"DOC(
TODO: Documentation of softmax_with_cross_entropy op.
)DOC");
  }
};


class SoftmaxWithCrossEntropyOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Logits");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(softmax_with_cross_entropy, SoftmaxWithCrossEntropyInferShapeFunctor,
                            PD_INFER_META(phi::CrossEntropyWithSoftmaxInferMeta));
DECLARE_INPLACE_OP_INFERER(SoftmaxWithCrossEntropyInplaceInferer,
                           {"Logits", "Softmax"});



class CummaxOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of cummax op.");
    AddOutput("out", "(Tensor), output 0 of cummax op.");
    AddOutput("indices", "(Tensor), output 1 of cummax op.");
    AddAttr<int>("axis", "(int), attribute 0 for cummax op.")
        .SetDefault(-1);
    AddAttr<int>("dtype", "(int), attribute 1 for cummax op.")
        .SetDefault(static_cast<int>(framework::TransToProtoVarType(phi::DataType::INT64)));
    AddComment(R"DOC(
TODO: Documentation of cummax op.
)DOC");
  }
};


class CummaxOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cummax, CummaxInferShapeFunctor,
                            PD_INFER_META(phi::CumWithIndicesInferMeta));



class CumminOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("x", "(Tensor), input 0 of cummin op.");
    AddOutput("out", "(Tensor), output 0 of cummin op.");
    AddOutput("indices", "(Tensor), output 1 of cummin op.");
    AddAttr<int>("axis", "(int), attribute 0 for cummin op.")
        .SetDefault(-1);
    AddAttr<int>("dtype", "(int), attribute 1 for cummin op.")
        .SetDefault(static_cast<int>(framework::TransToProtoVarType(phi::DataType::INT64)));
    AddComment(R"DOC(
TODO: Documentation of cummin op.
)DOC");
  }
};


class CumminOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "x");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cummin, CumminInferShapeFunctor,
                            PD_INFER_META(phi::CumWithIndicesInferMeta));



class CumprodOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of cumprod op.");
    AddOutput("Out", "(Tensor), output 0 of cumprod op.");
    AddAttr<int>("dim", "(int), attribute 0 for cumprod op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of cumprod op.
)DOC");
  }
};


class CumprodOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cumprod, CumprodInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMetaCheckAxis));
DECLARE_INPLACE_OP_INFERER(CumprodInplaceInferer,
                           {"X", "Out"});



class CumsumOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of cumsum op.");
    AddOutput("Out", "(Tensor), output 0 of cumsum op.");
    AddAttr<int>("axis", "(int), attribute 0 for cumsum op.")
        .SetDefault(-1)
        .SupportTensor();
    AddAttr<bool>("flatten", "(bool), attribute 1 for cumsum op.")
        .SetDefault(false);
    AddAttr<bool>("exclusive", "(bool), attribute 2 for cumsum op.")
        .SetDefault(false);
    AddAttr<bool>("reverse", "(bool), attribute 3 for cumsum op.")
        .SetDefault(false);
    AddComment(R"DOC(
TODO: Documentation of cumsum op.
)DOC");
  }
};


class CumsumOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cumsum, CumsumInferShapeFunctor,
                            PD_INFER_META(phi::CumScalarAxisInferMeta));
DECLARE_INPLACE_OP_INFERER(CumsumInplaceInferer,
                           {"X", "Out"});



class DataOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddOutput("out", "(Tensor), output 0 of data op.");
    AddAttr<std::string>("name", "(std::string), attribute 0 for data op.")
    ;
    AddInput("ShapeTensor", "attribute 1 for data op from 1D integer Tensor.")
        .AsDispensable();
    AddInput("ShapeTensorList", "attribute 1 for data op from list fo 0D integer Tensors.")
        .AsDuplicable()
        .AsDispensable();
      AddAttr<std::vector<int64_t>>("shape", "(std::vector<int64_t>), attribute 1 for data op.")
    ;
    AddAttr<int>("dtype", "(int), attribute 2 for data op.")
    ;
    AddAttr<int>("place", "(int), attribute 3 for data op.")
    ;
    AddComment(R"DOC(
TODO: Documentation of data op.
)DOC");
  }
};


class DataOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::proto::VarType::Type(ctx.Attr<int>("dtype"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
      kt.set_backend(
          phi::TransToPhiBackend(ctx.Input<phi::DenseTensor>("place")->place()));
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(data, DataInferShapeFunctor,
                            PD_INFER_META(phi::DataInferMeta));



class DepthwiseConv2dOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of depthwise_conv2d op.");
    AddInput("Filter", "(Tensor), input 1 of depthwise_conv2d op.");
    AddOutput("Output", "(Tensor), output 0 of depthwise_conv2d op.");
    AddAttr<std::vector<int>>("strides", "(std::vector<int>), attribute 0 for depthwise_conv2d op.")
        .SetDefault({1, 1});
    AddAttr<std::vector<int>>("paddings", "(std::vector<int>), attribute 1 for depthwise_conv2d op.")
        .SetDefault({0, 0});
    AddAttr<std::string>("padding_algorithm", "(std::string), attribute 2 for depthwise_conv2d op.")
        .SetDefault("EXPLICIT");
    AddAttr<int>("groups", "(int), attribute 3 for depthwise_conv2d op.")
        .SetDefault(1);
    AddAttr<std::vector<int>>("dilations", "(std::vector<int>), attribute 4 for depthwise_conv2d op.")
        .SetDefault({1, 1});
    AddAttr<std::string>("data_format", "(std::string), attribute 5 for depthwise_conv2d op.")
        .SetDefault("NCHW");
    AddComment(R"DOC(
TODO: Documentation of depthwise_conv2d op.
)DOC");
  }
};


class DepthwiseConv2dOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
    return GetConvExpectedKernelType(ctx, this);
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(depthwise_conv2d, DepthwiseConv2dInferShapeFunctor,
                            PD_INFER_META(phi::DepthwiseConvInferMeta));



class DeterminantOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of determinant op.");
    AddOutput("Out", "(Tensor), output 0 of determinant op.");
    AddComment(R"DOC(
TODO: Documentation of determinant op.
)DOC");
  }
};


class DeterminantOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(determinant, DeterminantInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class DiagV2OpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("X", "(Tensor), input 0 of diag_v2 op.");
    AddOutput("Out", "(Tensor), output 0 of diag_v2 op.");
    AddAttr<int>("offset", "(int), attribute 0 for diag_v2 op.")
        .SetDefault(0);
    AddAttr<float>("padding_value", "(float), attribute 1 for diag_v2 op.")
        .SetDefault(0.0);
    AddComment(R"DOC(
TODO: Documentation of diag_v2 op.
)DOC");
  }
};


class DiagV2Op : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(diag_v2, DiagV2InferShapeFunctor,
                            PD_INFER_META(phi::DiagInferMeta));



class DiagEmbedOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of diag_embed op.");
    AddOutput("Out", "(Tensor), output 0 of diag_embed op.");
    AddAttr<int>("offset", "(int), attribute 0 for diag_embed op.")
        .SetDefault(0);
    AddAttr<int>("dim1", "(int), attribute 1 for diag_embed op.")
        .SetDefault(-2);
    AddAttr<int>("dim2", "(int), attribute 2 for diag_embed op.")
        .SetDefault(-1);
    AddComment(R"DOC(
TODO: Documentation of diag_embed op.
)DOC");
  }
};


class DiagEmbedOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(diag_embed, DiagEmbedInferShapeFunctor,
                            PD_INFER_META(phi::DiagEmbedInferMeta));



class DiagonalOpMaker : public framework::OpProtoAndCheckerMaker {
 public:
  void Make() override {
    AddInput("Input", "(Tensor), input 0 of diagonal op.");
    AddOutput("Out", "(Tensor), output 0 of diagonal op.");
    AddAttr<int>("offset", "(int), attribute 0 for diagonal op.")
        .SetDefault(0);
    AddAttr<int>("axis1", "(int), attribute 1 for diagonal op.")
        .SetDefault(0);
    AddAttr<int>("axis2", "(int), attribute 2 for diagonal op.")
        .SetDefault(1);
    AddComment(R"DOC(
TODO: Documentation of diagonal op.
)DOC");
  }
};


class DiagonalOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(diagonal, DiagonalInferShapeFunctor,
                            PD_INFER_META(phi::DiagonalInferMeta));




template <typename T>
class AbsGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("abs_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AbsGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(abs_grad, AbsGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));


class AbsCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing abs_grad composite func";
    prim::abs_grad<prim::DescTensor>(x, out_grad, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class AbsDoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("abs_double_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AbsDoubleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("grad_x"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "X" || var_name == "grad_x_grad") {
         return phi::KernelKey(tensor.place(), tensor.layout(), tensor.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(abs_double_grad, AbsDoubleGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



class AbsTripleCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto grad_out_grad_grad = this->GetSingleOutputGrad(GradVarName("grad_out"));


    //get attr

    //get output
    auto grad_x_grad_grad_t = this->GetSingleInputGrad(GradVarName("grad_x"));

    //get output ptr
    auto grad_x_grad_grad = this->GetOutputPtr(&grad_x_grad_grad_t);

    //get output orginal name
    auto grad_x_grad_grad_name = this->GetOutputName(grad_x_grad_grad_t);

    //call composite backward func
    VLOG(6) << "Runing abs_triple_grad composite func";
    prim::abs_triple_grad<prim::DescTensor>(x, grad_out_grad_grad, grad_x_grad_grad);
    //recover output name
    this->RecoverOutputName(grad_x_grad_grad_t, grad_x_grad_grad_name);

  }
};

template <typename T>
class AcosGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("acos_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AcosGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(acos_grad, AcosGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AcosGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class AcoshGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("acosh_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AcoshGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(acosh_grad, AcoshGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AcoshGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class AddmmGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("addmm_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AddmmGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(addmm_grad, AddmmGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));



template <typename T>
class AffineGridGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("affine_grid_grad");

    grad_op->SetInput("Theta", this->Input("Theta"));
    grad_op->SetInput(GradVarName("Output"), this->OutputGrad("Output"));

    grad_op->SetOutput(GradVarName("Theta"), this->InputGrad("Theta"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("OutputShape")) {
      grad_op->SetInput("OutputShape", this->Input("OutputShape"));
    }
  }
};


class AffineGridGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(affine_grid_grad, AffineGridGradInferShapeFunctor,
                            PD_INFER_META(phi::AffineGridGradInferMeta));



template <typename T>
class AngleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("angle_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AngleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(angle_grad, AngleGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class ArgsortGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("argsort_grad");

    grad_op->SetInput("Indices", this->Output("Indices"));
    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class ArgsortGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(argsort_grad, ArgsortGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(ArgsortGradNoNeedBufferVarInferer,
                                    "X");

template <typename T>
class AsComplexGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("as_real");

    grad_op->SetInput("X", this->OutputGrad("Out"));

    grad_op->SetOutput("Out", this->InputGrad("X"));


  }
};

template <typename T>
class AsRealGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("as_complex");

    grad_op->SetInput("X", this->OutputGrad("Out"));

    grad_op->SetOutput("Out", this->InputGrad("X"));


  }
};


template <typename T>
class AsStridedGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("as_strided_grad");

    grad_op->SetInput("input", this->Input("input"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("input"), this->InputGrad("input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AsStridedGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(as_strided_grad, AsStridedGradInferShapeFunctor,
                            PD_INFER_META(phi::StridedUnChangedInferMeta));



template <typename T>
class AsinGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("asin_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AsinGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(asin_grad, AsinGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AsinGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class AsinhGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("asinh_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AsinhGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(asinh_grad, AsinhGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AsinhGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class AtanGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("atan_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AtanGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(atan_grad, AtanGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AtanGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class Atan2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("atan2_grad");

    grad_op->SetInput("X1", this->Input("X1"));
    grad_op->SetInput("X2", this->Input("X2"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X1"), this->InputGrad("X1"));
    grad_op->SetOutput(GradVarName("X2"), this->InputGrad("X2"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Atan2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(atan2_grad, Atan2GradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class AtanhGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("atanh_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class AtanhGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(atanh_grad, AtanhGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(AtanhGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class BceLossGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("bce_loss_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Label", this->Input("Label"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class BceLossGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(bce_loss_grad, BceLossGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(BceLossGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class BicubicInterpV2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("bicubic_interp_v2_grad");

    grad_op->SetInput("X", this->Input("X"));
    if (this->HasInput("OutSize")) {
      grad_op->SetInput("OutSize", this->Input("OutSize"));
    }
    if (this->HasInput("SizeTensor")) {
      grad_op->SetInput("SizeTensor", this->Input("SizeTensor"));
    }
    if (this->HasInput("Scale")) {
      grad_op->SetInput("Scale", this->Input("Scale"));
    }
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class BicubicInterpV2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "OutSize" || var_name == "SizeTensor" || var_name == "Scale") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(bicubic_interp_v2_grad, BicubicInterpV2GradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(BicubicInterpV2GradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class BilinearTensorProductGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("bilinear_tensor_product_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput("Weight", this->Input("Weight"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));
    grad_op->SetOutput(GradVarName("Weight"), this->InputGrad("Weight"));
    grad_op->SetOutput(GradVarName("Bias"), this->InputGrad("Bias"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class BilinearTensorProductGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(bilinear_tensor_product_grad, BilinearTensorProductGradInferShapeFunctor,
                            PD_INFER_META(phi::BilinearGradInferMeta));



template <typename T>
class BilinearInterpV2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("bilinear_interp_v2_grad");

    grad_op->SetInput("X", this->Input("X"));
    if (this->HasInput("OutSize")) {
      grad_op->SetInput("OutSize", this->Input("OutSize"));
    }
    if (this->HasInput("SizeTensor")) {
      grad_op->SetInput("SizeTensor", this->Input("SizeTensor"));
    }
    if (this->HasInput("Scale")) {
      grad_op->SetInput("Scale", this->Input("Scale"));
    }
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class BilinearInterpV2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

  phi::KernelKey GetKernelTypeForVar(
      const std::string& var_name,
      const phi::DenseTensor& tensor,
      const phi::KernelKey& expected_kernel_type) const override {
        if (var_name == "OutSize" || var_name == "SizeTensor" || var_name == "Scale") {
          return phi::KernelKey(phi::Backend::ALL_BACKEND,
                              expected_kernel_type.layout(),
                              expected_kernel_type.dtype());
        }
        else {
            return phi::KernelKey(
              tensor.place(), tensor.layout(), expected_kernel_type.dtype());
        }
      }

};


DECLARE_INFER_SHAPE_FUNCTOR(bilinear_interp_v2_grad, BilinearInterpV2GradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(BilinearInterpV2GradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class BmmGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("bmm_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class BmmGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(bmm_grad, BmmGradInferShapeFunctor,
                            PD_INFER_META(phi::BmmGradInferMeta));



template <typename T>
class BroadcastTensorsGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("broadcast_tensors_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X", false));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class BroadcastTensorsGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(broadcast_tensors_grad, BroadcastTensorsGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedMultiInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(BroadcastTensorsGradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class CeilGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("ceil_grad");

    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CeilGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(ceil_grad, CeilGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(CeilGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class CeluGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("celu_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CeluGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(celu_grad, CeluGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(CeluGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class CeluGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("celu_grad_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CeluGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(celu_grad_grad, CeluGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(CeluGradGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});



template <typename T>
class CholeskyGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cholesky_grad");

    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CholeskyGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cholesky_grad, CholeskyGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class CholeskySolveGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cholesky_solve_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CholeskySolveGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cholesky_solve_grad, CholeskySolveGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class ClipGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("clip_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("Min")) {
      grad_op->SetInput("Min", this->Input("Min"));
    }
    if (this->HasInput("Max")) {
      grad_op->SetInput("Max", this->Input("Max"));
    }
  }
};


class ClipGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(clip_grad, ClipGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(ClipGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class ClipDoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("clip_double_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("Min")) {
      grad_op->SetInput("Min", this->Input("Min"));
    }
    if (this->HasInput("Max")) {
      grad_op->SetInput("Max", this->Input("Max"));
    }
  }
};


class ClipDoubleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(clip_double_grad, ClipDoubleGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class ComplexGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("complex_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class ComplexGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(complex_grad, ComplexGradInferShapeFunctor,
                            PD_INFER_META(phi::ComplexGradInferMeta));



template <typename T>
class ConcatGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("concat_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X", false));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("AxisTensor")) {
      grad_op->SetInput("AxisTensor", this->Input("AxisTensor"));
    }
  }
};


class ConcatGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(concat_grad, ConcatGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedMultiInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(ConcatGradNoNeedBufferVarInferer,
                                    "X");

class ConcatCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetMultiForwardInput("X");
    auto out_grad = this->GetSingleOutputGrad("Out");

    auto tensor_axis = this->GetOptionalSingleForwardInput("AxisTensor");
    if (tensor_axis) {
      PADDLE_THROW(phi::errors::Unimplemented(
          "We don't support dynamic tensor attribute AxisTensor for concat_grad composite"
          "for now. "));
    }
    //get attr
    const int axis = this->Attr<int>("axis");

    //get output
    auto x_grad_t = this->GetMultiInputGrad("X");
    //get output ptr
    std::vector<paddle::Tensor*> x_grad(x_grad_t.size());
    for(size_t i = 0; i < x_grad.size(); ++i){
      x_grad[i] = &x_grad_t[i];
    }
    x_grad = this->GetOutputPtr(x_grad);
    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);
    //call composite backward func
    VLOG(6) << "Runing concat_grad composite func";
    prim::concat_grad<prim::DescTensor>(x, out_grad, axis, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};
template <typename T>
class ConcatDoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("concat");

    grad_op->SetInput("X", this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput("Out", this->InputGrad(GradVarName("Out")));

    if (this->HasInput("AxisTensor")) {
      grad_op->SetInput("AxisTensor", this->Input("AxisTensor"));
    }

    grad_op->SetAttr("axis", this->GetAttr("axis"));
  }
};

template <typename T>
class ConjGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("conj");

    grad_op->SetInput("X", this->OutputGrad("Out"));

    grad_op->SetOutput("Out", this->InputGrad("X"));


  }
};


template <typename T>
class Conv2dGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("conv2d_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Filter", this->Input("Filter"));
    grad_op->SetInput(GradVarName("Output"), this->OutputGrad("Output"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("Filter"), this->InputGrad("Filter"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Conv2dGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv2d_grad, Conv2dGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class Conv2dGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("conv2d_grad_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Filter", this->Input("Filter"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Output")));
    if (this->HasOutput(GradVarName("Input"))) {
      grad_op->SetInput(GradVarName("grad_input"), this->OutputGrad(GradVarName("Input")));
    }
    if (this->HasOutput(GradVarName("Filter"))) {
      grad_op->SetInput(GradVarName("grad_filter"), this->OutputGrad(GradVarName("Filter")));
    }

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("Filter"), this->InputGrad("Filter"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Output")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Conv2dGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv2d_grad_grad, Conv2dGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));



template <typename T>
class Conv3dGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("conv3d_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Filter", this->Input("Filter"));
    grad_op->SetInput(GradVarName("Output"), this->OutputGrad("Output"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("Filter"), this->InputGrad("Filter"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Conv3dGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv3d_grad, Conv3dGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class Conv3dGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("conv3d_grad_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Filter", this->Input("Filter"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Output")));
    if (this->HasOutput(GradVarName("Input"))) {
      grad_op->SetInput(GradVarName("grad_input"), this->OutputGrad(GradVarName("Input")));
    }
    if (this->HasOutput(GradVarName("Filter"))) {
      grad_op->SetInput(GradVarName("grad_filter"), this->OutputGrad(GradVarName("Filter")));
    }

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("Filter"), this->InputGrad("Filter"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Output")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Conv3dGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv3d_grad_grad, Conv3dGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));



template <typename T>
class Conv3dTransposeGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("conv3d_transpose_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Filter", this->Input("Filter"));
    grad_op->SetInput(GradVarName("Output"), this->OutputGrad("Output"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("Filter"), this->InputGrad("Filter"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class Conv3dTransposeGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(conv3d_transpose_grad, Conv3dTransposeGradInferShapeFunctor,
                            PD_INFER_META(phi::ConvTransposeGradInferMeta));



template <typename T>
class CopysignGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("copysign_grad");

    grad_op->SetInput("x", this->Input("x"));
    grad_op->SetInput("y", this->Input("y"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("x"), this->InputGrad("x"));
    grad_op->SetOutput(GradVarName("y"), this->InputGrad("y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CopysignGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(copysign_grad, CopysignGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(CopysignGradInplaceInferer,
                           {GradVarName("out"), GradVarName("x")});



template <typename T>
class CosGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cos_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CosGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cos_grad, CosGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(CosGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});


class CosCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing cos_grad composite func";
    prim::cos_grad<prim::DescTensor>(x, out_grad, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class CosDoubleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cos_double_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Out")));
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Out")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CosDoubleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cos_double_grad, CosDoubleGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(CosDoubleGradInplaceInferer,
                           {GradVarName("grad_x"), GradVarName("grad_out")});


class CosDoubleCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto grad_out = this->GetSingleForwardInput(GradVarName("Out"));
    auto grad_x_grad = this->GetSingleOutputGrad(GradVarName("X"));


    //get attr

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");
    auto grad_out_grad_t = this->GetSingleInputGrad(GradVarName("Out"));

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);
    auto grad_out_grad = this->GetOutputPtr(&grad_out_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);
    auto grad_out_grad_name = this->GetOutputName(grad_out_grad_t);

    //call composite backward func
    VLOG(6) << "Runing cos_double_grad composite func";
    prim::cos_double_grad<prim::DescTensor>(x, grad_out, grad_x_grad, x_grad, grad_out_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);
    this->RecoverOutputName(grad_out_grad_t, grad_out_grad_name);

  }
};

template <typename T>
class CosTripleGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cos_triple_grad");

    grad_op->SetInput("X", this->Input("X"));
    if (this->HasInput("grad_out")) {
      grad_op->SetInput("grad_out_forward", this->Input("grad_out"));
    }
    if (this->HasInput(GradVarName("grad_x"))) {
      grad_op->SetInput("grad_x_grad_forward", this->Input(GradVarName("grad_x")));
    }
    grad_op->SetInput(GradVarName("grad_x"), this->OutputGrad(GradVarName("X")));
    if (this->HasOutput(GradVarName("grad_out"))) {
      grad_op->SetInput(GradVarName("grad_out_grad"), this->OutputGrad(GradVarName("grad_out")));
    }

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("grad_out_forward"), this->InputGrad("grad_out"));
    grad_op->SetOutput(GradVarName("grad_x_grad_forward"), this->InputGrad(GradVarName("grad_x")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CosTripleGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cos_triple_grad, CosTripleGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));
DECLARE_INPLACE_OP_INFERER(CosTripleGradInplaceInferer,
                           {"grad_x_grad_forward", GradVarName("grad_out_forward")});



template <typename T>
class CoshGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cosh_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CoshGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cosh_grad, CoshGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));
DECLARE_INPLACE_OP_INFERER(CoshGradInplaceInferer,
                           {GradVarName("Out"), GradVarName("X")});



template <typename T>
class CropTensorGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("crop_tensor_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
    if (this->HasInput("Offsets")) {
      grad_op->SetInput("Offsets", this->Input("Offsets"));
    }
    if (this->HasInput("OffsetsTensor")) {
      grad_op->SetInput("OffsetsTensor", this->Input("OffsetsTensor"));
    }
  }
};


class CropTensorGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(crop_tensor_grad, CropTensorGradInferShapeFunctor,
                            PD_INFER_META(phi::CropGradInferMeta));



template <typename T>
class CrossGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cross_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Y", this->Input("Y"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));
    grad_op->SetOutput(GradVarName("Y"), this->InputGrad("Y"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CrossGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cross_grad, CrossGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class SoftmaxWithCrossEntropyGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("softmax_with_cross_entropy_grad");

    grad_op->SetInput("Label", this->Input("Label"));
    grad_op->SetInput("Softmax", this->Output("Softmax"));
    grad_op->SetInput(GradVarName("Loss"), this->OutputGrad("Loss"));

    grad_op->SetOutput(GradVarName("Logits"), this->InputGrad("Logits"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class SoftmaxWithCrossEntropyGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Loss"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(softmax_with_cross_entropy_grad, SoftmaxWithCrossEntropyGradInferShapeFunctor,
                            PD_INFER_META(phi::CrossEntropyWithSoftmaxGradInferMeta));
DECLARE_INPLACE_OP_INFERER(SoftmaxWithCrossEntropyGradInplaceInferer,
                           {"Softmax", GradVarName("Logits")});



template <typename T>
class CummaxGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cummax_grad");

    grad_op->SetInput("x", this->Input("x"));
    grad_op->SetInput("indices", this->Output("indices"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("x"), this->InputGrad("x"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CummaxGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cummax_grad, CummaxGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class CumminGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cummin_grad");

    grad_op->SetInput("x", this->Input("x"));
    grad_op->SetInput("indices", this->Output("indices"));
    grad_op->SetInput(GradVarName("out"), this->OutputGrad("out"));

    grad_op->SetOutput(GradVarName("x"), this->InputGrad("x"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CumminGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cummin_grad, CumminGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class CumprodGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cumprod_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CumprodGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
};


DECLARE_INFER_SHAPE_FUNCTOR(cumprod_grad, CumprodGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class CumsumGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("cumsum_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class CumsumGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "X");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(cumsum_grad, CumsumGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));


class CumsumCompositeGradOpMaker : public prim::CompositeGradOpMakerBase {
 public:
  using prim::CompositeGradOpMakerBase::CompositeGradOpMakerBase;
  void Apply() override {
    //get inputs
    auto x = this->GetSingleForwardInput("X");
    auto out_grad = this->GetSingleOutputGrad("Out");


    //get attr
    const int axis = this->Attr<int>("axis");
    const bool flatten = this->Attr<bool>("flatten");
    const bool exclusive = this->Attr<bool>("exclusive");
    const bool reverse = this->Attr<bool>("reverse");

    //get output
    auto x_grad_t = this->GetSingleInputGrad("X");

    //get output ptr
    auto x_grad = this->GetOutputPtr(&x_grad_t);

    //get output orginal name
    auto x_grad_name = this->GetOutputName(x_grad_t);

    //call composite backward func
    VLOG(6) << "Runing cumsum_grad composite func";
    prim::cumsum_grad<prim::DescTensor>(x, out_grad, axis, flatten, exclusive, reverse, x_grad);
    //recover output name
    this->RecoverOutputName(x_grad_t, x_grad_name);

  }
};

template <typename T>
class DepthwiseConv2dGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("depthwise_conv2d_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Filter", this->Input("Filter"));
    grad_op->SetInput(GradVarName("Output"), this->OutputGrad("Output"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("Filter"), this->InputGrad("Filter"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class DepthwiseConv2dGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(depthwise_conv2d_grad, DepthwiseConv2dGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralBinaryGradInferMeta));



template <typename T>
class DepthwiseConv2dGradGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("depthwise_conv2d_grad_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Filter", this->Input("Filter"));
    grad_op->SetInput("grad_out", this->Input(GradVarName("Output")));
    if (this->HasOutput(GradVarName("Input"))) {
      grad_op->SetInput(GradVarName("grad_input"), this->OutputGrad(GradVarName("Input")));
    }
    if (this->HasOutput(GradVarName("Filter"))) {
      grad_op->SetInput(GradVarName("grad_filter"), this->OutputGrad(GradVarName("Filter")));
    }

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));
    grad_op->SetOutput(GradVarName("Filter"), this->InputGrad("Filter"));
    grad_op->SetOutput(GradVarName("grad_out"), this->InputGrad(GradVarName("Output")));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class DepthwiseConv2dGradGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, "Input");
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(depthwise_conv2d_grad_grad, DepthwiseConv2dGradGradInferShapeFunctor,
                            PD_INFER_META(phi::GeneralTernaryGradInferMeta));



template <typename T>
class DeterminantGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("determinant_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput("Out", this->Output("Out"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class DeterminantGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(determinant_grad, DeterminantGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));



template <typename T>
class DiagV2GradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("diag_v2_grad");

    grad_op->SetInput("X", this->Input("X"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("X"), this->InputGrad("X"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class DiagV2GradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(diag_v2_grad, DiagV2GradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(DiagV2GradNoNeedBufferVarInferer,
                                    "X");


template <typename T>
class DiagonalGradOpMaker : public framework::SingleGradOpMaker<T> {
 public:
  using framework::SingleGradOpMaker<T>::SingleGradOpMaker;

 protected:
  void Apply(GradOpPtr<T> grad_op) const override {
    grad_op->SetType("diagonal_grad");

    grad_op->SetInput("Input", this->Input("Input"));
    grad_op->SetInput(GradVarName("Out"), this->OutputGrad("Out"));

    grad_op->SetOutput(GradVarName("Input"), this->InputGrad("Input"));

    grad_op->SetAttrMap(this->Attrs());
  }
};


class DiagonalGradOp : public framework::OperatorWithKernel {
 public:
  using framework::OperatorWithKernel::OperatorWithKernel;
 protected:
  phi::KernelKey GetExpectedKernelType(
      const framework::ExecutionContext& ctx) const override {
      phi::KernelKey kt;
    auto data_type = framework::OperatorWithKernel::IndicateVarDataType(ctx, GradVarName("Out"));
    kt = phi::KernelKey(data_type, ctx.GetPlace());
    return kt;
  }

};


DECLARE_INFER_SHAPE_FUNCTOR(diagonal_grad, DiagonalGradInferShapeFunctor,
                            PD_INFER_META(phi::UnchangedInferMeta));

DECLARE_NO_NEED_BUFFER_VARS_INFERER(DiagonalGradNoNeedBufferVarInferer,
                                    "Input");

}  // namespace operators
}  // namespace paddle

namespace ops = paddle::operators;
REGISTER_OPERATOR(abs, ops::AbsOp,
                  ops::AbsOpMaker,
                  ops::AbsGradOpMaker<paddle::framework::OpDesc>,
                  ops::AbsGradOpMaker<paddle::imperative::OpBase>,
                  ops::AbsInplaceInferer,
                  ops::AbsCompositeGradOpMaker,
                  ops::AbsInferShapeFunctor);


REGISTER_OPERATOR(accuracy, ops::AccuracyOp,
                  ops::AccuracyOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AccuracyInferShapeFunctor);


REGISTER_OPERATOR(acos, ops::AcosOp,
                  ops::AcosOpMaker,
                  ops::AcosGradOpMaker<paddle::framework::OpDesc>,
                  ops::AcosGradOpMaker<paddle::imperative::OpBase>,
                  ops::AcosInplaceInferer,
                  ops::AcosInferShapeFunctor);


REGISTER_OPERATOR(acosh, ops::AcoshOp,
                  ops::AcoshOpMaker,
                  ops::AcoshGradOpMaker<paddle::framework::OpDesc>,
                  ops::AcoshGradOpMaker<paddle::imperative::OpBase>,
                  ops::AcoshInplaceInferer,
                  ops::AcoshInferShapeFunctor);


REGISTER_OPERATOR(adagrad, ops::AdagradOp,
                  ops::AdagradOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AdagradInferShapeFunctor);


REGISTER_OPERATOR(adam, ops::AdamOp,
                  ops::AdamOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AdamInferShapeFunctor);


REGISTER_OPERATOR(adamax, ops::AdamaxOp,
                  ops::AdamaxOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AdamaxInferShapeFunctor);


REGISTER_OPERATOR(adamw, ops::AdamwOp,
                  ops::AdamwOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AdamwInferShapeFunctor);


REGISTER_OPERATOR(addmm, ops::AddmmOp,
                  ops::AddmmOpMaker,
                  ops::AddmmGradOpMaker<paddle::framework::OpDesc>,
                  ops::AddmmGradOpMaker<paddle::imperative::OpBase>,
                  ops::AddmmInplaceInferer,
                  ops::AddmmInferShapeFunctor);


REGISTER_OPERATOR(affine_grid, ops::AffineGridOp,
                  ops::AffineGridOpMaker,
                  ops::AffineGridGradOpMaker<paddle::framework::OpDesc>,
                  ops::AffineGridGradOpMaker<paddle::imperative::OpBase>,
                  ops::AffineGridInferShapeFunctor);

REGISTER_OP_VERSION(affine_grid)
  .AddCheckpoint(
    R"ROC(Compatible upgrade of affine_grid, add a new attribute [align_corners].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("align_corners", "Whether to align the corners of input and output.", true))
;

REGISTER_OPERATOR(allclose, ops::AllcloseOp,
                  ops::AllcloseOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AllcloseInferShapeFunctor);

REGISTER_OP_VERSION(allclose)
  .AddCheckpoint(
    R"ROC(Upgrade allclose, add two new inputs [Rtol] and [Atol].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewInput("Rtol", "The added input 'Rtol' is not dispensable.")
        .NewInput("Atol", "The added input 'Atol' is not dispensable."))
  .AddCheckpoint(
    R"ROC(Delete two float attributes [rtol] and [atol], then add 2 string attributes [atol, rtol]. Don't be surprised. This is because float cannot represent hight-precision floating-point values, and our framework doesn't support the use of double attributes. As a result, string instead of double is used here to represent high-precision floating-point values.)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("rtol", "The relative tolerance. Default::math:`1e-5` .", std::string("1e-5"))
        .DeleteAttr("rtol", "The attribute 'rtol' is deleted. The reason why it is deleted is that attributes do not support a float64 value and it is changed to a tensor.")
        .NewAttr("atol", "(string) The absolute tolerance. Default::math:`1e-8` .", std::string("1e-5"))
        .DeleteAttr("atol", "The attribute 'atol' is deleted. The reason why it is deleted is that attributes do not support a float64 value and it is changed to a tensor."))
;

REGISTER_OPERATOR(angle, ops::AngleOp,
                  ops::AngleOpMaker,
                  ops::AngleGradOpMaker<paddle::framework::OpDesc>,
                  ops::AngleGradOpMaker<paddle::imperative::OpBase>,
                  ops::AngleInferShapeFunctor);


REGISTER_OPERATOR(apply_per_channel_scale, ops::ApplyPerChannelScaleOp,
                  ops::ApplyPerChannelScaleOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ApplyPerChannelScaleInferShapeFunctor);


REGISTER_OPERATOR(arg_max, ops::ArgMaxOp,
                  ops::ArgMaxOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ArgMaxInferShapeFunctor);


REGISTER_OPERATOR(arg_min, ops::ArgMinOp,
                  ops::ArgMinOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ArgMinInferShapeFunctor);


REGISTER_OPERATOR(argsort, ops::ArgsortOp,
                  ops::ArgsortOpMaker,
                  ops::ArgsortGradOpMaker<paddle::framework::OpDesc>,
                  ops::ArgsortGradOpMaker<paddle::imperative::OpBase>,
                  ops::ArgsortInferShapeFunctor);


REGISTER_OPERATOR(as_complex, ops::AsComplexOp,
                  ops::AsComplexOpMaker,
                  ops::AsComplexGradOpMaker<paddle::framework::OpDesc>,
                  ops::AsComplexGradOpMaker<paddle::imperative::OpBase>,
                  ops::AsComplexInferShapeFunctor);


REGISTER_OPERATOR(as_real, ops::AsRealOp,
                  ops::AsRealOpMaker,
                  ops::AsRealGradOpMaker<paddle::framework::OpDesc>,
                  ops::AsRealGradOpMaker<paddle::imperative::OpBase>,
                  ops::AsRealInferShapeFunctor);


REGISTER_OPERATOR(as_strided, ops::AsStridedOp,
                  ops::AsStridedOpMaker,
                  ops::AsStridedGradOpMaker<paddle::framework::OpDesc>,
                  ops::AsStridedGradOpMaker<paddle::imperative::OpBase>,
                  ops::AsStridedNoNeedBufferVarInferer,
                  ops::AsStridedInferShapeFunctor);


REGISTER_OPERATOR(asgd, ops::AsgdOp,
                  ops::AsgdOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AsgdInferShapeFunctor);


REGISTER_OPERATOR(asin, ops::AsinOp,
                  ops::AsinOpMaker,
                  ops::AsinGradOpMaker<paddle::framework::OpDesc>,
                  ops::AsinGradOpMaker<paddle::imperative::OpBase>,
                  ops::AsinInplaceInferer,
                  ops::AsinInferShapeFunctor);


REGISTER_OPERATOR(asinh, ops::AsinhOp,
                  ops::AsinhOpMaker,
                  ops::AsinhGradOpMaker<paddle::framework::OpDesc>,
                  ops::AsinhGradOpMaker<paddle::imperative::OpBase>,
                  ops::AsinhInplaceInferer,
                  ops::AsinhInferShapeFunctor);


REGISTER_OPERATOR(atan, ops::AtanOp,
                  ops::AtanOpMaker,
                  ops::AtanGradOpMaker<paddle::framework::OpDesc>,
                  ops::AtanGradOpMaker<paddle::imperative::OpBase>,
                  ops::AtanInplaceInferer,
                  ops::AtanInferShapeFunctor);


REGISTER_OPERATOR(atan2, ops::Atan2Op,
                  ops::Atan2OpMaker,
                  ops::Atan2GradOpMaker<paddle::framework::OpDesc>,
                  ops::Atan2GradOpMaker<paddle::imperative::OpBase>,
                  ops::Atan2InferShapeFunctor);


REGISTER_OPERATOR(atanh, ops::AtanhOp,
                  ops::AtanhOpMaker,
                  ops::AtanhGradOpMaker<paddle::framework::OpDesc>,
                  ops::AtanhGradOpMaker<paddle::imperative::OpBase>,
                  ops::AtanhInplaceInferer,
                  ops::AtanhInferShapeFunctor);


REGISTER_OPERATOR(auc, ops::AucOp,
                  ops::AucOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AucInferShapeFunctor);

REGISTER_OP_VERSION(auc)
  .AddCheckpoint(
    R"ROC(Upgrade auc, add a new input [InsTagWeight].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewInput("ValueTensor", "In order to support multi-tag task."))
;

REGISTER_OPERATOR(average_accumulates, ops::AverageAccumulatesOp,
                  ops::AverageAccumulatesOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::AverageAccumulatesInferShapeFunctor);


REGISTER_OPERATOR(bce_loss, ops::BceLossOp,
                  ops::BceLossOpMaker,
                  ops::BceLossGradOpMaker<paddle::framework::OpDesc>,
                  ops::BceLossGradOpMaker<paddle::imperative::OpBase>,
                  ops::BceLossInplaceInferer,
                  ops::BceLossInferShapeFunctor);


REGISTER_OPERATOR(bernoulli, ops::BernoulliOp,
                  ops::BernoulliOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BernoulliInferShapeFunctor);


REGISTER_OPERATOR(bicubic_interp_v2, ops::BicubicInterpV2Op,
                  ops::BicubicInterpV2OpMaker,
                  ops::BicubicInterpV2GradOpMaker<paddle::framework::OpDesc>,
                  ops::BicubicInterpV2GradOpMaker<paddle::imperative::OpBase>,
                  ops::BicubicInterpV2InferShapeFunctor);


REGISTER_OPERATOR(bilinear_tensor_product, ops::BilinearTensorProductOp,
                  ops::BilinearTensorProductOpMaker,
                  ops::BilinearTensorProductGradOpMaker<paddle::framework::OpDesc>,
                  ops::BilinearTensorProductGradOpMaker<paddle::imperative::OpBase>,
                  ops::BilinearTensorProductInferShapeFunctor);


REGISTER_OPERATOR(bilinear_interp_v2, ops::BilinearInterpV2Op,
                  ops::BilinearInterpV2OpMaker,
                  ops::BilinearInterpV2GradOpMaker<paddle::framework::OpDesc>,
                  ops::BilinearInterpV2GradOpMaker<paddle::imperative::OpBase>,
                  ops::BilinearInterpV2InferShapeFunctor);


REGISTER_OPERATOR(bincount, ops::BincountOp,
                  ops::BincountOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BincountInferShapeFunctor);


REGISTER_OPERATOR(binomial, ops::BinomialOp,
                  ops::BinomialOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BinomialInferShapeFunctor);


REGISTER_OPERATOR(bitwise_and, ops::BitwiseAndOp,
                  ops::BitwiseAndOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BitwiseAndInplaceInferer,
                  ops::BitwiseAndInferShapeFunctor);


REGISTER_OPERATOR(bitwise_left_shift, ops::BitwiseLeftShiftOp,
                  ops::BitwiseLeftShiftOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BitwiseLeftShiftInplaceInferer,
                  ops::BitwiseLeftShiftInferShapeFunctor);


REGISTER_OPERATOR(bitwise_not, ops::BitwiseNotOp,
                  ops::BitwiseNotOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BitwiseNotInplaceInferer,
                  ops::BitwiseNotInferShapeFunctor);


REGISTER_OPERATOR(bitwise_or, ops::BitwiseOrOp,
                  ops::BitwiseOrOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BitwiseOrInplaceInferer,
                  ops::BitwiseOrInferShapeFunctor);


REGISTER_OPERATOR(bitwise_right_shift, ops::BitwiseRightShiftOp,
                  ops::BitwiseRightShiftOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BitwiseRightShiftInplaceInferer,
                  ops::BitwiseRightShiftInferShapeFunctor);


REGISTER_OPERATOR(bitwise_xor, ops::BitwiseXorOp,
                  ops::BitwiseXorOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BitwiseXorInplaceInferer,
                  ops::BitwiseXorInferShapeFunctor);


REGISTER_OPERATOR(bmm, ops::BmmOp,
                  ops::BmmOpMaker,
                  ops::BmmGradOpMaker<paddle::framework::OpDesc>,
                  ops::BmmGradOpMaker<paddle::imperative::OpBase>,
                  ops::BmmInferShapeFunctor);


REGISTER_OPERATOR(box_coder, ops::BoxCoderOp,
                  ops::BoxCoderOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::BoxCoderInferShapeFunctor);


REGISTER_OPERATOR(broadcast_tensors, ops::BroadcastTensorsOp,
                  ops::BroadcastTensorsOpMaker,
                  ops::BroadcastTensorsGradOpMaker<paddle::framework::OpDesc>,
                  ops::BroadcastTensorsGradOpMaker<paddle::imperative::OpBase>,
                  ops::BroadcastTensorsInferShapeFunctor);


REGISTER_OPERATOR(ceil, ops::CeilOp,
                  ops::CeilOpMaker,
                  ops::CeilGradOpMaker<paddle::framework::OpDesc>,
                  ops::CeilGradOpMaker<paddle::imperative::OpBase>,
                  ops::CeilInplaceInferer,
                  ops::CeilInferShapeFunctor);


REGISTER_OPERATOR(celu, ops::CeluOp,
                  ops::CeluOpMaker,
                  ops::CeluGradOpMaker<paddle::framework::OpDesc>,
                  ops::CeluGradOpMaker<paddle::imperative::OpBase>,
                  ops::CeluInferShapeFunctor);


REGISTER_OPERATOR(check_finite_and_unscale, ops::CheckFiniteAndUnscaleOp,
                  ops::CheckFiniteAndUnscaleOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::CheckFiniteAndUnscaleInplaceInferer,
                  ops::CheckFiniteAndUnscaleInferShapeFunctor);


REGISTER_OPERATOR(check_numerics, ops::CheckNumericsOp,
                  ops::CheckNumericsOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::CheckNumericsInferShapeFunctor);


REGISTER_OPERATOR(cholesky, ops::CholeskyOp,
                  ops::CholeskyOpMaker,
                  ops::CholeskyGradOpMaker<paddle::framework::OpDesc>,
                  ops::CholeskyGradOpMaker<paddle::imperative::OpBase>,
                  ops::CholeskyInferShapeFunctor);


REGISTER_OPERATOR(cholesky_solve, ops::CholeskySolveOp,
                  ops::CholeskySolveOpMaker,
                  ops::CholeskySolveGradOpMaker<paddle::framework::OpDesc>,
                  ops::CholeskySolveGradOpMaker<paddle::imperative::OpBase>,
                  ops::CholeskySolveInferShapeFunctor);


REGISTER_OPERATOR(class_center_sample, ops::ClassCenterSampleOp,
                  ops::ClassCenterSampleOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ClassCenterSampleInferShapeFunctor);


REGISTER_OPERATOR(clip, ops::ClipOp,
                  ops::ClipOpMaker,
                  ops::ClipGradOpMaker<paddle::framework::OpDesc>,
                  ops::ClipGradOpMaker<paddle::imperative::OpBase>,
                  ops::ClipInplaceInferer,
                  ops::ClipInferShapeFunctor);

REGISTER_OP_VERSION(clip)
  .AddCheckpoint(
    R"ROC(Upgrade clip add a new input [Min])ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewInput("Min", "Pass the mix, min value as input, not attribute. Min is dispensable.")
        .NewInput("Max", "Pass the mix, min value as input, not attribute. Max is dispensable."))
;

REGISTER_OPERATOR(clip_by_norm, ops::ClipByNormOp,
                  ops::ClipByNormOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::ClipByNormInferShapeFunctor);


REGISTER_OPERATOR(coalesce_tensor, ops::CoalesceTensorOp,
                  ops::CoalesceTensorOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::CoalesceTensorInferShapeFunctor);

REGISTER_OP_VERSION(coalesce_tensor)
  .AddCheckpoint(
    R"ROC(Upgrade coalesce_tensor: add a new attribute [use_align].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("use_align", "In order to optionally take memory alignment into account when coalescing tensors. The default value is true to be compatible with before.", true))
  .AddCheckpoint(
    R"ROC(Upgrade coalesce_tensor: add a new attribute [align_size].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("align_size", "In order to optionally take memory alignment into account when coalescing tensors. The default value is -1 and use the default align_size of each place to be compatible with before.", -1))
;

REGISTER_OPERATOR(complex, ops::ComplexOp,
                  ops::ComplexOpMaker,
                  ops::ComplexGradOpMaker<paddle::framework::OpDesc>,
                  ops::ComplexGradOpMaker<paddle::imperative::OpBase>,
                  ops::ComplexInferShapeFunctor);


REGISTER_OPERATOR(concat, ops::ConcatOp,
                  ops::ConcatOpMaker,
                  ops::ConcatGradOpMaker<paddle::framework::OpDesc>,
                  ops::ConcatGradOpMaker<paddle::imperative::OpBase>,
                  ops::ConcatCompositeGradOpMaker,
                  ops::ConcatInferShapeFunctor);


REGISTER_OPERATOR(conj, ops::ConjOp,
                  ops::ConjOpMaker,
                  ops::ConjGradOpMaker<paddle::framework::OpDesc>,
                  ops::ConjGradOpMaker<paddle::imperative::OpBase>,
                  ops::ConjInferShapeFunctor);


REGISTER_OPERATOR(conv2d, ops::Conv2dOp,
                  ops::Conv2dOpMaker,
                  ops::Conv2dGradOpMaker<paddle::framework::OpDesc>,
                  ops::Conv2dGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv2dInferShapeFunctor);

REGISTER_OP_VERSION(conv2d)
  .AddCheckpoint(
    R"ROC(Upgrade conv2d, add a new attribute [use_addto].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("use_addto", "In order to support new feature (inplace addto strategy) for gradient accumulation.", false))
;

REGISTER_OPERATOR(conv3d, ops::Conv3dOp,
                  ops::Conv3dOpMaker,
                  ops::Conv3dGradOpMaker<paddle::framework::OpDesc>,
                  ops::Conv3dGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv3dInferShapeFunctor);

REGISTER_OP_VERSION(conv3d)
  .AddCheckpoint(
    R"ROC(Upgrade conv3d, add a new attribute [use_addto].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("use_addto", "In order to support new feature (inplace addto strategy) for gradient accumulation.", false))
;

REGISTER_OPERATOR(conv3d_transpose, ops::Conv3dTransposeOp,
                  ops::Conv3dTransposeOpMaker,
                  ops::Conv3dTransposeGradOpMaker<paddle::framework::OpDesc>,
                  ops::Conv3dTransposeGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv3dTransposeInferShapeFunctor);

REGISTER_OP_VERSION(conv3d_transpose)
  .AddCheckpoint(
    R"ROC(Upgrade convtranspose add a new attribute [output_padding].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("output_padding", "In order to add additional size to one side of each dimension in the output.", std::vector<int>{}))
;

REGISTER_OPERATOR(copysign, ops::CopysignOp,
                  ops::CopysignOpMaker,
                  ops::CopysignGradOpMaker<paddle::framework::OpDesc>,
                  ops::CopysignGradOpMaker<paddle::imperative::OpBase>,
                  ops::CopysignInplaceInferer,
                  ops::CopysignInferShapeFunctor);


REGISTER_OPERATOR(cos, ops::CosOp,
                  ops::CosOpMaker,
                  ops::CosGradOpMaker<paddle::framework::OpDesc>,
                  ops::CosGradOpMaker<paddle::imperative::OpBase>,
                  ops::CosInplaceInferer,
                  ops::CosCompositeGradOpMaker,
                  ops::CosInferShapeFunctor);


REGISTER_OPERATOR(cosh, ops::CoshOp,
                  ops::CoshOpMaker,
                  ops::CoshGradOpMaker<paddle::framework::OpDesc>,
                  ops::CoshGradOpMaker<paddle::imperative::OpBase>,
                  ops::CoshInplaceInferer,
                  ops::CoshInferShapeFunctor);


REGISTER_OPERATOR(crop_tensor, ops::CropTensorOp,
                  ops::CropTensorOpMaker,
                  ops::CropTensorGradOpMaker<paddle::framework::OpDesc>,
                  ops::CropTensorGradOpMaker<paddle::imperative::OpBase>,
                  ops::CropTensorInferShapeFunctor);


REGISTER_OPERATOR(cross, ops::CrossOp,
                  ops::CrossOpMaker,
                  ops::CrossGradOpMaker<paddle::framework::OpDesc>,
                  ops::CrossGradOpMaker<paddle::imperative::OpBase>,
                  ops::CrossInferShapeFunctor);


REGISTER_OPERATOR(softmax_with_cross_entropy, ops::SoftmaxWithCrossEntropyOp,
                  ops::SoftmaxWithCrossEntropyOpMaker,
                  ops::SoftmaxWithCrossEntropyGradOpMaker<paddle::framework::OpDesc>,
                  ops::SoftmaxWithCrossEntropyGradOpMaker<paddle::imperative::OpBase>,
                  ops::SoftmaxWithCrossEntropyInplaceInferer,
                  ops::SoftmaxWithCrossEntropyInferShapeFunctor);


REGISTER_OPERATOR(cummax, ops::CummaxOp,
                  ops::CummaxOpMaker,
                  ops::CummaxGradOpMaker<paddle::framework::OpDesc>,
                  ops::CummaxGradOpMaker<paddle::imperative::OpBase>,
                  ops::CummaxInferShapeFunctor);


REGISTER_OPERATOR(cummin, ops::CumminOp,
                  ops::CumminOpMaker,
                  ops::CumminGradOpMaker<paddle::framework::OpDesc>,
                  ops::CumminGradOpMaker<paddle::imperative::OpBase>,
                  ops::CumminInferShapeFunctor);


REGISTER_OPERATOR(cumprod, ops::CumprodOp,
                  ops::CumprodOpMaker,
                  ops::CumprodGradOpMaker<paddle::framework::OpDesc>,
                  ops::CumprodGradOpMaker<paddle::imperative::OpBase>,
                  ops::CumprodInplaceInferer,
                  ops::CumprodInferShapeFunctor);


REGISTER_OPERATOR(cumsum, ops::CumsumOp,
                  ops::CumsumOpMaker,
                  ops::CumsumGradOpMaker<paddle::framework::OpDesc>,
                  ops::CumsumGradOpMaker<paddle::imperative::OpBase>,
                  ops::CumsumInplaceInferer,
                  ops::CumsumCompositeGradOpMaker,
                  ops::CumsumInferShapeFunctor);

REGISTER_OP_VERSION(cumsum)
  .AddCheckpoint(
    R"ROC(Upgrade cumsum add a new attribute [flatten].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("flatten", "In order to compute the cumsum over the flattened array when the argument `axis` in python API is None.", false))
;

REGISTER_OPERATOR(data, ops::DataOp,
                  ops::DataOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::DataInferShapeFunctor);


REGISTER_OPERATOR(depthwise_conv2d, ops::DepthwiseConv2dOp,
                  ops::DepthwiseConv2dOpMaker,
                  ops::DepthwiseConv2dGradOpMaker<paddle::framework::OpDesc>,
                  ops::DepthwiseConv2dGradOpMaker<paddle::imperative::OpBase>,
                  ops::DepthwiseConv2dInferShapeFunctor);

REGISTER_OP_VERSION(depthwise_conv2d)
  .AddCheckpoint(
    R"ROC(Upgrade depthwise_conv2d, add a new attribute [use_addto].)ROC",
      paddle::framework::compatible::OpVersionDesc()
        .NewAttr("use_addto", "In order to support new feature (inplace addto strategy) for gradient accumulation.", false))
;

REGISTER_OPERATOR(determinant, ops::DeterminantOp,
                  ops::DeterminantOpMaker,
                  ops::DeterminantGradOpMaker<paddle::framework::OpDesc>,
                  ops::DeterminantGradOpMaker<paddle::imperative::OpBase>,
                  ops::DeterminantInferShapeFunctor);


REGISTER_OPERATOR(diag_v2, ops::DiagV2Op,
                  ops::DiagV2OpMaker,
                  ops::DiagV2GradOpMaker<paddle::framework::OpDesc>,
                  ops::DiagV2GradOpMaker<paddle::imperative::OpBase>,
                  ops::DiagV2InferShapeFunctor);


REGISTER_OPERATOR(diag_embed, ops::DiagEmbedOp,
                  ops::DiagEmbedOpMaker,
                  paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
                  paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>,
                  ops::DiagEmbedInferShapeFunctor);


REGISTER_OPERATOR(diagonal, ops::DiagonalOp,
                  ops::DiagonalOpMaker,
                  ops::DiagonalGradOpMaker<paddle::framework::OpDesc>,
                  ops::DiagonalGradOpMaker<paddle::imperative::OpBase>,
                  ops::DiagonalInferShapeFunctor);


REGISTER_OPERATOR(abs_grad, ops::AbsGradOp,
                  ops::AbsDoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::AbsDoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::AbsGradInferShapeFunctor);


REGISTER_OPERATOR(abs_double_grad, ops::AbsDoubleGradOp,
                  ops::AbsTripleCompositeGradOpMaker,
                  ops::AbsDoubleGradInferShapeFunctor);


REGISTER_OPERATOR(acos_grad, ops::AcosGradOp,
                  ops::AcosGradInplaceInferer,
                  ops::AcosGradInferShapeFunctor);


REGISTER_OPERATOR(acosh_grad, ops::AcoshGradOp,
                  ops::AcoshGradInplaceInferer,
                  ops::AcoshGradInferShapeFunctor);


REGISTER_OPERATOR(addmm_grad, ops::AddmmGradOp,
                  ops::AddmmGradInferShapeFunctor);


REGISTER_OPERATOR(affine_grid_grad, ops::AffineGridGradOp,
                  ops::AffineGridGradInferShapeFunctor);


REGISTER_OPERATOR(angle_grad, ops::AngleGradOp,
                  ops::AngleGradInferShapeFunctor);


REGISTER_OPERATOR(argsort_grad, ops::ArgsortGradOp,
                  ops::ArgsortGradNoNeedBufferVarInferer,
                  ops::ArgsortGradInferShapeFunctor);


REGISTER_OPERATOR(as_strided_grad, ops::AsStridedGradOp,
                  ops::AsStridedGradInferShapeFunctor);


REGISTER_OPERATOR(asin_grad, ops::AsinGradOp,
                  ops::AsinGradInplaceInferer,
                  ops::AsinGradInferShapeFunctor);


REGISTER_OPERATOR(asinh_grad, ops::AsinhGradOp,
                  ops::AsinhGradInplaceInferer,
                  ops::AsinhGradInferShapeFunctor);


REGISTER_OPERATOR(atan_grad, ops::AtanGradOp,
                  ops::AtanGradInplaceInferer,
                  ops::AtanGradInferShapeFunctor);


REGISTER_OPERATOR(atan2_grad, ops::Atan2GradOp,
                  ops::Atan2GradInferShapeFunctor);


REGISTER_OPERATOR(atanh_grad, ops::AtanhGradOp,
                  ops::AtanhGradInplaceInferer,
                  ops::AtanhGradInferShapeFunctor);


REGISTER_OPERATOR(bce_loss_grad, ops::BceLossGradOp,
                  ops::BceLossGradInplaceInferer,
                  ops::BceLossGradInferShapeFunctor);


REGISTER_OPERATOR(bicubic_interp_v2_grad, ops::BicubicInterpV2GradOp,
                  ops::BicubicInterpV2GradNoNeedBufferVarInferer,
                  ops::BicubicInterpV2GradInferShapeFunctor);


REGISTER_OPERATOR(bilinear_tensor_product_grad, ops::BilinearTensorProductGradOp,
                  ops::BilinearTensorProductGradInferShapeFunctor);


REGISTER_OPERATOR(bilinear_interp_v2_grad, ops::BilinearInterpV2GradOp,
                  ops::BilinearInterpV2GradNoNeedBufferVarInferer,
                  ops::BilinearInterpV2GradInferShapeFunctor);


REGISTER_OPERATOR(bmm_grad, ops::BmmGradOp,
                  ops::BmmGradInferShapeFunctor);


REGISTER_OPERATOR(broadcast_tensors_grad, ops::BroadcastTensorsGradOp,
                  ops::BroadcastTensorsGradNoNeedBufferVarInferer,
                  ops::BroadcastTensorsGradInferShapeFunctor);


REGISTER_OPERATOR(ceil_grad, ops::CeilGradOp,
                  ops::CeilGradInplaceInferer,
                  ops::CeilGradInferShapeFunctor);


REGISTER_OPERATOR(celu_grad, ops::CeluGradOp,
                  ops::CeluGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::CeluGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::CeluGradInplaceInferer,
                  ops::CeluGradInferShapeFunctor);


REGISTER_OPERATOR(celu_grad_grad, ops::CeluGradGradOp,
                  ops::CeluGradGradInplaceInferer,
                  ops::CeluGradGradInferShapeFunctor);


REGISTER_OPERATOR(cholesky_grad, ops::CholeskyGradOp,
                  ops::CholeskyGradInferShapeFunctor);


REGISTER_OPERATOR(cholesky_solve_grad, ops::CholeskySolveGradOp,
                  ops::CholeskySolveGradInferShapeFunctor);


REGISTER_OPERATOR(clip_grad, ops::ClipGradOp,
                  ops::ClipDoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::ClipDoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::ClipGradInplaceInferer,
                  ops::ClipGradInferShapeFunctor);


REGISTER_OPERATOR(clip_double_grad, ops::ClipDoubleGradOp,
                  ops::ClipDoubleGradInferShapeFunctor);


REGISTER_OPERATOR(complex_grad, ops::ComplexGradOp,
                  ops::ComplexGradInferShapeFunctor);


REGISTER_OPERATOR(concat_grad, ops::ConcatGradOp,
                  ops::ConcatDoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::ConcatDoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::ConcatGradNoNeedBufferVarInferer,
                  ops::ConcatGradInferShapeFunctor);


REGISTER_OPERATOR(conv2d_grad, ops::Conv2dGradOp,
                  ops::Conv2dGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::Conv2dGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv2dGradInferShapeFunctor);


REGISTER_OPERATOR(conv2d_grad_grad, ops::Conv2dGradGradOp,
                  ops::Conv2dGradGradInferShapeFunctor);


REGISTER_OPERATOR(conv3d_grad, ops::Conv3dGradOp,
                  ops::Conv3dGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::Conv3dGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::Conv3dGradInferShapeFunctor);


REGISTER_OPERATOR(conv3d_grad_grad, ops::Conv3dGradGradOp,
                  ops::Conv3dGradGradInferShapeFunctor);


REGISTER_OPERATOR(conv3d_transpose_grad, ops::Conv3dTransposeGradOp,
                  ops::Conv3dTransposeGradInferShapeFunctor);


REGISTER_OPERATOR(copysign_grad, ops::CopysignGradOp,
                  ops::CopysignGradInplaceInferer,
                  ops::CopysignGradInferShapeFunctor);


REGISTER_OPERATOR(cos_grad, ops::CosGradOp,
                  ops::CosDoubleGradOpMaker<paddle::framework::OpDesc>,
                  ops::CosDoubleGradOpMaker<paddle::imperative::OpBase>,
                  ops::CosGradInplaceInferer,
                  ops::CosDoubleCompositeGradOpMaker,
                  ops::CosGradInferShapeFunctor);


REGISTER_OPERATOR(cos_double_grad, ops::CosDoubleGradOp,
                  ops::CosTripleGradOpMaker<paddle::framework::OpDesc>,
                  ops::CosTripleGradOpMaker<paddle::imperative::OpBase>,
                  ops::CosDoubleGradInplaceInferer,
                  ops::CosDoubleGradInferShapeFunctor);


REGISTER_OPERATOR(cos_triple_grad, ops::CosTripleGradOp,
                  ops::CosTripleGradInplaceInferer,
                  ops::CosTripleGradInferShapeFunctor);


REGISTER_OPERATOR(cosh_grad, ops::CoshGradOp,
                  ops::CoshGradInplaceInferer,
                  ops::CoshGradInferShapeFunctor);


REGISTER_OPERATOR(crop_tensor_grad, ops::CropTensorGradOp,
                  ops::CropTensorGradInferShapeFunctor);


REGISTER_OPERATOR(cross_grad, ops::CrossGradOp,
                  ops::CrossGradInferShapeFunctor);


REGISTER_OPERATOR(softmax_with_cross_entropy_grad, ops::SoftmaxWithCrossEntropyGradOp,
                  ops::SoftmaxWithCrossEntropyGradInplaceInferer,
                  ops::SoftmaxWithCrossEntropyGradInferShapeFunctor);


REGISTER_OPERATOR(cummax_grad, ops::CummaxGradOp,
                  ops::CummaxGradInferShapeFunctor);


REGISTER_OPERATOR(cummin_grad, ops::CumminGradOp,
                  ops::CumminGradInferShapeFunctor);


REGISTER_OPERATOR(cumprod_grad, ops::CumprodGradOp,
                  ops::CumprodGradInferShapeFunctor);


REGISTER_OPERATOR(cumsum_grad, ops::CumsumGradOp,
                  ops::CumsumGradInferShapeFunctor);


REGISTER_OPERATOR(depthwise_conv2d_grad, ops::DepthwiseConv2dGradOp,
                  ops::DepthwiseConv2dGradGradOpMaker<paddle::framework::OpDesc>,
                  ops::DepthwiseConv2dGradGradOpMaker<paddle::imperative::OpBase>,
                  ops::DepthwiseConv2dGradInferShapeFunctor);


REGISTER_OPERATOR(depthwise_conv2d_grad_grad, ops::DepthwiseConv2dGradGradOp,
                  ops::DepthwiseConv2dGradGradInferShapeFunctor);


REGISTER_OPERATOR(determinant_grad, ops::DeterminantGradOp,
                  ops::DeterminantGradInferShapeFunctor);


REGISTER_OPERATOR(diag_v2_grad, ops::DiagV2GradOp,
                  ops::DiagV2GradNoNeedBufferVarInferer,
                  ops::DiagV2GradInferShapeFunctor);


REGISTER_OPERATOR(diagonal_grad, ops::DiagonalGradOp,
                  ops::DiagonalGradNoNeedBufferVarInferer,
                  ops::DiagonalGradInferShapeFunctor);


